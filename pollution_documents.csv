Contenido,Cluster
"The oxidation state +1 can be produced by dissolving cadmium in a mixture of cadmium chloride and aluminium chloride, forming the Cd22+ cation, which is similar to the Hg22+ cation in mercury(I) chloride. Cd + CdCl2 + 2 AlCl3 → Cd2(AlCl4)2The structures of many cadmium complexes with nucleobases, amino acids, and vitamins have been determined.",1
"Naturally occurring cadmium is composed of eight isotopes. Two of them are radioactive, and three are expected to decay but have not done so under laboratory conditions. The two natural radioactive isotopes are 113Cd (beta decay, half-life is 7.7×1015 y) and 116Cd (two-neutrino double beta decay, half-life is 2.9×1019 y). The other three are 106Cd, 108Cd (both double electron capture), and 114Cd (double beta decay); only lower limits on these half-lives have been determined. At least three isotopes – 110Cd, 111Cd, and 112Cd – are stable.",1
"Among the isotopes that do not occur naturally, the most long-lived are 109Cd with a half-life of 462.6 days, and 115Cd with a half-life of 53.46 hours. All of the remaining radioactive isotopes have half-lives of less than 2.5 hours, and the majority have half-lives of less than 5 minutes. Cadmium has 8 known meta states, with the most stable being 113mCd (t1⁄2 = 14.1 years), 115mCd (t1⁄2 = 44.6 days), and 117mCd (t1⁄2 = 3.36 hours).The known isotopes of cadmium range in atomic mass from 94.950 u (95Cd) to 131.946 u (132Cd).",1
"For isotopes lighter than 112 u, the primary decay mode is electron capture and the dominant decay product is element 47 (silver). Heavier isotopes decay mostly through beta emission producing element 49 (indium).One isotope of cadmium, 113Cd, absorbs neutrons with high selectivity: With very high probability, neutrons with energy below the cadmium cut-off will be absorbed; those higher than the cut-off will be transmitted. The cadmium cut-off is about 0.5 eV, and neutrons below that level are deemed slow neutrons, distinct from intermediate and fast neutrons.Cadmium is created via the s-process in low- to medium-mass stars with masses of 0.6",1
"to 10 solar masses, over thousands of years. In that process, a silver atom captures a neutron and then undergoes beta decay. Cadmium (Latin cadmia, Greek καδμεία meaning ""calamine"", a cadmium-bearing mixture of minerals that was named after the Greek mythological character Κάδμος, Cadmus, the founder of Thebes) was discovered in contaminated zinc compounds sold in pharmacies in Germany in 1817 by Friedrich Stromeyer. Karl Samuel Leberecht Hermann simultaneously investigated the discoloration in zinc oxide and found an impurity, first suspected to be arsenic, because of the yellow precipitate with hydrogen sulfide.",1
"Additionally Stromeyer discovered that one supplier sold zinc carbonate instead of zinc oxide. Stromeyer found the new element as an impurity in zinc carbonate (calamine), and, for 100 years, Germany remained the only important producer of the metal. The metal was named after the Latin word for calamine, because it was found in this zinc ore. Stromeyer noted that some impure samples of calamine changed color when heated but pure calamine did not. He was persistent in studying these results and eventually isolated cadmium metal by roasting and reducing the sulfide.",1
"At the same time, these decreases in consumption were compensated by a growing demand for cadmium for nickel-cadmium batteries, which accounted for 81% of the cadmium consumption in the United States in 2006. Cadmium makes up about 0.1 ppm of Earth's crust. It is much rarer than zinc, which makes up about 65 ppm. No significant deposits of cadmium-containing ores are known. The only cadmium mineral of importance, greenockite (CdS), is nearly always associated with sphalerite (ZnS). This association is caused by geochemical similarity between zinc and cadmium, with no geological process likely to separate them.",1
"mined for phosphate fertilizers contain varying amounts of cadmium, resulting in a cadmium concentration of as much as 300 mg/kg in the fertilizers and a high cadmium content in agricultural soils. Coal can contain significant amounts of cadmium, which ends up mostly in coal fly ash.Cadmium in soil can be absorbed by crops such as rice and cocoa. Chinese ministry of agriculture measured in 2002 that 28% of rice it sampled had excess lead and 10% had excess cadmium above limits defined by law.",1
"Consumer Reports tested 28 brands of dark chocolate sold in the United States in 2022, and found cadmium in all of them, with 13 exceeding the California Maximum Allowable Dose level.Some plants such as willow trees and poplars have been found to clean both lead and cadmium from soil.Typical background concentrations of cadmium do not exceed 5 ng/m3 in the atmosphere; 2 mg/kg in soil; 1 μg/L in freshwater and 50 ng/L in seawater.",1
"Zinc metal is produced either by smelting the oxide with carbon or by electrolysis in sulfuric acid. Cadmium is isolated from the zinc metal by vacuum distillation if the zinc is smelted, or cadmium sulfate is precipitated from the electrolysis solution.The British Geological Survey reports that in 2001, China was the top producer of cadmium with almost one-sixth of the world's production, closely followed by South Korea and Japan. Cadmium is a common component of electric batteries, pigments, coatings, and electroplating.",1
Administration of cadmium to cells causes oxidative stress and increases the levels of antioxidants produced by cells to protect against macro molecular damage.However a cadmium-dependent carbonic anhydrase has been found in some marine diatoms. The diatoms live in environments with very low zinc concentrations and cadmium performs the function normally carried out by zinc in other anhydrases. This was discovered with X-ray absorption near edge structure (XANES) spectroscopy.Cadmium is preferentially absorbed in the kidneys of humans. Up to about 30 mg of cadmium is commonly inhaled throughout human childhood and adolescence.,1
"Cadmium is under research regarding its toxicity in humans, potentially elevating risks of cancer, cardiovascular disease, and osteoporosis. The biogeochemistry of cadmium and its release to the environment has been the subject of review, as has the speciation of cadmium in the environment. Individuals and organizations have been reviewing cadmium's bioinorganic aspects for its toxicity. The most dangerous form of occupational exposure to cadmium is inhalation of fine dust and fumes, or ingestion of highly soluble cadmium compounds. Inhalation of cadmium fumes can result initially in metal fume fever, but may progress to chemical pneumonitis, pulmonary edema, and death.Cadmium",1
"In the decades leading up to World War II, mining operations contaminated the Jinzū River in Japan with cadmium and traces of other toxic metals. As a consequence, cadmium accumulated in the rice crops along the riverbanks downstream of the mines. Some members of the local agricultural communities consumed the contaminated rice and developed itai-itai disease and renal abnormalities, including proteinuria and glucosuria. The victims of this poisoning were almost exclusively post-menopausal women with low iron and low body stores of other minerals.",1
"Similar general population cadmium exposures in other parts of the world have not resulted in the same health problems because the populations maintained sufficient iron and other mineral levels. Thus, although cadmium is a major factor in the itai-itai disease in Japan, most researchers have concluded that it was one of several factors.Cadmium is one of six substances banned by the European Union's Restriction of Hazardous Substances (RoHS) directive, which regulates hazardous substances in electrical and electronic equipment, but allows for certain exemptions and exclusions from the scope of the law.The",1
"exposure is associated with a large number of illnesses including kidney disease, early atherosclerosis, hypertension, and cardiovascular diseases. Although studies show a significant correlation between cadmium exposure and occurrence of disease in human populations, a molecular mechanism has not yet been identified. One hypothesis holds that cadmium is an endocrine disruptor and some experimental studies have shown that it can interact with different hormonal signaling pathways. For example, cadmium can bind to the estrogen receptor alpha, and affect signal transduction along the estrogen and MAPK signaling pathways at low doses.The",1
"tobacco plant absorbs and accumulates heavy metals such as cadmium from the surrounding soil into its leaves. Following tobacco smoke inhalation, these are readily absorbed into the body of users. Tobacco smoking is the most important single source of cadmium exposure in the general population. An estimated 10% of the cadmium content of a cigarette is inhaled through smoking. Absorption of cadmium through the lungs is more effective than through the gut. As much as 50% of the cadmium inhaled in cigarette smoke may be absorbed.",1
"On average, cadmium concentrations in the blood of smokers is 4 to 5 times greater than non-smokers and in the kidney, 2–3 times greater than in non-smokers. Despite the high cadmium content in cigarette smoke, there seems to be little exposure to cadmium from passive smoking.In a non-smoking population, food is the greatest source of exposure. High quantities of cadmium can be found in crustaceans, mollusks, offal, frog legs, cocoa solids, bitter and semi-bitter chocolate, seaweed, fungi and algae products. However, grains, vegetables, and starchy roots and tubers are consumed in much greater quantity in the U.S.,",1
"and are the source of the greatest dietary exposure there. Most plants bio-accumulate metal toxins such as cadmium and when composted to form organic fertilizers, yield a product that often can contain high amounts (e.g., over 0.5 mg) of metal toxins for every kilogram of fertilizer. Fertilizers made from animal dung (e.g., cow dung) or urban waste can contain similar amounts of cadmium. The cadmium added to the soil from fertilizers (rock phosphates or organic fertilizers) become bio-available and toxic only if the soil pH is low (i.e., acidic soils).",1
"Occupational Safety and Health Administration (OSHA) has set the permissible exposure limit (PEL) for cadmium at a time-weighted average (TWA) of 0.005 ppm. The National Institute for Occupational Safety and Health (NIOSH) has not set a recommended exposure limit (REL) and has designated cadmium as a known human carcinogen. The IDLH (immediately dangerous to life and health) level for cadmium is 9 mg/m3. In addition to mercury, the presence of cadmium in some batteries has led to the requirement of proper disposal (or recycling) of batteries.",1
"Caesium-137 has a half-life of about 30.05 years. About 94.6% decays by beta emission to a metastable nuclear isomer of barium: barium-137m (137mBa, Ba-137m). The remainder directly populates the ground state of 137Ba, which is stable. Barium-137m has a half-life of about 153 seconds, and is responsible for all of the gamma ray emissions in samples of 137Cs. Barium-137m decays to the ground state by emission of photons having energy 0.6617 MeV. A total of 85.1% of 137Cs decay generates gamma ray emission in this manner. One gram of 137Cs has an activity of 3.215 terabecquerel (TBq).",1
"However, while 137Cs is a waste product produced in great quantities in nuclear fission reactors, 192Ir and 60Co are specifically produced in commercial and research reactors and their life cycle entails the destruction of the involved high-value elements. Cobalt-60 decays to stable nickel, whereas iridium-192 can decay to either stable osmium or platinum. Due to the residual radioactivity and legal hurdles, the resulting material is not commonly recovered even from ""spent"" radioactive sources, meaning in essence that the entire mass is ""lost"" for non-radioactive uses.",1
": 114 However, unlike group 2 radionuclides like radium and strontium-90, caesium does not bioaccumulate and is excreted relatively quickly. The biological half-life of caesium is about 70 days.A 1961 experiment showed that mice dosed with 21.5 μCi/g had a 50% fatality within 30 days (implying an LD50 of 245 μg/kg). A similar experiment in 1972 showed that when dogs are subjected to a whole body burden of 3800 μCi/kg (140 MBq/kg, or approximately 44 μg/kg) of caesium-137 (and 950 to 1400 rads), they die within 33 days, while animals with half of that burden all survived for a year.",1
"Important researches have shown a remarkable concentration of 137Cs in the exocrine cells of the pancreas, which are those most affected by cancer. In 2003, in autopsies performed on 6 children who died (of reasons not directly linked to Chernobyl, mostly sepsis) in the polluted area near Chernobyl where they also reported a higher incidence of pancreatic tumors, Bandazhevsky found a concentration of 137Cs 3.9 times higher than in their liver (1359 vs 347 Bq/kg, equivalent to 36 and 9.3",1
"nCi/kg in these organs, 600 Bq/kg = 16 nCi/kg in the body according to measurements), thus demonstrating that pancreatic tissue is a strong accumulator and secretor in the intestine of radioactive cesium. Accidental ingestion of caesium-137 can be treated with Prussian blue (FeIII4[FeII(CN)6]3), which binds to it chemically and reduces the biological half-life to 30 days. Caesium-137, along with other radioactive isotopes caesium-134, iodine-131, xenon-133, and strontium-90, were released into the environment during nearly all nuclear weapon tests and some nuclear accidents, most notably the Chernobyl disaster and the Fukushima Daiichi disaster. Caesium-137 in the environment is substantially anthropogenic (human-made).",1
Surface soils and sediments are also dated by measuring the activity of 137Cs.,1
"As of today and for the next few hundred years or so, caesium-137 and strontium-90 continue to be the principal source of radiation in the zone of alienation around the Chernobyl nuclear power plant, and pose the greatest risk to health, owing to their approximately 30 year half-life and biological uptake. The mean contamination of caesium-137 in Germany following the Chernobyl disaster was 2000 to 4000 Bq/m2. This corresponds to a contamination of 1 mg/km2 of caesium-137, totaling about 500 grams deposited over all of Germany.",1
"In Scandinavia, some reindeer and sheep exceeded the Norwegian legal limit (3000 Bq/kg) 26 years after Chernobyl. As of 2016, the Chernobyl caesium-137 has decayed by half, but could have been locally concentrated by much larger factors.",1
"In April 2011, elevated levels of caesium-137 were also being found in the environment after the Fukushima Daiichi nuclear disasters in Japan. In July 2011, meat from 11 cows shipped to Tokyo from Fukushima Prefecture was found to have 1,530 to 3,200 becquerels per kilogram of 137Cs, considerably exceeding the Japanese legal limit of 500 becquerels per kilogram at that time. In March 2013, a fish caught near the plant had a record 740,000 becquerels per kilogram of radioactive caesium, above the 100 becquerels per kilogram government limit.",1
"A 2013 paper in Scientific Reports found that for a forest site 50 km from the stricken plant, 137Cs concentrations were high in leaf litter, fungi and detritivores, but low in herbivores. By the end of 2014, ""Fukushima-derived radiocaesium had spread into the whole western North Pacific Ocean"", transported by the North Pacific current from Japan to the Gulf of Alaska. It has been measured in the surface layer down to 200 meters and south of the current area down to 400 meters.Caesium-137 is reported to be the major health concern in Fukushima.",1
A number of techniques are being considered that will be able to strip out 80% to 95% of the caesium from contaminated soil and other materials efficiently and without destroying the organic material in the soil. These include hydrothermal blasting. The caesium precipitated with ferric ferrocyanide (Prussian blue) would be the only waste requiring special burial sites. The aim is to get annual exposure from the contaminated environment down to 1 mSv above background.,1
"The most contaminated area where radiation doses are greater than 50 mSv/year must remain off limits, but some areas that are currently less than 5 mSv/year may be decontaminated, allowing 22,000 residents to return. Caesium-137 gamma sources have been involved in several radiological accidents and incidents.",1
"In the Goiânia accident of 1987, an improperly disposed of radiation therapy system from an abandoned clinic in Goiânia, Brazil, was removed then cracked to be sold in junkyards, and the glowing caesium salt sold to curious, unadvised buyers. This led to four confirmed deaths and several serious injuries from radiation contamination.",1
"In 1997, several Georgian soldiers suffered radiation poisoning and burns. They were eventually traced back to training sources abandoned, forgotten, and unlabeled after the dissolution of the Soviet Union. One was a caesium-137 pellet in a pocket of a shared jacket that put out about 130,000 times the level of background radiation at 1 meter distance.",1
"In the Acerinox accident of 1998, the Spanish recycling company Acerinox accidentally melted down a mass of radioactive caesium-137 that came from a gamma-ray generator.",1
"In 2009, a Chinese cement company (in Tongchuan, Shaanxi Province) was demolishing an old, unused cement plant and did not follow standards for handling radioactive materials. This caused some caesium-137 from a measuring instrument to be included with eight truckloads of scrap metal on its way to a steel mill, where the radioactive caesium was melted down into the steel.",1
"Thirteen people were exposed to caesium-137 in May 2019 at the Research and Training building in the Harborview Medical Center complex. A contract crew was transferring the caesium from the lab to a truck when the powder was spilled. Five people were decontaminated and released, but 8 who were more directly exposed were taken to the hospital while the research building was evacuated.",1
"Public health authorities in Western Australia issued an emergency alert for a stretch of road measuring about 1,400 km after a capsule containing caesium-137 was lost in transport on 25 January 2023. The 8 mm capsule contained a small quantity of the radioactive material when it disappeared from a truck. The State Government immediately launched a search, with the WA Department of Health's chief health officer Andrew Robertson warning an exposed person could expect to receive the equivalent of ""about 10 X-rays an hour"". Experts warned, if the capsule were found, the public should stay at least 5 metres away.",1
The capsule was found on 1 February 2023.,1
"For example, the safe amount of lead in a product is 100 ppm; however, there have been findings where the amount of lead in a bead surpassed the limit 300 times over. This threatens parade-goers with exposure to high amounts of lead, especially younger children that could potentially put the beads in their mouths. Plastic beads became popular in the 1960s, and were not always a part of Mardi Gras; they were introduced only in the late 1970s. The ritual of throwing Mardi Gras beads dates back to the nineteenth century, particularly the 1970s, in New Orleans.",1
"One study examined identical twins who worked together as painters using lead-based paint. Using magnetic resonance spectroscopy, it was discovered that they both had lead levels in their bones about 5-10 times more than the average adult. One twin put himself at a higher risk of lead exposure because he was the only one that removed paint on the job. His lead concentration was 2.5 times higher than his twin’s; and after further testing, his memory was shown to be much worse than his twin’s.Cadmium has been shown to be carcinogenic due to interactions with DNA topoisomerase IIα.",1
"To support and enforce the restriction on toxic beads and ensure implementation of the non-toxic alternatives, the City of New Orleans could also begin imposing a substantial tax or fee on vendors, entertainers, attendees, and other individuals and businesses associated with Mardi Gras to alleviate the hefty financial cost of clean-up that the city itself must bear every year.",1
"Lorentz or Laplace forces act on conductors plunged in an external magnetic field. Equivalent electromagnetic forces due to the presence of an electrical field can involve electrostatic, electrostrictive and reverse piezoelectric effects. These phenomena can potentially generate vibrations of the ferromagnetic, conductive parts, coils and permanent magnets of electrical, magnetic and electromechanical device, resulting in an audible sound if the frequency of vibrations lies between 20 Hz and 20 kHz, and if the sound level is high enough to be heard (e.g. large surface of radiation and large vibration levels).",1
"Vibration level is increased in case of a mechanical resonance, when electromagnetic forces match with a structural mode natural frequency of the active component (magnetic circuit, electromagnetic coil or electrical circuit) or of its enclosure. The frequency of the noise depends on the nature of electromagnetic forces (quadratic or linear function of electrical field or magnetic field) and on the frequency content of the electromagnetic field (in particular if a DC component is present or not).",1
"Electromagnetic torque, which can be calculated as the average value of the Maxwell stress tensor along the airgap, is one consequence of electromagnetic forces in electric machines. As a static force, it does not create vibrations nor acoustic noise. However torque ripple (also called cogging torque for permanent magnet synchronous machines in open circuit), which represents the harmonic variations of electromagnetic torque, is a dynamic force creating torsional vibrations of both rotor and stator. The torsional deflection of a simple cylinder cannot radiate efficiently acoustic noise, but with particular boundary conditions the stator can radiate acoustic noise under torque ripple excitation.",1
"Structure-borne noise can also be generated by torque ripple when rotor shaft line vibrations propagate to the frame and shaft line. Some tangential magnetic force harmonics can directly create magnetic vibrations and acoustic noise when applied to the stator teeth: tangential forces create a bending moment of the stator teeth, resulting in radial vibrations of the yoke.Besides tangential force harmonics, Maxwell stress also includes radial force harmonics responsible for radial vibrations of the yoke, which in turn can radiate acoustic noise.",1
"In inductors, also called reactors or chokes, magnetic energy is stored in the airgap of the magnetic circuit, where large Maxwell forces apply. Resulting noise and vibrations depend on airgap material and magnetic circuit geometry.",1
"In transformers magnetic noise and vibrations are generated by several phenomena depending on the load case which include Lorentz force on the windings, Maxwell forces in the joints of the laminations, and magnetostriction inside the laminated core.",1
"Capacitors are also subject to large electrostatic forces. When the capacitor voltage/current waveform is not constant and contains time harmonics, some harmonic electric forces appear and acoustic noise can be generated. Ferroelectric capacitors also exhibit a piezoelectric effect that can be source of audible noise. This phenomenon is known as the ""singing capacitor"" effect.",1
"In radial flux rotating electric machines, resonance due to electromagnetic forces is particular as it occurs at two conditions: there must be a match between the exciting Maxwell force and the stator or rotor natural frequency, and between the stator or rotor modal shape and the exciting Maxwell harmonic wavenumber (periodicity of the force along the airgap). As an example a resonance with the elliptical modal shape of the stator can occur if the force wavenumber is 2. Under resonance conditions, the maxima of the electromagnetic excitation along the airgap and the maxima of the modal shape displacement are in phase.",1
The simulation of electromagnetically induced noise and vibrations is a multiphysic modeling process carried in three steps: calculation of the electromagnetic forces calculation of the resulting magnetic vibrations calculation of the resulting magnetic noiseIt is generally considered as a weakly coupled problem: the deformation of the structure under electromagnetic forces is assumed not to change significantly the electromagnetic field distribution and the resulting electromagnetic stress.,1
"The assessment of audible magnetic noise in electrical machines can be done using three methods: using dedicated electromagnetic and vibro-acoustic simulation software (e.g. MANATEE ) using electromagnetic (e.g. Flux, Jmag, Maxwell, Opera), structural (e.g. Ansys Mechanical, Nastran, Optistruct) and acoustic (e.g. Actran, LMS, Sysnoise) numerical software together with dedicated coupling methods using multiphysics numerical simulation software environment (e.g. Comsol Multiphysics, Ansys Workbench)",1
"The harmonic electromagnetic forces responsible for magnetic noise and vibrations in a healthy machine can come from Pulse-width modulation supply of the machine slotting effects magnetic saturationIn a faulty machine, additional noise and vibrations due to electromagnetic forces can come from mechanical static and dynamic eccentricities uneven air-gap demagnetization short circuits missing magnetic wedgesUnbalanced Magnetic Pull (UMP) describes the electromagnetic equivalence of mechanical rotating unbalance: if electromagnetic forces are not balanced, a non-zero net magnetic force appears on stator and rotor. This force can excite the bending mode of the rotor and create additional vibration and noise.",1
"NVH mitigation techniques in electrical machines include reducing the magnitude of electromagnetic excitations, independently of the structural response of the electrical machine reducing the magnitude of the structural response, independently of the electromagnetic excitations reducing the resonances occurring between electromagnetic excitations and structural modesElectromagnetic noise and vibration mitigation techniques in electrical machines include: choosing the right slot/pole combination and winding design avoiding resonances match between stator and electromagnetic excitations skewing the stator or the rotor implementing pole shaping / pole shifting / pole pairing techniques implementing harmonic current injection or spread spectrum PWM strategies using notches / flux barriers on the",1
stator or the rotor increasing damping increasing the frequency outside the audible frequency range,1
"Coil noise mitigation actions include: add some glue (e.g. a layer of glue is often added on the top of television coils ; over the years, this glue degrades and the sound level increases) change the shape of the coil (e.g. change coil shape to a figure eight rather than a traditional coil shape) isolate the coil from the rest of the device to minimize structure-borne noise increase damping A varying electromagnetic force can be produced either by a moving source of DC magnetic field (e.g.",1
"rotating permanent magnet or rotating coil supplied with DC current), or by a steady source of AC magnetic field (e.g. a coil fed by a variable current).",1
This animation illustrates how a ferromagnetic sheet can be deformed due to the magnetic field of a rotating magnet. It corresponds to an ideal one pole pair permanent magnet synchronous machine with a slotless stator.,1
"The resonance effect of magnetic vibration with a structural mode can be illustrated using a tuning fork made of iron. A prong of the tuning fork is wound with a coil fed by a variable frequency power supply. A variable flux density circulates between the two prongs and some dynamic magnetic forces appear between the two prongs at twice the supply frequency. When the exciting force frequency matches the fundamental mode of the tuning fork close to 400 Hz, a strong acoustic resonance occurs.",1
Video of a resonating tuning fork magnetically excited by a variable frequency current on YouTube Video of a tuning fork magnetically excited by a fixed frequency current on YouTube Video of a ferromagnetic cylinder deformed by a rotating magnet on YouTube,1
"Compared with other emissions, sulfate and soot particles have a smaller direct effect: sulfate particles have a cooling effect and reflect radiation, while soot has a warming effect and absorbs heat, while the clouds' properties and formation are influenced by particles. Contrails and cirrus clouds evolving from particles may have a greater radiative forcing effect than CO2 emissions. As soot particles are large enough to serve as condensation nuclei, they are thought to cause the most contrail formation. Soot production may be decreased by reducing the aromatic compound of jet fuel.In",1
"1999, the IPCC estimated aviation's radiative forcing in 1992 to be 2.7 (2 to 4) times that of CO2 alone − excluding the potential effect of cirrus cloud enhancement. This was updated for 2000, with aviation's radiative forcing estimated at 47.8 mW/m2, 1.9 times the effect of CO2 emissions alone, 25.3 mW/m2.In 2005, research by David S. Lee, et al.,",1
"published in the scientific journal Atmospheric Environment estimated the cumulative radiative forcing effect of aviation at 55 mW/m2, which is twice the 28 mW/m2 radiative forcing effect of its CO2 emissions alone, excluding induced cirrus cloud, with a very low level of scientific understanding. In 2012, research from Chalmers university estimated this weighting factor at 1.3–1.4 if aviation induced cirrus is not included, 1.7–1.8 if they are included (within a range of 1.3–2.9).Uncertainties remain on the NOx–O3–CH4 interactions, aviation-produced contrails formation, the effects of soot aerosols on cirrus clouds and measuring non-CO2 radiative forcing.In 2018, CO2 represented 34.3",1
"mW/m2 of aviation's effective radiative forcing (ERF, on the surface), with a high confidence level (± 6 mW/m2), NOx 17.5 mW/m2 with a low confidence level (± 14) and contrail cirrus 57.4 mW/m2, also with a low confidence level (± 40). All factors combined represented 43.5 mW/m2 (1.27 that of CO2 alone) excluding contrail cirrus and 101 mW/m2 (±45) including them, 3.5% of the anthropogenic ERF of 2290 mW/m2 (± 1100).",1
"Between 1960 and 2018, RPKs increased from 109 to 8,269 billion.In 1992, aircraft emissions represented 2% of all man-made CO2 emissions, having accumulated a little more than 1% of the total man-made CO2 increase over 50 years. By 2015, aviation accounted for 2.5% of global CO2 emissions. In 2018, global commercial operations emitted 918 million tonnes (Mt) of CO2, 2.4% of all CO2 emissions: 747 Mt for passenger transport and 171 Mt for freight operations. Between 1960 and 2018, CO2 emissions increased 6.8 times from 152 to 1,034 million tonnes per year.",1
"Emissions from flights rose by 32% between 2013 and 2018. Between 1990 and 2006, greenhouse gas emissions from aviation increased by 87% in the European Union. In 2010, about 60% of aviation emissions came from international flights, which are outside the emission reduction targets of the Kyoto Protocol. International flights are not covered by the Paris Agreement, either, to avoid a patchwork of individual country regulations. That agreement was adopted by the International Civil Aviation Organization, however, capping airlines carbon emissions to the year 2020 level, while allowing airlines to buy carbon credits from other industries and projects.In",1
"1992, aircraft radiative forcing was estimated by the IPCC at 3.5% of the total man-made radiative forcing.",1
"ICAO targets a 2% efficiency improvement per year between 2013 and 2050, while the IATA targets 1.5% for 2009–2020 and to cut net CO2 emissions in half by 2050 relative to 2005.",1
"In 1999, the IPCC estimated aviation's radiative forcing may represent 190 mW/m2 or 5% of the total man-made radiative forcing in 2050, with the uncertainty ranging from 100 to 500 mW/m2. If other industries achieve significant reductions in greenhouse gas emissions over time, aviation's share, as a proportion of the remaining emissions, could rise. Alice Bows-Larkin estimated that the annual global CO2 emissions budget would be entirely consumed by aviation emissions to keep the climate change temperature increase below 2 °C by mid-century.",1
"Sleep disruption can be reduced by banning or restricting flying at night, but disturbance progressively decreases and legislation differs across countries.The ICAO Chapter 14 noise standard applies for aeroplanes submitted for certification after 31 December 2017, and after 31 December 2020 for aircraft below 55 t (121,000 lb), 7 EPNdB (cumulative) quieter than Chapter4. The FAA Stage 5 noise standards are equivalent. Higher bypass ratio engines produce less noise. The PW1000G is presented as 75% quieter than previous engines. Serrated edges or 'chevrons' on the back of the nacelle reduce noise.A",1
"Low oxygen concentrations reduce usable aquatic habitat because organisms die if they cannot move to areas with sufficient oxygen levels. Bottom feeder populations can be reduced or eliminated by low DO levels, changing a community's species profile or altering critical food-web interactions.: 2–30 Glycol-based deicing fluids are toxic to humans and other mammals. Research into non-toxic alternative deicing fluids is ongoing. Aviation is the main human source of ozone, a respiratory health hazard, causing an estimated 6,800 premature deaths per year.Aircraft engines emit ultrafine particles (UFPs) in and near airports, as does ground support equipment.",1
"The initiative is led by ACI Europe, ASD Europe, A4E, CANSO and ERA. This would apply to flights within and departing the European single market and the UK.In October 2021, the IATA committed to net-zero carbon emissions by 2050. In 2022, the ICAO agreed to support a net-zero carbon emission target for 2050.The aviation sector could be decarbonized by 2050 with moderate demand growth, continuous efficiency improvements, new short-haul engines, higher SAF production and CO2 removal to compensate for non-CO2 forcing.",1
"Projected cost decreases of green hydrogen and carbon capture could make synthetic fuels more affordable, and lower feedstock costs and higher conversion efficiencies would help FT and HEFA biofuels. Policy incentives like cleaner aviation fuel tax credits and low-carbon fuel standards could induce improvements, and carbon pricing could render SAFs more competitive, accelerating their deployment and reducing their costs through learning and economies of scale.According to a 2023 Royal Society study, reaching net zero would need replacing fossil aviation fuel with a low or zero carbon energy source, as battery technologies are unlikely to give enough specific energy.Biofuels",1
"its Sixth Assessment Report, the IPCC notes that sustainable biofuels, low-emissions hydrogen, and derivatives (including ammonia and synthetic fuels) can support mitigation of CO2 emissions but some hard-to-abate residual GHG emissions remain and would need to be counterbalanced by deployment of carbon dioxide removal methods. On 29 March 2003, during a Senate hearing, hydrogen propulsion proponents like ZeroAvia or Universal Hydrogen bemoaned the incumbents like GE Aerospace or Boeing were supporting sustainable aviation fuel (SAF) because it does not require major changes to existing infrastructure.An",1
April 2023 report of the Sustainable Aero Lab estimate current in-production aircraft will be the vast majority of the 2050 fleet as electric aircraft will not have enough range and hydrogen aircraft will not be available soon enough : the main decarbonisation drivers will be SAF ; replacing regional jets with turboprop aircraft ; and incentives to replace older jets with new generation ones.,1
"Electric aircraft operations do not produce any emissions and electricity can be generated by renewable energy. Lithium-ion batteries including packaging and accessories gives a 160 Wh/kg energy density while aviation fuel gives 12,500 Wh/kg. As electric machines and converters are more efficient, their shaft power available is closer to 145 Wh/kg of battery while a gas turbine gives 6,545 Wh/kg of fuel: a 45:1 ratio. For Collins Aerospace, this 1:50 ratio forbids electric propulsion for long-range aircraft. By November 2019, the German Aerospace Center estimated large electric planes could be available by 2040.",1
"Large, long-haul aircraft are unlikely to become electric before 2070 or within the 21st century, whilst smaller aircraft can be electrified. As of May 2020, the largest electric airplane was a modified Cessna 208B Caravan. For the UK's Committee on Climate Change (CCC), huge technology shifts are uncertain, but consultancy Roland Berger points to 80 new electric aircraft programmes in 2016–2018, all-electric for the smaller two-thirds and hybrid for larger aircraft, with forecast commercial service dates in the early 2030s on short-haul routes like London to Paris, with all-electric aircraft not expected before 2045.",1
"Berger predicts a 24% CO2 share for aviation by 2050 if fuel efficiency improves by 1% per year and if there are no electric or hybrid aircraft, dropping to 3–6% if 10-year-old aircraft are replaced by electric or hybrid aircraft due to regulatory constraints, starting in 2030, to reach 70% of the 2050 fleet. This would greatly reduce the value of the existing fleet of aircraft, however. Limits to the supply of battery cells could hamper their aviation adoption, as they compete with other industries like electric vehicles. Lithium-ion batteries have proven fragile and fire-prone and their capacity deteriorates with age.",1
"However, alternatives are being pursued, such as sodium-ion batteries.",1
"A short-range aircraft (< 2,000 km, 1,100 nmi) with hybrid Fuel cell/Turbines could reduce climate impact by 70-80% for a 20-30% additional cost, a medium-range airliner with H2 turbines could have a 50-60% reduced climate impact for a 30-40% overcost, and a long-range aircraft (> 7,000 km, 3,800 nmi) also with H2 turbines could reduce climate impact by 40-50% for a 40-50% additional cost. Research and development would be required, in aircraft technology and into hydrogen infrastructure, regulations and certification standards.",1
"The Potsdam Institute for Climate Impact Research reported a €800–1,200 mitigation cost per ton of CO2 for hydrogen-based e-fuels. Those could be reduced to €20–270 per ton of CO2 in 2050, but maybe not early enough to replace fossil fuels.Climate policies could bear the risk of e-fuel uncertain availability, and Hydrogen and e-fuels may be prioritised when direct electrification is inaccessible.",1
"The ICCT estimates that 3% of the global population take regular flights. Stefan Gössling of the Western Norway Research Institute estimates 1% of the world population emits half of commercial aviation's CO2, while close to 90% does not fly in a given year.",1
"A carbon offset is a means of compensating aviation emissions by saving enough carbon or absorbing carbon back into plants through photosynthesis (for example, by planting trees through reforestation or afforestation) to balance the carbon emitted by a particular action. However, carbon credits permanence and additionality can be questionable. More than 90% of rainforest offset credits certified by Verra's Verified Carbon Standard may not represent genuine carbon reductions.",1
"In UK, transportation replaced power generation as the largest emissions source. This includes aviation's 4% contribution. This is expected to expand until 2050 and passenger demand may need to be reduced. For the UK Committee on Climate Change (CCC), the UK target of an 80% reduction from 1990 to 2050 was still achievable from 2019, but the committee suggests that the Paris Agreement should tighten its emission targets. Their position is that emissions in problematic sectors, like aviation, should be offset by greenhouse gas removal, carbon capture and storage and reforestation.",1
The UK will include international aviation and shipping in their carbon budgets and hopes other countries will too.,1
"in November 2019, UK budget carrier EasyJet decided to offset carbon emissions for all its flights, through investments in atmospheric carbon reduction projects. It claims to be the first major operator to be carbon neutral, at a cost of £25 million for its 2019–20 financial year. Its CO2 emissions were 77 g per passenger in its 2018–19 financial year, down from 78.4 g the previous year.From January 2020, British Airways began offsetting its 75 daily domestic flights emissions through carbon-reduction project investments. The airline seeks to become carbon neutral by 2050 with fuel-efficient aircraft, sustainable fuels and operational changes.",1
"become carbon neutral by 2050, United Airlines invests to build in the US the largest carbon capture and storage facility through the company 1PointFive, jointly owned by Occidental Petroleum and Rusheen Capital Management, with Carbon Engineering technology, aiming for nearly 10% offsets.",1
million tonnes of excess CO2 emissions.,1
"Non-CO2 emissions Besides carbon dioxide, aviation produces nitrogen oxides (NOx), particulates, unburned hydrocarbons (UHC) and contrails. Flight routes can be optimized: modelling CO2, H2O and NOx effects of transatlantic flights in winter shows westbound flights climate forcing can be lowered by up to 60% and ~25% for jet stream-following eastbound flights, costing 10–15% more due to longer distances and lower altitudes consuming more fuel, but 0.5% costs increase can reduce climate forcing by up to 25%.",1
"A 2000 feet (~600 m) lower cruise altitude than the optimal altitude has a 21% lower radiative forcing, while a 2000 feet higher cruise altitude 9% higher radiative forcing.Nitrogen oxides (NOx) As designers work to reduce NOx emissions from jet engines, they fell by over 40% between 1997 and 2003. Cruising at a 2,000 ft (610 m) lower altitude could reduce NOx-caused radiative forcing from 5 mW/m2 to ~3 mW/m2.Particulates Modern engines are designed so that no smoke is produced at any point in the flight while particulates and smoke were a problem with early jet engines at high power settings.Unburned",1
"hydrocarbons (UHC) Produced by incomplete combustion, more unburned hydrocarbons are produced with low compressor pressures and/or relatively low combustor temperatures, they have been eliminated in modern jet engines through improved design and technology, like particulates.Contrails Contrail formation would be reduced by lowering the cruise altitude with slightly increased flight times, but this would be limited by airspace capacity, especially in Europe and North America, and increased fuel burn due to lower efficiency at lower altitudes, increasing CO2 emissions by 4%.",1
"""Tracking report: Aviation"". International Energy Agency. June 2020. Hannah Ritchie (22 October 2020). ""Climate change and flying: what share of global CO2 emissions come from aviation?"". Our World in Data. ""The aviation industry wants to be net zero—but not soon"". The Economist. 14 May 2023.",1
He was later charged with six felony counts of aggravated assault with a deadly weapon.,1
"California law prohibits operating a vehicle ""in a manner resulting in the escape of excessive smoke, flame, gas, oil, or fuel residue"". The California Highway Patrol or local police can cite a vehicle under this section or others for rolling coal.",1
"""The engine and power mechanism of a motor vehicle must be equipped and adjusted so as to prevent escape of excessive fumes or smoke"".",1
Vehicles must be equipped and adjusted to prevent the escape of excessive fumes or smoke.,1
"A person may not knowingly or intentionally cause a diesel-powered motor vehicle to discharge clearly visible smoke, soot, or other exhaust emissions onto another person or motor vehicle. Normal operations, commercial vehicles of 10,000 pounds or more, and construction site vehicles are exempt.",1
"The ordinance, which was passed in September 2017, exempts several categories of vehicles, and provides for a fine up to $499.",1
The engine and power mechanism of every motor vehicle shall be so equipped and adjusted as to prevent the escape of excessive fumes or smoke.,1
"These counties have ""smoking vehicle"" report forms online.",1
"The ordinance, which was passed in July 2017, exempts several categories of vehicles and provides for a fine of up to $750 and up to six months in jail. A first attempt in July 2016 failed, but Cheyenne police had clarified at that time that they had been writing tickets for coal rolling under state law.",1
"""A person who contravenes this section commits an offence and is liable on conviction to a fine of not less than $50 and not more than $5,000.""",1
"Section 75.1 of the Ontario Highway Traffic Act prohibits modifications to a vehicle's emissions systems to increase emissions output exceeding that of the manufacturer's specifications, and modifications which tamper a vehicle’s emission control system to bypass, disable or otherwise negate it. Furthermore, Ontario Regulation 169/22 restricts the opacity of vehicle emissions and modifications to a vehicle's emissions system. Violations can result in a fine ranging from $300 to $1000 CAD for non-commercial vehicles, and $400 to $20 000 for commercial vehicles.",1
"Truck nuts Wet stacking, a term for when diesel engines exhaust unburned fuel, whether unintentionally or as part of rolling coal ""Diesel Technology Forum Statement on ""Rolling Coal"""". Diesel Technology Forum. July 17, 2014. Statement from the diesel industry criticising the practice. Archived from the original on August 8, 2014. Retrieved August 5, 2014. Bell, Lucas (7 Dec 2022). ""The EPA Is Hunting Performance Shops and Diesel Tuners Are to Blame"". Hearst Digital Media. Road and Track. Retrieved 12 December 2022.",1
"Election litter usually is defined as placing campaign signs on public, government-owned property, or on privately owned property (including residences) without the owner's permission. It is usually banned by local government. According to the ""State Board of Elections littering notification"" statute of the U.S. state of North Carolina: [...] the State Board of Elections shall notify the candidate of the provisions concerning campaign signs in G.S. 136‑32 and G.S. 14‑156, and the rules adopted by the Department of Transportation pursuant to G.S. 136‑18. (2001‑512, s. 7.) Similarly, Chapter 23.04",1
"While almost all laws about election litter restrict its placement on tax-funded public property and private property without permission, there are also special time limits imposed. For example, election signs in San Jose, California, are allowed no more than 10 days after election; San Bruno, California, 14 days; Tucson, Arizona, 15 days; County Kerry (Ireland), 7 days after election.In addition, regulation can be placed on the size of election signs. For example, Saint Paul, Minnesota, places an area limit of 16 square feet (1.5 m2). Tucson disallows the height of election signs to exceed 10 feet (3.0",1
"In 1984, the United States Supreme Court held that although political signs are protected under the First Amendment the state may enact and enforce content-neutral laws to limit their ""visual assault on the citizens"". The problem addressed by this ordinance -- the visual assault on the citizens of Los Angeles presented by an accumulation of signs posted on public property -- constitutes a significant substantive evil within the City's power to prohibit. ""[The] city's interest in attempting to preserve [or improve] the quality of urban life is one that must be accorded high respect.",1
"Later that decade the Fourth circuit court of appeal held in Major Media of the Southeast v. City of Raleigh 1987 that "". . . no empirical studies are necessary for reasonable people to conclude that billboards pose a traffic hazard, since by their very nature they are designed to distract drivers and their passengers from maintaining their view of the road."" Similarly the California Supreme Court held in Metromedia v. San Diego that "". . . as a matter of law that an ordinance which eliminates billboards designed to be viewed from streets and highways reasonably relates to traffic safety.""",1
"Some places allow election signs to be posted on public property, subject to certain restrictions. For example, in the United States, California's Department of Transportation allows ""temporary political signs"" in the lead up to an election, subject to certain requirements such as picking up the signs within a certain timeframe, size, and filing a statement of responsibility. Flyposting Littering A brochure by Litterbug.org advocating against election litter",1
"The term ""engine braking"" refers to the braking effect that occurs in gasoline engines when the accelerator pedal is released. This causes fuel injection to cease and the throttle valve to close almost completely, greatly restricting forced airflow from, for example, a turbocharger. The restriction causes a strong manifold vacuum which the cylinders have to work against, sapping much of the potential energy out of the system over time and producing the majority of the engine-braking effect. This vacuum manifold effect can often be amplified by a down-shift, which induces a faster spinning drivetrain to engage with the engine.",1
"Engine braking is a viable method of controlling the speed at which a vehicle travels downhill. By shifting to a lower gear in a manual transmission, or selecting the ""low gear"" mode on an automatic transmission, engine braking reduces the need to repeatedly apply the foot brake, lowering the risk of the brakes overheating.While some of the braking force is produced due to friction in the drive train, this is negligible compared to the effect from the manifold vacuum caused by the air-flow restriction.On",1
"an automatic transmission, engine braking often spontaneously increases the engine RPM, causing a sudden revving to occur even without applying the accelerator pedal.",1
Diesel engines in personal cars provide little engine braking as they are not equipped with a throttle body and thus cannot draw a vacuum in the intake manifold. In heavy vehicles the engine is often made to provide extra braking power to take some strain off the vehicle's regular brake system and to help avoid overheating the brakes. In its simplest form this consists of a butterfly valve that stops the exhaust flow. This is referred to as an exhaust brake and mostly found on older trucks.,1
"It has a limited effect, and more advanced systems as described below are near universal on newer heavy vehicles.",1
"An exhaust brake works by causing a restriction in the exhaust, much like the intake throttle causes in a gasoline engine. In simple terms, it works by increasing the back-pressure of the exhaust. Nearly all of these brakes are butterfly valves similar to a throttle valve, mounted downstream of the turbocharger if there is one.",1
"Engine braking in a premix two-stroke engine can be extremely harmful to the engine, because cylinder and piston lubricant is delivered to each cylinder mixed with fuel. Consequently, during engine braking, the engine starves not only of fuel but also lubricant, causing accelerated wear. Many old two-stroke cars (Saab Automobile, Wartburg 353, etc.) had a freewheel device on the transmission to make engine braking optional. Most two-stroke motorcycle engines since the 1970s have had lubrication by an oil pump, independent of the throttle and fuel system, such as Suzuki's Posi-Force system.",1
"The desired speed is maintained by using engine braking to counteract gravitational acceleration. Potential transmission wear caused by engine braking can be mitigated by certain techniques. Slipping the clutch to complete a downshift wears the clutch plate as it slows the vehicle, doing the job of the brake pads or shoes. A well-executed rev-match in the same setting minimizes stresses on transmission components, so engine braking does the work of slowing the vehicle. Improper engine braking technique can cause the wheels to skid (also called shift-locking), especially on slippery surfaces, as a result of too much deceleration.",1
"As in a skid caused by overbraking, the vehicle will not regain traction until the wheels are allowed to turn more quickly. If the driver reduces engine braking by shifting back up, or disengaging the clutch on a manual transmission, traction can be regained. In hybrid electric vehicles, like the Toyota Prius, engine braking is simulated by the computer software to match the feel of a traditional automatic transmission. For long downhill runs, the ""B"" mode acts like a lower gear, using the higher RPM of the internal combustion engine to waste energy, preventing the battery from being overcharged.",1
"Although no longer in production in most countries, there are still plenty of carbureted engines in service, with which engine braking is counter-productive to fuel economy due to the lack of a DFCO mechanism. The cost of wasted fuel can well outweigh the gain of reduced brake wear. Dynamic braking, similar effect with electric engines Retarder Certain types of braking in steam locomotives that are conceptually comparable (using compression in the steam engine cylinders for braking) Countersteam brake Counter-pressure brake",1
"Treatment of the various streams depends on local regulations and the amount of contaminant. Some low volatility organic contaminants have a short hydrolysis half-life For contaminants like these, i.e. 1,1,2,2-Tetrachloroethane and 1,1,1-trichloroethane, hydrolysis can be the primary form of remediation. As the subsurface is heated the hydrolysis half-life of the contaminant will decrease as described by the Arrhenius equation. This results in a rapid degradation of the contaminant. The hydrolysis by-product may be remediated by conventional ERH, however the majority of the mass of the primary contaminant will not be recovered but rather will degrade to a by-product.",1
There are predominantly two electrical load arrangements for ERH: three-phase and six-phase. Three-phase heating consists of electrodes in a repeating triangular or delta pattern. Adjacent electrodes are of a different electrical phase so electricity conducts between them as shown in Figure 1. The contaminated area is depicted by the green shape while the electrodes are depicted by the numbered circles. Six-phase heating consists of six electrodes in a hexagonal pattern with a neutral electrode in the center of the array. The six-phase arrays are outlined in blue in Figure 2 below.,1
"Once again the contaminated area is depicted by the green shape while the electrodes are depicted by the numbered circles. In a six-phase heating pattern there can be hot spots and cold spots depending on the phases that are next to each other. For this reason, six-phase heating typically works best on small circular areas that are less than 65 feet in diameter. ERH is typically most effective on volatile organic compounds (VOCs). The chlorinated compounds perchloroethylene, trichloroethylene, and cis- or trans- 1,2-dichloroethylene are contaminants that are easily remediated with ERH.",1
The table shows contaminants that can be remediated with ERH along with their respective boiling points. Less volatile contaminants like xylene or diesel can also be remediated with ERH but energy requirements increase as the volatility decreases. Electrode spacing and operating time can be adjusted to balance the overall remediation cost with the desired cleanup time. A typical remediation may consist of electrodes spaced 15 to 20 feet apart with operating times usually less than a year.,1
"The design and cost of an ERH remediation system depends on a number of factors, primarily the volume of soil/groundwater to be treated, the type of contamination, and the treatment goals. The physical and chemical properties of the target compounds are governed by laws that make heated remediations advantageous over most conventional methods. The electrical energy usage required for heating the subsurface and volatilizing the contaminants can account for 5 to 40% of the overall remediation cost. There are several laws that govern an ERH remediation. Dalton’s law governs the boiling point of a relatively insoluble contaminant.",1
Raoult’s law governs the boiling point of mutually soluble co-contaminants and Henry’s law governs the ratio of the contaminant in the vapor phase to the contaminant in the liquid phase.,1
"For mutually soluble compounds, Raoult's law states that the partial pressure of a compound is equal to its vapor pressure times its mole fraction. This means that mutually soluble contaminants will volatilize slower than if there was only one compound present.",1
"At ERH sites, steam stripping was observed to effectively transfer 1,4-dioxane to the vapor phase for subsequent treatment. 99.8% reductions (or greater) in 1,4-dioxane concentrations in groundwater have been documented on recent ERH remediation. Monitoring of the above grade treatment streams indicates that 95% of 1,4-dioxane remained in the vapor stream after removal from the subsurface. Furthermore, granular activated carbon has proven to be an effective 1,4-dioxane vapor treatment method.",1
This is the original purpose for the development of ERH - to enhance oil recovery (see § History above). Weaknesses of ERH include heat losses on small sites. Treatment volumes that have a large surface area but are thin with respect to depth will have significant heat losses which makes ERH less efficient. The minimum treatment interval for efficient ERH remediation is approximately 10 vertical feet. Co-contaminants like oil or grease make remediation more difficult. Oil and grease cause a Raoult’s Law effect which requires more energy to remove the contaminants.,1
Peat or high organic carbon in the subsurface will preferentially adsorb VOCs due to van der Waals forces. This preferential adsorption will increase the amount of energy required to remove the VOCs from the subsurface. Fuel sites are less-commonly treated by ERH because other less-expensive remediation technologies are available and because fuel sites are usually thin (resulting in significant heat losses). Sites within landfills are also challenging because metallic debris can distort the electric current paths. ERH is more uniform in natural soil or rock. ERH is adaptable to all soil types and sedimentary bedrock.,1
"After ERH treatment, elevated subsurface temperatures will slowly cool over a period of months or years and return to ambient. This period with elevated temperatures is an important part of the remediation process. The elevated temperatures will enhance Bioremediation, hydrolysis and iron reductive dehalogenation.",1
"CLU-IN Remediation Technology Overview Citizen's Guide to In Situ Thermal Treatment EPA CLU-IN Technology News and Trends: Electrical Resistance Heating Resolves Difficult Removal of CEC Source Area – Summer 2014 Electrical Resistance Heating of Volatile Organic Compounds in Sedimentary Rock - Remediation Journal, Winter 2014 In Situ Remediation of 1,4-Dioxane Using Electrical Resistance Heating – Remediation Journal, Spring 2015 EPA CLU-IN Technology News and Trends: Strategic Sampling and Adaptive Remedy Implementation for Improved Cleanup Performance at Commencement Bay-South Tacoma Channel – Winter 2015 EPA CLU-IN Technology News and Trends: Continued Triad Approach for NAPL Removal Expedites Fort Lewis Cleanup - July",1
"The positively charged silver ion can also attach to the negatively charged cell walls of bacteria, leading to deactivation of cellular enzymes, disruption of membrane permeability, and eventually, cell lysis and death. However, its toxicity to microorganisms is not overtly observed since the free silver ion is found in low concentrations in wastewater treatment systems and the natural environment due to its complexation with ligands such as chloride, sulfide, and thiosulfate.",1
"After passing through both treatment processes, the silver nanoparticles are eventually deposited into the environment.A majority of the submerged portions of wastewater treatment plants are anoxic and rich in sulfur. During the wastewater treatment process, silver nanoparticles either remain the same, are converted into free silver ions, complex with ligands, or agglomerate. Silver nanoparticles can also attach to wastewater biosolids found in both the sludge and the effluent. Silver ions in wastewater are removed efficiently because of their strong complexation with chloride or sulfide.A",1
"majority of the silver found in wastewater treatment plant effluent is associated with reduced sulfur as organic thiol groups and inorganic sulfides. Silver nanoparticles also tend to accumulate in activated sludge, and the dominant form of the silver found in sewage sludge is Ag2S. Therefore, most of the silver found in wastewater treatment plants is in the form of silver nanoparticles or silver precipitates such as Ag2S and AgCl.The amount of silver precipitate formed depends on silver ion release, which increases with increasing dissolved oxygen concentration and decreasing pH.",1
"The silver nanoparticles that pass through wastewater treatment plants undergo transformations in the environment through changes in aggregation state, oxidation state, precipitation of secondary phases, or sorption of organic species. These transformations can result in the formation of colloidal solutions. Each of these new species potentially have toxic effects which have yet to be fully examined.Most silver nanoparticles in products have an organic shell structure around a core of Ag0. This shell is often created with carboxylic acids functional groups, usually using citrate, leading to stabilization through adsorption or covalent attachment of organic compounds.",1
"In seawater, glutathione reacts with citrate to form a thioester via esterification. Thioesters exhibit electrosteric repulsive forces due to amine functional groups and their size, which prevents aggregation. These electrostatic repulsive forces are weakened by counterions in solution, such as Ca2+ found in seawater. Ca2+ ions are naturally found in seawater due to the weathering of calcareous rocks, and allow for dissolution of the oxide-coated particle at low electrolyte concentrations.This leads to the aggregation of silver nanoparticles onto thioesters in seawater. When aggregation occurs, the silver nanoparticles lose microbial toxicity, but have greater exposure in the environment for larger organisms.",1
"These effects have not been completely identified, but may be hazardous to an organism’s health via biological magnification.",1
"Silver nanoparticles are thermodynamically unstable in oxic environments. In seawater, silver oxide is not thermodynamically favored when chloride and sulfur are present. On the surface where O2 is present in much greater quantities than chloride or sulfur, silver reacts to form a silver oxide surface layer. This oxidation has been shown to occur in nanoparticles as well, despite their shell.Dissolution of Ag2O in Water:Ag2O + H2O → 2Ag− + 2OH− The nano-size of the particles aids in oxidation since their smaller surface area increases their redox potential.",1
"Silver and Sulfur Reaction in Seawater:2Ag(aq) + H2S(aq) → Ag2S(s) + H2(aq) H2S is not the only source of sulfur that Ag will readily bind to. Organosulfur compounds, which are produced by aquatic organisms, form extremely stable sulfide complexes with silver. Silver outcompetes other metals for the available sulfide, leading to an overall decrease in bioavailable sulfur in the community. Thus, the formation of Ag2S limits the amount of bioavailable sulfur and contributes to a reduction in toxicity of silver nanoparticles to nitrifying bacteria.",1
"Silver nanoparticles are experimentally shown to inhibit autotrophic nitrifying bacterial growth (86±3%) more than Ag+ ions (42±7%) or AgCl colloids (46±4%). Silver nanoparticle-inhibited heterotrophic growth (55±8%) in Escherichia coli is best observed at lower concentrations, between 1.0 uM and 4.2 uM. This is less than Ag+ ions (~100%), but greater than AgCl colloids (66±6%). The actual cause of these results is undetermined as growth conditions and cell properties differ between nitrifying bacteria and heterotrophic E. coli. Studies conducted in natural lake environments show less response from bacterioplankton than in laboratory environments when exposed to similar concentrations of silver nanoparticles.",1
"This may be due to the binding of free Ag+ ions to dissolved organic matter in lake environments, rendering the Ag+ unavailable.Within toothpaste, Ag+ ions have been shown to have a stronger effect on gram-negative bacteria than on gram-positive bacteria. In comparison to other nanoparticles, such as gold, silver tends to have a broader antimicrobial effect, which is another reason why it is incorporated into so many products. Ag+ is less effective on gram-positive bacteria due to the thick layer of peptidoglycan around them that gram-negative species lack.",1
"Approximately half of the peptidoglycan wall is composed of teichoic acids linked by phosphodiester bonds, which results in an overall negative charge in the peptidoglycan layer. This negative charge may trap the positive Ag+ and prevent them from entering the cell and disrupting the flow of electrons.",1
"The most environmentally relevant species of these nanoparticles are silver chloride within marine ecosystems and organic thiols within terrestrial ecosystems. Once Ag0 enters the environment, it is oxidized to Ag+. Of the potential species formed in seawater, such as Ag2S and Ag2CO3, AgCl is the most thermodynamically favored due to its stability, solubility, and the abundance of Cl− in seawater. Research has shown that partially oxidized nanoparticles may be more toxic than those that are freshly prepared.It was also found that Ag dissolutes more in solution when the pH is low and bleaching has occurred.",1
"This effect, coupled with ocean acidification and increasing coral reef bleaching events, leads to a compounding effect of Ag accumulation in the global marine ecosystem. These free formed Ag+ ions can accumulate and block the regulation of Na+ and Cl− ion exchange within the gills of fish, leading to blood acidosis which is fatal if left unchecked. Additionally, fish can accumulate Ag through their diet. Phytoplankton, which form the base level of aquatic food chains, can absorb and collect silver from their surroundings.As",1
"fish eat phytoplankton, the silver accumulates within their circulatory system, which has been shown to negatively impact embryonic fish, causing spinal cord deformities and cardiac arrhythmia. The other class of organisms heavily affected by silver nanoparticles is bivalves. Filter feeding bivalves accumulate nanoparticles to concentrations 10,000 times greater than was added to seawater, and Ag+ ions are proven to be extremely toxic to them.The base of complex food webs consists of microbes, and these organisms are most heavily impacted by nanoparticles. These effects cascade into the problems that have now reached an observable scale.",1
"Several US radars were the first to start carrying out beam-park tracking. These were the Haystack Radar in Massachusetts, Goldstone Radar in California, and multiple radars at the Kwajalein Atoll. Most notable, the Haystack radar is capable of tracking objects as small as 2 mm.The first known European beam-park experiments were carried out by the German TIRA system in 1993. Performing observations in the L-band during a 10-hour long experiment, the system was able to detect small-sized objects in LEO. The first 24-hour operational measurement campaign was performed on 13–14 December 1994, with TIRA and the Fylingdales Phased-Array Radar.",1
ESA Space Situational Awareness Programme US Space Surveillance Network Kessler syndrome,1
"The disruption of whales' ability to communicate with one another is an extreme threat and is affecting their ability to survive. According to a Discovery Channel article on Sonic Sea Journeys Deep into the Ocean over the last century, extremely loud noise from commercial ships, oil and gas exploration, naval sonar exercises and other sources has transformed the ocean's delicate acoustic habitat, challenging the ability of whales and other marine life to prosper and ultimately to survive. Whales are starting to react to this in ways that are life-threatening. Kenneth C. Balcomb, a whale researcher and a former U.S",1
"Navy officer states that the day 15 March 2000, is the day of infamy. Although sonar helps to protect us, it is destroying marine life. According to IFAW Animal Rescue Program Director Katie Moore, ""There's different ways that sounds can affect animals. There's that underlying ambient noise level that's rising, and rising, and rising that interferes with communication and their movement patterns. And then there's the more acute kind of traumatic impact of sound, that's causing physical damage or a really strong behavioral response. It's fight or flight"".",1
"Marine mammals, such as whales and manatees, risk being struck by ships, causing injury and death. For example, a collision with a ship traveling at only 15 knots has a 79% chance of being lethal to a whale. Ship collisions may be one of the leading causes of population decline for whale sharks.One notable example of the impact of ship collisions is the endangered North Atlantic right whale, of which 400 or fewer remain. The greatest danger to the North Atlantic right whale is injury sustained from ship strikes. Between 1970 and 1999, 35.5% of recorded deaths were attributed to collisions.",1
"From 1999 to 2003, incidents of mortality and serious injury attributed to ship strikes averaged one per year. From 2004 to 2006, that number increased to 2.6. Deaths from collisions has become an extinction threat. The United States' National Marine Fisheries Service (NMFS) and National Oceanic and Atmospheric Administration (NOAA) introduced vessel speed restrictions to reduce ship collisions with North Atlantic right whales in 2008, which expired in 2013. However, in 2017 an unprecedented mortality event occurred, resulting in the deaths of 17 North Atlantic right whales caused primarily from ship-strikes and entanglement in fishing gear.",1
"The discharged material can be harmful to marine life, especially in nearshore settings. In a recent study, the future of ship emissions has been investigated and reported that the growth of carbon dioxide emissions do not change with most common alternatives such as Ultra-low sulfur diesel (ULSD) or liquified natural gas (LNG) as well as growing volume of methane emission due to methane slip through the LNG supply-chain. Methane is a much more powerful greenhouse gas than carbon dioxide per unit volume, and is only slowly broken down in the environment by various chemical, photochemical and biological processes.",1
"In inland-waters-based applications where sulfur cannot (fully) be removed from the fuel before combustion (desulfurization), flue gas scrubbing is commonly employed. However, this would add weight and cost on ships and produce a further waste stream (usually calcium sulfate if flue gases are scrubbed by being passed through calcium hydroxide solution) which would have to be disposed of, adding yet further cost. In addition, calcium hydroxide commonly being produced by calcination of calcium carbonate releases yet more carbon dioxide into the atmosphere.",1
"While this stream is comparatively small in relation to carbon-dioxide emissions caused by combustion of fossil fuels, it needs to be taken into account as well, as part of a complete life-cycle assessment.",1
"Ships can also have a significant impact in areas without large commercial ports: they contribute about 37 percent of total area nitrogen oxide emissions in the Santa Barbara, California area, and that percentage is expected to increase to 61 percent by 2015. Again, there is little cruise-industry specific data on this issue. They comprise only a small fraction of the world shipping fleet, but cruise ship emissions may exert significant impacts on a local scale in specific coastal areas that are visited repeatedly.",1
"Shipboard incinerators also burn large volumes of garbage, plastics, and other waste, producing ash that must be disposed of. Incinerators may release toxic emissions as well. In 2005, MARPOL Annex VI came into force to combat this problem. As such cruise ships now employ CCTV monitoring on the smokestacks as well as recorded measuring via opacity meter while some are also using clean burning gas turbines for electrical loads and propulsion in sensitive areas.",1
"Maritime transport accounts for 3.5% to 4% of all greenhouse gas emissions, primarily carbon dioxide. According to the World Bank, in 2022, the shipping industry's 3% of global greenhouse gas emissions make it ""the sixth largest greenhouse gas emitter worldwide, ranking between Japan and Germany.""Although the industry was not a focus of attention of the Paris Climate Accord signed in 2016, the United Nations and the IMO have discussed CO2 emissions goals and limits. The First Intersessional Meeting of the IMO Working Group on Greenhouse Gas Emissions took place in Oslo, Norway on 23–27 June 2008.",1
"It was tasked with developing the technical basis for the reduction mechanisms that may form part of a future IMO regime to control greenhouse gas emissions from international shipping, and a draft of the actual reduction mechanisms themselves, for further consideration by the IMO's Marine Environment Protection Committee (MEPC). In 2018, the industry discussed in London placing limits to cut levels from a benchmark of 2008 carbon dioxide emissions by 50% by the year 2050.",1
"Some methods of reducing emissions of the industry include lowering speeds of shipping (which can be potentially problematic for perishable goods) as well as changes to fuel standards. In 2019, international shipping organizations, including the International Chamber of Shipping, proposed creating a $5 billion fund to support the research and technology necessary to cut GHG emissions.",1
"The ship ran aground and dumped a massive amount of oil into the ocean in March 1989. Despite efforts of scientists, managers and volunteers, over 400,000 seabirds, about 1,000 sea otters, and immense numbers of fish were killed. Blackwater is sewage, wastewater from toilets and medical facilities, which can contain harmful bacteria, pathogens, viruses, intestinal parasites, and harmful nutrients. Discharges of untreated or inadequately treated sewage can cause bacterial and viral contamination of fisheries and shellfish beds, producing risks to public health.",1
"Estimates of greywater range from 110 to 320 liters per day per person, or 330,000 to 960,000 liters per day for a 3,000-person cruise ship.: 15 A large cruise ship (3,000 passengers and crew) generates an estimated 55,000 to 110,000 liters per day of blackwater waste.: 13 The cruise line industry dumps 970,000 litres (255,000 US gal) of greywater and 110,000 litres (30,000 US gal) of blackwater into the sea every day.MARPOL annex IV was brought into force September 2003 strictly limiting untreated waste discharge.",1
"Cruise ships typically manage solid waste by a combination of source reduction, waste minimization, and recycling. However, as much as 75 percent of solid waste is incinerated on board, and the ash typically is discharged at sea, although some is landed ashore for disposal or recycling. Marine mammals, fish, sea turtles, and birds can be injured or killed from entanglement with plastics and other solid waste that may be released or disposed off of cruise ships. On average, each cruise ship passenger generates at least two pounds of non-hazardous solid waste per day.",1
"With large cruise ships carrying several thousand passengers, the amount of waste generated in a day can be massive. For a large cruise ship, about 8 tons of solid waste are generated during a one-week cruise. It has been estimated that 24% of the solid waste generated by vessels worldwide (by weight) comes from cruise ships.: 38–39 : Table 2–3 Most cruise ship garbage is treated on board (incinerated, pulped, or ground up) for discharge overboard.",1
"However, this picture has been changing since the 1980s when regional initiatives in the EU and its member states began to play a larger role, partly due to an increasing dissatisfaction with the lacking regulation and enforcement efforts of the IMO. This has led to a new synergy developing between the EU and the IMO and other regional actors, broadly characterized as a polycentric mode of governance. The polycentric synergy of the EU and IMO has largely been driven by the active and leading role taken by the EU in both implementing and influencing IMO conventions.",1
"In the Caribbean, many ports lack proper waste disposal facilities, and many ships dump their waste at sea Due to complexities of shipping trade and the difficulties involved in regulating this business, a comprehensive and generally acceptable regulatory framework on corporate responsibility for reducing GHG emissions is unlikely to be achieved soon. As in the case of negotiations around taxation of shipping fuels, international agreement around uniform regulation has not been reached, resulting instead in a deadlock.",1
"Overlaps of decision-making authority between central institutions can pose similar barriers, if central norm conflicts between them are large enough – as in the case of competing principles guiding the United Nations Framework Convention on Climate Change (UNFCCC) and the IMO. The UNFCCC is guided by the principle of Common but Differentiated Responsibilities (CBDR) which holds that since developed countries proportionately have contributed the most in terms of GHG emissions, they also take the largest responsibility for addressing the reduction of these emissions.",1
"The IMO in contrast is guided by principles of “non-discrimination and equal treatment and No More Favourable Treatment (NMFT) to all ships irrespective of their flag”. This has led to a conflict between central interests, since developed states support the NMFT principle, while developing states support the CBDR principle. The effect of this conflict is that we are left with no clear principle around which to regulate resulting in impeding the “legislation efficiency and consensus”.A",1
"The challenges standing in the way of this – the “allocation of emissions, carbon leakage, permit allocation, treatment of the great variety in ship type, size and usage, and transaction cost” – are however hard to overcome without global market-based economies. Others incentive-based schemes for achieving decarbonization include pricing schemes or the incentivization of “front-runner ships that implement decarbonization technologies beyond regulations”. However, evaluation of current the incentive schemes reveals that the schemes are onerous and only taken up by shipping enterprises or ports to a limited degree.",1
"Lastly, When MBMs become the primary means of addressing climate change at sea, Monios argues, this business-as-usual logic is strengthened, since they crowd out non-market norms and render invisible governance alternatives such as direct regulation and supply-side approaches.",1
"MRV Monitoring, reporting and verification of CO2 emissions from large ships using EU ports",1
"Depending on the sources and ingredients, there are various ways in which the public can dispose of pharmaceutical and personal care products in acceptable ways. The most environmentally safe disposal method is to take advantage of community drug take-back programs that collect drugs at a central location for proper disposal. Several local public health departments in the United States have initiated these programs. In addition, the United States Drug Enforcement Administration (DEA) periodically promotes local take-back programs, as well as the National Take Back Initiative.Take-back",1
"programs in the US are funded by state or local health departments or are volunteer programs through pharmacies or health care providers. In recent years, the proposition that pharmaceutical manufacturers should be responsible for their products ""from the cradle to the grave"" has been gaining attention. Where there is no local take-back program, the U.S.",1
"antibiotics, yielding levels of the drugs in local surface waters higher than those found in the blood of patients under treatment.The major route for pharmaceutical residues to reach the aquatic environment is most probably by excretion from patients undergoing pharma treatment. Since many pharmaceutical substances are not metabolized in the body they may be excreted in biologically active form, usually via the urine. Furthermore, many pharmaceutical substances are not fully taken up from the intestine (following oral administration in patients) into their blood stream.",1
"Some PPCPs are broken down or processed easily by a human or animal body and/or degrade quickly in the environment. However, others do not break down or degrade easily. The likelihood or ease with which an individual substance will break down depends on its chemical makeup and the metabolic pathway of the compound.",1
"Although most chemical concentrations were detected at low levels (nano-grams/Liter (ng/L)), there are uncertainties that remain regarding the levels at which toxicity occurs and the risks of bioaccumulation of these pharmaceutical compounds.",1
"The scope of human exposure to pharmaceuticals and personal care products from the environment is a complex function of many factors. These factors include the concentrations, types, and distribution of pharmaceuticals in the environment; the pharmacokinetics of each drug; the structural transformation of the chemical compounds either through metabolism or natural degradation processes; and the potential bioaccumulation of the drugs. More research is needed to determine the effects on humans of long-term exposure to low levels of PPCPs. The full effects of mixtures of low concentrations of different PPCPs is also unknown.""The U.S.",1
"Some microbiologists believe that if antibiotic concentrations are higher than the minimum inhibitory concentrations (MICs) of a species of pathogenic bacteria, a selective pressure would be exerted and, as a result, antibiotic resistance would be selectively promoted. It has also been demonstrated that at even sub-inhibitory concentrations (e.g., one-fourth of the MIC), several antibiotics are able to have an effect on gene expression (e.g., as shown for the modulation of expression of toxin-encoding genes in Staphylococcus aureus).For",1
"Next, a survey was created to examine the disposal patterns of the participants and their perception of the existing risk or threat against the environment. Respondents were asked the following questions in part one of the survey: 1. When and how they disposed of pharmaceuticals. 2. How they perceive the risk to the environment posed by pharmaceuticals. 3. To differentiate between the risks associated with different classed of pharmaceuticals. Part two of the survey involved each of the eight pharmaceutical groups described above individually. Finally, the third part asked information about the age, sex, profession, postcode, and education of participants.",1
"The sample size of participants was precise in comparison to the actual distribution of males and females in the UK: Sample- 54.8 percent were female and 45.2 percent male vs. Actual- the UK of 51.3 percent female to 48.7 percent male. Results showed that when a medication must be discarded, 63.2 percent of participants throw them in a bin, 21.8 percent return them to a pharmacist, and 11.5 percent dispose of them via the toilet/sink, while the remaining 3.5 percent keep them. Only half of the respondents felt like pharmaceuticals could potentially be harmful to the environment.",1
"By educating patients on proper disposal of unused drugs, steps are being taken to further prevent pharmaceutical waste in the environment. Consumers should take precautions before tossing out drugs in the trash or flushing them down the toilet. Community take-back programs have been set up for consumers to bring back unused drugs for proper disposal. Another initiative is for pharmacies to serve as a take-back site for proper drug disposal such as implementing recycling bins for customers to bring back unused or expired medicines while they're shopping.",1
"""Extensive research must be conducted to determine the amount of pharmaceutical contamination in the environment and its effects on animals and marine life"".Many pharmaceuticals pass through the human body unchanged, so there are advantages when human excreta does not go into waterways, even after conventional sewage treatment, which also does not remove most of these chemicals. It is therefore preferable for human feces and urine to go into fertile soil, where they will receive more effective treatment by numerous microbes found there, over longer amounts of time, and stay away from waterways.:",1
"While the full effects of most PPCPs on the environment are not understood, there is concern about the potential they have for harm because they may act unpredictably when mixed with other chemicals from the environment or concentrate in the food chain. Additionally, some PPCPs are active at very low concentrations, and are often released continuously in large or widespread quantities. Because of the high solubility of most PPCPs, aquatic organisms are especially vulnerable to their effects. Researchers have found that a class of antidepressants may be found in frogs and can significantly slow their development.",1
"The measured effluent level of Levonorgestrel in the three areas was shown to reduce the fertility of the rainbow trout.The three sites chosen for field exposures were in located in Stockholm, Gothenburg, and Umeå. They were chosen according to their varying degrees of treatment technologies, geographic locations, and size. The effluent treatment includes active sludge treatment, nitrogen and phosphorus removal (except in Umeå), primary clarification, and secondary clarification. Juvenile rainbow trout were procured from Antens fiskodling AB, Sweden and Umlax AB, Sweden. The fish were exposed to aerated, undiluted, treated effluent.",1
"research on PPCPs aims to answer these questions: What is the effect of exposure to low levels of PPCPs over time? What is the effect of exposure to mixtures of chemicals? Are the effects acute (short-term) or chronic (long-term)? Are certain populations, such as the elderly, very young, or immuno-compromised, more vulnerable to the effects of these compounds? What is the effect of PPCPs on bacterial, fungal, and aquatic life? Are the levels of antibiotics in the aquatic environment sufficient to promote antibiotic resistance? What is the effect of exposure to steroid hormones on animal and human populations?",1
"The investigations showed that depending on the installed technologies the treatment costs for such a hospital treatment facility may be up to 5.50 € per m3. Other studies and comparisons expect the treatment costs to increase up to 10%, mainly due to energy demand. It is therefore important to define best available technique before extensive infrastructure investments are introduced on a wide basis. The fate of incoming pharmaceutical residues in the STP is unpredictable. Some substances seem to be more or less completely eliminated, while others pass the different steps in the STP unaffected.",1
"80% of pills in the world are packed with blister packaging, which is the most convenient type for several reasons. Blister packs have two main components, the ""lid"" and the ""blister"" (cavity). Lid is mainly manufactured with aluminum (Al) and paper. The Cavity consists of polyvinyl chloride (PVC), polypropylene (PP), polyester (PET) or aluminum (Al). If users employ proper disposal methods, all these materials can be recycled and the harmful effects to the environment can be minimized. However, a problem arises with the improper disposal either by burning or disposing as normal household waste.",1
"[C3H6]n + 9n/2 O2 → 3n CO2 +3n H2O [C10H8O4]n + 10n O2 → 10n CO2 +4n H2O [CH2CHCl]n + 2n O2 → n CO2 + n H2O + n HCl + n CO Even though polypropylene and polyester is harmful to the environment, the most toxic effect is due to the combustion of polyvinyl chloride since it produces hydrochloric acid (HCl) which is an irritant in the lower and upper respiratory tract that can cause adverse effects to human beings.The",1
"As a result, the negative effects of both aquatic and terrestrial ecosystems can be generated. 2Al(s)+ 6H+ → 2Al3+ (aq) + 3H2 (g)By employing proper disposal methods, all manufacturing materials of blister packs like PP, PE, PVC and Al can be recycled and the adverse effects to the environment can be minimized. Even though, the synthesis of these polymers relatively simple, the recycling process can be very complex since the blister packs contain metals and polymers together.As the first step of recycling, separation of Al and Polymers using the hydrometallurgical method which uses hydrochloric acid (HCl) can be incorporated.",1
"In nail salons, employees can be exposed to dozens of chemicals found in nail polish and nail polish removers. Nail polishes have many ingredients which are considered toxic, including solvents, resins, colorants and pigments, among others.[1] In the early 2000's some of the toxic components found in nail polish (toluene, formaldehyde and dibutyl phthalate) started being replaced by other substances. One of the new components was triphenyl phosphate which is known as a endocrine-disrupting plasticizer. Now many labels are available including not only 3-Free but higher, for example 5-Free or 12-Free.",1
"There are few studies on the possible health outcomes of nail polish exposures; these include skin problems, respiratory disorders, neurologic disorders, and reproductive disorders.",1
"When temperatures are between 100 - 350 degrees Celsius, the following mechanism occurs: (CH3)2CO + hv → CH3 + CH3CO CH3CO → CH3+ CO CH3+ (CH3)2CO → CH4 + CH2COCH32CH3 → C2H6A second pathway that nail polish remover can enter in the atmosphere is reacting with hydroxyl radicals. When acetone reacts with hydroxyl radicals, its main product is methylglyoxal. Methylglyoxal is an organic compound that is a by-product of many metabolic pathways. It is an intermediate precursor for many advanced glycation end-products, that are formed for diseases such as diabetes or neurodegenerative diseases.",1
The following reaction occurs: (CH3)2CO + ·OH → CH3C(O)OH + ·CH3CH3C(O)OH + ·CH3→ CH3C(O)COH + 3H+,1
"The term ""waste"" is reserved for residue or material which is dumped by the buyer rather than recycled, including residue from reuse and recycling operations, because loads of surplus electronics are frequently commingled (good, recyclable, and non-recyclable). Several public policy advocates apply the term ""e-waste"" and ""e-scrap"" broadly to apply to all surplus electronics. Cathode ray tubes (CRTs) are considered one of the hardest types to recycle. Using a different set of categories, the Partnership on Measuring ICT for Development defines e-waste in six categories: Products in each category vary in longevity profile, impact, and collection methods, among other differences.",1
"These CRT devices are often confused between the DLP Rear Projection TV, both of which have a different recycling process due to the materials of which they are composed. The EU and its member states operate a system via the European Waste Catalogue (EWC) – a European Council Directive, which is interpreted into ""member state law"". In the UK, this is in the form of the List of Wastes Directive.",1
"However, the list (and EWC) gives a broad definition (EWC Code 16 02 13*) of what is hazardous electronic waste, requiring ""waste operators"" to employ the Hazardous Waste Regulations (Annex 1A, Annex 1B) for refined definition. Constituent materials in the waste also require assessment via the combination of Annex II and Annex III, again allowing operators to further determine whether waste is hazardous.Debate continues over the distinction between ""commodity"" and ""waste"" electronics definitions.",1
"Some exporters are accused of deliberately leaving difficult-to-recycle, obsolete, or non-repairable equipment mixed in loads of working equipment (though this may also come through ignorance, or to avoid more costly treatment processes). Protectionists may broaden the definition of ""waste"" electronics in order to protect domestic markets from working secondary equipment. The high value of the computer recycling subset of electronic waste (working and reusable laptops, desktops, and components like RAM) can help pay the cost of transportation for a larger number of worthless pieces than what can be achieved with display devices, which have less (or negative) scrap value.",1
"In 2018, an estimated 50 million tonnes of e-waste was reported, thus the name 'tsunami of e-waste' given by the UN. Its value is at least $62.5 billion annually.Rapid changes in technology, changes in media (tapes, software, MP3), falling prices, and planned obsolescence have resulted in a fast-growing surplus of electronic waste around the globe. Technical solutions are available, but in most cases, a legal framework, a collection, logistics, and other services need to be implemented before a technical solution can be applied.",1
"Display units (CRT, LCD, LED monitors), processors (CPU, GPU, or APU chips), memory (DRAM or SRAM), and audio components have different useful lives. Processors are most frequently out-dated (by software no longer being optimized) and are more likely to become ""e-waste"" while display units are most often replaced while working without repair attempts, due to changes in wealthy nation appetites for new display technology. This problem could potentially be solved with modular smartphones (such as the Phonebloks concept). These types of phones are more durable and have the technology to change certain parts of the phone making them more environmentally friendly.",1
"According to a report by UNEP titled, ""Recycling – from e-waste to Resources,"" the amount of e-waste being produced – including mobile phones and computers – could rise by as much as 500 percent over the next decade in some countries, such as India. The United States is the world leader in producing electronic waste, tossing away about 3 million tons each year. China already produces about 2.3 million tons (2010 estimate) domestically, second only to the United States. And, despite having banned e-waste imports, China remains a major e-waste dumping ground for developed countries.",1
"Society today revolves around technology and by the constant need for the newest and most high-tech products we are contributing to a mass amount of e-waste. Since the invention of the iPhone, cell phones have become the top source of e-waste products . Electrical waste contains hazardous but also valuable and scarce materials. Up to 60 elements can be found in complex electronics. Concentration of metals within the electronic waste is generally higher than a typical ore, such as copper, aluminium, iron, gold, silver, and palladium. As of 2013, Apple has sold over 796 million iDevices (iPod, iPhone, iPad).",1
"Cell phone companies make cell phones that are not made to last so that the consumer will purchase new phones. Companies give these products such short lifespans because they know that the consumer will want a new product and will buy it if they make it. In the United States, an estimated 70% of heavy metals in landfills comes from discarded electronics.While",1
"In 2016, Asia was the territory that had the most extensive volume of e-waste (18.2 Mt), accompanied by Europe (12.3 metric tons), America (11.3 metric tons), Africa (2.2 metric tons), and Oceania (0.7 metric tons). The smallest in terms of total e-waste made, Oceania was the largest generator of e-waste per capita (17.3 kg/inhabitant), with hardly 6% of e-waste cited to be gathered and recycled. Europe is the second broadest generator of e-waste per citizen, with an average of 16.6 kg/inhabitant; however, Europe bears the loftiest assemblage figure (35%). America generates 11.6",1
"kg/inhabitant and solicits only 17% of the e-waste caused in the provinces, which is commensurate with the assortment count in Asia (15%). However, Asia generates fewer e-waste per citizen (4,2 kg/inhabitant). Africa generates only 1.9 kg/inhabitant, and limited information is available on its collection percentage. The record furnishes regional breakdowns for Africa, Americas, Asia, Europe, and Oceania. The phenomenon somewhat illustrates the modest number figure linked to the overall volume of e-waste made that 41 countries have administrator e-waste data. For 16 other countries, e-waste volumes were collected from exploration and evaluated.",1
"The outcome of a considerable bulk of the e-waste (34.1 Metric tons) is unidentified. In countries where there is no national E-waste constitution in the stand, e-waste is possible interpreted as an alternative or general waste. This is land-filled or recycled, along with alternative metal or plastic scraps. There is the colossal compromise that the toxins are not drawn want of accordingly, or they are chosen want of by an informal sector and converted without well safeguarding the laborers while venting the contaminations in e-waste.",1
"Although the e-waste claim is on the rise, a flourishing quantity of countries are embracing e-waste regulation. National e-waste governance orders enclose 66% of the world population, a rise from 44% that was reached in 2014",1
"In 2019, an enormous volume of e-waste (53.6 Mt, with a 7.3 kg per capita average) was generated globally. This is projected to increase to 74 Mt by 2030. Asia still remains the largest contributor of a significant volume of electronic waste at 24.9 Mt, followed by the Americas (13.1 Mt), Europe (12 Mt), and Africa and Oceania at 2.9 Mt and 0.7 Mt, respectively. In per capita generation, Europe came first with 16.2 kg, and Oceania was second largest generator at 16.1 kg, and followed by the Americas. Africa is the least generator of e-waste per capita at 2.5 kg.",1
"Regarding the collection and recycling of these waste, the continent of Europe ranked first (42.5%), and Asia came second (11.7%). The Americas and Oceania are next (9.4% and 8.8% respectively), and Africa trails behind at 0.9%. Out of the 53.6 Metric tons generated e-waste globally, the formally documented collection and recycling was 9.3%, and the fate of 44.3% remains uncertain, with its whereabouts and impact to the environment varying across different regions of the world. However, the number of countries with national e-waste legislation, regulation or policy, have increased since 2014, from 61 to 78.",1
"A great proportion of undocumented commercial and domestic waste get mixed with other streams of waste like plastic and metal waste, implying that fractions which are easily recyclable might be recycled, under conditions considered to be inferior without depollution and recovery of all materials considered valuable.",1
"In 2022, an increase of 3.4% was estimated of the generated e-waste globally, hitting 59.4Mt, which made the total unrecycled e-waste on earth to 2022 is over 347 Mt. The transboundary flow of e-waste has gained attention from the public due to a number of worrisome headlines, but global study on the volumes and trading routes has not yet been conducted. According to the Transboundary E-waste Flows Monitor, 5.1 Mt (or slightly under 10% of the 53.6 Mt of global e-waste) crossed international boundaries in 2019.",1
"When it comes to Western Balkan countries, North Macedonia has adopted a Law on Batteries and Accumulators in 2010, followed by the Law on Management of electrical and electronic equipment in 2012. Serbia has regulated management of special waste stream, including electronic waste, by National waste management strategy (2010–2019).[5] Montenegro has adopted Concessionary Act concerning electronic waste with ambition to collect 4 kg of this waste annually per person until 2020.[6] Albanian legal framework is based on the draft act on waste from electrical and electronic equipment from 2011 which focuses on the design of electrical and electronic equipment.",1
"Contrary to this, Bosnia and Herzegovina is still missing a law regulating electronic waste. As of October 2019, 78 countries globally have established either a policy, legislation or specific regulation to govern e-waste. However, there is no clear indication that countries are following the regulations. Regions such as Asia and Africa are having policies that are not legally binding and rather only programmatic ones. Hence, this poses as a challenge that e-waste management policies are yet not fully developed by globally by countries.",1
"Solving the E-waste Problem is a membership organization that is part of United Nations University and was created to develop solutions to address issues associated with electronic waste. Some of the most eminent players in the fields of Production, Reuse and Recycling of Electrical and Electronic Equipment (EEE), government agencies and NGOs as well as UN Organisations count themselves among its members. StEP encourages the collaboration of all stakeholders connected with e-waste, emphasizing a holistic, scientific yet applicable approach to the problem.:",1
"The European Commission (EC) of the EU has classified waste electrical and electronic equipment (WEEE) as the waste generated from electrical devices and household appliances like refrigerators, televisions, and mobile phones and other devices. In 2005 the EU reported total waste of 9 million tonnes and in 2020 estimates waste of 12 million tonnes. This electronic waste with hazardous materials if not managed properly, may end up badly affecting our environment and causing fatal health issues. Disposing of these materials requires a lot of manpower and properly managed facilities.",1
"The EC revised this Directive in December 2008, since this has become the fastest growing waste stream. In August 2012, the WEEE Directive was rolled out to handle the situation of controlling electronic waste and this was implemented on 14 February 2014 (Directive 2012/19/EU [8]). On 18 April 2017, the EC adopted a common principle of carrying out research and implementing a new regulation to monitor the amount of WEEE. It requires each member state to monitor and report their national market data.",1
"- Annex III to the WEEE Directive (Directive 2012/19/EU): Re-examination of the timelines for waste collection and setting up individual targets (Report [9]). WEEE Legislation: - On 4 July 2012, the EC passed legislation on WEEE (Directive 2012/19/EU [10]). To know more about the progress in adopting the Directive 2012/19/EU (Progress [11]). - On 15 February 2014, the EC revised the Directive. To know more about the old Directive 2002/96/EC, see (Report [12]).",1
"On 21 November 2017, the European Parliament and Council has published this legislation amending the RoHS 2 Directive in their official journal [18].",1
"Generally, many parts of these batteries and accumulators / capacitors can be recycled without releasing these hazardous materials release into our environment and contaminating our natural resources. The EC has rolled out a new Directive to control the waste from the batteries and accumulators known as 'Batteries Directive'[19] aiming to improve the collecting and recycling process of the battery waste and control the impact of battery waste on our environment. This Directive also supervises and administers the internal market by implementing required measures.",1
"This Directive restricts the production and marketing of batteries and accumulators which contains hazardous materials and are harmful to the environment, difficult to collect and recycle them. Batteries Directive [20] targets on the collection, recycling and other recycling activities of batteries and accumulators, also approving labels to the batteries which are environment neutral. On 10 December 2020, The EC has proposed a new regulation (Batteries Regulation [21]) on the batteries waste which aims to make sure that batteries entering the European market are recyclable, sustainable and non-hazardous (Press release [22]).",1
"Legislation: In 2006, the EC has adopted the Batteries Directive and revised it in 2013. - On 6 September 2006, the European Parliament and European Council have launched Directives in waste from Batteries and accumulators (Directive 2006/66/EC [23]). - Overview of Batteries and accumulators Legislation [24] Evaluation of Directive 2006/66/EC (Batteries Directive): Revising Directives could be based on the Evaluation [25] process, considering the fact of the increase in the usage of batteries with an increase in the multiple communication technologies, household appliances and other small battery-powered products.",1
"The EC's regulations and guidelines has made the evaluation process more impactful in a positive way. The participation of number of stakeholders in the evaluation process who are invited and asked to provide their views and ideas to improve the process of evaluation and information gathering. On 14 March 2018, stakeholders and members of the association participated to provide information about their findings, support and increase the process of Evaluation Roadmap [27].",1
"In the 2011 Directive, 2011/65/EU it was stated as the motivation for more specific restriction on the usage of hazardous materials in the planning and manufacturing process of electronic and electrical devices as there was a disparity of the EU Member State laws and the need arose to set forth rules to protect human health and for the environmentally sound recovery and disposal of WEEE. (2011/65/EU, (2)) The Directive lists several substances subject to restriction. The Directive states restricted substances for maximum concentration values tolerated by weight in homogeneous materials are the following: lead (0.1%); mercury (0.1%), cadmium (0.1%),",1
"hexavalent chromium (0.1%), polybrominated biphenyls (PBB) (0.1%) and polybrominated diphenyl ethers (PBDE) (0.1 %). If technologically feasible and substitution is available, the usage of substitution is required. There are, however, exemptions in the case in which substitution is not possible from the scientific and technical point of view. The allowance and duration of the substitutions should take into account the availability of the substitute and the socioeconomic impact of the substitute.",1
"(2011/65/EU, (18)) EU Directive 2012/19/EU regulates WEEE and lays down measures to safeguard the ecosystem and human health by inhibiting or shortening the impact of the generation and management of waste of WEEE. (2012/19/EU, (1)) The Directive takes a specific approach to the product design of EEE. It states in Article 4 that Member States are under the constraint to expedite the kind of model and manufacturing process as well as cooperation between producers and recyclers as to facilitate re-use, dismantling and recovery of WEEE, its components, and materials.",1
"Under Annex I of Directive 2012/19/EU, the categories of EEE covered are as follows: Large household appliances Small household appliances IT and telecommunications equipment Consumer equipment and photovoltaic panels Lighting equipment Electrical and electronic tools (with the exception of large-scale stationary industrial tools) Toys, leisure and sports equipment Medical devices (with the exception of all implanted and infected products) Monitoring and control instruments Autonomic dispensersMinimum recovery targets referred in Directive 2012/19/EU starting from 15 August 2018: WEEE falling within category 1 or 10 of Annex I - 85% shall be recovered, and 80% shall be prepared for re-use and recycled; WEEE",1
"falling within category 3 or 4 of Annex I - 80% shall be recovered, and 70% shall be prepared for re-use and recycled; WEEE falling within category 2, 5, 6, 7, 8 or 9 of Annex I -75% shall be recovered, and 55% shall be prepared for re-use and recycled; For gas and discharged lamps, 80% shall be recycled. In 2021, the European Commission proposed the implementation of a standardization – for iterations of USB-C – of phone charger products after commissioning two impact assessment studies and a technology analysis study.",1
"Regulations like this may reduce electronic waste by small but significant amounts as well as, in this case, increase device-interoperability, convergence and convenience for consumers while decreasing resource-needs and redundancy. The regulations were passed in June 2022, mandating that all phones sold in the EU to have USB-C charging ports by late 2024.",1
A report by the United Nations Environment Management Group lists key processes and agreements made by various organizations globally in an effort to manage and control e-waste. Details about the policies could be retrieved in the links below.,1
"Electronic waste is often sent to various African and Asian countries such as China, Malaysia, India, and Kenya for processing, sometimes illegally. Many surplus laptops are routed to developing nations as ""dumping grounds for e-waste"".Because the United States has not ratified the Basel Convention or its Ban Amendment, and has few domestic federal laws forbidding the export of toxic waste, the Basel Action Network estimates that about 80% of the electronic waste directed to recycling in the U.S. does not get recycled there at all, but is put on container ships and sent to countries such as China.",1
"million tons) of all the e-waste discarded in 2012 ended up in the officially reported amounts of collection and recycling systems. The other 65% (6.15 million tons) was either: Exported (1.5 million tons), Recycled under non-compliant conditions in Europe (3.15 million tons), Scavenged for valuable parts (750,000 tons), or Simply thrown in waste bins (750,000 tons).",1
"Guiyu in the Guangdong region of China is a massive electronic waste processing community. It is often referred to as the ""e-waste capital of the world."" Traditionally, Guiyu was an agricultural community; however, in the mid-1990s it transformed into an e-waste recycling center involving over 75% of the local households and an additional 100,000 migrant workers. Thousands of individual workshops employ laborers to snip cables, pry chips from circuit boards, grind plastic computer cases into particles, and dip circuit boards in acid baths to dissolve the precious metals.",1
"Guiyu is likely one of the oldest and largest informal e-waste recycling sites in the world; however, there are many sites worldwide, including India, Ghana (Agbogbloshie), Nigeria, and the Philippines. There are a handful of studies that describe exposure levels in e-waste workers, the community, and the environment. For example, locals and migrant workers in Delhi, a northern union territory of India, scavenge discarded computer equipment and extract base metals using toxic, unsafe methods. Bangalore, located in southern India, is often referred as the ""Silicon Valley of India"" and has a growing informal e-waste recycling sector.",1
"A study found that e-waste workers in the slum community had higher levels of V, Cr, Mn, Mo, Sn, Tl, and Pb than workers at an e-waste recycling facility.",1
"Furthermore, the rate at which Bitcoin disposes of its waste exceeds that of major financial organizations such as VISA, which produces 40 grams of waste for every 100,000 transactions.A major point of concern is the rapid turnover of technology in the bitcoin industry which results in such high levels of e-waste. This can be attributed to the proof-of-work principle bitcoin employs where miners receive currency as a reward for being the first to decode the hashes that encode its blockchain. As such, miners are encouraged to compete with one another to decode the hash first.",1
"However, computing these hashes requires massive computing power which, in effect, drives miners to obtain rigs with the highest processing power possible. In an attempt to achieve this, miners increase the processing power in their rigs by purchasing more advanced computer chips.According to Koomey's Law, efficiency in computer chips doubles every 1.5 years, meaning that miners are incentivized to purchase new chips to keep up with competing miners even though the older chips are still functional. In some cases, miners even discard their chips earlier than this timeframe for the sake of profitability.",1
"Developing a recycling infrastructure for bitcoin mining may prove to be beneficial, though, as the aluminum heat sinks and metal casings in ASIC chips can be recycled into new technology. Much of this responsibility falls onto Bitmain, the leading manufacturer of bitcoin, which currently lacks the infrastructure to recycle waste from bitcoin mining. Without such programs, much of bitcoin waste ends up in landfill along with 83.6% of the global total of e-waste.Many argue for relinquishing the proof-of-work model altogether in favour of the proof-of-stake one.",1
"Into this area—one of the largest informal e-waste dumping and processing sites in Africa—about 215,000 tons of secondhand consumer electronics, primarily from Western Europe, are imported annually. Because this region has considerable overlap among industrial, commercial, and residential zones, Pure Earth (formerly Blacksmith Institute) has ranked Agbogbloshie as one of the world's 10 worst toxic threats (Blacksmith Institute 2013).A separate study at the Agbogbloshie e-waste dump, Ghana found a presence of lead levels as high as 18,125 ppm in the soil. US EPA standard for lead in soil in play areas is 400 ppm and 1200 ppm for non-play areas.",1
"Scrap workers at the Agbogbloshie e-waste dump regularly burn electronic components and auto harness wires for copper recovery, releasing toxic chemicals like lead, dioxins and furans into the environment. Researchers such as Brett Robinson, a professor of soil and physical sciences at Lincoln University in New Zealand, warn that wind patterns in Southeast China disperse toxic particles released by open-air burning across the Pearl River Delta Region, home to 45 million people. In this way, toxic chemicals from e-waste enter the ""soil-crop-food pathway,"" one of the most significant routes for heavy metals' exposure to humans.",1
"E-waste has a horrible effect on the environment and it is important to dispose it with an R2 certifies recycling facility. In May 2020, a scientific study was conducted in China that investigated the occurrence and distribution of traditional and novel classes of contaminants, including chlorinated, brominated, and mixed halogenated dibenzo-p-dioxins/dibenzofurans (PCDD/Fs, PBDD/Fs, PXDD/Fs), polybrominated diphenyl ethers (PBDEs), polychlorinated biphenyls (PCBs) and polyhalogenated carbazoles (PHCZs) in soil from an e-waste disposal site in Hangzhou (which has been in operation since 2009 and has a treatment capacity of 19.6 Wt/a).",1
"This may include such steps as re-formatting of storage media and overwriting with random data to make data unrecoverable, or even physical destruction of media by shredding and incineration to ensure all data is obliterated. For example, on many operating systems deleting a file may still leave the physical data file intact on the media, allowing data retrieval by routine methods. Recycling is an essential element of e-waste management. Properly carried out, it should greatly reduce the leakage of toxic materials into the environment and militate against the exhaustion of natural resources.",1
"However, it does need to be encouraged by local authorities and through community education. Less than 20% of e-waste is formally recycled, with 80% either ending up in landfill or being informally recycled – much of it by hand in developing countries, exposing workers to hazardous and carcinogenic substances such as mercury, lead and cadmium.There are generally three methods of extracting precious metals from electronic waste, namely hydrometallurgical, pyrometallurgical, and hydro-pyrometallurgical methods. Each of these methods has its own advantages and disadvantages together with the production of toxic waste.One",1
"of the major challenges is recycling the printed circuit boards from electronic waste. The circuit boards contain such precious metals as gold, silver, platinum, etc. and such base metals as copper, iron, aluminum, etc. One way e-waste is processed is by melting circuit boards, burning cable sheathing to recover copper wire and open- pit acid leaching for separating metals of value. Conventional method employed is mechanical shredding and separation but the recycling efficiency is low. Alternative methods such as cryogenic decomposition have been studied for printed circuit board recycling, and some other methods are still under investigation.",1
"Properly disposing of or reusing electronics can help prevent health problems, reduce greenhouse-gas emissions, and create jobs.",1
"While there have been major benefits from the rise in recycling and waste collection created by producers and consumers, such as valuable materials being recovered and kept away from landfill and incineration, there are still many problems present with the EPR system including ""how to ensure proper enforcement of recycling standards, what to do about waste with positive net value, and the role of competition,"" (Kunz et al.).",1
"Many stakeholders agreed there needs to be a higher standard of accountability and efficiency to improve the systems of recycling everywhere, as well as the growing amount of waste being an opportunity more so than downfall since it gives us more chances to create an efficient system. To make recycling competition more cost-effective, the producers agreed that there needs to be a higher drive for competition because it allows them to have a wider range of producer responsibility organizations to choose from for e-waste recycling.The",1
"These groups allege that, since prisons do not have adequate safety standards, inmates are dismantling the products under unhealthy and unsafe conditions.",1
"In many developed countries, electronic waste processing usually first involves dismantling the equipment into various parts (metal frames, power supplies, circuit boards, plastics), often by hand, but increasingly by automated shredding equipment. A typical example is the NADIN electronic waste processing plant in Novi Iskar, Bulgaria—the largest facility of its kind in Eastern Europe. The advantages of this process are the human worker's ability to recognize and save working and repairable parts, including chips, transistors, RAM, etc. The disadvantage is that the labor is cheapest in countries with the lowest health and safety standards.",1
"In an alternative bulk system, a hopper conveys material for shredding into an unsophisticated mechanical separator, with screening and granulating machines to separate constituent metal and plastic fractions, which are sold to smelters or plastics recyclers. Such recycling machinery is enclosed and employs a dust collection system. Some of the emissions are caught by scrubbers and screens. Magnets, eddy currents, and Trommel screens are employed to separate glass, plastic, and ferrous and nonferrous metals, which can then be further separated at a smelter. Copper, gold, palladium, silver and tin are valuable metals sold to smelters for recycling.",1
"Materials that can be recycled include ""ferrous (iron-based) and non-ferrous metals, glass, and various types of plastic."" ""Non-ferrous metals, mainly aluminum and copper can all be re-smelted and re-manufactured. Ferrous metals such as steel and iron also can be re-used."" Due to the recent surge in popularity in 3D printing, certain 3D printers have been designed (FDM variety) to produce waste that can be easily recycled which decreases the amount of harmful pollutants in the atmosphere. The excess plastic from these printers that comes out as a byproduct can also be reused to create new 3D printed creations.Benefits",1
"Since many companies were responsible for the recycling of their own products, this imposed responsibility on manufacturers requiring many to redesign their infrastructure. As a result, manufacturers in Japan have the added option to sell the recycled metals.Improper management of e-waste is resulting in a significant loss of scarce and valuable raw materials, such as gold, platinum, cobalt and rare earth elements. As much as 7% of the world's gold may currently be contained in e-waste, with 100 times more gold in a tonne of e-waste than in a tonne of gold ore.",1
"Consumer dissatisfaction with this state of affairs has led to a growing repair movement. Often, this is at a community level such as through repair cafės or the ""restart parties"" promoted by the Restart Project.The Right to Repair is spearheaded in the US by farmers dissatisfied with non-availability of service information, specialised tools and spare parts for their high-tech farm machinery. But the movement extends far beyond farm machinery with, for example, the restricted repair options offered by Apple coming in for criticism. Manufacturers often counter with safety concerns resulting from unauthorised repairs and modifications.An",1
"easy method of reducing electronic waste footprint is to sell or donate electronic gadgets, rather than dispose of them. Improperly disposed e-waste is becoming more and more hazardous, especially as the sheer volume of e-waste increases. For this reason, large brands like Apple, Samsung, and others have started giving options to customers to recycle old electronics. Recycling allows the expensive electronic parts inside to be reused. This may save significant energy and reduce the need for mining of additional raw resources, or manufacture of new components.",1
"Electronic recycling programs may be found locally in many areas with a simple online search; for example, by searching ""recycle electronics"" along with the city or area name. Cloud services have proven to be useful in storing data, which is then accessible from anywhere in the world without the need to carry storage devices. Cloud storage also allows for large storage, at low cost. This offers convenience, while reducing the need for manufacture of new storage devices, thus curbing the amount of e-waste generated. The market has a lot of different types of electrical products.",1
"It is an international nomenclature which is an integrated system to allow classify common basis for customs purposes. Some computer components can be reused in assembling new computer products, while others are reduced to metals that can be reused in applications as varied as construction, flatware, and jewellery. Substances found in large quantities include epoxy resins, fiberglass, PCBs, PVC (polyvinyl chlorides), thermosetting plastics, lead, tin, copper, silicon, beryllium, carbon, iron, and aluminum. Elements found in small amounts include cadmium, mercury, and thallium.",1
"Potential health risks include mental health, impaired cognitive function, and general physical health damage (see also Electronic waste#Hazardous). DNA damage was also found more prevalent in all the e-waste exposed populations (i.e. adults, children, and neonates) than the populations in the control area. DNA breaks can increase the likelihood of wrong replication and thus mutation, as well as lead to cancer if the damage is to a tumor suppressor gene.",1
"Prenatal exposure to e-waste has found to have adverse effects on human body burden of pollutants of the neonates. In Guiyu, one of the most famous e-waste recycling sites in China, it was found that increased cord blood lead concentration of neonates was associated with parents' participation in e-waste recycling processes, as well as how long the mothers spent living in Guiyu and in e-waste recycling factories or workshops during pregnancy.",1
"Besides, a higher placental metallothionein (a small protein marking the exposure of toxic metals) was found among neonates from Guiyu as a result of Cd exposure, while the higher Cd level in Guiyu's neonates was related to the involvement in e-waste recycling of their parents. High PFOA exposure of mothers in Guiyu is related to adverse effect on growth of their new-born and the prepotency in this area.Prenatal exposure to informal e-waste recycling can also lead to several adverse birth outcomes (still birth, low birth weight, low Apgar scores, etc.)",1
and longterm effects such as behavioral and learning problems of the neonates in their future life.,1
"Children are especially sensitive to e-waste exposure because of several reasons, such as their smaller size, higher metabolism rate, larger surface area in relation to their weight, and multiple exposure pathways (for example, dermal, hand-to-mouth, and take-home exposure). They were measured to have an 8-time potential health risk compared to the adult e-waste recycling workers. Studies have found significant higher blood lead levels (BLL) and blood cadmium levels (BCL) of children living in e-waste recycling area compared to those living in control area. For example, one study found that the average BLL in Guiyu was nearly 1.5",1
"times compared to that in the control site (15.3 ug/dL compared to 9.9 ug/dL), while the CDC of the United States has set a reference level for blood lead at 5 ug/dL. The highest concentrations of lead were found in the children of parents whose workshop dealt with circuit boards and the lowest was among those who recycled plastic.Exposure to e-waste can cause serious health problems to children.",1
"Children's exposure to developmental neurotoxins containing in e-waste such as lead, mercury, cadmium, chromium, arsenic, nickel and PBDEs can lead to a higher risk of lower IQ, impaired cognitive function, exposure to known human carcinogens and other adverse effects. In certain age groups, a decreased lung function of children in e-waste recycling sites has been found. Some studies also found associations between children's e-waste exposure and impaired coagulation, hearing loss, and decreased vaccine antibody tilters in e-waste recycling area.",1
"For instance, nickel exposure in boys aged 8–9 years at an e-waste site leads to lower forced vital capacity, decrease in catalase activities and significant increase in superoxide dismutase activities and malondialdehyde levels.",1
"The complex composition and improper handling of e-waste adversely affect human health. A growing body of epidemiological and clinical evidence has led to increased concern about the potential threat of e-waste to human health, especially in developing countries such as India and China. For instance, in terms of health hazards, open burning of printed wiring boards increases the concentration of dioxins in the surrounding areas. These toxins cause an increased risk of cancer if inhaled by workers and local residents.",1
"Toxic metals and poison can also enter the bloodstream during the manual extraction and collection of tiny quantities of precious metals, and workers are continuously exposed to poisonous chemicals and fumes of highly concentrated acids. Recovering resalable copper by burning insulated wires causes neurological disorders, and acute exposure to cadmium, found in semiconductors and chip resistors, can damage the kidneys and liver and cause bone loss. Long-term exposure to lead on printed circuit boards and computer and television screens can damage the central and peripheral nervous system and kidneys, and children are more susceptible to these harmful effects.The",1
"Occupational Safety & Health Administration (OSHA) has summarized several potential safety hazards of recycling workers in general, such as crushing hazards, hazardous energy released, and toxic metals. OSHA has also specified some chemical components of electronics that can potentially do harm to e-recycling workers' health, such as lead, mercury, PCBs, asbestos, refractory ceramic fibers (RCFs), and radioactive substances. Besides, in the United States, most of these chemical hazards have specific Occupational exposure limits (OELs) set by OSHA, National Institute for Occupational Safety and Health (NIOSH), and American Conference of Governmental Industrial Hygienists (ACGIH).",1
"For the details of health consequences of these chemical hazards, see also Electronic waste#Electronic waste substances.",1
"Safety equipment such as gloves, face masks, and ventilation fans are virtually unknown, and workers often have little idea of what they are handling. In another study of e-waste recycling in India, hair samples were collected from workers at an e-waste recycling facility and an e-waste recycling slum community (informal industry) in Bangalore. Levels of V, Cr, Mn, Mo, Sn, Tl, and Pb were significantly higher in the workers at the e-waste recycling facility compared to the e-waste workers in the slum community.",1
"However, Co, Ag, Cd, and Hg levels were significantly higher in the slum community workers compared to the facility workers. Even in formal e-recycling industry, workers can be exposed to excessive pollutants. Studies in the formal e-recycling facilities in France and Sweden found workers' overexposure (compared to recommended occupational guidelines) to lead, cadmium, mercury and some other metals, as well as BFRs, PCBs, dioxin and furans. Workers in formal industry are also exposed to more brominated flame-retardants than reference groups.",1
"For occupational health and safety of e-waste recycling workers, both employers and workers should take actions. Suggestions for the e-waste facility employers and workers given by California Department of Public Health are illustrated in the graphic.",1
"(13 MB PDF) Shiani A, Sharafi K, Omer AK, Kiani A, Karamimatin B, Massahi T, Ebrahimzadeh G (January 2023). ""A systematic literature review on the association between exposures to toxic elements and an autism spectrum disorder"". Sci Total Environ. 857 (Pt 2): 159246. doi:10.1016/j.scitotenv.2022.159246. PMID 36220469. Carroll, Chris (January 2008). ""High-Tech Trash"". National Geographic Society. Sustainable Management of Electronics MOOC: Massive Online Open Course ""Waste Management and Critical Raw Materials"" on (amongst others) recycling and reuse of electronics.",1
"The Noise Control Act of 1972 and the Quiet Communities Act of 1978 were never rescinded by Congress and remain in effect today, although essentially unfunded.Today, in the absence of a national guidance and enforcement by the EPA, states, cities, and municipalities have had little or no guidance on writing competent and effective noise regulations. Since the EPA last published its Model Community Noise Ordinance in 1974, communities have struggled to develop their ordinances, often relying on copying guidance from other communities, and sometimes copying their mistakes.",1
"Noise laws and ordinances vary widely among municipalities though most specify some general prohibition against making noise that is a nuisance and the allowable sound levels that can cross a property line. Some ordinances set out specific guidelines for the level of noise allowable at certain times of the day and for certain activities.The Federal Aviation Administration (FAA) regulates aircraft noise by specifying the maximum noise level that individual civil aircraft can emit through requiring aircraft to meet certain noise certification standards. These standards designate changes in maximum noise level requirements by ""stage"" designation. The U.S.",1
noise standards are defined in the Code of Federal Regulations (CFR) Title 14 Part 36 – Noise Standards: Aircraft Type and Airworthiness Certification (14 CFR Part 36). The FAA also pursues a program of aircraft noise control in cooperation with the aviation community. The FAA has set up a process to report aviation-related noise complaints for anyone who may be impacted by Aircraft noise. The Federal Highway Administration (FHWA) developed noise regulations to control highway noise as required by the Federal-Aid Highway Act of 1970.,1
"implementation is divided into phases: In the first phase, the member states shall inform about major roads with more than six million vehicles a year, major railways with more than 60,000 trains per year, major airports with more than 50,000 movements per year and metropolitan areas with more than 250,000 inhabitants. In the second phase, these numbers are halved; only the criteria for airports remains unchanged. In the third and the following phases, the methods for calculation of the noise levels will change while the criteria remains unchanged.",1
In Austria the institution which is responsible for the noise sources is also responsible for the noise maps concerning these sources. This means that the Federation is responsible for the federal roads and each state is responsible for the country's roads.,1
"Ceiling dust, topsoil, surface and groundwater of nearby properties should also be tested, both before and after any remediation. This is a controversial step as: No one wants to have to pay for the cleanup of the site; If nearby properties are found to be contaminated it may have to be noted on their property title, potentially affecting the value; No one wants to pay for the cost of assessment.Often",1
"Other countries have other mechanisms and commonly sites are rezoned to ""higher"" uses such as high density housing, to give the land a higher value so that after deducting cleanup costs there is still an incentive for a developer to purchase the land, clean it up, redevelop it and sell it on, often as apartments (home units). There are several tools for mapping these sites and which allow the user to view additional information.",1
"Thermal desorption is a technology for soil remediation. During the process a desorber volatilizes the contaminants (e.g. oil, mercury or hydrocarbon) to separate them from especially soil or sludge. After that the contaminants can either be collected or destroyed in an offgas treatment system.",1
"Excavation processes can be as simple as hauling the contaminated soil to a regulated landfill, but can also involve aerating the excavated material in the case of volatile organic compounds (VOCs). Recent advancements in bioaugmentation and biostimulation of the excavated material have also proven to be able to remediate semi-volatile organic compounds (SVOCs) onsite. If the contamination affects a river or bay bottom, then dredging of bay mud or other silty clays containing contaminants (including sewage sludge with harmful microorganisms) may be conducted. Recently, ExSitu Chemical oxidation has also been utilized in the remediation of contaminated soil.",1
This process involves the excavation of the contaminated area into large bermed areas where they are treated using chemical oxidation methods.,1
"This technology is also successful when utilized as the initial step in a multi-faceted remedial approach utilizing SEAR then In situ Oxidation, bioremediation enhancement or soil vapor extraction (SVE).",1
"Other methods include trying to increase the dissolved oxygen content of the groundwater to support microbial degradation of the compound (especially petroleum) by direct injection of oxygen into the subsurface, or the direct injection of a slurry that slowly releases oxygen over time (typically magnesium peroxide or calcium oxy-hydroxide).",1
"Controlled, high temperature incineration with filtering of exhaust gases however should not pose any risks. Two different technologies can be employed to oxidize the contaminants of an extracted vapor stream. The selection of either thermal or catalytic depends on the type and concentration in parts per million by volume of constituent in the vapor stream. Thermal oxidation is more useful for higher concentration (~4,000 ppmV) influent vapor streams (which require less natural gas usage) than catalytic oxidation at ~2,000 ppmV.Thermal",1
"oxidation which uses a system that acts as a furnace and maintains temperatures ranging from 1,350 to 1,500 °F (730 to 820 °C). Catalytic oxidation which uses a catalyst on a support to facilitate a lower temperature oxidation. This system usually maintains temperatures ranging from 600 to 800 °F (316 to 427 °C).Vapor condensation is the most effective off-gas treatment technology for high (over 4,000 ppmV) VOC concentration vapor streams.",1
The process involves cryogenically cooling the vapor stream to below 40 degrees C such that the VOCs condensate out of the vapor stream and into liquid form where it is collected in steel containers. The liquid form of the VOCs is referred to as dense non-aqueous phase liquids (DNAPL) when the source of the liquid consists predominantly of solvents or light non-aqueous phase liquids (LNAPL) when the source of the liquid consists predominantly of petroleum or fuel products. This recovered chemical can then be reused or recycled in a more environmentally sustainable or green manner than the alternatives described above.,1
This technology is also known as cryogenic cooling and compression (C3-Technology).,1
"Using nano-sized reactive agents to degrade or immobilize contaminants is termed nanoremediation. In soil or groundwater nanoremediation, nanoparticles are brought into contact with the contaminant through either in situ injection or a pump-and-treat process. The nanomaterials then degrade organic contaminants through redox reactions or adsorb to and immobilize metals such as lead or arsenic. In commercial settings, this technology has been dominantly applied to groundwater remediation, with research into wastewater treatment. Research is also investigating how nanoparticles may be applied to cleanup of soil and gases.Nanomaterials",1
"Some of the important challenges currently limiting nanoremediation technologies include identifying coatings or other formulations that increase dispersal of the nanoparticle agents to better reach target contaminants while limiting any potential toxicity to bioremediation agents, wildlife, or people.",1
"Those that manufacture microbes for bioremediation must be approved by the EPA; however, the EPA traditionally has been more cautious about negative externalities that may or may not arise from the introduction of these species. One of their concerns is that the toxic chemicals would lead to the microbe's gene degradation, which would then be passed on to other harmful bacteria, creating more issues, if the pathogens evolve the ability to feed off of pollutants.",1
"The proponent needs to learn about ""sensitive"" (future) uses like childcare, schools, hospitals, and playgrounds as well as community concerns and interests information. Consultation should be open, on a group basis so that each member of the community is informed about issues they may not have individually thought about. An independent chairperson acceptable to both the proponent and the community should be engaged (at proponent expense if a fee is required).",1
"In some jurisdictions this is 1 in 1,000,000 but in other jurisdictions the acceptable projected rate of increase is 1 in 100,000. A relatively small incremental health risk from a single project is not of much comfort if the area already has a relatively high health risk from other operations like incinerators or other emissions, or if other projects exist at the same time causing a greater cumulative risk or an unacceptably high total risk.",1
Just because the emission is emanating from an area zoned industrial does not mean that in a nearby residential area there should be permitted any exceedances of the appropriate residential standards.Monitoring for compliance against each standards is critical to ensure that exceedances are detected and reported both to authorities and the local community.Enforcement is necessary to ensure that continued or significant breaches result in fines or even a jail sentence for the polluter.Penalties must be significant as otherwise fines are treated as a normal expense of doing business. Compliance must be cheaper than to have continuous breaches.,1
"Assessment should be made of the risks of operations, transporting contaminated material, disposal of waste which may be contaminated including workers' clothes, and a formal emergency response plan should be developed. Every worker and visitor entering the site should have a safety induction personalised to their involvement with the site. The rezoning is often resisted by local communities and local government because of the adverse effects on the local amenity of the remediation and the new development. The main impacts during remediation are noise, dust, odour and incremental health risk. Then there is the noise, dust and traffic of developments.",1
"Then there is the impact on local traffic, schools, playing fields, and other public facilities of the often vastly increased local population.",1
CHEJ (US - Grew out of Love Canal controversy) Greenpeace (International organisation with National sites),1
"The diffuse exposure might contribute to extinction of species and imbalance of sensible ecosystems, as many EPPPs affect the reproductive systems of for example frogs, fish and mussels; genetic, developmental, immune and hormonal health effects to humans and other species, in the same way as e.g. oestrogen-like chemicals; development of microbes resistant to antibiotics, as is found in India.",1
and growth inhibition test of algae. Most medications on the Swedish market are now classified. This gives the health care possibilities to make better choices when prescribing medicines.,1
"France, the Cyclamed take-back program enables people to bring back unused or expired pharmaceuticals back to the pharmacies. Wrong disposal via sink or toilet and hereby to the wastewater system still seems to be a problem in many EU member states: investigations in Germany showed that up to 24% of liquid pharmaceuticals and 7% of tablets or ointments are disposed always or at least ""rarely"" via the toilet or sink.This is one of the aspects considered in the above-mentioned EU strategic approaches.",1
"These observations on feminization of fish by estrogenic compounds in STP effluents have been observed in many countries, and have also been observed in other species, like frogs, alligators and molluscs.",1
"Some SSRIs have been shown to accumulate in exposed fish. Citalopram has been detected in liver from wild perch in low µg per kg levels, and fluoxetine affects the serotonin system in the same way that it does in humans. Fluoxetine has also been shown to affect swimming activity in shellfish; whether this is linked to a disturbance of serotonin function in the brain is still unknown.",1
"The term ""eco-shadow"" has been introduced to describe the ecological impact of antibiotics. Antibiotics with a wide spectrum that are also stable will have a greater impact on the bacterial flora (a long eco-shadow) than those with a narrow antibacterial spectrum which disintegrates more rapidly (a short eco-shadow). The ecological effects of tetracyclines and quinolones have been observed. They are not metabolized in the human body and are therefore excreted unmodified. When entered into the environment they are poorly degraded. They can be toxic to other animals, affecting particularly microorganism and fish.",1
"Kummerer, K.; Kranert, M. (2011). ""Assessment of pharmaceutical waste management at selected hospitals and homes in Ghana"". Waste Management & Research. 30 (6): 625–30. doi:10.1177/0734242X11423286. PMID 22081380. S2CID 594119. Kümmerer, Klaus (2010). ""Pharmaceuticals in the Environment"". Annual Review of Environment and Resources. 35: 57–75. doi:10.1146/annurev-environ-052809-161223. S2CID 29671379.",1
"County Council of Stockholm Mistra Pharma Wiki Database Pharmaceuticals as pollutants - Swedish Doctors for the Environment (LfM) Pharmaceuticals in the Environment Resource Centre. Health Care Without Harm Europe (HCWH). Strategic Approach to International Chemicals Management SAICM, Beograd, November 14, 2011: A critical event? MistraPharma Research programme Pharmas Research programme Ecopharmacovigilance AstraZeneca",1
"all categories of pharmaceuticals including pain killers (analgesics and anti-inflammatory), antibiotics (antibacterial), anticonvulsant drugs, beta blockers, blood lipid regulators, X-ray contrast media, cytostatic drugs (chemotherapy), oral contraceptives, and veterinary pharmaceuticals among many others have been found in the environment. PhACs can be entered into the environment in two main ways; direct and indirect. Indirect sources are PhACs that have performed their biologically intended effect and are passed onto the environment in either their complete or a modified state. PhAC's can be discharged directly by manufacturers of the pharmaceuticals or effluents from hospitals.",1
"However with increasing regulation by local, state and federal regulating agencies, direct discharge is becoming much less of an issue.There are also several indirect sources of PhACs into the environment. One common indirect source of PhACs into the environment is the passing of antibiotics, anesthetics and growth promoting hormones by domesticated animals in urine and manure. This is often stored in large pits before being pumped and applied to fields as fertilizers where many of the PhACs can be washed away by rainfall to aquatic environments. Family pets can also be an indirect source of PhACs into the environment.Most",1
"of the PhACs in the environment however come from human sources. A direct human source is leachate from a landfill. Often the pharmaceuticals that are located in landfills are found in their original, most chemically active state. Most pharmaceuticals are administered and passed through the human body in one of three ways: Metabolized partially or completely within the body and made inactive (Ideal) Partially metabolized and passed through the system Passed through the body unmodified (Worst Case Scenario).",1
"Because PhACs have come into the limelight relatively recently their effects on the environment are not completely understood. PhACs are also not generally intended to come in contact with the environment, and therefore are not typically tested environmentally prior to release. Therefore several tests are required to determine the different mechanisms and side effects of PhACs in the environment making testing largely impractical.Many PhACs have very broad modes of action in humans. Similar, subtle reactions may occur in organisms in the environment that are not easily seen by humans.",1
"Highly specific mechanisms in humans may solicit profound effects at extremely low concentrations. Many effects may not necessarily be readily detectable and lead to ecological change that would be erroneously attributed to natural change. This said there are several effects that have been identified in the literature. One long term, possibly irreversible effect is microbiological resistance to antibiotics (antibiotic resistance). Some bacteria may be able to survive when administered antibiotics (especially at low concentrations). Those colonies will multiply and produce new colonies that are resistant to that particular antibiotic and will not succumb the next time antibiotics are administered.",1
"Because rivers and streams are ever flowing objects they are an ideal pathway for antibiotics to reach bacteria and therefore provide a source and reservoir for resistant strains to develop and establish themselves.Another recent discovery is endocrine disruptors. Endocrine disruptors can replace or disturb the balance of hormones within an organism and have been found to be occurring in waters with a concentration in the ng/L level for certain compounds. Some possible effects of endocrine disruptors are male and female sterility, feminization of males, masculinization of females and abnormal testes growth among many others.",1
"The exact pathway of occurrence of endocrine disruptors is not completely certain, however several pathways have been proposed.Typically PhACs are found in low concentrations, (<1 ug/L) making acute toxicity effects fairly unlikely. However, because of their continual input to the environment it is possible for chronic toxicity effects to occur. One major area of concern with several compounds being present at low levels at the same time is what happens when the compounds mix? It is possible and truly likely that these mixtures will have additive, neutralistic or synergistic effects.",1
But again testing would be both time consuming and very expensive to test all of the combined effects.,1
Acetaminophen Acetylsalicylic Acid Diclofenac Codeine Ibuprofen,1
Macrolide Antibiotics Sulfonamides Fluoroquinolones Chloramphenicol Tylosin Trimethoprim Erythromycin Lincomycin Sulfamethoxazole Trimethoprim,1
Carbamazepine Primidone,1
Metoprolol Propanolol Betaxolol Bisoprolol Nadolol,1
Iopromide Iopamidol Iohexol Diatrizoate,1
Cyclophosphamide Mycophenolic acid Ifosfamide Bicalutamide Epirubicin,1
17α-ethinylestradiol Mestranol 19-norethisterone,1
Aerosol Aeroponics Brocken spectre Drizzle Fog Haze Spray (disambiguation) Rain,1
"The NCEC was formed in 1973 as a government agency. On 1 March 1979 the Centre launched, in cooperation with the Home Office, its Hazfile computer database, made available to fifteen British fire services, listing over 10,000 chemical compounds; this was later replaced by the Chemdata system. A similar system in the USA is called RTECS (Registry of Toxic Effects of Chemical Substances). Most chemical safety legislation in the UK covers the transport of hazardous chemicals by road. Companies carrying dangerous substances must comply with the legislation.",1
The NCEC worked with the European Chemical Industry Council (CEFIC) to develop a set of safety codes for carrying dangerous chemicals for National Intervention in Chemical Transport Emergencies Centres across Europe.,1
"The first symptom of NIHL may be difficulty hearing a conversation against a noisy background. The effect of hearing loss on speech perception has two components. The first component is the loss of audibility, which may be perceived as an overall decrease in volume. Modern hearing aids compensate this loss with amplification. The second component is known as ""distortion"" or ""clarity loss"" due to selective frequency loss. Consonants, due to their higher frequency, are typically affected first. For example, the sounds ""s"" and ""t"" are often difficult to hear for those with hearing loss, affecting clarity of speech.",1
"NIHL can affect either one or both ears. Unilateral hearing loss causes problems with directional hearing, affecting the ability to localize sound.",1
"PTS (Permanent Threshold Shift) is a permanent change of the hearing threshold (the intensity necessary for one to detect a sound) following an event, which will never recover. PTS is measured in decibels. TTS (Temporary Threshold Shift) is a temporary change of the hearing threshold the hearing loss that will be recovered after a few hours to couple of days. Also called auditory fatigue. TTS is also measured in decibels.In addition to hearing loss, other external symptoms of an acoustic trauma can be: Tinnitus Otalgia Hyperacusis Dizziness or vertigo; in the case of vestibular damages, in the inner-ear",1
"Tinnitus is described as hearing a sound when an external sound is not present. Noise-induced hearing loss can cause high-pitched tinnitus. An estimated 50 million Americans have some degree of tinnitus in one or both ears; 16 million of them have symptoms serious enough for them to see a doctor or hearing specialist. As many as 2 million become so debilitated by the unrelenting ringing, hissing, chirping, clicking, whooshing or screeching, that they cannot carry out normal daily activities.Tinnitus is the largest single category for disability claims in the military, with hearing loss a close second.",1
"The third largest category is post-traumatic stress disorder, which itself may be accompanied by tinnitus and may exacerbate it.",1
NIHL has implications on quality of life that extend beyond related symptoms and the ability to hear. The annual disability-adjusted life years (DALYs) were estimated for noise-exposed U.S. workers.[20] DALYs represent the number of healthy years lost due to a disease or other health condition. They were defined by the 2013 Global Burden of Disease (GBD) Study. The DALYs calculation accounts for life limitations experienced because of hearing loss as a lost portion of a healthy year of life. The results indicate the number of healthy years lost by a group of people over a specific time period.,1
"Mining, Construction and Manufacturing workers lost more healthy years than workers in other industry sectors; specifically and respectively in those sectors, 3.5, 3.1 and 2.7 healthy years were lost each year for every 1,000 workers.",1
"The negative impacts of NIHL on one's ability to reciprocate communication, socialize and interact with society are largely invisible. Hearing loss, in general, is not just an issue of volume; individuals may experience difficulty in understanding what is said over the phone, when several people are talking at once, in a large space, or when the speaker's face cannot be seen. Subsequently, challenging social interactions can negatively lead to decreased self-esteem, shame, and fear. This can be more acutely felt by those who experience hearing impairment or loss earlier in life, rather than later when it is more socially accepted.",1
"Such psychosocial states, regardless of age, can lead to social isolation, which is known to negatively impact one's overall health and well-being. The compounding impacts can also lead to depression, especially if hearing impairment leads to tinnitus. Research suggests that those with hearing impairment or loss may be at a greater risk for deterioration of quality of life, as captured by a quote from Helen Keller: ""Blindness cuts us off from things, but deafness cuts us off from people.""",1
"Hearing loss is typically quantified by results from an audiogram; however, the degree of loss of hearing does not predict the impact on one's quality of life. The impact that NIHL can have on daily life and psychosocial function can be assessed and quantified using a validated questionnaire tool, such as the Hearing Handicap Inventory for the Elderly (HHIE). The HHIE is considered a ""useful tool for quantifying the perceived emotional and social/situational consequences of hearing loss."" The original tool was designed to test adults 65 years of age and older; however, modified versions exist.",1
The ear can be exposed to short periods of sound in excess of 120 dB without permanent harm — albeit with discomfort and possibly pain — but long term exposure to sound levels over 85 dB(A) can cause permanent hearing loss.There are two basic types of NIHL: NIHL caused by acoustic trauma NIHL that gradually develops.,1
"NIHL caused by acute acoustic trauma refers to permanent cochlear damage from a one-time exposure to excessive sound pressure. This form of NIHL commonly results from exposure to high-intensity sounds such as explosions, gunfire, a large drum hit loudly, and firecrackers. According to one US study, excessive noise levels in cinemas are sufficiently brief that movie-goers do not experience hearing loss.",1
"The discomfort threshold is the loudness level from which a sound starts to be felt as too loud and thus painful by an individual. Industry workers tend to have a higher discomfort threshold (i.e. the sounds must be louder to feel painful than for non-industry workers), but the sound is just as harmful to their ears. Industry workers often have NIHL because the discomfort threshold is not a relevant indicator of the harmfulness of a sound.",1
"Gradually developing NIHL refers to permanent cochlear damage from repeated exposure to loud sounds over a period of time. Unlike acoustic trauma, this form of NIHL does not occur from a single exposure to a high-intensity sound pressure level. Gradually developing NIHL can be caused by multiple exposures to excessive noise in the workplace or any source of repetitive, frequent exposures to sounds of excessive volume, such as home and vehicle stereos, concerts, nightclubs, and personal media players. Earplugs have been recommended for those people who regularly attend live music concerts.",1
"A range of earplugs are now available ranging from inexpensive disposable sets to custom fit, attenuated earplugs which provide true fidelity at reduced audio levels.",1
"Although research is limited, it suggests that increased exposure to loud noise through personal listening devices is a risk factor for noise induced hearing loss. A systematic review of adolescents and young adults reports that over half of the research subjects had been exposed to sound through music exposure on personal devices greater than recommended levels. Research suggests stronger correlations between extended duration or elevated usage of personal listening devices and hearing loss.",1
"About 22 million workers are exposed to hazardous noise, with additional millions exposed to solvents and metals that could put them at increased risk for hearing loss. Occupational hearing loss is one of the most common occupational diseases. 49% of male miners have hearing loss by the age of 50. By the age of 60, this number goes up to 70%. Construction workers also have an elevated risk. A screening program focused on construction workers employed at US Department of Energy facilities found 58% with significant abnormal hearing loss due to noise exposures at work.",1
Occupational hearing loss is present in up to 33% of workers overall. Occupational exposure to noise causes 16% of adult disabling hearing loss worldwide.The following is a list of occupations that are most susceptible to hearing loss: Agriculture Mining Police Construction Manufacturing Utilities Transportation Military Musicians Orchestra conductors,1
"Musicians, from classical orchestras to rock groups, are exposed to high decibel ranges. Some rock musicians experience noise-induced hearing loss from their music, and some studies have found that ""symphonic musicians suffer from hearing impairment and that the impairment might be ascribed to symphonic music.""In terms of the population of musicians, usually the rates of hearing disorders is lower than other occupational groups. However, many exposure scenarios can be considered a risk of hearing disorders, and many individuals are negatively impacted by tinnitus and other hearing problems.",1
"While some population studies have shown that the risk for hearing loss increases as music exposure increases, other studies found little to no correlation between the two. Experts at the 2006 ""Noise-Induced Hearing Loss in Children at Work and Play"" Conference agreed that further research into this field was still required before making a broad generalization about music-induced hearing loss.Given the extensive research suggesting that industrial noise exposure can cause sensorineural hearing loss, a link between hearing loss and music exposures of similar level and duration to industrial noise seems highly plausible.",1
"Determining which individuals or groups are at risk for such exposures may be a difficult task. Despite concerns about the proliferation of personal music players, there is only scarce evidence supporting their impact on hearing loss, and some small-sample studies suggest that only a fraction of users are affected. People from ages to 6–19 have an approximately 15% rate of hearing loss. Recommendations for musicians to protect their hearing were released in 2015 by NIOSH. The recommendations emphasized education of musicians and those who work in or around the music industry.",1
"Annual hearing assessments were also recommended to monitor thresholds, as were sound level assessments to help determine the amount of time musicians and related professionals should spend in that environment. Hearing protection was also recommended, and the authors of the NIOSH recommendations further suggested that musicians consider custom earplugs as a way to combat NIHL.In 2016, the National Association of Schools of Music (NASM), a music school accreditation body in the US, published a hearing health advisory to help with efforts directed at informing faculty and music students about potential risks associated with school activities, during rehearsal and performance.NASM-PAMA",1
"Research suggests that education programs can be beneficial to musicians, as can working with hearing care professionals to help address the specific issues that musicians face.In 2018, a musician named Chris Goldscheider won a case against Royal Opera House for damaging his hearing in a rehearsal of Wagner's thunderous opera Die Walkure.",1
"In the United States, the Occupational Safety and Health Administration (OSHA) describes standards for occupational noise exposure in articles 1910.95 and 1926.52. OSHA states that an employer must implement hearing conservation programs for employees if the noise level of the workplace is equal to or above 85 dB(A) for an averaged eight-hour time period. OSHA also states that ""exposure to impulsive or impact noise should not exceed 140 dB peak sound pressure level"".",1
"The National Institute for Occupational Safety and Health (NIOSH) recommends that all worker exposures to noise should be controlled below a level equivalent to 85 dBA for eight hours to minimize occupational noise induced hearing loss. NIOSH also recommends a 3 dBA exchange rate so that every increase by 3 dBA doubles the amount of the noise and halves the recommended amount of exposure time. The United States Department of Defense (DoD) instruction 605512 has some differences from OSHA 1910.95 standard, for example, OSHA 1910.95 uses a 5 dB exchange rate and DoD instruction 605512 uses a 3 dB exchange rate.",1
"the European Union, directive 2003/10/EC mandates that employers shall provide hearing protection at noise levels exceeding 80 dB(A), and that hearing protection is mandatory for noise levels exceeding 85 dB(A). Both values are based on 8 hours per day, with a 3 dB exchange rate. A 2017 Cochrane review found low-quality evidence that legislation to reduce noise in the workplace was successful in reducing exposure both immediately and long-term.",1
"Several sports stadiums pride themselves in having louder stadiums than their opponents because it may create a more difficult environment for opposing teams to play in. Currently, there are few studies on noise in sports stadiums, but some preliminary measurements show noise levels reaching 120 dB, and informal studies suggest that people may receive up to a 117% noise dose in one game. There are many challenges that face hearing conservationists such as sports culture.",1
"Sports fans will create noise in an attempt to distract other teams, and some sports teams have been known to create artificial noise in an attempt to make the stadium louder. In doing that, workers, teams, and fans may be at potential risk for damage to the auditory system. NIOSH conducted a health hazard evaluation and studies at Monster Trucking and Stock Car racing events, spectators average noise levels ranged from 95 to 100 dBA at the Monster Truck event and over 100 dBA at the stock car racing event.",1
"NIOSH researchers also published noise exposure levels for drivers, crew members, and staff. Noise levels at the Bristol Motor Speedway ranged from 96 dBA in the stands to 114 dBA for a driver inside a car during practice. Peak noise levels in the Pit area reached or exceeded 130 dB SPL, a level often associated with human hearing threshold for pain. Several prominent NASCAR drivers have complete or partial hearing loss and other symptoms from their many years of exposure.During",1
"the FIFA World Cup in 2010, noise levels created by fans blowing Vuvuzela averaged 131 dBA at the horn opening and 113 dBA at 2 meter distance. Peak levels reached 144 dB SPL, louder than a jet engine at takeoff.A study of occupational and recreational noise exposure at indoor hockey arenas found noise levels from 81 dBA to 97 dBA, with peak sound pressure levels ranging from 105 dB SPLto 124 dB SPL. Another study examined the hearing threshold of hockey officials and found mean noise exposures of 93 dBA. Hearing threshold shifts were observed in 86% of the officials (25/29).In",1
"Workers often will not exceed OSHA standards of 90 dBA, but NIOSH, whose focus is on best practice, has stricter standards which say that when exposed to noise at or exceeding 85 dBA workers need to be put on a hearing conservation program. Workers may also be at risk for overexposure because of impact noises that can cause instant damage. Experts are suggesting that sports complexes create hearing conservation programs for workers and warn fans of the potential damage that may occur with their hearing.Studies",1
"are still being done on fan exposure, but some preliminary findings show that there are often noises that can be at or exceed 120 dB which, unprotected, can cause damage to the ears in seconds. NIHL occurs when too much sound intensity is transmitted into and through the auditory system. An acoustic signal from a sound source, such as a radio, enters into the external auditory canal (ear canal), and is funneled through to the tympanic membrane (eardrum), causing it to vibrate.",1
"The vibration of the tympanic membrane drives the middle ear ossicles, the malleus, incus, and stapes to vibrate in sync with the eardrum. The middle ear ossicles transfer mechanical energy to the cochlea by way of the stapes footplate hammering against the oval window of the cochlea, effectively amplifying the sound signal. This hammering causes the fluid within the cochlea (perilymph and endolymph) to be displaced.",1
Displacement of the fluid causes movement of the hair cells (sensory cells in the cochlea) and an electrochemical signal to be sent from the auditory nerve (CN VIII) to the central auditory system within the brain. This is where sound is perceived. Different groups of hair cells are responsive to different frequencies. Hair cells at or near the base of the cochlea are most sensitive to higher frequency sounds while those at the apex are most sensitive to lower frequency sounds.,1
"There are two known biological mechanisms of NIHL from excessive sound intensity: damage to the structures called stereocilia that sit atop hair cells and respond to sound, and damage to the synapses that the auditory nerve makes with hair cells, also termed ""hidden hearing loss"".",1
"The symptoms mentioned above are the external signs of the physiological response to cochlear overstimulation. Here are some elements of this response: Damaged sensory hairs (stereocilia) of the hair cells; damaged hair cells degenerate and die. In humans and other mammals, dead hair-cells are never replaced; the resulting hearing loss is permanent. Inflammation of the exposed areas. This inflammation causes poor blood flow in the exposed blood vessels (vascular stasis), and poor oxygen supply for the liquid inside the cochlea (endolymphatic hypoxia) Those noxious conditions worsen the damaged hair cell degeneration. Synaptic damages, by excitotoxicity.",1
"Noise overstimulation causes an excessive release of glutamate, causing the postsynaptic bouton to swell and burst. However the neuron connection can be repaired, and the hearing loss only caused by the ""wiring"" (i.e. excitotoxicity) can thus be recovered within 2–3 days.",1
"When the ear is exposed to excessive sound levels or loud sounds over time, the overstimulation of the hair cells leads to heavy production of reactive oxygen species, leading to oxidative cell death. In animal experiments, antioxidant vitamins have been found to reduce hearing loss even when administered the day after noise exposure. They were not able to fully prevent it. Antioxidants however do not seem to be effective in protecting the human ear. Damage ranges from exhaustion of the hair (hearing) cells in the ear to loss of those cells.",1
"NIHL is, therefore, the consequence of overstimulation of the hair cells and supporting structures. Structural damage to hair cells (primarily the outer hair cells) will result in hearing loss that can be characterized by an attenuation and distortion of incoming auditory stimuli. During hair cell death 'scars' develop, which prevent potassium rich fluid of the endolymph from mixing with the fluid on the basal domain. The potassium rich fluid is toxic to the neuronal endings and can damage hearing of the entire ear.",1
"If the endolymph fluid mixes with the fluid on the basal domain the neurons become depolarized, causing complete hearing loss. In addition to complete hearing loss, if the area is not sealed and leakage continues further tissue damage will occur. The 'scars' that form to replace the damaged hair cell are caused by supporting hair cells undergoing apoptosis and sealing the reticular lamina, which prevents fluid leakage. The cell death of two supporting hair cells rapidly expands their apical domain, which compresses the hair cell beneath its apical domain.",1
"Recent studies have investigated additional mechanisms of NIHL involving delayed or disabled electrochemical transmission of nerve impulses from the hair cell to and along the auditory nerve. In cases of extreme acute acoustic trauma, a portion of the postsynaptic dendrite (where the hair cell transfers electrochemical signals to the auditory nerve) can rupture from overstimulation, temporarily stopping all transmission of auditory input to the auditory nerve. This is known as excitotoxicity. Usually, this sort of rupture heals within about five days, resulting in functional recovery of that synapse.",1
"While healing, an over-expression of glutamate receptors can result in temporary tinnitus, or ringing in the ears. Repeated ruptures at the same synapse may eventually fail to heal, leading to permanent hearing loss.Prolonged exposure to high intensity noise has also been linked to the disruption of ribbon synapses located in the synaptic cleft between inner hair cells and spiral ganglion nerve fibers, leading to a disorder referred to as cochlear synaptopathy or hidden hearing loss.",1
"This disorder is cumulative and over time, leads to degeneration of the spiral ganglion cells of the inner ear and overall dysfunction in the neural transmission between auditory nerve fibers and the central auditory pathway. The most common symptom of cochlear synaptopathy is difficulty understanding speech, especially in the presence of competing noise. However, this type of hearing impairment is often undetectable by conventional pure tone audiometry, thus the name ""hidden"" hearing loss. Acoustic over-exposure can also result in decreased myelination at specific points on the auditory nerve.",1
"Myelin, an insulating sheath surrounding nerve axons, expedites electrical impulses along nerves throughout the nervous system. Thinning of the myelin sheath on the auditory nerve significantly slows the transmission of electrical signals from hair cell to auditory cortex, reducing comprehension of auditory stimuli by delaying auditory perception, particularly in noisy environments.",1
"NIHL is generally observed to decrease hearing sensitivity in the higher frequencies, also called an audiometric notch, especially at 4000 Hz, but sometimes at 3000 or 6000 Hz. The symptoms of NIHL are usually presented equally in both ears.This typical 4000 Hz notch is due to the transfer function of the ear. As does any object facing a sound, the ear acts as a passive filter, although the inner ear is not an absolute passive filter because the outer hair cells provide active mechanisms.",1
"A passive filter is a low pass: the high frequencies are more absorbed by the object because high frequencies impose a higher pace of compression-decompression to the object. The high frequency harmonics of a sound are more harmful to the inner-ear.However, not all audiological results from people with NIHL match this typical notch. Often a decline in hearing sensitivity will occur at frequencies other than at the typical 3000–6000 Hz range. Variations arise from differences in people's ear canal resonance, the frequency of the harmful acoustic signal, and the length of exposure.",1
"Also referred to Hearing Loss Prevention Programs and Hearing Preservation Programs Workers in general industry who are exposed to noise levels above 85 dBA are required by the Occupational Safety and Health Administration (OSHA) to be in a hearing conservation program (HCP), which includes noise measurement, noise control, periodic audiometric testing, hearing protection, worker education, and record keeping. Twenty-four states, Puerto Rico, and the U.S. Virgin Islands have OSHA-approved state plans and have adopted their own standards and enforcement policies. Most of these state standards are identical to those of federal OSHA.",1
"However, some states have adopted different standards or may have different enforcement policies. Most health and safety regulations are designed to keep damage risk within ""acceptable limits"" — that is, some people are likely to incur a hearing loss even when exposed to less than the maximum daily amount of noise specified in a regulation. Hearing conservation programs in other arenas (schools, military) have become more common, and it has been established that unsafe listening behaviors, such as listening to loud noise for extended periods of time without protection, persist despite knowledge of potential hearing loss effects.However,",1
"it is understood that HCPs are designed to change behavior, which is known to be a complex issue that requires a multi-faceted approach. According to Keppler et al. in their 2015 study of such programming, they cite the necessary attitude change towards the susceptibility of risk and degree of severity of hearing loss. Among young adults, the concept of severity is most crucial because it has been found that behavior change may not occur unless an individual experiences NIHL or similarly related NIHL tinnitus, furthering warranting a multi-pronged approach based on hearing conservation programming and education.",1
"Other possible solutions include improved enforcement of existing legislation and better implementation of well-designed prevention programmes, which have not yet been proven conclusively to be effective. The implications is that further research could affect conclusions reached. Several hearing conservation programs have been developed to educate a variety of audiences about the dangers of NIHL and how to prevent it. Dangerous Decibels aims to significantly reduce the prevalence of noise induced hearing loss and tinnitus through exhibits, education and research. We're hEAR for You is a small non-profit that distributes information and ear plugs at concert and music festival venues.",1
"The Buy Quiet program was created to combat occupational noise exposures by promoting the purchase of quieter tools and equipment and encourage manufacturers to design quieter equipment. The National Institute on Deafness and Other Communication Disorders developed the It's a Noisy Planet. Protect their Hearing educational campaign to inform preteens, parents, and educators about the causes and prevention of NIHL.",1
The National Institute for Occupational Safety and Health partnered with the National Hearing Conservation Association in 2007 to establish the Safe-in-Sound Excellence and Innovation in Hearing Loss Prevention Awards to recognize organizations that are successfully implementing hearing loss prevention concepts into their daily routines.,1
"Education is key to prevention. Before hearing protective actions will take place, a person must understand they are at risk for NIHL and know their options for prevention. Hearing protection programs have been hindered by people not wearing the protection for various reasons, including the desire to converse, uncomfortable devices, lack of concern about the need for protection, and social pressure against wearing protection. Although youth are at risk for hearing loss, one study found that 96.3%",1
"of parents did not believe their adolescents were at risk, and only 69% had talked to their children about hearing protection; those aware of NIHL risks were more likely to talk to their teens.Programs that increased the proportion of workers wearing hearing protection equipment did reduce overall hearing loss.",1
"Medications are still being researched to determine if they can prevent NIHL. No medication has been proven to prevent or repair NIHL in humans. There is evidence that hearing loss can be minimized by taking high doses of magnesium for a few days, starting as soon as possible after exposure to the loud noise. A magnesium-high diet also seems to be helpful as an NIHL-preventative if taken in advance of exposure to loud noises.",1
"Along the same line of research, higher dietary or supplemental intakes of magnesium combined with antioxidant vitamins, specifically β-carotene and vitamin C, appear to be associated with a lower risk of hearing loss. Consuming excessive amounts of magnesium can be potentially harmful, so any treatments should be followed with caution.Tentative research in a mouse model suggests that blocking the GluA2-lacking, calcium-permeable forms of the AMPA receptor protects against hearing damage.",1
"Despite different people having different thresholds for what noises are painful, this pain threshold has no correlation with which noises cause hearing damage. The ear can not get more resistant to noise harmfulness by training it to noise. The cochlea is partially protected by the acoustic reflex, but being frequently exposed to noise does not lower the reflex threshold. It had been observed that noise conditioning (i.e. exposure to loud non-traumatizing noise) several hours prior to the exposure to traumatizing sound level, significantly reduced the damages inflicted to the hair-cells.",1
"The same ""protective effect"" was also observed with other stressors such as heat-shock conditioning and stress (by restraint) conditioning. This ""protective effect"" only happens if the traumatizing noise is presented within an optimum interval of time after the sound-conditioning session (-24 hours for a 15 min. sound-conditioning; no more protection after 48 hours). This ""protective effect"" had long been thought to involve the active mechanisms of the outer hair cells and the efferent system commanding them. The contractile effect of the outer hair cells, activated by the efferent nervous system has been proven to provide a protective effect against acoustic trauma.",1
"However, a 2006 study revealed a different protective mechanism for stress conditioning. The study revealed that the stressor (sound, heat, or stress) conditioning increases the receptibility to glucocorticoid, a kind of anti-inflammatory hormone. The effects of glucocorticoid thus mitigate the inflammation from an acoustic trauma that can lead to hearing loss. In fact, high doses of corticoids are often prescribed by physicians after an acoustic-trauma in order to mitigate the inflammatory response. Summarized, sound (or other stressor) conditioning is a pre-emptive medication against cochlea inflammation. It does not make the ear more resistant to noise.",1
"It reduces the inflammation caused by the acoustic trauma, which would cause subsequent damages to hair cells. While an anti-inflammatory medication would increase the quantity of anti-inflammatory hormone in the whole body, noise conditioning increases the number of receptors for the anti-inflammatory hormone, and only in the areas where it is much needed (i.e. cochlea).Physiological response stressor (noise, heat shock or stress) conditioning activates hormonal glands: the HPA axis.",1
"Note that the HPA axis is associated to the immune system this HPA axis activation results in the up regulation of glucocorticoid receptors (GR) in the cochlea and the paraventricular nucleus (PVN) of the hypothalamus. Note that the glucocorticoid hormone is a kind of immune-reaction-inhibitor, including the inflammation reaction. This up regulation of GR thus prevents GR down regulation induced by acoustic trauma The protective effect of noise-conditioning is blocked by adrenalectomy or pharmacological treatment with RU486 + metyrapone (a glucocorticoid receptor antagonist). Treatment options that offer ""cures"" for NIHL are under research and development.",1
"Several clinical trials have been conducted to treat temporary NIHL occurring after a traumatic noise event, such as a gunshot or firework. In 2007, individuals with acute acoustic trauma after firecracker exposure were injected intratympanically with a cell permeable ligand, AM-111. The trial found AM-111 to have a therapeutic effect on at least two cases of those with acute trauma. Treatment with a combination of prednisolone and piracetam appeared to rescue patients with acute trauma after exposure to gunshots.",1
"However, those who received the treatment within an hour of exposure had higher rates of recovery and significantly lower threshold shifts compared to those who received treatment after one hour.Additionally, clinical trials using antioxidants after a traumatic noise event to reduce reactive oxygen species have displayed promising results. Injections with allopurinol, lazaroids, α-D-tocopherol, and mannitol were found to reduce the threshold shift after noise exposure. Another antioxidant, Ebselen, has been shown to have promising results for both TTS and PTS. Ebselen mimics gluthathione peroxide, an enzyme that has many functions, including scavenging hydrogen peroxide and reactive oxygen species.",1
"After noise exposure, gluthathione peroxide decreases in the ear. An oral administration of ebselen in both preclinical tests on guinea pigs and human trials indicate that noise induced TTS and PTS was reduced.Recently, combination therapy with hyperbaric oxygen therapy (HBO) and corticosteroids has been found to be effective for acute acoustic trauma. Acute noise exposure causes inflammation and lower oxygen supply in the inner ear. Corticosteroids hinder the inflammatory reaction and HBO provides an adequate oxygen supply. This therapy has been shown to be effective when initiated within three days after acoustic trauma. Therefore, this condition is considered an ENT emergency.",1
"One study involves the replacement of damaged hair cells with regenerated cells, via the mechanism of gene transfer of atonal gene Math1 to pluripotent stem cells within the inner ear. Other atonal genes are being studied to induce regeneration of hair cells in the inner ear.",1
"Hearing aids can mask or cover up the tinnitus, and many with hearing loss and tinnitus find relief by using hearing aids. Though there is no cure or agreed-upon treatment for tinnitus, some drugs have been shown to provide temporary reduction of tinnitus. Other treatments for tinnitus include cognitive-behavioral therapy, biofeedback, and electrical stimulation. Annual audiological evaluations are recommended to monitor any changes in a patient's hearing and to modify hearing-aid prescriptions.",1
"It examines health and nutritional status of adults and children in the United States. While there is no perfect way to pinpoint hearing loss from excessive noise, researchers look for audiometric notches in a hearing test—dips in the ability to hear certain frequencies—as signs of possible NIHL. As of 2011 data, approximately 24% adults age 20–69 in the United States has an audiometric notch. This data identified differences in NIHL based on age, gender, race/ethnicity, and whether or not a person is exposed to noise at work. Among people aged 20–29, 19.2% had an audiometric notch, compared to 27.3%",1
"of people aged 50–59. Males in general had a notch more often than females, regardless of occupational noise exposure, for both unilateral and bilateral audiometric notches. An epidemiological study of 6557 automotive manufacturing workers in China (median age 28 years old) reported that in 62% of the settings where noise exposures were evaluated, levels exceeded the recommended level of 85 dBA. The prevalence of hearing loss was 41% among auto part manufacturing workers, followed by 31% of power train workers and 24% in automotive manufacturing. Across job categories, the highest prevalence rate was observed among welders, of 53%.",1
"The prevalence rates were associated with noise levels and the workers' cumulative noise exposure.Occupational noise exposure is the main risk factor for work-related hearing loss. One study examined hearing test results obtained between 2000 and 2008 for workers ages 18–65 who had a higher occupational noise exposure than the average worker. Of the sample taken, 18% of the workers had hearing loss. Of the occupations considered, the Mining industry had the highest prevalence and risk of hearing loss, at approximately 27%. Other industries with a higher prevalence and risk included Construction (23.48%)",1
"and Manufacturing, especially Wood Product and Non-metallic Mineral Product (19.89%), Apparel (20.18%), and Machinery (21.51%). Estimates of rates of hearing loss have been reported for workers in the Agriculture, Forestry, Fishing, and Hunting (AFFH) sector. The overall prevalence of hearing loss (defined as a pure‐tone average threshold across frequencies 1000, 2000, 3000, and 4000 Hz of 25 dB or more in either ear) was 15% but that rate was exceeded in several of the subsectors of those industries. Prevalences were highest among workers in Forest Nurseries and Gathering of Forest Products at 36% and Timber Tract Operations at 22%.",1
"the overall HSA sector prevalence for hearing loss was 19%, the prevalence in the Medical Laboratories subsector and the Offices of All Other Miscellaneous Health Practitioners subsector were 31% and 24%, respectively. The Child Day Care Services subsector had a 52% higher risk than the reference industry of workers who are not exposed to noise at work (Couriers and Messengers). Overall, audiometric records show that about 33% of working-age adults with a history of occupational noise exposure have evidence of noise-induced hearing damage, and 16% of noise-exposed workers have material hearing impairment.",1
"Advisories on Hearing HealthNoise from power sources NIOSH Power Tools Database Buy Quiet Noise-Induced Hearing Loss from the National Institutes of Health Dangerous Decibels Includes general information and a ""virtual exhibit"" as well as resources for teachers. NIOSH Noise and Hearing Loss Prevention Topic Page NIOSH Power Tools Sound Pressure and Vibrations Database New York City construction noise control products and vendor guidance sheet Online Audiometric Test Calibrated test, up to 80 dBHL. Confirm your hearing status loss and track if it changes over time. An online audiometric test featuring equal loudness curves NIOSH Buy Quiet Topic Page www.cochlea.org/en/noise",1
"- animation of damage of hairs, harmful intensities graph www.cochlea.eu/en/hair-cells - illustrations and images of hair cells A video hosted by the National Hearing Conservation Association about noise-exposed workers with hearing loss or tinnitus",1
"At 11:30 PM on the evening of Friday June 8, 1990, an explosion in the cargo room of the Norwegian oil tanker the Mega Borg “ruptured the bulkhead between the pump room and the engine room”, causing the ship to catch fire and begin to leak oil. The 853-foot-long, 15-year-old vessel was about 50 miles off the coast of Galveston, Texas when the explosion occurred. The weather at the time was calm and the tanker had easily passed Coast Guard safety inspections in April earlier that year.",1
"While the direct cause of the engine room explosion remains unknown, the initial blast occurred during a lightering process in which the Mega Borg was transferring oil onto a smaller Italian tanker, the Fraqmura, in order to then transport the oil to Houston. This transfer was necessary, as the Mega Borg was too large to dock at the Texas port. Three million gallons of the total 38 million gallons of light Angolan Palanca crude oil on board the tanker were able to be transferred to the Fraqmura before the blast.",1
"The light crude oil spilled in the Mega Borg incident was brown and evaporated much quicker than the heavy crude oil in spills such as the Exxon Valdez. This means that the oil is less likely to heavily coat nearby beaches, flora and fauna, however the tanker was carrying more oil than the Exxon Valdez incident spilled in total, so there was a lot of concern about the oil not being able to evaporate if the slick became too thick.The",1
"The nearest fire control equipment of the type necessary for a fire of this size and type was in Louisiana, so it had to be shipped in and was not available as quickly as some people believe it should have been. Additional equipment was shipped in from the Netherlands, adding to the belief that it could have been found closer to the spill site and thus the oil could have been contained earlier.",1
"Redding answered this by explaining that “A foam attack without extensive cooling has no chance of killing a fire of this type.” The explosion’s initial damage was inflicted on the 41 crew members aboard – two of them died, two disappeared and are presumed dead, and 17 were injured.The Gulf of Mexico is one of the United States’ richest fishing grounds, and the Mega Borg spill added to an abundance of oil spills that have happened in the area. This affects not only marine microorganisms in deep waters, but larger deep-water fish and thus both recreational and commercial fishermen.",1
"Additionally, the National Wildlife Refuges near Galveston’s shores, nearby salt marches, and oyster reefs were all in potential danger depending on the extent of the slick’s spread.On June 29, 1990, it was reported that tar balls from the Mega Borg spill were appearing as far away as Louisiana beaches. The Mega Borg spill brought attention to the 984 protocols of legislation that have been held up in Senate since 1985. The Protocols passed the House, but have not been ratified due to arguments over international liabilities and whether or not the US should join international funding groups for oil spills.",1
"If ratified, the protocols would do a number of things including create multiple new federal response teams and a new fleet of special containment booms and skimmers. Media related to Mega Borg fire at Wikimedia Commons AP. ""FIREFIGHTERS START GAINING CONTROL OVER STUBBORN SUPERTANKER BLAZE."" Journal of Commerce [Galveston] 13 June 1990, sec. MARITIME: 8B. Lexis Nexis. Web. 21 Jan. 2014. Belkin, Lisa. ""Flaming Oil Is Spilled Into Gulf as Blasts Rack Tanker."" The New York Times 11 June 1990, sec. A: 1.lexisnexis.com. Web. 21 Jan. 2012. Booth, William.",1
"21 Jan. 2014. DiBenedetto, William. ""SKINNER URGES PASSAGE OF OIL SPILL LEGISLATION, ADOPTION OF TREATIES."" Journal of Commerce [Washington] 14 June 1990, sec. MARITIME: 8B. Lexis Nexis. Web. 21 Jan. 2014. Fehr, Stephen C.. ""New Blasts Wrack Tanker Burning off Texas; Spill of Light Crude Oil Is Accelerated; Four Are Feared Dead."" The Washington Post[Washington] 11 June 1990, sec. First Section: A1. Lexis Nexis. Web. 21 Jan. 2014. Leavitt, Paul. ""Mega Borg tar balls appear in Louisiana."" USA Today [Galveston] 29 June 1990, Final Edition ed., sec. NEWS: 3A. Print. Leveille, Thomas P..",1
"""The Mega Borg Fire and Oil Spill: A Case Study."" U.S. Coast Guard Marine Safety Office Oil Spill Conference (1991): n. pag.ioscproceedings.org. Web. 21 Jan. 2014. Maraniss, David. ""Shipowner's Choice of Firefighters Stirs Dispute; Local Crews Could Have Arrived Faster, Competitor Says; Situation at Tanker Stabilized."" The Washington Post 13 June 1990, Final Edition ed., sec. First Section: A4. Lexis Nexis. Web. 21 Jan. 2014. Morris, Julie, and Mark Mayfield. ""'Gulf is just being trashed'; Oil spill stirring up more troubled waters,' More and more risk for the gulf'."" USA Today [Galveston] 12 June 1990, Final Edition ed., sec. NEWS: 1A.",1
"Lexis Nexis. Web. 21 Jan. 2014. Morris, Julie. ""Legacy of the Mega Borg; Bacteria could mop up oil; Wary Texas keeps an eye on beaches."" USA Today[Galveston] 15 June 1990, sec. NEWS: 3A. Lexis Nexis. Web. 21 Jan. 2012. Reports, Wire. ""FIREBOATS ATTACK GULF TANKER BLAZE."" Journal of Commerce [Galveston] 12 June 1990, sec. MARITIME: 3B. Lexis Nexis. Web. 21 Jan. 2014. Rigby, Peter. ""Norwegian Tanker Me6ga Borg Rocked by Explosion."" Sunday Tasmanian [Hobart Mercury] 13 June 1990: 1. Lexis Nexis. Web. 21 Jan. 2014. Staff, Journal of Commerce. ""MEXICAN SHIP AIDED MEGA BORG OIL CLEANUP.""",1
"Journal of Commerce [Mexico City] 6 July 1990, sec. MARITIME: 6B. Lexis Nexis. Web. 21 Jan. 2014. Suro, Roberto. ""Ship Burned All Week; Salvagers Explain Why."" The New York Times 17 June 1990, Late Edition ed., sec. Section 1, National Dest: 18. Lexis Nexis. Web. 21 Jan. 2014. ""THE MEGA BORG FIRE AND OIL SPILL: A CASE STUDY."" U.S. Coast Guard Marine Safety Office Oil Spill Conference (1991): n. pag. ioscproceedings.org. Web. 21 Jan. 2014.",1
"Harford County, Maryland, found MTBE in wells near several of its filling stations beginning in 2004. This led the state of Maryland to make moves to ban MTBE.In 2005, an Exxon-Mobil station in Fallston, Maryland, was found to be leaking MTBE into the local wells. The discovery resulted in the station being abruptly closed. Exxon-Mobil referred to the closure as a ""business decision"". Following the closure, MTBE levels in the area dropped.In September 2004, Harford County placed a six-month moratorium on construction of filling stations.",1
"In 2006, the wells of a neighborhood in Jacksonville, Maryland, were contaminated by a spill of 26,000 gallons of gasoline from an Exxon-Mobil station in the area, resulting in an ongoing court battle. The suit has been filed by the state of Maryland's Department of the Environment on behalf of the area's residents, seeking millions of dollars in damages from Exxon-Mobil. Many residents also filed their own separate lawsuits.The case began in 2006, when a gasoline tank sprang a leak that was not detected for 34 days. Testing of 120 wells resulted in dangerously high levels of MTBE being found.",1
"March 2009, a jury awarded $150 million in damages to some of the area's residents. The jury did not assess any punitive damages in the case, finding that Exxon Mobil did not act fraudulently. A separate case including over 150 property owners as plaintiffs began in early 2011. Punitive damages were awarded to the second group of plaintiffs, on the basis that Exxon acted fraudulently, however this decision was later reversed.",1
"The leakage problem is partially attributed to the lack of effective regulations for underground storage tanks, but spillage from overfilling is also a contributor. As an ingredient in unleaded gasoline, MTBE is the most water-soluble component. When dissolved in groundwater, MTBE will lead the contaminant plume with the remaining components such as benzene and toluene following. Thus the discovery of MTBE in public groundwater wells indicates that the contaminant source was a gasoline release. Its criticism and subsequent decreased usage, some claim, is more a product of its easy detectability (taste) in extremely low concentrations (ppb) than its toxicity.",1
The lack of MTBE liability protection in the law also prompted refiners to substitute ethanol for MTBE as a gasoline additive.,1
IMO article on the 2003 Protocol ePolitix article on the Act,1
"Mercury release occurs through both natural and anthropogenic processes. Natural processes are mainly geogenic such as volcanic activities and land emissions through the soil. Volcanoes release mercury from the underground reservoirs upon eruption. Land emissions are usually observed in regions closer to plate tectonic boundaries where soils are enriched with minerals such as cinnabar (mercury sulfide(HgS)). This mercury is released, usually as a salt, either by natural weathering of the rocks or by geothermal reactions. While natural phenomena account for a certain percentage of present-day emissions, anthropogenic emissions alone have increased mercury concentration in the environment by threefold.",1
"Global Mercury Assessment 2013 states main anthropogenic sources of mercury emission are artisanal and small–scale gold mining, fossil fuel burning and primary production of non-ferrous metals. Other sources such as cement production, consumer product waste, crematoria, contaminated sites, and the chloralkali industry also contribute in relatively small percentages.Mercury enters the ocean in different ways. Atmospheric deposition is the largest source of mercury in the oceans. Atmospheric deposition introduces three types of mercury to the ocean. Gaseous elemental mercury (Hg0) enters the ocean through air-water exchange. Inorganic mercury (Hg2+/HgII) and particle-bound mercury (Hg(P)) enter through wet and dry deposition.",1
"In addition, mercury enters the ocean via rivers, estuaries, sediments, and, hydrothermal vents, etc. These sources also release organic mercury compounds such as Methyl mercury. Once they are in the ocean they can undergo many reactions primarily grouped as; redox reactions (gain or loss of electrons), adsorption processes (binding to solid particles), methylation, and demethylation (addition or removal of a methyl group).",1
"Mercury can enter seas and the open ocean as a result of the down-stream movement and re-deposition of contaminated sediments from urban estuaries. For example, high total Hg content up to 5 mg/kg and averaging about 2 mg/kg occur in the surface sediments and sediment cores of the tidal River Mersey, UK, due to discharge from historical industries located along the banks of the tidal river including industries such as historical chlor-alkali industry.",1
"Sediments along a 100 km stretch of the Thames Estuary have also been shown to have total Hg contents of up to 12 mg/kg and a mean of 2 mg/kg with the highest concentrations found at depth in and around London. A gradual and statistically significant decrease in sedimentary Hg content occurs in the Thames as a results of greater distance from the historical and current point-sources, sorption and in-river deposition in the mud reaches as well as dilution by marine sands from the Southern North Sea.",1
"The biological transformations are different and have a smaller rate compared to sunlight-driven processes above. Inorganic mercury Hg2+ and methyl mercury have the ability to get adsorbed into particles. A positive correlation of binding is observed for the amount of organic matter vs. the concentration of these mercury species showing that most of them bind to organic matter. This phenomenon can determine the bioavailability and toxicity of mercury in the ocean. Some methyl mercury is released into the ocean through river run-off. However, most of the methyl mercury found in the ocean is produced in –situ (inside the ocean itself).",1
"addition to the cleaning processes, minimizing the usage of coal power and shifting to cleaner energy sources, reducing small-scale artisanal gold mining, proper treatment of industrial mercury waste, and implementation policies are sound approaches to reduce mercury emissions in the long term-large scale plan. Public awareness is critical in achieving this goal.",1
"MARPOL is divided into Annexes according to various categories of pollutants, each of which deals with the regulation of a particular group of ship emissions.",1
"Oil discharge monitoring equipment (ODME) is a very important technology mentioned in MARPOL Annex I that has greatly helped improve sanitation in these areas.The oil record book is another integral part of MARPOL Annex I, helping crew members log and keep track of oily wastewater discharges, among other things.",1
"Previously, chemical tankers constructed before 1 July 1986 must comply with the requirements of the Code for the Construction and Equipment of Ships Carrying Dangerous Chemicals in Bulk (BCH Code).",1
"to enable any non-compliance to be detected, for example during port state controls (PSC's). MARPOL Annex VI amendments according with MEPC 176(58) came into force 1 July 2010.Amended Regulations 12 concerns control and record keeping of Ozone Depleting Substances.Amended Regulation 14 concerns mandatory fuel oil change over procedures for vessels entering or leaving SECA areas and FO sulphur limits. MARPOL Annex V has been amended multiple times, changing different aspects of the original text. MEPC.219(63)",1
"came into force on 2 March 2012 to generally prohibit the discharge of any garbage into the ocean, with the exception of food wastes, cargo residues, wash-water, and animal carcasses. There are further provisions describing when and how to dispose of the acceptable wastes. MEPC.220(63) came into force on 2 March 2012 to encourage the creation of a waste management plan on-board vessels.",1
"In order for IMO standards to be binding, they must first be ratified by a total number of member countries whose combined gross tonnage represents at least 50% of the world's gross tonnage, a process that can be lengthy. A system of tacit acceptance has therefore been put into place, whereby,if no objections are heard from a member state after a certain period has elapsed, it is assumed they have assented to the treaty. All six Annexes have been ratified by the requisite number of nations; the most recent is Annex VI, which took effect in May 2005.",1
"The country that the ship visits can conduct its own examination to verify a ship's compliance with international standards and can detain the ship if it finds significant noncompliance. When incidents occur outside such country's jurisdiction or jurisdiction cannot be determined, the country refers cases to flag states, in accordance with MARPOL. A 2000 US GAO report documented that even when referrals have been made, the response rate from flag states has been poor.On the 1st of January,2015, maritime shipping levels became legally subject to new MARPOL directives because the SECA (Sulphur Emission Controlled Areas) zone increased in size.",1
"It is believed that the United Nations Convention on the Law Of the Sea (UNCLOS) allows port States to assert jurisdiction over such violations of emission regulation (also of future regulations of GHG) when they occur on the high seas. Coastal States can assert jurisdiction over violations occurring within their waters, with certain exceptions pertaining to innocent passage and the right of transit passage. The special obligations for flag States and the broadened jurisdictions for coastal and port States, to enforce MARPOL (including Annex VI) are found within the special provisions of part XII of UNCLOS.",1
Areas,1
"These components include: Field map The map, including general reference points (such as streams, residences, wellheads etc.), number of acres, and soil types is the base for the rest of the plan. Soil test How much of each nutrient (N-P-K and other critical elements such as pH and organic matter) is in the soil profile? The soil test is a key component needed for developing the nutrient rate recommendation.",1
"Recommended rates Here's the place where science, technology, and art meet. Given everything you've noted, what is the optimum rate of N, P, K, lime and any other nutrients? While science tells us that a crop has changing nutrient requirements during the growing season, a combination of technology and farmer's management skills assure nutrient availability at all stages of growth. No-till corn generally requires starter fertilizer to give the seedling a healthy start.",1
"Slope, rainfall patterns, soil type, crop rotation and many other factors determine which method is best for optimizing nutrient efficiency (availability and loss) in farms. The combination that's right in one field may differ in another field even with the same crop. Annual review and update Even the best managers are forced to deviate from their plans. What rate was actually applied? Where? Using which method? Did an unusually mild winter or wet spring reduce soil nitrate? Did a dry summer, disease, or some other unusual factor increase nutrient carryover? These and other factors should be noted as they occur.When",1
Nitrogen can be lost from the plant-soil system by one or more of the following processes: leaching; surface runoff; soil erosion; ammonia volatilization; and denitrification.,1
"Incorporation and/or injection of urea and ammonium-containing fertilizers decreases ammonia volatilization because good soil contact buffers pH and slows the generation of ammonia gas from ammonium ions. Urease inhibitors temporarily block the function of the urease enzyme, maintaining urea-based fertilizers in the non-volatile urea form, reducing volatilization losses when these fertilizers are surface applied; these losses can be meaningful in high-residue, conservation tillage systems.",1
"Nitrate is the form of nitrogen that is most susceptible to loss from the soil, through denitrification and leaching. The amount of N lost via these processes can be limited by restricting soil nitrate concentrations, especially at times of high risk. This can be done in many ways, although these are not always cost-effective.",1
"Preplant soil tests provide information on the soil's N-supply power. Late spring or pre-side-dress N tests can determine if and how much additional N is needed. New soil test and sampling procedures, such as amino sugar tests, grid mapping, and real-time sensors can refine N requirements. Post-harvest soil tests determine if N management the previous season was appropriate.",1
"Plant tissue tests can identify N deficiencies. Sensing variations in plant chlorophyll content facilitates variable rate N applications in-season. Post-black-layer corn stalk nitrate tests help to determine if N rates were low, optimal, or excessive in the previous crop, so that management changes can be made in following crops.",1
"Variable rate applicators, combined with intensive soil or crop sampling, allow more precise and responsive application rates.",1
"Slow or controlled release fertilizer delays the availability of nitrogen to the plant until a time that is more appropriate for plant uptake - the risk of N loss through denitrification and leaching is reduced by limiting nitrate concentrations in the soil. Nitrification inhibitors maintain applied N in the ammonium form for a longer period of time, thereby reducing leaching and denitrification losses.",1
"Good agronomic practice, including appropriate plant populations and spacing and good weed and pest management, allows crops to produce large root systems to optimise N capture and crop yield.",1
"In the United States, ORVR has been mandated on all passenger cars (phasing in over the 1998-2000 model years) and light trucks up to 10,000 lbs gross vehicle weight rating (phasing in over the 2001-2006 model years) by the EPA. As the years went by, ORVR systems became so widespread throughout the United States, that Stage II systems were becoming obsolete. On May 9, 2012 EPA Administrators released their final rule making which acknowledged enough ORVR systems were operational to remove further need for Stage II systems.",1
"Vehicle ORVR systems have design characteristics that are not compatible with Stage II vacuum assisted systems. When these two systems work in conjunction, the overall efficiency declines significantly, as compared to each system functioning on its own.",1
"An ORVR carbon-filled canister (installed on modern vehicles) is designed to capture fuel vapors displaced while refueling, and then to inject them into the intake manifold later on, so that they are burned along with the regular fuel, during normal engine operation. However, a Stage II vapor recovery system, installed on refueling gas station pumps, uses a vacuum to prevent fuel vapors from being released into the atmosphere. The design of the fill pipe seal in ORVR systems prevents fuel vapors from entering the fuel tank fill pipe.",1
"The vapors which are displaced from the fuel tank by the incoming fuel are routed via the vapor vent line to the canister and are absorbed by activated carbon. These canisters are made of either steel or plastic. The size of this canister is tailored to accommodate expected evaporative emissions. The emissions occur throughout the day, even when the vehicle is parked.",1
The vent line is a tube that routes vapors from the fuel tank to the vapor storage device.,1
"The vapor purge line directs vapors from the vapor storage device to the engine to be burned, to purge the vapor storage device.",1
The anti-spitback valve prevents spilling of vapors and is located in the fillneck.,1
The fuel tank necessarily contains fuel vapors (occupying all the space which is not occupied by fuel). These are the vapors that must be contained so they do not escape into the atmosphere.,1
"The vent/rollover valve provides a method of controlled escape for gasoline vapors during the refueling process. It has a mechanism which closes the vent in the event the vehicle rolls over, to prevent spilling of VOCs or fuel in general. It also acts as a fill limiter. Stage II vapor recovery system F. Woodcock, William E. Ruhig, Jr., Loren H. Kline",1
"Hempton, Gordon; Grossmann, John (2009). One Square Inch of Silence: One Man's Search for Natural Silence in a Noisy World. Free Press (Simon & Schuster). ISBN 978-1416559085. Man's quest to defend one square-inch of silence, KING-TV, May 16, 2011 Official website One Square Inch of Silence, from the documentary ""Soundtracker"" on YouTube",1
"The main purposes of the program were to develop technologies to reduce the impact of cars and light trucks on the environment and to decrease the US dependency on imported petroleum. The program was to make working vehicles achievimg up to triple the contemporaryng fuel efficiency as and further minimizing emissions but without sacrificing affordability, performance, or safety. The common term for the vehicles was ""supercar"" because of the technological advances. The goal of achieving the 80 mpg‑US (2.9 L/100 km; 96 mpg‑imp) target with a family-sized sedan included using new fuel sources, powerplants, aerodynamics, and lightweight materials.The",1
"program was established in 1993 to support the domestic US automakers (GM, Ford, and Chrysler) develop prototypes of a safe, clean, and affordable car the size of the Ford Taurus but tripling its fuel efficiency. The program ""overcame many challenges and has forged a useful and productive partnership of industry and government participants"" by ""resulting in three concept cars that demonstrate the feasibility of a variety of new automotive technologies"" with diesel-electric transmission.The three domestic automakers (GM, Ford, and Chrysler) developed fully-operational concept cars. They were full-sized five-passenger family cars and achieved at least 72 mpg‑US (3.3 L/100 km; 86 mpg‑imp).General",1
"Motors developed the 80 mpg Precept, Ford designed the 72 mpg Prodigy, and Chrysler built the 72 mpg ESX-3. They featured aerodynamic lightweight aluminum or thermoplastic construction and were hybrid-powered by using 3- or 4-cylinder diesel engines and NiMH/lithium batteries.Researchers for the PNGV identified a number of ways to reach 80 mpg, including reducing vehicle weight, increasing engine efficiency, combining gasoline engines and electric motors in hybrid vehicles, implementing regenerative braking, and switching to high-efficiency fuel cell powerplants.",1
"ratios of power electronics to within 25 percent of targets while reducing the cost by 86 percent to $10/kW since 1995 Reduction in cost of lightweight aluminum, magnesium, and glass-fiber-reinforced polymer components to less than 50% of the cost of steel Reduction in the cost of fuel cells from $10,000/kW in 1994 to $300/kW in 2000 Substantial weight reduction to within 5-10% of the vehicle weight reduction goal Ralph Nader called the program ""an effort to coordinate the transfer of property rights for federally funded research and development to the automotive industry.""The",1
"Transportation Research Board; Division on Engineering and Physical Sciences (2001). Review of the Research Program of the Partnership for a New Generation of Vehicles: Seventh Report. The National Academies Press. doi:10.17226/10180. ISBN 978-0-309-07603-6. Retrieved 17 January 2018. ""Partnership for a New Generation of Vehicles Organization (PNGV)"". Al Gore 2008 Draft Campaign. 11 March 2007. Archived from the original on 12 October 2007. Retrieved 17 January 2018. Sperling, Daniel (Spring 2002). ""Updating Automotive Research"". Issues in Science and Technology. 18 (3). Archived from the original on 23 May 2013. Retrieved 17 January 2018. ""Supercar"". Chicago Tribune. Retrieved 17 January 2018.",1
DOE vehicle technologies homepage USCAR Website,1
"The Centers for Disease Control and Prevention reports that about 70 chemicals present in secondhand smoke are carcinogenic. Lung cancer: Passive smoking is a risk factor for lung cancer. In the United States, secondhand smoke is estimated to cause more than 7,000 deaths from lung cancer a year among non-smokers. A quarter of all cases occur in people who have never smoked.",1
"A 2015 meta-analysis found that the evidence that passive smoking moderately increased the risk of breast cancer had become ""more substantial than a few years ago"". Cervical cancer: A 2015 overview of systematic reviews found that exposure to secondhand smoke increased the risk of cervical cancer. Bladder cancer: A 2016 systematic review and meta-analysis found that secondhand smoke exposure was associated with a significant increase in the risk of bladder cancer. Circulatory system: risk of heart disease and reduced heart rate variability.Epidemiological studies have shown that both active and passive cigarette smoking increase the risk of atherosclerosis.",1
"Passive smoking is strongly associated with an increased risk of stroke, and this increased risk is disproportionately high at low levels of exposure. Lung problems: Risk of asthma Risk of chronic obstructive pulmonary disease (COPD) According to a 2015 review, passive smoking may increase the risk of tuberculosis infection and accelerate the progression of the disease, but the evidence remains weak. The majority of studies on the association between secondhand smoke exposure and sinusitis have found a significant association between the two.",1
"Cognitive impairment and dementia: Exposure to secondhand smoke may increase the risk of cognitive impairment and dementia in adults 50 and over. Children exposed to secondhand smoke show reduced vocabulary and reasoning skills when compared with non-exposed children as well as more general cognitive and intellectual deficits. Mental health: Exposure to secondhand smoke is associated with an increased risk of depressive symptoms. During pregnancy: Miscarriage: a 2014 meta-analysis found that maternal secondhand smoke exposure increased the risk of miscarriage by 11%. Low birth weight, part B, ch. 3. Premature birth, part B, ch.",1
"3 (Evidence of the causal link is described only as ""suggestive"" by the US Surgeon General in his 2006 report.) Laws limiting smoking decrease premature births. Stillbirth and congenital malformations in children Recent studies comparing females exposed to secondhand smoke and non-exposed females, demonstrate that females exposed while pregnant have higher risks of delivering a child with congenital abnormalities, longer lengths, smaller head circumferences, and neural tube defects. General: Worsening of asthma, allergies, and other conditions.",1
"A 2014 systematic review and meta-analysis found that passive smoking was associated with a slightly increased risk of allergic diseases among children and adolescents; the evidence for an association was weaker for adults. Type 2 diabetes. It remains unclear whether the association between passive smoking and diabetes is causal. Risk of carrying Neisseria meningitidis or Streptococcus pneumoniae. A possible increased risk of periodontitis. Overall increased risk of death in both adults, where it was estimated to kill 53,000 nonsmokers per year in the U.S in 1991, and in children.",1
"The World Health Organization states that passive smoking causes about 600,000 deaths a year, and about 1% of the global burden of disease. As of 2017, passive smoking causes about 900,000 deaths a year, which is about 1/8 of all deaths caused by smoking. Skin conditions: A 2016 systematic review and meta-analysis found that passive smoking was associated with a higher rate of atopic dermatitis.",1
"Sudden infant death syndrome (SIDS). In his 2006 report, the US Surgeon General concludes: ""The evidence is sufficient to infer a causal relationship between exposure to secondhand smoke and sudden infant death syndrome."" Secondhand smoking has been estimated to be associated with 430 SIDS deaths in the United States annually. Asthma. Secondhand smoke exposure is also associated with an almost doubled risk of hospitalization for asthma exacerbation among children with asthma. Lung infections, also including more severe illness with bronchiolitis and bronchitis, and worse outcome, as well as increased risk of developing tuberculosis if exposed to a carrier.",1
"In the United States, it is estimated that secondhand smoke has been associated with between 150,000 and 300,000 lower respiratory tract infections in infants and children under 18 months of age, resulting in between 7,500 and 15,000 hospitalizations each year. Impaired respiratory function and slowed lung growth Allergies Maternal passive smoking increases the risk of non-syndromic orofacial clefts by 50% among their children. Learning difficulties, developmental delays, executive function problems, and neurobehavioral effects. Animal models suggest a role for nicotine and carbon monoxide in neurocognitive problems.",1
"An increase in tooth decay (as well as related salivary biomarkers) has been associated with passive smoking in children. Increased risk of middle ear infections. Invasive meningococcal disease. Anesthesia complications and some negative surgical outcomes. Sleep disordered breathing: Most studies have found a significant association between passive smoking and sleep disordered breathing in children, but further studies are needed to determine whether this association is causal. Adverse effects on the cardiovascular system of children. Epidemiological studies show that non-smokers exposed to secondhand smoke are at risk for many of the health problems associated with direct smoking.",1
"In 1992, a review estimated that secondhand smoke exposure was responsible for 35,000 to 40,000 deaths per year in the United States in the early 1980s. The absolute risk increase of heart disease due to ETS was 2.2%, while the attributable risk percent was 23%. A 1997 meta-analysis found that secondhand smoke exposure increased the risk of heart disease by a quarter, and two 1999 meta-analyses reached similar conclusions.Evidence shows that inhaled sidestream smoke, the main component of secondhand smoke, is about four times more toxic than mainstream smoke.",1
"This fact has been known to the tobacco industry since the 1980s, though it kept its findings secret. Some scientists believe that the risk of passive smoking, in particular the risk of developing coronary heart diseases, may have been substantially underestimated.In 1997, a meta-analysis on the relationship between secondhand smoke exposure and lung cancer concluded that such exposure caused lung cancer. The increase in risk was estimated to be 24% among non-smokers who lived with a smoker. In 2000, Copas and Shi reported that there was clear evidence of publication bias in the studies included in this meta-analysis.",1
"They further concluded that after correcting for publication bias, and assuming that 40% of all studies are unpublished, this increased risk decreased from 24% to 15%. This conclusion has been challenged on the basis that the assumption that 40% of all studies are unpublished was ""extreme"".: 1269 In 2006, Takagi et al. reanalyzed the data from this meta-analysis to account for publication bias and estimated that the relative risk of lung cancer among those exposed to secondhand smoke was 1.19, slightly lower than the original estimate. A 2000 meta-analysis found a relative risk of 1.48",1
"for lung cancer among men exposed to secondhand smoke, and a relative risk of 1.16 among those exposed to it at work. Another meta-analysis confirmed the finding of an increased risk of lung cancer among women with spousal exposure to secondhand smoke the following year. It found a relative risk of lung cancer of 1.29 for women exposed to secondhand smoke from their spouses. A 2014 meta-analysis noted that ""the association between exposure to secondhand smoke and lung cancer risk is well established.""A",1
"minority of epidemiologists have found it hard to understand how secondhand smoke, which is more diluted than actively inhaled smoke, could have an effect that is such a large fraction of the added risk of coronary heart disease among active smokers. One proposed explanation is that secondhand smoke is not simply a diluted version of ""mainstream"" smoke, but has a different composition with more toxic substances per gram of total particulate matter.",1
"Passive smoking appears to be capable of precipitating the acute manifestations of cardio-vascular diseases (atherothrombosis) and may also have a negative impact on the outcome of patients who have acute coronary syndromes.In 2004, the International Agency for Research on Cancer (IARC) of the World Health Organization (WHO) reviewed all significant published evidence related to tobacco smoking and cancer. It concluded: These meta-analyses show that there is a statistically significant and consistent association between lung cancer risk in spouses of smokers and exposure to second-hand tobacco smoke from the spouse who smokes.",1
"The excess risk is of the order of 20% for women and 30% for men and remains after controlling for some potential sources of bias and confounding. Subsequent meta-analyses have confirmed these findings.The National Asthma Council of Australia cites studies showing that secondhand smoke is probably the most important indoor pollutant, especially around young children: Smoking by either parent, particularly by the mother, increases the risk of asthma in children. The outlook for early childhood asthma is less favourable in smoking households. Children with asthma who are exposed to smoking in the home generally have more severe disease.",1
"Many adults with asthma identify ETS as a trigger for their symptoms. Doctor-diagnosed asthma is more common among non-smoking adults exposed to ETS than those not exposed. Among people with asthma, higher ETS exposure is associated with a greater risk of severe attacks.In France, exposure to secondhand smoke has been estimated to cause between 3,000 and 5,000 premature deaths per year, with the larger figure cited by Prime Minister Dominique de Villepin during his announcement of a nationwide smoke-free law: ""That makes more than 13 deaths a day. It is an unacceptable reality in our country in terms of public health.""There",1
is good observational evidence that smoke-free legislation reduces the number of hospital admissions for heart disease.,1
"The International Agency for Research on Cancer of the World Health Organization concluded in 2004 that there was sufficient evidence that secondhand smoke caused cancer in humans. Those who work in environments where smoke is not regulated are at higher risk. Workers particularly at risk of exposure include those in installation repair and maintenance, construction and extraction, and transportation.Much research has come from studies of nonsmokers who are married to a smoker.",1
"A systematic review compared smoking control programmes and their effects on smoke exposure in children. The review distinguishes between community-based, ill-child and healthy-child settings and the most common types of interventions were counselling or brief advice during clinical visits. The review did not find superior outcomes for any intervention, and the authors caution that evidence from adult settings may not generalise well to children.",1
"Also, it may be difficult for individuals to recall their exposure to tobacco smoke.A 2007 study in the Addictive Behaviors journal found a positive correlation between secondhand tobacco smoke exposure and concentrations of nicotine and/or biomarkers of nicotine in the body. Significant biological levels of nicotine from secondhand smoke exposure were equivalent to nicotine levels from active smoking and levels that are associated with behaviour changes due to nicotine consumption.",1
"Cotinine levels of the skin, such as the hair and nails, reflect tobacco exposure over the previous three months and are a more reliable biomarker.",1
"A 2004 study by the International Agency for Research on Cancer of the World Health Organization concluded that non-smokers are exposed to the same carcinogens as active smokers. Sidestream smoke contains more than 4,000 chemicals, including 69 known carcinogens. Of special concern are polynuclear aromatic hydrocarbons, tobacco-specific N-nitrosamines, and aromatic amines, such as 4-aminobiphenyl, all known to be highly carcinogenic. Mainstream smoke, sidestream smoke, and secondhand smoke contain largely the same components, however the concentration varies depending on type of smoke.",1
"tobacco smoke exposure has immediate and substantial effects on blood and blood vessels in a way that increases the risk of a heart attack, particularly in people already at risk. Exposure to tobacco smoke for 30 minutes significantly reduces coronary flow velocity reserve in healthy nonsmokers. Secondhand smoke is also associated with impaired vasodilation among adult nonsmokers. Secondhand smoke exposure also affects platelet function, vascular endothelium, and myocardial exercise tolerance at levels commonly found in the workplace.Pulmonary emphysema can be induced in rats through acute exposure to sidestream tobacco smoke (30 cigarettes per day) over a period of 45 days.",1
"This prohibition was enacted because third-hand smoke poses a special danger for the developing brains of infants and small children.In 2008, there were more than 161,000 deaths attributed to lung cancer in the United States. Of these deaths, an estimated 10% to 15% were caused by factors other than first-hand smoking; equivalent to 16,000 to 24,000 deaths annually. Slightly more than half of the lung cancer deaths caused by factors other than first-hand smoking were found in nonsmokers. Lung cancer in non-smokers may well be considered one of the most common cancer mortalities in the United States.",1
"A 2001 study found that 95% of adults agreed that secondhand smoke was harmful to children, and 96% considered tobacco-industry claims that secondhand smoke was not harmful to be untruthful.A 2007 Gallup poll found that 56% of respondents felt that secondhand smoke was ""very harmful"", a number that has held relatively steady since 1997. Another 29% believe that secondhand smoke is ""somewhat harmful""; 10% answered ""not too harmful"", while 5% said ""not at all harmful"".",1
"As part of its attempt to prevent or delay tighter regulation of smoking, the tobacco industry funded a number of scientific studies and, where the results cast doubt on the risks associated with secondhand smoke, sought wide publicity for those results. The industry also funded libertarian and conservative think tanks, such as the Cato Institute in the United States and the Institute of Public Affairs in Australia which criticised both scientific research on passive smoking and policy proposals to restrict smoking.",1
"New Scientist and the European Journal of Public Health have identified these industry-wide coordinated activities as one of the earliest expressions of corporate denialism. Further, they state that the disinformation spread by the tobacco industry has created a tobacco denialism movement, sharing many characteristics of other forms of denialism, such as HIV-AIDS denialism.",1
"A 2003 study by James Enstrom and Geoffrey Kabat, published in the British Medical Journal, argued that the harms of passive smoking had been overstated. Their analysis reported no statistically significant relationship between passive smoking and lung cancer, coronary heart disease (CHD), or chronic obstructive pulmonary disease, though the accompanying editorial noted that ""they may overemphasise the negative nature of their findings."" This paper was widely promoted by the tobacco industry as evidence that the harms of passive smoking were unproven.",1
"in order for me to effectively compete against the large mountain of epidemiologic data and opinions that already exist regarding the health effects of ETS and active smoking."" In a US racketeering lawsuit against tobacco companies, the Enstrom and Kabat paper was cited by the US District Court as ""a prime example of how nine tobacco companies engaged in criminal racketeering and fraud to hide the dangers of tobacco smoke.""",1
"2006, Enstrom and Kabat published a meta-analysis of studies regarding passive smoking and coronary heart disease in which they reported a very weak association between passive smoking and heart disease mortality. They concluded that exposure to secondhand smoke increased the risk of death from CHD by only 5%, although this analysis has been criticized for including two previous industry-funded studies that suffered from widespread exposure misclassification.",1
"Gio Batta Gori, a tobacco industry spokesman and consultant and an expert on risk utility and scientific research, wrote in the libertarian Cato Institute's magazine Regulation that ""...of the 75 published studies of ETS and lung cancer, some 70% did not report statistically significant differences of risk and are moot. Roughly 17% claim an increased risk and 13% imply a reduction of risk.""",1
"Steven Milloy, the ""junk science"" commentator for Fox News and a former Philip Morris consultant, claimed that ""of the 19 studies"" on passive smoking ""only 8— slightly more than 42%— reported statistically significant increases in heart disease incidence.""Another component of criticism cited by Milloy focused on relative risk and epidemiological practices in studies of passive smoking. Milloy, who has a master's degree from the Johns Hopkins School of Hygiene and Public Health, argued that studies yielding relative risks of less than 2 were meaningless junk science.",1
"This approach to epidemiological analysis was criticized in the American Journal of Public Health: A major component of the industry attack was the mounting of a campaign to establish a ""bar"" for ""sound science"" that could not be fully met by most individual investigations, leaving studies that did not meet the criteria to be dismissed as ""junk science."" The tobacco industry and affiliated scientists also put forward a set of ""Good Epidemiology Practices"" which would have the practical effect of obscuring the link between secondhand smoke and lung cancer; the privately stated goal of these standards was to ""impede adverse legislation"".",1
"However, this effort was largely abandoned when it became clear that no independent epidemiological organization would agree to the standards proposed by Philip Morris et al.",1
"In 1995, Levois and Layard, both tobacco industry consultants, published two analyses in the journal Regulatory Toxicology and Pharmacology regarding the association between spousal exposure to secondhand smoke and heart disease. Both of these papers reported no association between secondhand smoke and heart disease. These analyses have been criticized for failing to distinguish between current and former smokers, despite the fact that former smokers, unlike current ones, are not at a significantly increased risk of heart disease.",1
"The reports, appearing in the British Sunday Telegraph and The Economist, among other sources, alleged that the WHO withheld from publication of its own report that supposedly failed to prove an association between passive smoking and a number of other diseases (lung cancer in particular). In response, the WHO issued a press release stating that the results of the study had been ""completely misrepresented"" in the popular press and were in fact very much in line with similar studies demonstrating the harms of passive smoking.",1
"The study was published in the Journal of the National Cancer Institute in October of the same year, and concluded the authors found ""no association between childhood exposure to ETS and lung cancer risk"" but ""did find weak evidence of a dose–response relationship between risk of lung cancer and exposure to spousal and workplace ETS."" An accompanying editorial summarized: When all the evidence, including the important new data reported in this issue of the Journal, is assessed, the inescapable scientific conclusion is that ETS is a low-level lung carcinogen.",1
"With the release of formerly classified tobacco industry documents through the Tobacco Master Settlement Agreement, it was found (by Elisa Ong and Stanton Glantz) that the controversy over the WHO's alleged suppression of data had been engineered by Philip Morris, British American Tobacco, and other tobacco companies in an effort to discredit scientific findings which would harm their business interests.",1
"A WHO inquiry, conducted after the release of the tobacco-industry documents, found that this controversy was generated by the tobacco industry as part of its larger campaign to cut the WHO's budget, distort the results of scientific studies on passive smoking, and discredit the WHO as an institution. This campaign was carried out using a network of ostensibly independent front organizations and international and scientific experts with hidden financial ties to the industry.",1
"The United States District Court for the Middle District of North Carolina ruled in favor of the tobacco industry in 1998, finding that the EPA had failed to follow proper scientific and epidemiologic practices and had ""cherry picked"" evidence to support conclusions which they had committed to in advance. The court stated in part, ""EPA publicly committed to a conclusion before research had begun…adjusted established procedure and scientific norms to validate the Agency's public conclusion...",1
"In conducting the ETS Risk Assessment, disregarded information and made findings on selective information; did not disseminate significant epidemiologic information; deviated from its Risk Assessment Guidelines; failed to disclose important findings and reasoning…"" In 2002, the EPA successfully appealed this decision to the United States Court of Appeals for the Fourth Circuit. The EPA's appeal was upheld on the preliminary grounds that their report had no regulatory weight, and the earlier finding was vacated.In 1998, the U.S.",1
"The tobacco industry's role in funding scientific research on secondhand smoke has been controversial. A review of published studies found that tobacco-industry affiliation was strongly correlated with findings exonerating secondhand smoke; researchers affiliated with the tobacco industry were 88 times more likely than independent researchers to conclude that secondhand smoke was not harmful. In a specific example which came to light with the release of tobacco-industry documents, Philip Morris executives successfully encouraged an author to revise his industry-funded review article to downplay the role of secondhand smoke in sudden infant death syndrome. The 2006 U.S.",1
"Surgeon General's report criticized the tobacco industry's role in the scientific debate: The industry has funded or carried out research that has been judged to be biased, supported scientists to generate letters to editors that criticized research publications, attempted to undermine the findings of key studies, assisted in establishing a scientific society with a journal, and attempted to sustain controversy even as the scientific community reached consensus.",1
"This strategy was outlined at an international meeting of tobacco companies in 1988, at which Philip Morris proposed to set up a team of scientists, organized by company lawyers, to ""carry out work on ETS to keep the controversy alive."" All scientific research was subject to oversight and ""filtering"" by tobacco-industry lawyers: Philip Morris then expect the group of scientists to operate within the confines of decisions taken by PM scientists to determine the general direction of research, which apparently would then be 'filtered' by lawyers to eliminate areas of sensitivity. Philip Morris reported that it was putting ""...vast",1
"amounts of funding into these projects... in attempting to coordinate and pay so many scientists on an international basis to keep the ETS controversy alive.""",1
"Measures to tackle secondhand smoke pose a serious economic threat to the tobacco industry, having broadened the definition of smoking beyond a personal habit to something with a social impact. In a confidential 1978 report, the tobacco industry described increasing public concerns about secondhand smoke as ""the most dangerous development to the viability of the tobacco industry that has yet occurred."" In United States of America v. Philip Morris et al., the District Court for the District of Columbia found that the tobacco industry ""...",1
"recognized from the mid-1970s forward that the health effects of passive smoking posed a profound threat to industry viability and cigarette profits,"" and that the industry responded with ""efforts to undermine and discredit the scientific consensus that ETS causes disease.""Accordingly, the tobacco industry have developed several strategies to minimise the impact on their business: The industry has sought to position the secondhand smoke debate as essentially concerned with civil liberties and smokers' rights rather than with health, by funding groups such as FOREST.",1
"Funding bias in research; in all reviews of the effects of secondhand smoke on health published between 1980 and 1995, the only factor associated with concluding that secondhand smoke is not harmful was whether an author was affiliated with the tobacco industry. However, not all studies that failed to find evidence of harm were by industry-affiliated authors.",1
"Delaying and discrediting legitimate research (see for an example of how the industry attempted to discredit Takeshi Hirayama's landmark study, and for an example of how it attempted to delay and discredit a major Australian report on passive smoking) Promoting ""good epidemiology"" and attacking so-called junk science (a term popularised by industry lobbyist Steven Milloy): attacking the methodology behind research showing health risks as flawed and attempting to promote sound science. Ong & Glantz (2001) cite an internal Phillip Morris memo giving evidence of this as company policy. Creation of outlets for favourable research.",1
"In 1989, the tobacco industry established the International Society of the Built Environment, which published the peer-reviewed journal Indoor and Built Environment. This journal did not require conflict-of-interest disclosures from its authors. With documents made available through the Master Settlement, it was found that the executive board of the society and the editorial board of the journal were dominated by paid tobacco-industry consultants. The journal published a large amount of material on passive smoking, much of which was ""industry-positive"".Citing the tobacco industry's production of biased research and efforts to undermine scientific findings, the 2006 U.S.",1
"Surgeon General's report concluded that the industry had ""attempted to sustain controversy even as the scientific community reached consensus... industry documents indicate that the tobacco industry has engaged in widespread activities... that have gone beyond the bounds of accepted scientific practice."" The U.S. District Court, in U.S.A. v. Philip Morris et al., found that ""...despite their internal acknowledgment of the hazards of secondhand smoke, Defendants have fraudulently denied that ETS causes disease.""",1
"The positions of major tobacco companies on the issue of secondhand smoke is somewhat varied. In general, tobacco companies have continued to focus on questioning the methodology of studies showing that secondhand smoke is harmful. Some (such as British American Tobacco and Philip Morris) acknowledge the medical consensus that secondhand smoke carries health risks, while others continue to assert that the evidence is inconclusive. Several tobacco companies advocate the creation of smoke-free areas within public buildings as an alternative to comprehensive smoke-free laws.",1
"On September 22, 1999, the U.S. Department of Justice filed a racketeering lawsuit against Philip Morris and other major cigarette manufacturers. Almost 7 years later, on August 17, 2006, U.S. District Court Judge Gladys Kessler found that the Government had proven its case and that the tobacco company defendants had violated the Racketeer Influenced Corrupt Organizations Act (RICO).",1
"In particular, Judge Kessler found that PM and other tobacco companies had: conspired to minimize, distort and confuse the public about the health hazards of smoking; publicly denied, while internally acknowledging, that secondhand tobacco smoke is harmful to nonsmokers, and destroyed documents relevant to litigation.The ruling found that tobacco companies undertook joint efforts to undermine and discredit the scientific consensus that secondhand smoke causes disease, notably by controlling research findings via paid consultants. The ruling also concluded that tobacco companies were fraudulently continuing to deny the health effects of ETS exposure.On May 22, 2009, a three-judge panel of the U.S.",1
"Court of Appeals for the District of Columbia Circuit unanimously upheld the lower court's 2006 ruling. As a consequence of the health risks associated with secondhand smoke, many national and local governments have outlawed smoking in indoor public places, including restaurants, cafés, and nightclubs, as well as some outdoor open areas. Ireland was the first country in the world to institute a comprehensive national ban on smoking in all indoor workplaces on 29 March 2004. Since then, many others have followed suit.",1
"The countries which have ratified the WHO Framework Convention on Tobacco Control (FCTC) have a legal obligation to implement effective legislation ""for protection from exposure to tobacco smoke in indoor workplaces, public transport, indoor public places and, as appropriate, other public places."" (Article 8 of the FCTC) The parties to the FCTC have further adopted Guidelines on the Protection from Exposure to secondhand Smoke which state that ""effective measures to provide protection from exposure to tobacco smoke ... require the total elimination of smoking and tobacco smoke in a particular space or environment in order to create a 100% smoke-free environment.""Opinion",1
"polls have shown considerable support for smoke-free laws. In June 2007, a survey of 15 countries found 80% approval for such laws. A survey in France, reputedly a nation of smokers, showed 70% support.",1
"Smoking bans by governments result in decreased harm from secondhand smoke, including less admissions for acute coronary syndrome. In the first 18 months after the town of Pueblo, Colorado, enacted a smoke-free law in 2003, hospital admissions for heart attacks dropped 27%. Admissions in neighbouring towns without smoke-free laws showed no change, and the decline in heart attacks in Pueblo was attributed to the resulting reduction in secondhand smoke exposure. A 2004 smoking ban instituted in Massachusetts workplaces decreased workers' secondhand smoke exposure from 8% of workers in 2003 to 5.4% of workers in 2010.",1
"Also, the employees' support for a smoke-free workplace substantially increased in the post-implementation survey compared to pre-implementation survey.",1
"Recent surveys taken by the Society for Research on Nicotine and Tobacco demonstrate supportive attitudes of the public, towards smoke-free policies in outdoor areas. A vast majority of the public supports restricting smoking in various outdoor settings. The respondents' support for the policies were for varying reasons such as litter control, establishing positive smoke-free role models for youth, reducing youth opportunities to smoke, and avoiding exposure to secondhand smoke.",1
"The American Society of Heating, Refrigerating and Air-Conditioning Engineers (ASHRAE) officially concluded in 2005 that while completely isolated smoking rooms do eliminate the risk to nearby non-smoking areas, smoking bans are the only means of eliminating health risks associated with indoor exposure. They further concluded that no system of dilution or cleaning was effective at eliminating risk. The U.S. Surgeon General and the European Commission Joint Research Centre have reached similar conclusions. The implementation guidelines for the WHO Framework Convention on Tobacco Control states that engineering approaches, such as ventilation, are ineffective and do not protect against secondhand smoke exposure.",1
"Big Blue Ocean Cleanup was established on 27 February 2018, by Rory Sinclair.In March 2019, it supported the “Cash for trash” initiative, launched by an APEM freshwater consultancy.On 22 April 2020 (the Earth Day), Big Blue Ocean Cleanup was featured in Zac Efron’s documentary The Great Global Clean Up, aired on Discovery Channel. In May 2020, Big Blue Ocean Cleanup’s volunteers were involved in removing the remainants of a large fin whale from the Clacton-on-Sea beach in Essex. In September 2020, the organization partnered with the team of Scottish rowers on their Northwest Passage expedition, planned for 2021.",1
"Cleaning up beaches is the main activity of Big Blue Ocean Cleanup. These events are being organized by the non-profit ambassadors and involve various communities, from company workers to students, to local volunteers.",1
"In October 2018, Big Blue Ocean Cleanup’s experts supported Ocean Saviour project, an initiative of Richard W. Roberts and Simon White, founders of TheYachtMarket.com, to build self-powering 70m tri-deck clean-up vessel, which will retrieve and recycle plastic from the ocean. The non-profit is supported mainly by small and medium-sized enterprises (some examples being search-engine Ekoru, Subsea Expo, provider of marine engineering services James Fisher & Sons and packaging supplier Storopack). Official website",1
"The word ""benzene"" derives from ""gum benzoin"" (benzoin resin), an aromatic resin known since ancient times in Southeast Asia; and later to European pharmacists and perfumers in the 16th century via trade routes. An acidic material was derived from benzoin by sublimation, and named ""flowers of benzoin"", or benzoic acid. The hydrocarbon derived from benzoic acid thus acquired the name benzin, benzol, or benzene. Michael Faraday first isolated and identified benzene in 1825 from the oily residue derived from the production of illuminating gas, giving it the name bicarburet of hydrogen.",1
"In 1833, Eilhard Mitscherlich produced it by distilling benzoic acid (from gum benzoin) and lime. He gave the compound the name benzin. In 1836, the French chemist Auguste Laurent named the substance ""phène""; this word has become the root of the English word ""phenol"", which is hydroxylated benzene, and ""phenyl"", the radical formed by abstraction of a hydrogen atom (free radical H•) from benzene. In 1845, Charles Blachford Mansfield, working under August Wilhelm von Hofmann, isolated benzene from coal tar. Four years later, Mansfield began the first industrial-scale production of benzene, based on the coal-tar method.",1
"Gradually, the sense developed among chemists that a number of substances were chemically related to benzene, comprising a diverse chemical family. In 1855, Hofmann was the first to apply the word ""aromatic"" to designate this family relationship, after a characteristic property of many of its members. In 1997, benzene was detected in deep space.",1
"The empirical formula for benzene was long known, but its highly polyunsaturated structure, with just one hydrogen atom for each carbon atom, was challenging to determine. Archibald Scott Couper in 1858 and Johann Josef Loschmidt in 1861 suggested possible structures that contained multiple double bonds or multiple rings, but too little evidence was then available to help chemists decide on any particular structure. In 1865, the German chemist Friedrich August Kekulé published a paper in French (for he was then teaching in Francophone Belgium) suggesting that the structure contained a ring of six carbon atoms with alternating single and double bonds.",1
"The new understanding of benzene, and hence of all aromatic compounds, proved to be so important for both pure and applied chemistry that in 1890 the German Chemical Society organized an elaborate appreciation in Kekulé's honor, celebrating the twenty-fifth anniversary of his first benzene paper. Here Kekulé spoke of the creation of the theory. He said that he had discovered the ring shape of the benzene molecule after having a reverie or day-dream of a snake biting its own tail (a symbol in ancient cultures known as the ouroboros).",1
"This vision, he said, came to him after years of studying the nature of carbon-carbon bonds. This was seven years after he had solved the problem of how carbon atoms could bond to up to four other atoms at the same time. Curiously, a similar, humorous depiction of benzene had appeared in 1886 in a pamphlet entitled Berichte der Durstigen Chemischen Gesellschaft (Journal of the Thirsty Chemical Society), a parody of the Berichte der Deutschen Chemischen Gesellschaft, only the parody had monkeys seizing each other in a circle, rather than snakes as in Kekulé's anecdote.",1
"Some historians have suggested that the parody was a lampoon of the snake anecdote, possibly already well known through oral transmission even if it had not yet appeared in print. Kekulé's 1890 speech in which this anecdote appeared has been translated into English. If the anecdote is the memory of a real event, circumstances mentioned in the story suggest that it must have happened early in 1862.In 1929, the cyclic nature of benzene was finally confirmed by the crystallographer Kathleen Lonsdale using X-ray diffraction methods.",1
"Using large crystals of hexamethylbenzene, a benzene derivative with the same core of six carbon atoms, Lonsdale obtained diffraction patterns. Through calculating more than thirty parameters, Lonsdale demonstrated that the benzene ring could not be anything but a flat hexagon, and provided accurate distances for all carbon-carbon bonds in the molecule.",1
"X-ray diffraction shows that all six carbon-carbon bonds in benzene are of the same length, at 140 picometres (pm). The C–C bond lengths are greater than a double bond (135 pm) but shorter than a single bond (147 pm). This intermediate distance is caused by electron delocalization: the electrons for C=C bonding are distributed equally between each of the six carbon atoms. Benzene has 6 hydrogen atoms, fewer than the corresponding parent alkane, hexane, which has 14.",1
"Benzene and cyclohexane have a similar structure, only the ring of delocalized electrons and the loss of one hydrogen per carbon distinguishes it from cyclohexane. The molecule is planar. The molecular orbital description involves the formation of three delocalized π orbitals spanning all six carbon atoms, while the valence bond description involves a superposition of resonance structures. It is likely that this stability contributes to the peculiar molecular and chemical properties known as aromaticity. To accurately reflect the nature of the bonding, benzene is often depicted with a circle inside a hexagonal arrangement of carbon atoms.",1
"Derivatives of benzene occur sufficiently often as a component of organic molecules, so much so that the Unicode Consortium has allocated a symbol in the Miscellaneous Technical block with the code U+232C (⌬) to represent it with three double bonds, and U+23E3 (⏣) for a delocalized version. Many important chemical compounds are derived from benzene by replacing one or more of its hydrogen atoms with another functional group. Examples of simple benzene derivatives are phenol, toluene, and aniline, abbreviated PhOH, PhMe, and PhNH2, respectively. Linking benzene rings gives biphenyl, C6H5–C6H5.",1
"Further loss of hydrogen gives ""fused"" aromatic hydrocarbons, such as naphthalene, anthracene, phenanthrene, and pyrene. The limit of the fusion process is the hydrogen-free allotrope of carbon, graphite. In heterocycles, carbon atoms in the benzene ring are replaced with other elements. The most important variations contain nitrogen. Replacing one CH with N gives the compound pyridine, C5H5N. Although benzene and pyridine are structurally related, benzene cannot be converted into pyridine. Replacement of a second CH bond with N gives, depending on the location of the second N, pyridazine, pyrimidine, or pyrazine.",1
"Four chemical processes contribute to industrial benzene production: catalytic reforming, toluene hydrodealkylation, toluene disproportionation, and steam cracking etc. According to the ATSDR Toxicological Profile for benzene, between 1978 and 1981, catalytic reformates accounted for approximately 44–50% of the total U.S benzene production.",1
"In catalytic reforming, a mixture of hydrocarbons with boiling points between 60 and 200 °C is blended with hydrogen gas and then exposed to a bifunctional platinum chloride or rhenium chloride catalyst at 500–525 °C and pressures ranging from 8–50 atm. Under these conditions, aliphatic hydrocarbons form rings and lose hydrogen to become aromatic hydrocarbons. The aromatic products of the reaction are then separated from the reaction mixture (or reformate) by extraction with any one of a number of solvents, including diethylene glycol or sulfolane, and benzene is then separated from the other aromatics by distillation.",1
"The extraction step of aromatics from the reformate is designed to produce aromatics with lowest non-aromatic components. Recovery of the aromatics, commonly referred to as BTX (benzene, toluene and xylene isomers), involves such extraction and distillation steps. In similar fashion to this catalytic reforming, UOP and BP commercialized a method from LPG (mainly propane and butane) to aromatics.",1
"Under these conditions, toluene undergoes dealkylation to benzene and methane: C 6 H 5 CH 3 + H 2 ⟶ C 6 H 6 + CH 4 {\displaystyle {\ce {C6H5CH3 + H2 -> C6H6 + CH4}}} This irreversible reaction is accompanied by an equilibrium side reaction that produces biphenyl (aka diphenyl) at higher temperature: 2 C6H6 ⇌ H2 + C6H5–C6H5If the raw material stream contains much non-aromatic components (paraffins or naphthenes), those are likely decomposed to lower hydrocarbons such as methane, which increases the consumption of hydrogen. A typical reaction yield exceeds 95%.",1
"Highly instructive but of far less industrial significance is the Friedel-Crafts alkylation of benzene (and many other aromatic rings) using an alkyl halide in the presence of a strong Lewis acid catalyst. Similarly, the Friedel-Crafts acylation is a related example of electrophilic aromatic substitution. The reaction involves the acylation of benzene (or many other aromatic rings) with an acyl chloride using a strong Lewis acid catalyst such as aluminium chloride or Iron(III) chloride.",1
"Benzene is an excellent ligand in the organometallic chemistry of low-valent metals. Important examples include the sandwich and half-sandwich complexes, respectively, Cr(C6H6)2 and [RuCl2(C6H6)]2. Benzene is classified as a carcinogen, which increases the risk of cancer and other illnesses, and is also a notorious cause of bone marrow failure. Substantial quantities of epidemiologic, clinical, and laboratory data link benzene to aplastic anemia, acute leukemia, bone marrow abnormalities and cardiovascular disease. The specific hematologic malignancies that benzene is associated with include: acute myeloid leukemia (AML), aplastic anemia, myelodysplastic syndrome (MDS), acute lymphoblastic leukemia (ALL), and chronic myeloid leukemia (CML).The",1
"As benzene can cause cancer, NIOSH recommends that all workers wear special breathing equipment when they are likely to be exposed to benzene at levels exceeding the recommended (8-hour) exposure limit of 0.1 ppm.",1
"OSHA has also established an action level of 0.5 ppm to encourage even lower exposures in the workplace.The U.S. National Institute for Occupational Safety and Health (NIOSH) revised the Immediately Dangerous to Life and Health (IDLH) concentration for benzene to 500 ppm. The current NIOSH definition for an IDLH condition, as given in the NIOSH Respirator Selection Logic, is one that poses a threat of exposure to airborne contaminants when that exposure is likely to cause death or immediate or delayed permanent adverse health effects or prevent escape from such an environment.",1
"The purpose of establishing an IDLH value is (1) to ensure that the worker can escape from a given contaminated environment in the event of failure of the respiratory protection equipment and (2) is considered a maximum level above which only a highly reliable breathing apparatus providing maximum worker protection is permitted. In September 1995, NIOSH issued a new policy for developing recommended exposure limits (RELs) for substances, including carcinogens. As benzene can cause cancer, NIOSH recommends that all workers wear special breathing equipment when they are likely to be exposed to benzene at levels exceeding the REL (10-hour) of 0.1",1
ppm. The NIOSH short-term exposure limit (STEL – 15 min) is 1 ppm. American Conference of Governmental Industrial Hygienists (ACGIH) adopted Threshold Limit Values (TLVs) for benzene at 0.5 ppm TWA and 2.5 ppm STEL.,1
"Several tests can determine exposure to benzene. Benzene itself can be measured in breath, blood or urine, but such testing is usually limited to the first 24 hours post-exposure due to the relatively rapid removal of the chemical by exhalation or biotransformation. Most people in developed countries have measureable baseline levels of benzene and other aromatic petroleum hydrocarbons in their blood. In the body, benzene is enzymatically converted to a series of oxidation products including muconic acid, phenylmercapturic acid, phenol, catechol, hydroquinone and 1,2,4-trihydroxybenzene.",1
"Most of these metabolites have some value as biomarkers of human exposure, since they accumulate in the urine in proportion to the extent and duration of exposure, and they may still be present for some days after exposure has ceased. The current ACGIH biological exposure limits for occupational exposure are 500 μg/g creatinine for muconic acid and 25 μg/g creatinine for phenylmercapturic acid in an end-of-shift urine specimen.",1
"These include cytochrome P450 2E1 (CYP2E1), quinine oxidoreductase (NQ01 or DT-diaphorase or NAD(P)H dehydrogenase (quinone 1)), GSH, and myeloperoxidase (MPO). CYP2E1 is involved at multiple steps: converting benzene to oxepin (benzene oxide), phenol to hydroquinone, and hydroquinone to both benzenetriol and catechol. Hydroquinone, benzenetriol and catechol are converted to polyphenols. In the bone marrow, MPO converts these polyphenols to benzoquinones.",1
"These intermediates and metabolites induce genotoxicity by multiple mechanisms including inhibition of topoisomerase II (which maintains chromosome structure), disruption of microtubules (which maintains cellular structure and organization), generation of oxygen free radicals (unstable species) that may lead to point mutations, increasing oxidative stress, inducing DNA strand breaks, and altering DNA methylation (which can affect gene expression). NQ01 and GSH shift metabolism away from toxicity. NQ01 metabolizes benzoquinone toward polyphenols (counteracting the effect of MPO). GSH is involved with the formation of phenylmercapturic acid.Genetic polymorphisms in these enzymes may induce loss of function or gain of function.",1
"For example, mutations in CYP2E1 increase activity and result in increased generation of toxic metabolites. NQ01 mutations result in loss of function and may result in decreased detoxification. Myeloperoxidase mutations result in loss of function and may result in decreased generation of toxic metabolites. GSH mutations or deletions result in loss of function and result in decreased detoxification. These genes may be targets for genetic screening for susceptibility to benzene toxicity.",1
The paradigm of toxicological assessment of benzene is shifting towards the domain of molecular toxicology as it allows understanding of fundamental biological mechanisms in a better way. Glutathione seems to play an important role by protecting against benzene-induced DNA breaks and it is being identified as a new biomarker for exposure and effect. Benzene causes chromosomal aberrations in the peripheral blood leukocytes and bone marrow explaining the higher incidence of leukemia and multiple myeloma caused by chronic exposure.,1
"These aberrations can be monitored using fluorescent in situ hybridization (FISH) with DNA probes to assess the effects of benzene along with the hematological tests as markers of hematotoxicity. Benzene metabolism involves enzymes coded for by polymorphic genes. Studies have shown that genotype at these loci may influence susceptibility to the toxic effects of benzene exposure. Individuals carrying variant of NAD(P)H:quinone oxidoreductase 1 (NQO1), microsomal epoxide hydrolase (EPHX) and deletion of the glutathione S-transferase T1 (GSTT1) showed a greater frequency of DNA single-stranded breaks.",1
"One way of understanding the carcinogenic effects of benzene is by examining the products of biological oxidation. Pure benzene, for example, oxidizes in the body to produce an epoxide, benzene oxide, which is not excreted readily and can interact with DNA to produce harmful mutations.",1
"of retained benzene was eliminated through the lungs within five to seven hours after a two- to three-hour exposure to 47 to 110 ppm and only 0.07 to 0.2% of the remaining benzene was excreted unchanged in the urine. After exposure to 63 to 405 mg/m3 of benzene for 1 to 5 hours, 51 to 87% was excreted in the urine as phenol over a period of 23 to 50 hours. In another human study, 30% of absorbed dermally applied benzene, which is primarily metabolized in the liver, was excreted as phenol in the urine.",1
"Under specific conditions and in the presence of other chemicals benzoic acid (a preservative) and ascorbic acid (Vitamin C) may interact to produce benzene. In March 2006, the official Food Standards Agency in United Kingdom conducted a survey of 150 brands of soft drinks. It found that four contained benzene levels above World Health Organization limits. The affected batches were removed from sale. Similar problems were reported by the FDA in the United States.",1
"of Health and Human Services: TR-289: Toxicology and Carcinogenesis Studies of Benzene Video Podcast of Sir John Cadogan giving a lecture on Benzene since Faraday, in 1991 Substance profile Benzene in the ChemIDplus database NLM Hazardous Substances Databank – Benzene",1
The FDA can rely on evidence from animal studies to provide substantial evidence of product effectiveness if: There is a reasonably well-understood mechanism for the toxicity of the agent and its amelioration or prevention by the product; The effect is demonstrated in either: More than one animal species expected to react with a response predictive for humans; or One well-characterized animal species model (adequately evaluated for its responsiveness in humans) for predicting the response in humans.,1
"The animal study endpoint is clearly related to the desired benefit in humans; and Data or information on the pharmacokinetics and pharmacodynamics of the product or other relevant data or information in animals or humans is sufficiently well understood to allow selection of an effective dose in humans, and it is, therefore, reasonable to expect the effectiveness of the product in animals to be a reliable indicator of its effectiveness in humans.FDA published a Guidance for Industry on the Animal Rule in October 2015. 21 CFR Parts 314 and 601, Docket No.",1
"98N-0237 New Drug and Biological Drug Products; Evidence Needed to Demonstrate Effectiveness of New Drugs When Human Efficacy Studies Are Not Ethical or Feasible. What is meant by ""Required Under Animal Efficacy Rule"" in the search results display? FDA.gov Postmarketing Requirements and Commitments: Frequently Asked Questions (FAQ)",1
"About 8:15 p.m. on the evening of February 19, 1994, Ramirez, suffering from severe heart palpitations, was brought into the emergency department of Riverside General Hospital in Riverside, by paramedics. She was extremely confused and was suffering from tachycardia and Cheyne–Stokes respiration. The medical staff administered diazepam, midazolam, and lorazepam to sedate her. When it became clear that Ramirez was responding poorly to treatment, the staff tried to defibrillate her heart; at that point several medical workers saw an oily sheen covering Ramirez's body, and some noticed a fruity, garlic-like odor that they thought was coming from her mouth.",1
"Registered nurse Susan Kane drew blood from Ramirez's arm and noticed an ammonia-like smell coming from the tube.She passed the tube to Julie Gorchynski, a medical resident, who noticed manila-colored [yellow-brown] particles floating in the blood. At this point, Kane fainted and was removed from the room. Shortly thereafter, Gorchynski began to feel nauseated. Complaining that she was lightheaded, she left the trauma room and sat at a nurse's desk. A staff member asked her if she was okay, but before she could respond she also fainted.",1
"Maureen Welch, a respiratory therapist who was assisting in the trauma room, was the third to pass out. The staff was then ordered to evacuate all emergency department patients to the parking lot outside the hospital. Overall, 23 people became ill and five were hospitalized. A skeleton crew stayed behind to stabilize Ramirez. At 8:50 p.m., after 45 minutes of CPR and defibrillation, Ramirez was pronounced dead from kidney failure related to her cancer. The county health department called in California's Department of Health and Human Services, which put two scientists, Drs. Ana Maria Osorio and Kirsten Waller, on the case.",1
"They interviewed 34 hospital staff who had been working in the emergency department on February 19. Using a standardized questionnaire, Osorio and Waller found that the people who had developed severe symptoms, such as loss of consciousness, shortness of breath, and muscle spasms, tended to have certain things in common. People who had worked within two feet of Ramirez and had handled her intravenous lines had been at high risk.",1
"But other factors that correlated with severe symptoms did not appear to match a scenario in which fumes had been released: the survey found that those afflicted tended to be women rather than men, and they all had normal blood tests after the exposure. They believed the hospital workers suffered from mass hysteria.Gorchynski denied that she had been affected by mass hysteria and pointed to her own medical history as evidence. After the exposure, she spent two weeks in the intensive care unit with breathing problems. She developed hepatitis and avascular necrosis in her knees.",1
"Oxygen administered by the paramedics would have combined with the DMSO to form dimethyl sulfone (DMSO2). DMSO2 is known to crystallize at room temperature, and crystals were observed in some of Ramirez's drawn blood. Electric shocks administered during emergency defibrillation could have then converted the DMSO2 into dimethyl sulfate (DMSO4), the highly toxic dimethyl ester of sulfuric acid, exposure to which could have caused some of the reported symptoms of the emergency department staff. The Livermore scientists postulated on The New Detectives that the change in temperature of the blood drawn, from the 98.6",1
"°F (37 °C) of Ramirez's body to the 64 °F (18 °C) of the emergency department, may have contributed to its conversion from DMSO2 into DMSO4. This, however, has not been confirmed. Two months after Ramirez died, her severely decomposed body was released for an independent autopsy and burial. The Riverside Coroner's Office hailed Livermore's DMSO conclusion as the probable cause of the hospital workers' symptoms, while her family disagreed. The Ramirez family's pathologist was unable to determine a cause of death because her heart was missing, her other organs were cross-contaminated with fecal matter, and her body was too decomposed.",1
"On April 20, 1994—ten weeks after her death—Ramirez was buried at Olivewood Memorial Park in Riverside. The possible chemical explanation for this incident by Patrick M. Grant of the Livermore Forensic Science Center is beginning to appear in basic forensic science textbooks. In Houck and Siegel's textbook, the authors state that, although some weaknesses exist, the postulated scenario is ""the most scientific explanation to date"" and that ""beyond this theory, no credible explanation has ever been offered for the strange case of Gloria Ramirez.""Grant's",1
"conclusions and speculations about the incident were evaluated by professional forensic scientists, chemists, and toxicologists, passed peer review in an accredited, refereed journal, and were published by Forensic Science International. The first paper was technically detailed and contained two potential chemical reaction mechanisms that may possibly have formed dimethyl sulfate from dimethyl sulfoxide and dimethyl sulfone precursors. The second communication gave supplemental support for the postulated chemical scenario as well as insight into some of the sociology and vested interests inherent in the case. List of unsolved deaths List of unusual deaths",1
"monitoring and assessing aquatic species (incl. plants, animals, and bacteria) monitoring the behavior of certain aquatic species and assessing any changes in species behavior analyzing the biochemical make-up of the waterbody, and its potential influence on the species that depend on it.",1
"Species community assemblages and changes therein can help researchers to infer changes in the health of an ecosystem. In typical unpolluted temperate streams of Europe and North America, certain insect taxa predominate. Mayflies (Ephemeroptera), caddisflies (Trichoptera), and stoneflies (Plecoptera) are the most common insects in these undisturbed streams. In contrast, in rivers disturbed by urbanization, agriculture, forestry, and other perturbations, flies (Diptera), and especially midges (family Chironomidae) predominate.",1
"From his investigations, Mitchell thought the haze had come from industrial areas in Europe and China. He went on to become an eminent climatologist. The haze is seasonal, reaching a peak in late winter and spring. When an aircraft is within a layer of Arctic haze, pilots report that horizontal visibility can drop to one tenth that of normally clear sky. At this time it was unknown whether the haze was natural or was formed by pollutants.",1
"aerosols in the atmosphere affect cloud formation, leading to localized cooling effects over industrialized regions due to increased reflection of sunlight, which masks the opposite effect of trapped warmth beneath the cloud cover. During the Arctic winter, however, there is no sunlight to reflect. In the absence of this cooling effect, the dominant effect of changes to Arctic clouds is an increased trapping of infrared radiation from the surface.",1
"The trapped particles were dark gray the next year he took a sample. That was caused by a heavy amount of industrial pollutants.A 2013 study found that at least 40% of the black carbon deposited in the Arctic originated from gas flares, predominately from oil extraction activities throughout the northern latitudes. The black carbon is short-lived, but such routine flaring also emits vast quantities of sulphur. Home fires in India also contribute.",1
"13 November 2006. Seattle Post-Intelligencer. Rozell, Ned. Arctic Haze: An Uninvited Spring Guest. 2 April 1996. Geographical Institute, University of Alaska Fairbanks. 1 May 2007 Study: The Haze is Heating Up the Arctic. 10 May 2006. United Press International. Garrett, Tim. Pollutant Haze is Heating up the Arctic. 10 May 2006. Earth Observatory. Contaminating the Arctic. 1 January 1999. Scholastic. Gorrie, Peter. Grim prognosis for Earth. 3 January 2007. Toronto Star. What is Arctic Haze? Archived 27 January 2013 at the Wayback Machine",1
"ISBN 978-88-97683-47-6 Mian N Riaz, Riaz N Riaz, Muhammad M Chaudry. Halal Food Production, CRC Press, 2004. ISBN 1-58716-029-3 Tsai, Michelle. ""What's in a can of dog food?, Slate, March 19, 2007. Earthly Origin of Materials, is a material animal, vegetable, or mineral?",1
"These databases are invaluable resources in the field of aquatic toxicology because the likelihood that a chemical will cause toxicity is highly variable across the broad spectrum of contaminants in the environment. This is because the likelihood of adverse effects on an organism is dependent on the concentration of that substance in the target tissues of the organism, the physicochemical properties of that chemical and the duration of exposure to the chemical. Tools capable of predicting the toxicity of specific chemicals to particular organisms or groups of organisms are essential to regulators and researchers in the field of toxicology.",1
"Data regarding organism response endpoints or effects are measured as the concentration of chemical in the tissue of the test organism at the time which effects such as lethality, metabolic depression, or increased respiration occur. More than 3,000 effects may be queried from a small piece of downloaded software to gather survival, growth or reproductive endpoint effect data.",1
"ECOTOX is considered to be more comprehensive in that it holds results from toxicity tests of single chemicals on aquatic and terrestrial plants and animals. Data can be found on both freshwater and marine taxa. ECOTOX collects data from previously EPA established databases AQUIRE, TERRATOX, and PHYTOTOX which individually provide aquatic, terrestrial species and plant data respectively. Data large is collected from peer reviewed literature however some amount of data is sourced from grey literature. Using the Quick Database Query function enables searches by chemical, taxonomic name, effect, and publication year.",1
Data resulting from toxicity studies that is integrated in to the ECOTOX database is subjected to a screening and quality assurance criteria developed by the EPA and the Office of Pesticide Programs (OPP).,1
"In addition to the criteria listed above, the following criteria, which are discussed in further detail in Attachment I, are applied by OPP as a further screen of acceptability: Toxicology information is reported for a chemical of concern to OPP; The article is published in the English language; The study is presented as a full article; The paper is a publicly available document; The paper is the primary source of the data A calculated endpoint is reported; Treatment(s) are compared to an acceptable control; The location of the study (e.g., laboratory vs.",1
The Toxicity/Residue Database EPA database USGS database United States Army Corps of Engineers database National Oceanic and Atmospheric Administration database Office of Pesticide Programs,1
"The concept of the oceanic anoxic event (OAE) was first proposed in 1976 by Seymour Schlanger (1927–1990) and geologist Hugh Jenkyns and arose from discoveries made by the Deep Sea Drilling Project (DSDP) in the Pacific Ocean. The finding of black, carbon-rich shales in Cretaceous sediments that had accumulated on submarine volcanic plateaus (e.g.",1
"Shatsky Rise, Manihiki Plateau), coupled with their identical age to similar, cored deposits from the Atlantic Ocean and known outcrops in Europe—particularly in the geological record of the otherwise limestone-dominated Apennines chain in Italy—led to the observation that these widespread, similarly distinct strata recorded very unusual, oxygen-depleted conditions in the world's oceans spanning several discrete periods of geological time. Modern sedimentological investigations of these organic-rich sediments typically reveal the presence of fine laminations undisturbed by bottom-dwelling fauna, indicating anoxic conditions on the seafloor believed to coincide with a low-lying poisonous layer of hydrogen sulfide, H2S.",1
"Furthermore, detailed organic geochemical studies have recently revealed the presence of molecules (so-called biomarkers) that derive from both purple sulfur bacteria and green sulfur bacteria—organisms that required both light and free hydrogen sulfide (H2S), illustrating that anoxic conditions extended high into the photic upper-water column. This is a recent understanding, the puzzle having been pieced slowly together in the last three decades. The handful of known and suspected anoxic events have been tied geologically to large-scale production of the world's oil reserves in worldwide bands of black shale in the geologic record.",1
"Anoxic events with euxinic (anoxic, sulfidic) conditions have been linked to extreme episodes of volcanic outgassing. Volcanism contributed to the buildup of CO2 in the atmosphere and increased global temperatures, causing an accelerated hydrological cycle that introduced nutrients into the oceans (stimulating planktonic productivity). These processes potentially acted as a trigger for euxinia in restricted basins where water-column stratification could develop. Under anoxic to euxinic conditions, oceanic phosphate is not retained in sediment and could hence be released and recycled, aiding perpetual high productivity.",1
"Temperatures throughout the Jurassic and Cretaceous are generally thought to have been relatively warm, and consequently dissolved oxygen levels in the ocean were lower than today—making anoxia easier to achieve. However, more specific conditions are required to explain the short-period (less than a million years) oceanic anoxic events. Two hypotheses, and variations upon them, have proved most durable.",1
"One hypothesis suggests that the anomalous accumulation of organic matter relates to its enhanced preservation under restricted and poorly oxygenated conditions, which themselves were a function of the particular geometry of the ocean basin: such a hypothesis, although readily applicable to the young and relatively narrow Cretaceous Atlantic (which could be likened to a large-scale Black Sea, only poorly connected to the World Ocean), fails to explain the occurrence of coeval black shales on open-ocean Pacific plateaus and shelf seas around the world.",1
"There are suggestions, again from the Atlantic, that a shift in oceanic circulation was responsible, where warm, salty waters at low latitudes became hypersaline and sank to form an intermediate layer, at 500 to 1,000 m (1,640 to 3,281 ft) depth, with a temperature of 20 to 25 °C (68 to 77 °F).The second hypothesis suggests that oceanic anoxic events record a major change in the fertility of the oceans that resulted in an increase in organic-walled plankton (including bacteria) at the expense of calcareous plankton such as coccoliths and foraminifera.",1
"Such an accelerated flux of organic matter would have expanded and intensified the oxygen minimum zone, further enhancing the amount of organic carbon entering the sedimentary record. Essentially this mechanism assumes a major increase in the availability of dissolved nutrients such as nitrate, phosphate and possibly iron to the phytoplankton population living in the illuminated layers of the oceans. For such an increase to occur would have required an accelerated influx of land-derived nutrients coupled with vigorous upwelling, requiring major climate change on a global scale.",1
"Geochemical data from oxygen-isotope ratios in carbonate sediments and fossils, and magnesium/calcium ratios in fossils, indicate that all major oceanic anoxic events were associated with thermal maxima, making it likely that global weathering rates, and nutrient flux to the oceans, were increased during these intervals. Indeed, the reduced solubility of oxygen would lead to phosphate release, further nourishing the ocean and fuelling high productivity, hence a high oxygen demand—sustaining the event through a positive feedback.Another",1
"way to explain anoxic events is that the Earth releases a huge volume of carbon dioxide during an interval of intense volcanism; global temperatures rise due to the greenhouse effect; global weathering rates and fluvial nutrient flux increase; organic productivity in the oceans increases; organic-carbon burial in the oceans increases (OAE begins); carbon dioxide is drawn down due to both burial of organic matter and weathering of silicate rocks (inverse greenhouse effect); global temperatures fall, and the ocean–atmosphere system returns to equilibrium (OAE ends).",1
"In this way, an oceanic anoxic event can be viewed as the Earth's response to the injection of excess carbon dioxide into the atmosphere and hydrosphere. One test of this notion is to look at the age of large igneous provinces (LIPs), the extrusion of which would presumably have been accompanied by rapid effusion of vast quantities of volcanogenic gases such as carbon dioxide.",1
"The age of three LIPs (Karoo-Ferrar flood basalt, Caribbean large igneous province, Ontong Java Plateau) correlates well with that of the major Jurassic (early Toarcian) and Cretaceous (early Aptian and Cenomanian–Turonian) oceanic anoxic events, indicating that a causal link is feasible. Oceanic anoxic events most commonly occurred during periods of very warm climate characterized by high levels of carbon dioxide (CO2) and mean surface temperatures probably in excess of 25 °C (77 °F). The Quaternary levels, the current period, are just 13 °C (55 °F) in comparison.",1
"Studies suggest the huge release of natural gas could be a major climatological trigger, methane itself being a greenhouse gas many times more powerful than carbon dioxide. However, anoxia was also rife during the Hirnantian (late Ordovician) ice age. Oceanic anoxic events have been recognized primarily from the already warm Cretaceous and Jurassic Periods, when numerous examples have been documented, but earlier examples have been suggested to have occurred in the late Triassic, Permian, Devonian (Kellwasser event), Ordovician and Cambrian.",1
"The Paleocene–Eocene Thermal Maximum (PETM), which was characterized by a global rise in temperature and deposition of organic-rich shales in some shelf seas, shows many similarities to oceanic anoxic events. Typically, oceanic anoxic events lasted for less than a million years, before a full recovery. Oceanic anoxic events have had many important consequences. It is believed that they have been responsible for mass extinctions of marine organisms both in the Paleozoic and Mesozoic. The early Toarcian and Cenomanian-Turonian anoxic events correlate with the Toarcian and Cenomanian-Turonian extinction events of mostly marine life forms.",1
"Apart from possible atmospheric effects, many deeper-dwelling marine organisms could not adapt to an ocean where oxygen penetrated only the surface layers. An economically significant consequence of oceanic anoxic events is the fact that the prevailing conditions in so many Mesozoic oceans has helped produce most of the world's petroleum and natural gas reserves. During an oceanic anoxic event, the accumulation and preservation of organic matter was much greater than normal, allowing the generation of potential petroleum source rocks in many environments across the globe.",1
"Consequently, some 70 percent of oil source rocks are Mesozoic in age, and another 15 percent date from the warm Paleogene: only rarely in colder periods were conditions favorable for the production of source rocks on anything other than a local scale.",1
"The increased UV radiation caused by this ozone depletion would have amplified the destruction of plant and animal life. Fossil spores from strata recording the Permian-Triassic extinction event show deformities consistent with UV radiation. This evidence, combined with fossil biomarkers of green sulfur bacteria, indicates that this process could have played a role in that mass extinction event, and possibly other extinction events. The trigger for these mass extinctions appears to be a warming of the ocean caused by a rise of carbon dioxide levels to about 1000 parts per million.",1
"In the late Silurian mid-Pridoli event, increases are seen in the Fe, Cu, As, Al, Pb, Ba, Mo and Mn levels in shallow-water sediment and microplankton; this is associated with a marked increase in the malformation rate in chitinozoans and other microplankton types, likely due to metal toxicity. Similar metal enrichment has been reported in sediments from the mid-Silurian Ireviken event.",1
"Detailed stratigraphic studies of Cretaceous black shales from many parts of the world have indicated that two oceanic anoxic events (OAEs) were particularly significant in terms of their impact on the chemistry of the oceans, one in the early Aptian (~120 Ma), sometimes called the Selli Event (or OAE 1a) after the Italian geologist Raimondo Selli (1916–1983), and another at the Cenomanian–Turonian boundary (~93 Ma), also called the Bonarelli Event (or OAE2) after the Italian geologist Guido Bonarelli (1871–1951). OAE1a lasted for ~1.0 to 1.3 Myr.",1
"The duration of OAE2 is estimated to be ~820 kyr based on a high-resolution study of the significantly expanded OAE2 interval in southern Tibet, China. Insofar as the Cretaceous OAEs can be represented by type localities, it is the striking outcrops of laminated black shales within the vari-coloured claystones and pink and white limestones near the town of Gubbio in the Italian Apennines that are the best candidates. The 1-metre thick black shale at the Cenomanian–Turonian boundary that crops out near Gubbio is termed the 'Livello Bonarelli' after the scientist who first described it in 1891.More",1
"minor oceanic anoxic events have been proposed for other intervals in the Cretaceous (in the Valanginian, Hauterivian, Albian and Coniacian–Santonian stages), but their sedimentary record, as represented by organic-rich black shales, appears more parochial, being dominantly represented in the Atlantic and neighbouring areas, and some researchers relate them to particular local conditions rather than being forced by global change.",1
"The only oceanic anoxic event documented from the Jurassic took place during the early Toarcian (~183 Ma). Since no DSDP (Deep Sea Drilling Project) or ODP (Ocean Drilling Program) cores have recovered black shales of this age—there being little or no Toarcian ocean crust remaining—the samples of black shale primarily come from outcrops on land. These outcrops, together with material from some commercial oil wells, are found on all major continents and this event seems similar in kind to the two major Cretaceous examples.",1
"If the high latitude waters are below 5 °C (41 °F), they will be dense enough to sink; as they are cool, oxygen is highly soluble in their waters, and the deep ocean will be oxygenated. If high latitude waters are warmer than 5 °C (41 °F), their density is too low for them to sink below the cooler deep waters. Therefore, thermohaline circulation can only be driven by salt-increased density, which tends to form in warm waters where evaporation is high.",1
"The periods with cold poles are termed ""P-episodes"" (short for primo), and are characterised by bioturbated deep oceans, a humid equator and higher weathering rates, and terminated by extinction events—for example, the Ireviken and Lau events. The inverse is true for the warmer, oxic ""S-episodes"" (secundo), where deep ocean sediments are typically graptolitic black shales. A typical cycle of secundo-primo episodes and ensuing event typically lasts around 3 Ma.The duration of events is so long compared to their onset because the positive feedbacks must be overwhelmed.",1
"Carbon content in the ocean-atmosphere system is affected by changes in weathering rates, which in turn is dominantly controlled by rainfall. Because this is inversely related to temperature in Silurian times, carbon is gradually drawn down during warm (high CO2) S-episodes, while the reverse is true during P-episodes. On top of this gradual trend is overprinted the signal of Milankovic cycles, which ultimately trigger the switch between P- and S- episodes.These events become longer during the Devonian; the enlarging land plant biota probably acted as a large buffer to carbon dioxide concentrations.The",1
"end-Ordovician Hirnantian event may alternatively be a result of algal blooms, caused by sudden supply of nutrients through wind-driven upwelling or an influx of nutrient-rich meltwater from melting glaciers, which by virtue of its fresh nature would also slow down oceanic circulation.",1
"""Diazotrophic cyanobacteria as the major photoautotrophs during mid-Cretaceous oceanic anoxic events: Nitrogen and carbon isotopic evidence from sedimentary porphyrin"". Organic Geochemistry. 39 (5): 532–549. Bibcode:2008OrGeo..39..532K. doi:10.1016/j.orggeochem.2007.11.010. Kump, L.R.; Pavlov, A. & Arthur, M.A. (2005). ""Massive release of hydrogen sulfide to the surface ocean and atmosphere during intervals of oceanic anoxia"". Geology. 33 (5): 397–400. Bibcode:2005Geo....33..397K. doi:10.1130/G21295.1. Hallam, A. (2004). Catastrophes and lesser calamities: the causes of mass extinctions. Oxford [Oxfordshire]: Oxford University Press. pp. 91–607. ISBN 978-0-19-852497-7. Demaison G.J. and Moore G.T., (1980),""Anoxic environments and oil source bed genesis"". American Association of Petroleum Geologists (AAPG) Bulletin, Vol.54, 1179–1209.",1
"Hot and stinky: The oceans without oxygen Charles E. Jones; Hugh C. Jenkyns (February 2001). ""Seawater strontium isotopes, oceanic anoxic events, and seafloor spreading"" (PDF). American Journal of Science. Archived from the original (PDF) on 2005-05-07. Cretaceous climate-ocean dynamics Pancost, Richard D.; Crawford, Neal; Magness, Simon; Turner, Andy; Jenkyns, Hugh C.; Maxwell, James R. (May 2004). ""Further evidence for the development of photic-zone euxinic conditions during Mesozoic oceanic anoxic events"". Journal of the Geological Society. 161 (3): 353–364. Bibcode:2004JGSoc.161..353P. doi:10.1144/0016764903-059. S2CID 130919916.",1
"Hugh Jenkyns talking about the Bonarelli Level and OAEs [1] Original article (Geologie en Mijnbouw, 55, 179–184, 1976) on oceanic anoxic events authored by Seymour Schlanger and Hugh Jenkyns [2]",1
"death or other adverse effect to the organism). Concentration is on the x-axis and percent inhibition or response is on the y-axis.The criteria for effects, or endpoints tested for, can include lethal and sublethal effects (see Toxicological effects).There are different types of toxicity tests that can be performed on various test species. Different species differ in their susceptibility to chemicals, most likely due to differences in accessibility, metabolic rate, excretion rate, genetic factors, dietary factors, age, sex, health and stress level of the organism. Common standard test species are the fathead minnow (Pimephales promelas), daphnids (Daphnia magna, D. pulex, D.",1
"field testing, end-point selection, and time and resources available to conduct the assays are some of the most common influencing factors on test design.",1
"Chronic tests are generally considered full life cycle tests and cover an entire generation time or reproductive life cycle (“egg to egg”). Chronic tests are not considered valid if mortality in the control sample is greater than 20%. These results have generally been reported in NOECs (No observed effects level) and LOECs (Lowest observed effects level). However, NOECs and LOECs are becoming less common as endpoints are dependent on the concentration series chosen for the test. These reports are starting to become a topic of debate in the field because of the way it may alter the results of the tests.",1
"For example, if the concentration rate of the NOEC is 100, 50, 25, 11.25, 6.25 and the toxicology is reported at 2%, the NOEC would report the concentration as 6.25. Early life stage tests are considered as subchronic exposures that are less than a complete reproductive life cycle and include exposure during early, sensitive life stages of an organism. These exposures are also called critical life stage, embryo-larval, or egg-fry tests. Early life stage tests are not considered valid if mortality in the control sample is greater than 30%.Short-term",1
"These endpoints include behavioral, physiological, biochemical, histological changes.There are a number of effects that occur when an organism is simultaneously exposed to two or more toxicants. These effects include additive effects, synergistic effects, potentiation effects, and antagonistic effects. An additive effect occurs when combined effect is equal to a combination or sum of the individual effects. A synergistic effect occurs when the combination of effects is much greater than the two individual effects added together.",1
Critical Body Residue (CBR) – An approach that routinely examines whole-body chemical concentrations of an exposed organism that is associated with an adverse biological response. Baseline toxicity – Refers to narcosis which is a depression in biological activity due to toxicants being present in the organism. Biomagnification – The process by which the concentration of a chemical in the tissues of an organism increases as it passes through several levels in the food web. Lowest Observed Effect Concentration (LOEC) – The lowest test concentration that has a statistically significant effect over a specified exposure time.,1
"While sediment quality guidelines are not meant for regulation, they provide a way to rank and compare sediment quality developed by National Oceanic and Atmospheric Administration(NOAA). These sediment quality guidelines are summarized in NOAA's Screening Quick Reference Tables (SQuiRT) for many different chemicals.",1
"""Big Oil and Gas spread the 'Big Lie' about toxic waste"". Workers World. Lodge, Terry (16 March 2018). ""Don't be fooled - don't buy bottled radioactive waste!"". The Columbus Freepress.",1
"'BAT conclusions' are to be considered by Member States of the European Union as reference when setting permit conditions for all installations within the scope of the Industrial Emissions Directive. Best Available Techniques (BAT) Reference Document (BREF) is defined in Article 3(11) of the Industrial Emissions Directive 2010/75/EU as: ""[...]",1
"a document, resulting from the exchange of information organised pursuant to Article 13, drawn up for defined activities and describing, in particular, applied techniques, present emissions and consumption levels, techniques considered for the determination of best available techniques as well as BAT conclusions and any emerging techniques, giving special consideration to the criteria listed in Annex III"".BAT conclusions are defined in Article 3(12) of the Industrial Emissions Directive 2010/75/EU as: ""[...]",1
"a document containing the parts of a BAT reference document laying down the conclusions on best available techniques, their description, information to assess their applicability, the emission levels associated with the best available techniques, associated monitoring, associated consumption levels and, where appropriate, relevant site remediation measures"".According",1
"The process is codified into law by Commission Implementing Decision 2012/119/EU. The most important chapter of the BREFs, the BAT conclusions, are published as implementing decisions of the European Commission in the Official Journal of the European Union. According to article 14(3) of the Industrial Emissions Directive, the BAT conclusions shall be the reference for setting permit conditions of large industrial installations.",1
"A Reference Document on Best Available Techniques (BREF) in the food, drink and milk industries of the European Union was published in August 2006, and reflected an information exchange carried out according to Article 16.2 of Council Directive 96/61/EC. It runs to more than 600 pages, and is replete with tables and flowchart diagrams. The 2006 BREF on these industries was superseded by another published in January 2017, which runs to more than 1000 pages.",1
Industrial wastewater treatment Low Impact Development (LID) Nationwide Urban Runoff Program (NURP) - EPA research program on stormwater BMPs Stochastic Empirical Loading and Dilution Model for modeling the performance of BMPs Sustainable urban drainage systems Blue-Green cities - Incorporating many of the same concepts into a holistic approach for city design.,1
International Stormwater BMP Database – Performance Data on Urban Stormwater BMPs California Stormwater BMP Handbooks - California Stormwater Quality Association Technology Assessment Protocol – Ecology (TAPE) - Washington State Department of Ecology's process for evaluating and approving emerging stormwater treatment BMPs Technology Acceptance Reciprocity Partnership (TARP) - Multi-state protocol for stormwater BMP demonstrations Pennsylvania Stormwater BMP Manual (2006),1
"List of Designated Reference and Equivalent Methods. EPA: Research Triangle park, 2013. Online: http://www.epa.gov/ttn/amtic/criteria.html .",1
"Rather than engaging in active debris removal (ADR) of real space debris, the RemoveDEBRIS mission plan was to test the efficacy of several ADR technologies on mock targets in low Earth orbit. In order to complete its planned experiments the platform was equipped with a net, a harpoon, a laser ranging instrument, a dragsail, and two CubeSats (miniature research satellites).The experiments were as follows: Net experiment - One of the CubeSats, called DebrisSat 1, deployed a balloon meant to simulate a piece of space debris.",1
"From a short distance away, the RemoveDEBRIS satellite captured the debris in a net and then manoeuvred this package to fall into Earth's atmosphere and burn up. Vision-based navigation - The other CubeSat, called DebrisSat 2, was released and the RemoveDEBRIS satellite underwent a series of manoeuvres in order to obtain data and images using both lidar and optical cameras. Harpoon and deployable target - A harpoon connected by a tether was fired at a plate attached to an arm extending from the RemoveDEBRIS platform itself.",1
"The RemoveDEBRIS platform was based on a SSTL X50 Structure that had been customised for deployment from the International Space Station. The platform hosted all the experimental payloads as well as providing power, data and control for the mission. A high degree of autonomy was built in using time-tagged commands to allow experiments to be run out of sight of the groundstation.",1
DebrisSat 1 decayed from orbit on 2 March 2019.,1
"The DebrisSat 2 (DS-2, aka REMDEB-DS2, COSPAR: 1998-067PR) was also based on a 2U CubeSat with two deployable panels solar panels and communications. The spacecraft contained a GPS receiver as well as an inter-satellite link to provide location and attitude data back to the platform to assess the VBN camera performance. The avionics were based on the QB50 avionics stack developed by the Surrey Space Centre and Electronic Systems Laboratory (ESL) at Stellenbosch University. In addition the spacecraft also tested out a low-cost UART camera which was able to beam back pictures to the platform as it separated.",1
DebrisSat 2 deorbited 30 May 2020.,1
"NASA Astronauts Drew Feustel and Ricky Arnold removed the platform handling panels, completed final preparation and loaded the satellite into the Japanese Experiment Module (JEM) airlock on 6 June 2018. An airlock cycle was performed on 19 June 2018 and RemoveDEBRIS moved outside the JEM via the airlock slide table. The spacecraft was grasped by the Kaber interface on the Mobile Servicing System Special Purpose Dexterous Manipulator (MSS SPDM) and placed in the deployment position.",1
"Deployment of the satellite from the station's Kibo module via robotic Canadarm-2 took place on 20 June 2018. At approximately 100 kg, RemoveDEBRIS was the largest satellite to have ever been deployed from the ISS. The platform contained two CubeSat deployers from ISISpace. The full lifespan of the mission from launch to re-entry was estimated at 1.5 years.",1
"On 28 October 2018, DebrisSat 2 was deployed at 06:15UTC. The VBN camera on the platform took 361 images of the spacecraft crucial to determining the performance of the camera system. Position and attitude data from DebrisSat 2 was transmitted back to the platform providing ground truth for the experiment. DebrisSat 2 also forwarded low resolution photos of the deployment to the platform from its own vantage point.",1
"On 8 February 2019, SSTL demonstrated the RemoveDEBRIS harpoon which was fired at a speed of 20 metres per second penetrating a simulated target extended from the satellite on a 1.5 m (4 ft 11 in) boom.",1
"It is illegal in many of the countries in which it is practiced, although these laws are often minimally enforced. Grouper, wrasse, and coral trout are among the more popular species of fish captured through cyanide fishing.",1
"Estimates suggest 70% to 90% of aquarium fish exported from the Philippines are caught with cyanide. Due to the post-capture handling stress and the effects of the cyanide, fish are bound to have a shorter life-span than usual in aquariums. According to an interview with experienced aquarium owners, they were willing to pay more for net-caught fish, because of the higher survival rate. They also said they would not trust an ecolabelling system, which can be misleading.The",1
"Cases have been reported of fishermen dumping drums of concentrated cyanide in places where fishing is difficult or economic times are hard. Such high concentrations normally kill most of the haul, but in these cases, the objective is no longer to catch live fish, but to catch the largest amount possible. In seawater, sodium cyanide breaks down into sodium and cyanide ions. In humans, cyanides block the oxygen-transporting protein haemoglobin; the haemoglobin in fish is closely related to that of humans, and can combine with oxygen even faster.",1
"This is a constant danger for the fishermen; there are many local accounts of such 'occupational accidents', but such incidents are not recorded in official statistics or statements. Many fishing and diving areas across the whole of South East Asia, already severely damaged from the impact of dynamite fishing, have been ruined or totally lost through cyanide fishing. Cyanide concentration slows photosynthesis in zooxanthellae, which results in coral reefs losing colour; it also eliminates one of their major food sources. Even at very low doses, cyanide results in higher mortality levels among corals. (in German) nikswieweg.colibri-reisen.de:",1
"detailed article on illegal fishing methods in Palawan, Philippines A Poisonous Business - information on cyanide fishing that supplies the pet trade",1
"Cyclonic spray scrubbers are more efficient than spray towers, but not as efficient as venturi scrubbers, in removing particulate from the inlet gas stream. Particulates larger than 5 μm are generally collected by impaction with 90% efficiency. In a simple spray tower, the velocity of the particulates in the gas stream is low: 0.6 to 1.5 m/s (2 to 5 ft/s). By introducing the inlet gas tangentially into the spray chamber, the cyclonic scrubber increases gas velocities (thus, particulate velocities) to approximately 60 to 180 m/s (200 to 600 ft/s).",1
"The velocity of the liquid spray is approximately the same in both devices. This higher particulate-to-liquid relative velocity increases particulate collection efficiency for this device over that of the spray chamber. Gas velocities of 60 to 180 m/s are equivalent to those encountered in a venturi scrubber. However, cyclonic spray scrubbers are not as efficient as venturi scrubbers because they are not capable of producing the same degree of useful turbulence. High gas velocities through these devices reduce the gas-liquid contact time, thus reducing absorption efficiency.",1
"Cyclonic spray scrubbers are capable of effectively removing some gases; however, they are rarely chosen when gaseous pollutant removal is the only concern. The main maintenance problems with cyclonic scrubbers are nozzle plugging and corrosion or erosion of the side walls of the cyclone body. Nozzles have a tendency to plug from particulates that are in the recycled liquid and/or particulates that are in the gas stream. The best solution is to install the nozzles so that they are easily accessible for cleaning or removal.",1
"The DSSAM Model is constructed to allow dynamic decay of most pollutants; for example, total nitrogen and phosphorus are allowed to be consumed by benthic algae in each time step, and the algal communities are given a separate population dynamic in each river reach (e.g.metabolic rate based upon river temperature). Sources throughout the watershed include non-point agricultural and urban stormwater as well as a multiplicity of point source discharges of treated municipal wastewater effluent. Subsequent to the first generation of DSSAM model development, calibration and application, later refinements were made.",1
"These augmentations to model functionality focussed on increased flexibility in modeling the diel cycle and also allowed inclusion of analyzing particulate nitrogen and phosphorus. In developing DSSAM III several changes in the model operation and scope were performed. Numerous different uses of the model have been made including (a)analysis of public policies for urban stormwater runoff, (b) researching agricultural methods for surface runoff minimization, (c) innovative solutions for non-point source control and d)engineering aspects of treated wastewater discharge. Regarding stormwater runoff in Washoe County, the specific elements within a new xeriscape ordinance were analyzed for efficacy using the model.",1
"If one considers an isolated particle circling in the upper cylindrical component of the cyclone at a rotational radius of r {\displaystyle r} from the cyclone's central axis, the particle is therefore subjected to drag, centrifugal, and buoyant forces. Given that the fluid velocity is moving in a spiral the gas velocity can be broken into two component velocities: a tangential component, V t {\displaystyle V_{t}} , and an outward radial velocity component V r {\displaystyle V_{r}} .",1
"Assuming Stokes' law, the drag force in the outward radial direction that is opposing the outward velocity on any particle in the inlet stream is: F d = − 6 π r p μ V r . {\displaystyle F_{d}=-6\pi r_{p}\mu V_{r}.} Using ρ p {\displaystyle \rho _{p}} as the particle's density, the centrifugal component in the outward radial direction is: F c = m V t 2 r {\displaystyle F_{c}=m{\frac {V_{t}^{2}}{r}}} = 4 3 π ρ p r p 3 V t 2 r . {\displaystyle ={\frac {4}{3}}\pi \rho _{p}r_{p}^{3}{\frac {V_{t}^{2}}{r}}.} The buoyant force component is in the inward radial direction.",1
"It is in the opposite direction to the particle's centrifugal force because it is on a volume of fluid that is missing compared to the surrounding fluid. Using ρ f {\displaystyle \rho _{f}} for the density of the fluid, the buoyant force is: F b = − V p ρ f V t 2 r {\displaystyle F_{b}=-V_{p}\rho _{f}{\frac {V_{t}^{2}}{r}}} = − 4 π r p 3 3 V t 2 r ρ f . {\displaystyle =-{\frac {4\pi r_{p}^{3}}{3}}{\frac {V_{t}^{2}}{r}}\rho _{f}.} In this case, V p {\displaystyle V_{p}} is equal to the volume of the particle (as opposed to the velocity).",1
"Determining the outward radial motion of each particle is found by setting Newton's second law of motion equal to the sum of these forces: m d V r d t = F d + F c + F b {\displaystyle m{\frac {dV_{r}}{dt}}=F_{d}+F_{c}+F_{b}} To simplify this, we can assume the particle under consideration has reached ""terminal velocity"", i.e., that its acceleration d V r d t {\displaystyle {\frac {dV_{r}}{dt}}} is zero. This occurs when the radial velocity has caused enough drag force to counter the centrifugal and buoyancy forces.",1
This simplification changes our equation to: F d + F c + F b = 0 {\displaystyle F_{d}+F_{c}+F_{b}=0} Which expands to: − 6 π r p μ V r + 4 3 π r p 3 V t 2 r ρ p − 4 3 π r p 3 V t 2 r ρ f = 0 {\displaystyle -6\pi r_{p}\mu V_{r}+{\frac {4}{3}}\pi r_{p}^{3}{\frac {V_{t}^{2}}{r}}\rho _{p}-{\frac {4}{3}}\pi r_{p}^{3}{\frac {V_{t}^{2}}{r}}\rho _{f}=0} Solving for V r {\displaystyle V_{r}} we have V r = 2 9 r p 2 μ V t 2 r ( ρ p − ρ f ) {\displaystyle V_{r}={\frac {2}{9}}{\frac {r_{p}^{2}}{\mu,1
"Rearranging terms we obtain d V r d t + 9 2 μ ρ p r p 2 V r − ( 1 − ρ f ρ p ) V t 2 r = 0 {\displaystyle {\frac {dV_{r}}{dt}}+{\frac {9}{2}}{\frac {\mu }{\rho _{p}r_{p}^{2}}}V_{r}-\left(1-{\frac {\rho _{f}}{\rho _{p}}}\right){\frac {V_{t}^{2}}{r}}=0} Since V r {\displaystyle V_{r}} is distance per time, this is a 2nd order differential equation of the form x ″ + c 1 x ′ + c 2 = 0 {\displaystyle x''+c_{1}x'+c_{2}=0} .",1
"Experimentally it is found that the velocity component of rotational flow is proportional to r 2 {\displaystyle r^{2}} , therefore: V t ∝ r 2 . {\displaystyle V_{t}\propto r^{2}.} This means that the established feed velocity controls the vortex rate inside the cyclone, and the velocity at an arbitrary radius is therefore: U r = U i n r R i n . {\displaystyle U_{r}=U_{in}{\frac {r}{R_{in}}}.}",1
"Subsequently, given a value for V t {\displaystyle V_{t}} , possibly based upon the injection angle, and a cutoff radius, a characteristic particle filtering radius can be estimated, above which particles will be removed from the gas stream. The above equations are limited in many regards. For example, the geometry of the separator is not considered, the particles are assumed to achieve a steady state and the effect of the vortex inversion at the base of the cyclone is also ignored, all behaviours which are unlikely to be achieved in a cyclone at real operating conditions.",1
link is broken alternate link to cited patent,1
Lden is calculated as: L d e n = 10 ⋅ l o g 10 ( 1 24 ( 12 ⋅ 10 L d a y 10 + 4 ⋅ 10 L e v e n i n g + 5 10 + 8 ⋅ 10 L n i g h t + 10 10 ) ) {\displaystyle L_{den}=10\cdot log_{10}\left({\frac {1}{24}}\left(12\cdot 10^{\frac {L_{day}}{10}}+4\cdot 10^{\frac {L_{evening}+5}{10}}+8\cdot 10^{\frac {L_{night}+10}{10}}\right)\right)} Where the long-term average noise levels are defined as: The exact hours of the three periods may be chosen differently by individual EU member states.,1
"Participants include heads of State and Government, civil society representatives, business people, actors, academics and scientists and ocean and marine life advocates from around 200 countries. Around 6,000 leaders gathered for the conference over the course of the week.The Governments of Fiji and Sweden had the co-hosting responsibilities of the Conference.7 partnership dialogues with a rich state-developed state theme were co-chaired by Australia-Kenya, Iceland-Peru, Canada-Senegal, Estonia-Grenada, Italy-Palau, Monaco-Mozambique and Norway-Indonesia.Ministers from small island states such as Palau, Fiji and Tuvalu pleaded for help as for them the issue is existential not just on the long-term.",1
"Over 1,300 voluntary commitments have been made which UN Under-Secretary-General for Economic and Social Affairs Wu Hongbo called ""truly impressive"" and stated that they now comprise ""an ocean solution registry"" via the public online platform. 44 percent of the commitments came from governments, 19 percent from NGOs, 9 percent from UN entities and 6 percent from the private sector.Delegates from China, Thailand, Indonesia and the Philippines pledged to work to keep plastics out of the seas.",1
"New Zealand affirmed the government's commitment to establishing the Kermadec/Rangitahua Ocean Sanctuary, which − with 620,000 square kilometres − would be one of the world's largest fully protected areas. Pakistan also announced its first marine protected area.The US-based international wildlife organisation Wildlife Conservation Society created the MPA Fund in 2016 as well as the blue moon fund for a combined $15 million commitment which aims to create 3.7 million square kilometers of new marine protected areas with The Tiffany & Co. Foundation adding a $1 million grant toward this fund in the week of the conference.",1
"Germany's Federal Minister for the Environment, Nature Conservation and Nuclear Safety Barbara Hendricks also pledged to allocate €670 million for marine conservation projects and made 11 voluntary commitments.Deputy Director-General of the State Oceanic Administrations Lin Shanqing of China − the world's main fish producer and exporter − stated that the country would be ""willing, based on its own development experience, to work actively for the establishment in the area of the ocean of an open, inclusive, concrete, pragmatic, mutually beneficial and win-win blue partnership with other countries and international organizations"".The",1
"On 9 June an official side event of the United Nations Ocean Conference for addressing ways by which the private sector provides practical solutions to address the problems such as by improving energy efficiency, waste management and introducing market-based tools to shift investment, subsidy and production.Nine of the world's biggest fishing companies from Asia, Europe and the US have signed up for The Seafood Business for Ocean Stewardship (SeaBOS) initiative, supported by the Stockholm Resilience Centre, aiming to end unsustainable practices.",1
"At the conference Indonesia published its vessel monitoring system (VMS) publicly revealing the location and activity of its commercial fishing boats on the Global Fishing Watch public mapping platform. Brian Sullivan states that the platform is can easily incorporate additional data sources which may allow ""mov[ing] from raw data to quickly producing dynamic visualizations and reporting that promote scientific discovery and support policies for better fishery management"".Irina",1
"Bokova of UNESCO notes that ""we cannot manage what we cannot measure, and no single country is able to measure the myriad changes taking place in the ocean"", and asks for more maritime research and the sharing of knowledge to craft common science-based policies. Peru co-chaired the ""Partnership Dialogue 6 – Increasing scientific knowledge, and developing research capacity and transfer of marine technology"" with Iceland. On 7 June researchers at the Dutch The Ocean Cleanup foundation published a study according to which rivers − such as the Yangtze − carry an around 1.15–2.41",1
"million tonnes of plastic into the sea every year. UN Secretary-General António Guterres warned that unless nations overcome short-term territorial and resource interests the state of the oceans will continue to deteriorate. He also names ""the artificial dichotomy"" between jobs and healthy oceans as one of the main challenges and asks for strong political leadership, new partnerships and concrete steps.Deputy Secretary-General of the United Nations Amina J Mohammed warns about the harm of overlooking the climate concerns in turn for perceived ""national gain"", claiming that ""a moral obligation to the world which [one] live[s] on"" exists.India,",1
"President Evo Morales told the conference that, one of the world's main polluters, the United States denied science, turned its backs on multilateralism, and attempted to deny a future to upcoming generations by its national government deciding to leave the Paris agreement, making ""it the main threat to Mother Earth and life itself"". Albert II, Prince of Monaco called Trump's withdrawal ""catastrophic"" and the reaction from US mayors, governors and many in the corporate world as ""wonderful"".",1
"On 30 May Sweden's deputy prime minister Isabella Lövin stated that the United States is resisting plans to highlight how climate change is disrupting life in the oceans at the conference, that the US has negatively affected preparations and that ""the decline of the oceans is really a threat to the entire planet"" with a ""need to start working together"". Lövin also makes note of difficulties to engage with Washington in the conference, partly because key posts at the National Oceanic and Atmospheric Administration remain unfilled since the end of the Obama administration.UNCTAD",1
"Secretary-General Mukhisa Kituyi states that subsidies from wealthy governments encourage overfishing, overcapacity and may contribute to illegal and unregulated fishing, creating food insecurity, unemployment and poverty for people relying mainly on fish as their primary source of nourishment or livelihood. Marine biologist Ayana Elizabeth Johnson notes that the UN's work alone is not nearly enough and that for a solution to this existential crisis of the health of our global environment, strong and inspired leadership at all levels – from mayors, to governors, CEOs, scientists, artists and presidents is needed.In",1
"2010 the international community agreed to protect 10% of the ocean by 2020 in the Convention on Biological Diversity's Strategic Plan for Biodiversity 2011–2020 and Sustainable Development Goal 14. However as of June 2017 less than 3% of the ocean are under some form of protection. Pledges made during the conference would add around an additional 4.4 percent of protected marine areas, increasing the protected total to around 7.4% of the ocean. A later study (in 2018), reveals that 3,6% was protected.Peter",1
"Portugal's Minister for the Seas, Ana Paula Vitorino stated that Lisbon would like to host the next event in 2020. Kenya's Foreign Affairs Cabinet Secretary Amina Mohamed also offered for Kenya to host the next event. The event coincided with the World Oceans Day on 8 June and started with the World Environment Day on 5 June.On 4 June the World Ocean Festival took place at New York City's Governors Island. The festival was hosted by the City of New York, organized by the Global Brain Foundation and was free and open to the public.China",1
"The #CleanSeas cyber campaign calls on governments, industry and citizens to end excessive, wasteful usage of single-use plastic and eliminate microplastics in cosmetics with its petition getting signed by more than 1 million people. Official website #OceanConference on Twitter United Nations – LIVE – UN Ocean Conference, recording of the livestreamed conference on YouTube",1
The quantity of the effluent is low and is characterized by significant fluctuations.,1
"In locations with developed infrastructure, decentralized wastewater systems could be a viable alternative of the conventional centralized system, especially in cases of upgrading or retrofitting existing systems. Many different combinations and variations of hybrid systems are possible. The development of new treatment technologies allows for decentralized solutions, which are technically and aesthetically sound and acceptable.Decentralized applications are a necessity in cases of new urban developments, where the construction of the infrastructure is not ready or will be executed in future.",1
"This approach requires separate parallel pipeline/plumbing systems to convey the segregated flows and the purpose is to apply different level of treatment and handling of each flow and to enhance the safe reuse and disposal of the end products.In the specific case of developing countries, where localities with poor infrastructure are common, decentralized wastewater treatment has been promoted extensively because of the possibility to apply technologies with low operation and maintenance requirements. In addition, decentralized approaches require smaller scale investments, compared to centralized solutions.",1
"Based on the size of the served area, different scales of decentralization could be found: Decentralization at the level of a suburb or satellite township in an urban area – these systems could be defined as small centralized systems when applied to small towns or rural communities. But if they are applied only to selected suburbs or districts in medium or large population centres, with existing centralized system, the whole system could be defined as a hybrid system, where decentralization is applied to parts of the whole drained area.",1
"Decentralization at the level of a neighbourhood – this category includes clusters of homes, gated communities, small districts and areas, which are served by vacuum sewers. Decentralization at “on-site” level (on-site sanitation) – in these cases the whole system lays within one property and serves one or several buildings.",1
"Their application requires significant surface area, because of the slow pace of the biological processes applied. For the same reason they are more suitable for warmer climates, because the rate of the purification process is temperature dependent. These technologies are more resilient to fluctuating loads and do not require complex maintenance and operation. Constructed wetlands are more suitable for applications at on-site or at neighbourhood level, while stabilization ponds could be a viable alternative for decentralized systems at the level of small towns or rural communities.",1
"There is a large variety of wastewater treatment plants where different treatment processes and technologies are applied. Small-scale treatment facilities in decentralized systems, apply similar technologies as medium or large plants. For on-site applications package plants are developed, which are compact and have different compartments for the different processes. However, the design and operation of small treatment plants, especially at neighbourhood or on-site level, present significant challenges to wastewater engineers, related to flow fluctuations, necessity of competent and specialized operation and maintenance, required to deal with a large number of small plants, and relatively high per capita cost.",1
"In hybrid systems and small centralized systems in towns or rural communities management can be executed in the same way.In the case of decentralization at on-site level and clusters of buildings, the whole wastewater system is located within private premises. The costs and responsibility for the design, construction, operation and maintenance is the responsibility of the owner. In many cases specialized companies might execute the operation and maintenance procedures. The local authorities issue permits and may provide support for the operation and management in the form of collecting wastes, issuing certificates/licenses for standardized treatment equipment, or for selected qualified private companies.",1
"From regulatory point of view, the control of the quality of treated effluent for reuse, discharge or disposal is entirely the responsibility of local or national government authorities. This might be a challenge if a large number of systems must be controlled and inspected. It is in the owner's interest to operate and maintain the system properly, especially in the case of reuse of the treated effluent.",1
"If planned decentralized solutions are applied, stormwater drainage should be executed together with the roads system.In under-developed population centres where no infrastructure is available, is difficult to provide sustainable sanitation measures; e.g. pit latrines/septic tanks need periodic cleansing, usually executed by vacuum trucks, which have to access the latrine and need a basic road for this purpose. Fecal sludge management deals with the organization and implementation of this practice in a sustainable way, including collection, transport, treatment and disposal/reuse of faecal sludge from pit latrines and septic tanks.In",1
"the cases of new urban/rural developments, or the retrofitting of existing ones, it is advisable to consider different alternatives regarding the design of the wastewater system, including decentralized solutions. A sustainable approach would require optimal technical solutions in terms of reliability and cost effectiveness. From this perspective, centralized solutions might be more appropriate in many cases, depending on existing sizes of plots, topography, geology, groundwater tables and climatic conditions. But when applied adequately, decentralized systems allow for the application of environmentally friendly solutions and reuse of the treated effluent, including resource recovery.",1
"This technology was researched and tested in South Africa where it was shown that the treatment efficiency was lower than expected.Another example is ECOSTP which is a Zero Power, Zero Chemicals Sewage Treatment Technology based on Cow's digestive system.Rediscovering Nature’s Genius in treating Sewage - the cow’s stomach. The unique patented technology treats sewage in a decentralised, self- sustainable way in underground chambers without power, chemicals or human intervention. Using Biomimicry, regenerative innovation inspired by nature, the ECOSTP utilises functional principles and strategies of microorganisms and ecosystem found in a cow’s stomach.A",1
"case study of a decentralized wastewater system at on-site level with treated effluent reuse was performed at the Botswana Technology Centre in Gaborone, Botswana. It is an example of a decentralized wastewater system, which serves one institutional building, located in an area served by municipal sewerage. Wastewater from the building is treated in a plant consisting of: septic tank, followed by planted rock filter, bio-filter and a surface flow wetland. The treated effluent is reused for irrigation of the surrounding green areas, but the study registered outflow from the wetland only during periods of heavy rains.",1
"Exponential growth leads to rapid increases in the density of certain types of these phytoplankton, a phenomenon known as an algal bloom. Limnologist Dr. David Schindler, whose research at the Experimental Lakes Area led to the banning of harmful phosphates in detergents, warned about algal blooms and dead zones, ""The fish-killing blooms that devastated the Great Lakes in the 1960s and 1970s haven't gone away; they've moved west into an arid world in which people, industry, and agriculture are increasingly taxing the quality of what little freshwater there is to be had here....This isn't just a prairie problem.",1
"The eastern tropical Pacific Ocean and northern Indian Ocean have lowered oxygen concentrations which are thought to be in regions where there is minimal circulation to replace the oxygen that is consumed. These areas are also known as oxygen minimum zones (OMZ). In many cases, OMZs are permanent or semi-permanent areas.Remains of organisms found within sediment layers near the mouth of the Mississippi River indicate four hypoxic events before the advent of synthetic fertilizer. In these sediment layers, anoxia-tolerant species are the most prevalent remains found.",1
"In severe anoxic conditions, microbial life may experience dramatic shifts in community identity as well, resulting in an increased abundance of anaerobic organisms as aerobic microbes decrease in number and switch energy sources for oxidation such as nitrate, sulfate, or iron reduction. Sulfur reduction is a particular concern as Hydrogen sulfide is toxic and stresses most organisms within the zone further, exacerbating mortality risks.Low oxygen levels can have severe effects on survivability of organisms inside the area while above lethal anoxic conditions.",1
"Studies conducted along the Gulf Coast of North America have shown hypoxic conditions lead to reduction of reproductive rates and growth rates in a variety of organisms including fish and benthic invertebrates. Organisms able to leave the area typically do so when oxygen concentrations decrease to less than 2 mg l−1. At these oxygen concentrations and below, organisms that survive inside the oxygen deficient environment and are unable to escape the area will often exhibit progressively worsening stress behavior and die. Surviving organisms tolerant of hypoxic conditions often exhibit physiological adaptations appropriate for persisting within hypoxic environments.",1
"This results in a shift towards faster establishing colonizers with shorter and more opportunistic life strategies, potentially disrupting historic benthic compositions.",1
"The influence of dead zones on fisheries and other marine commercial activities varies by the length of occurrence and location. Dead zones are often accompanied by a decrease in biodiversity and collapse in benthic populations, lowering the diversity of yield in commercial fishing operations, but in cases of eutrophication-related dead zone formations, the increase in nutrient availability can lead to temporary rises in select yields among pelagic populations, such as anchovies. However, studies estimate that the increased production in the surrounding areas do not offset the net decrease in productivity resulting from the dead zone.",1
"For instance, an estimated 17,000 MT of carbon in the form of prey for fisheries has been lost as a result of Dead Zones in the Gulf of Mexico. Additionally, many stressors in fisheries are worsened by hypoxic conditions. Indirect factors such as increased success by invasive species and increased pandemic intensity in stressed species such as oysters both lead to losses in revenue and ecological stability in affected regions.",1
"Hypoxia can have indirect effects like the abundance of algae and spread of coral diseases in the ecosystems. While coral is unable to handle such low levels of oxygen, algae is quite tolerant. Because of this, in interaction zones between algae and coral, increased hypoxia will cause more coral death and higher spread of algae. The increase mass coral dead zones is reinforced by the spread of coral diseases. Coral diseases can spread easily when there are high concentrations of sulfide and hypoxic conditions.",1
"These mass die-offs due to extreme hypoxic events can have severe impacts on reef fish populations. Coral reef ecosystems offer a variety of essential ecosystem services including shoreline protection, nitrogen fixation, and waste assimilation, and tourism opportunities. The continued decline of oxygen in oceans on coral reefs is concerning because it takes many years (decades) to repair and regrow corals.",1
"Despite most other life forms being killed by the lack of oxygen, jellyfish can thrive and are sometimes present in dead zones in vast numbers. Jellyfish blooms produce large quantities of mucus, leading to major changes in food webs in the ocean since few organisms feed on them. The organic carbon in mucus is metabolized by bacteria which return it to the atmosphere in the form of carbon dioxide in what has been termed a ""jelly carbon shunt"".",1
"The potential worsening of jellyfish blooms as a result of human activities has driven new research into the influence of dead zones on jelly populations. The primary concern is the potential for dead zones to serve as breeding grounds for jelly populations as a result of the hypoxic conditions driving away competition for resources and common predators of jellyfish. The increased population of jellyfish could have high commercial costs with loss of fisheries, destruction and contamination of trawling nets and fishing vessels, and lowered tourism revenue in coastal systems.",1
"Globally, seagrass has been declining rapidly. It is estimated that 21% of the 71 known seagrass species have decreasing population trends and 11% of those species have been designated as threatened on the ICUN Red List. Hypoxia that leads to eutrophication caused form ocean deoxygenation is one of the main underlying factors of these die-offs. Eutrophication causes enhanced nutrient enrichment which can result in seagrass productivity, but with continual nutrient enrichment in seagrass meadows, it can cause excessive growth of microalgae, epiphytes and phytoplankton resulting in hypoxic conditions.Seagrass",1
"Generally, seagrass is able to combat the sulfides by supplying enough oxygen to the roots. However, deoxygenation causes the seagrass to be unable to supply this oxygen, thus killing it off.Deoxygenation reduces the diversity of organisms inhabiting seagrass beds by eliminating species that cannot tolerate the low oxygen conditions. Indirectly, the loss and degradation of seagrass threatens numerous species that rely on seagrass for either shelter or food. The loss of seagrass also effects the physical characteristics and resilience of seagrass ecosystems. Seagrass beds provide nursery grounds and habitat to many harvested commercial, recreational, and subsistence fish and shellfish.",1
"marine dead zones have appeared in coastal waters of South America, China, Japan, and New Zealand. A 2008 study counted 405 dead zones worldwide.",1
"In a paper published in 2004, researchers specifically divided the Baltic Sea into 9 sub-areas, each having its own specific characteristics. The 9 sub-areas are discerned as follows: Gulf of Bothnia, Archipelago region, Gulf of Finland, Gulf of Riga, Gulf of Gdansk, Swedish East-coast, Central Baltic, Belt Sea region, and Kattegat. Each sub-area has responded differently to nutrient additions and eutrophication; however, there are a few general patterns and measures for the Baltic Sea as a whole.",1
"As the researchers Rönnberg and Bonsdorff state, “Irrespective of the area-specific effects of the increased loads of nutrients to the Baltic Sea, the sources are more or less similar in the whole region. The extent and the severity of the discharges may differ, however. As is seen in e.g. HELCOM (1996) and Rönnberg (2001), the major sources in the input of nutrients are derived from agriculture, industry, municipal sewage and transports. Nitrogen emissions in form of atmospheric depositions are also important, as well as local point sources, such as aquaculture and leakage from forestry.”In",1
"The Elizabeth River estuary is important for Norfolk, Virginia, Chesapeake, Virginia, Virginia Beach, Virginia and Portsmouth, Virginia. It has been polluted by nitrogen and phosphorus, but also toxic deposits from the shipbuilding industry, the military, the world's largest coal export facility, refineries, loading docks, container-repair facilities and others, so fish had been ""offlimits since the 1920s"". In 1993, a group formed to clean it up, adopting the mummichog as a mascot, and has removed thousands of tons of contaminated sediment.",1
"In 2006, a 35-acre biological dead zone called Money Point was dredged out, and this let fish return and the wetland recover.",1
"A seasonal dead zone exists in the central part of Lake Erie from east of Point Pelee to Long Point and stretches to shores in Canada and the United States. Between the months of July and October the dead zone has the ability to grow to the size of 10,000 square kilometers. Lake Erie has an excess of phosphorus due to agricultural runoff that quickens the growth of algae which then contributes to hypoxic conditions.",1
"A dead zone exists in the Lower St. Lawrence River area from east the Saguenay River to east of Baie Comeau, greatest at depths over 275 metres (902 ft) and noticed since the 1930s. The main concern for Canadian scientists is the impact on fish found in the area.",1
"In 2009, one scientist described ""thousands and thousands"" of suffocated, crabs, worms, and sea stars along the seafloor of the hypoxic zone. In 2021, 1.9 million dollars were put into monitoring and continuing to study the hypoxic conditions in the area that the dead zone occurs in.",1
"late summer 1988 the dead zone disappeared as the great drought caused the flow of Mississippi to fall to its lowest level since 1933. During times of heavy flooding in the Mississippi River Basin, as in 1993, ""the ""dead zone"" dramatically increased in size, approximately 5,000 km (3,107 mi) larger than the previous year"".",1
"Some assert that the dead zone threatens lucrative commercial and recreational fisheries in the Gulf of Mexico. ""In 2009, the dockside value of commercial fisheries in the Gulf was $629 million. Nearly three million recreational fishers further contributed about $10 billion to the Gulf economy, taking 22 million fishing trips."" Scientists are not in universal agreement that nutrient loading has a negative impact on fisheries. Grimes makes a case that nutrient loading enhances the fisheries in the Gulf of Mexico. Courtney et al.",1
"hypothesize, that nutrient loading may have contributed to the increases in red snapper in the northern and western Gulf of Mexico.In 2017, Tulane University offered a $1 million challenge grant for growing crops with less fertilizer.",1
"Shrimp trawlers first reported a 'dead zone' in the Gulf of Mexico in 1950, but it was not until 1970 when the size of the hypoxic zone had increased that scientists began to investigate.After 1950, the conversion of forests and wetlands for agricultural and urban developments accelerated. ""Missouri River Basin has had hundreds of thousands of acres of forests and wetlands (66,000,000 acres) replaced with agriculture activity [. . .] In the Lower Mississippi one-third of the valley's forests were converted to agriculture between 1950 and 1976.""In",1
"July 2007, a dead zone was discovered off the coast of Texas where the Brazos River empties into the Gulf. The Energy Independence and Security Act of 2007 calls for the production of 36 billion US gallons (140,000,000 m3) of renewable fuels by 2022, including 15 billion US gallons (57,000,000 m3) of corn-based ethanol, a tripling of current production that would require a similar increase in corn production. Unfortunately, the plan poses a new problem; the increase in demand for corn production results in a proportional increase in nitrogen runoff.",1
"The recovery of benthic communities is primarily dependent upon the length and severity of hypoxic conditions inside the hypoxic zone. Less severe conditions and temporary depletion of oxygen allow rapid recovery of benthic communities in the area due to reestablishment by benthic larvae from adjacent areas, with longer conditions of hypoxia and more severe oxygen depletion leading to longer reestablishment periods. Recovery also depends upon stratification levels within the area, so heavily stratified areas in warmer waters are less likely to recover from anoxic or hypoxic conditions in addition to being more susceptible to eutrophication driven hypoxia.",1
"The difference in recovery ability and susceptibility to hypoxia in stratified marine environments is expected to complicate recovery efforts of dead zones in the future as ocean warming continues. Small scale hypoxic systems with rich surrounding communities are the most likely to recover after nutrient influxes leading to eutrophication stop. However, depending on the extent of damage and characteristics of the zone, large scale hypoxic condition could also potentially recover after a period of a decade.",1
"""Reconstructing a 180 yr record of natural and anthropogenic induced low-oxygen conditions from Louisiana continental shelf sediments"". Geology. 33 (4): 329. Bibcode:2005Geo....33..329O. doi:10.1130/G21341.1. S2CID 55361042. Taylor, F. J.; Taylor, N. J.; Walsby, J. R. (1985). ""A Bloom of the Planktonic Diatom,Cerataulina pelagica, off the Coast of Northeastern New Zealand in 1983, and its Contribution to an Associated Mortality of Fish and Benthic Fauna"". Internationale Revue der gesamten Hydrobiologie und Hydrographie. 70 (6): 773–795. doi:10.1002/iroh.19850700602. Morrisey, D.J; Gibbs, M.M; Pickmere, S.E; Cole, R.G (May 2000). ""Predicting impacts and recovery of marine-farm sites in Stewart Island, New Zealand, from the Findlay–Watling model"". Aquaculture.",1
"Eutrophication: A new wine in an old bottle? Elsevier, Science of the Total Environment 651:1-11. Growing 'dead zone' Confirmed by Underwater Robots in the Gulf of Oman, phys.org, April 2018 Hendy, Ian (August 2017), Gulf of Mexico 'dead zone' is already a disaster – but it could get worse, The Conversation Bryant, Lee (April 2015), Ocean 'dead zones' are spreading – and that spells disaster for fish, The Conversation David Stauth (Oregon State University), ""Hypoxic ""dead zone"" growing off the Oregon Coast"", July 31, 2006 at archive.today",1
"MSNBC report on dead zones, March 29, 2004 Joel Achenbach, ""A 'Dead Zone' in The Gulf of Mexico: Scientists Say Area That Cannot Support Some Marine Life Is Near Record Size"", The Washington Post, July 31, 2008 Joel Achenbach, ""'Dead Zones' Appear In Waters Worldwide: New Study Estimates More Than 400"", The Washington Post, August 15, 2008 Louisiana Universities Marine Consortium UN Geo Yearbook 2003 report on nitrogen and dead zones at the Library of Congress Web Archives (archived 2005-08-02) NASA on dead zones (Satellite pictures) Gulf of Mexico Dead Zone – multimedia Gulf of Mexico Hypoxia Watch, NOAA, Joel Achenbach",1
"at the Wayback Machine (archived 2007-10-09) NutrientNet at the Wayback Machine (archived 2010-07-11), an online nutrient trading tool developed by the World Resources Institute, designed to address issues of eutrophication. See also the PA NutrientNet website designed for Pennsylvania's nutrient trading program.",1
"In 1985 the TxDOT asked Mike Blair and Tim McClure of GSD&M to create a slogan for an anti-littering campaign. At the time the state of Texas spent about $20 million annually to clean litter from highways. McClure said that ""bubbas in pickup trucks"" who regularly littered beer cans and other items out of vehicle windows and ordinary Texans who believed that littering was a ""God-given right"" were targets of the advertising campaign. McClure said that he created the slogan when he saw garbage while walking near his house.",1
"In 1986 the slogan premiered its first television advertisement, featuring Stevie Ray Vaughan, at the 50th Annual Cotton Bowl Classic on January 1, 1986, singing the ""Eyes of Texas"" with the line ""Don't Mess with Texas"" added at the end of the song. Since then, numerous musicians, athletes, celebrities and other famous Texans have appeared in ""Don't Mess with Texas"" radio and television public service announcements, including: In a 12-year period with the agency GSD&M, over 26 television spots appeared.Due",1
"In the Stephen King novel 11/22/63, the time-travelling main character, Jake Epping, encounters a shop in a North Dallas neighborhood selling Texas state flags emblazoned with ""DON'T MESS WITH TEXAS"" in September 1960, twenty years before McClure created the slogan. McClure sent a copy of his book to King's agent to educate him about the error, but he has said that he is happy to have people think the slogan is much older than it really is. McClure has no desire to see a correction made to the novel regarding this anachronism.",1
"Litter in the United States McClure, Tim; Spence, Roy (2006). Don't Mess with Texas: The Story Behind the Legend. Idea City Press. ISBN 0972282513. Clemons, Leigh (2013). Branding Texas: performing culture in the Lone Star State. University of Texas Press. ISBN 978-0292752078. Don't Mess with Texas website ""Don't mess"" with this Texas slogan from MSNBC A list of objects that infringe on the trademark from Texas Monthly",1
"Detailed information on measurement of aircraft acoustic signature to meet the requirements of Annex 16 is found in ICAO Document 9501 and IEC 61265. Data acquisition in one-third-octave bands is required, followed by processing to yield a logarithmically-scaled value in decibels relative to a sound pressure of 20 micropascals for each one-third-octave band. The individual band sound pressure levels are converted to ""noy"" values which are then summed in the manner of Stevens' MKVI loudness to yield a total noy value.",1
"To quantitatively assess changes in the composition of biologic communities, IBIs are developed to accurately reflect the ecological complexity from statistical analysis. There is no one universal IBI, and developing metrics that consistently give accurate assessment of the monitored population requires rigorous testing to confirm its validity for a given subject. Often IBIs are region-specific and require experienced professionals to provide sufficient quality data to correctly assess a score. Because communities naturally vary as do samples collected from a larger population, identifying robust statistics with acceptable variance is an area of active and important research.",1
"Plumes of sulfates, smoke particles, and other anthropogenic aerosols blowing over the Indian Ocean was blocking sunlight and promoting cloud formation. The amount of sunlight reaching the Earth's surface was reduced by 10%. Asian brown cloud Veerabhadran Ramanathan",1
Counts are reported as colony forming units per 100 mL (cfu/100 mL).,1
"Early studies showed that individuals who swam in waters with geometric mean coliform densities above 2300/100 mL for three days had higher illness rates. In the 1960s, these numbers were converted to fecal coliform concentrations assuming 18 percent of total coliforms were fecal. Consequently, the National Technical Advisory Committee in the US recommended the following standard for recreational waters in 1968: 10 percent of total samples during any 30-day period should not exceed 400 fecal coliforms/100 mL or a log mean of 200/100 mL (based on a minimum of 5 samples taken over not more than a 30-day period).Despite",1
"rates of bacteria in the environment are often exponential, therefore, direct deposition of fecal material into waters generally contribute higher concentrations of pathogens than material that must be transported overland or through the subsurface.",1
"The more assumptions that are made, the more uncertain estimates of risk related to pathogens will be. However, even with considerable uncertainty, QMRAs are a good way to compare different risk scenarios. In a study comparing estimated health risks from exposures to recreational waters impacted by human and non-human sources of fecal contamination, QMRA determined that the risk of gastrointestinal illness from exposure to waters impacted by cattle were similar to those impacted by human waste, and these were higher than for waters impacted by gull, chicken, or pig faeces.",1
the following affiliate members: The Romanian Chamber of Energy Auditors (OAER) IEQ-GA website,1
EPA also recommends that people think about fixing their homes for radon levels between 2 pCi/L and 4 pCi/L.,1
Infants in homes with mold have a much greater risk of developing asthma and allergic rhinitis. More than half of adult workers in moldy/humid buildings suffer from nasal or sinus symptoms due to mold exposure.,1
"The last four are products of Stachybotrys chartarum, which has been linked with sick building syndrome.",1
"According to ASHRAE, ""Existing evidence for direct impacts of Carbon dioxide (CO2) on health, well-being, learning outcomes, and work performance at commonly observed indoor concentrations is inconsistent, and therefore does not currently justify changes to ventilation and IAQ standards, regulations, or guidelines."" NASA noted research on the CO2 levels found on submarines or spacecraft (of 3000ppm-7000ppm) had found it didn't affect the performance of astronauts or submarine officers. However, they decided to limit it to 5000ppm to avoid headaches. Whereas in non-specialised populations, pure CO2 at a concentration common in indoor environments was found to affect high-level decision-making.Moreover,",1
"Recent research has shown that mortality and morbidity increase in the general population during periods of higher outdoor ozone and that the threshold for this effect is around 20 parts per billion (ppb). Many people assume that buildings are simple physical entities, relatively stable over time with little interaction between the building, what is in it (occupants and contents), and what is around it (the larger environment). In fact, the true nature of buildings can be viewed as the result of a complex set of dynamic physical, chemical, and biological interactions. Buildings can be described and understood as complex systems.",1
"Solid waste, often called municipal solid waste, typically refers to material that is not hazardous. This category includes trash, rubbish and refuse; and may include materials such as construction debris and yard waste. Hazardous waste typically has specific definitions, due to the more careful and complex handling required of such wastes. Under US law, waste may be classified as hazardous based on certain characteristics: ignitability, reactivity, corrosivity and toxicity. Some types of hazardous waste are specifically listed in regulations.",1
"In coastal areas, fish and other aquatic life can be contaminated by untreated waste; beaches and other recreational areas can be damaged or closed.: 273–309",1
"In Thailand the roles in municipal solid waste (MSW) management and industrial waste management are organized by the Royal Thai Government, which is organized as central (national) government, regional government, and local government. Each government is responsible for different tasks. The central government is responsible for stimulating regulation, policies, and standards. The regional governments are responsible for coordinating the central and local governments. The local governments are responsible for waste management in their governed area.",1
"The 1976 Resource Conservation and Recovery Act (RCRA) provides for federal regulation of industrial, household, and manufacturing solid and hazardous wastes in the United States. RCRA aims to conserve natural resources and energy, protect human health, eliminate or reduce waste, and to clean up waste when needed. RCRA first began as an amendment to the Solid Waste Disposal Act of 1965, and in 1984, Congress passed the Hazardous and Solid Waste Amendments (HSWA) which strengthened RCRA by: Eliminating land disposal—land disposal means placing waste on or in land (e.g. injection wells, landfills, etc.),",1
"Under the HSWA, the EPA can necessitate corrective action at permitted and non-permitted TSDFs.Furthermore, the EPA uses Superfund to find sites of contamination, identify the parties responsible, and in the occurrences where said parties are not known or able to, the program funds cleanups. Superfund also works on figuring out and applying final remedies for cleanups.",1
The specific pollutants generated and the resultant effluent concentrations can vary widely among the industrial sectors.,1
"Battery manufacturers specialize in fabricating small devices for electronics and portable equipment (e.g., power tools), or larger, high-powered units for cars, trucks and other motorized vehicles. Pollutants generated at manufacturing plants includes cadmium, chromium, cobalt, copper, cyanide, iron, lead, manganese, mercury, nickel, silver, zinc, oil and grease.",1
"The inorganic chemicals sector covers a wide variety of products and processes, although an individual plant may produce a narrow range of products and pollutants. Products include aluminum compounds; calcium carbide and calcium chloride; hydrofluoric acid; potassium compounds; borax; chrome and fluorine-based compounds; cadmium and zinc-based compounds. The pollutants discharged vary by product sector and individual plant, and may include arsenic, chlorine, cyanide, fluoride; and heavy metals such as chromium, copper, iron, lead, mercury, nickel and zinc.",1
"Although many plants operate acid recovery plants (particularly those using hydrochloric acid), where the mineral acid is boiled away from the iron salts, there remains a large volume of highly acid ferrous sulfate or ferrous chloride to be disposed of. Many steel industry wastewaters are contaminated by hydraulic oil, also known as soluble oil.",1
"Many industries perform work on metal feedstocks (e.g. sheet metal, ingots) as they fabricate their final products. The industries include automobile, truck and aircraft manufacturing; tools and hardware manufacturing; electronic equipment and office machines; ships and boats; appliances and other household products; and stationary industrial equipment (e.g. compressors, pumps, boilers). Typical processes conducted at these plants include grinding, machining, coating and painting, chemical etching and milling, solvent degreasing, electroplating and anodizing. Wastewater generated from these industries may contain heavy metals such as cadmium, chromium, copper, lead, nickel, silver and zinc; cyanide and various organic chemical solvents; and oil and grease.",1
"Following crushing and extraction of the desirable materials, undesirable materials may enter the wastewater stream. For metal mines, this can include unwanted metals such as zinc and other materials such as arsenic. Extraction of high value metals such as gold and silver may generate slimes containing very fine particles in where physical removal of contaminants becomes particularly difficult.Additionally, the geologic formations that harbour economically valuable metals such as copper and gold very often consist of sulphide-type ores. The processing entails grinding the rock into fine particles and then extracting the desired metal(s), with the leftover rock being known as tailings.",1
"Pollutants discharged at petroleum refineries and petrochemical plants include conventional pollutants (BOD, oil and grease, suspended solids), ammonia, chromium, phenols and sulfides.",1
"For mills with high inorganic loadings like salt, tertiary treatments may be required, either general membrane treatments like ultrafiltration or reverse osmosis or treatments to remove specific contaminants, such as nutrients.",1
"Textile mills, including carpet manufacturers, generate wastewater from a wide variety of processes, including cleaning and finishing, yarn manufacturing and fabric finishing (such as bleaching, dyeing, resin treatment, waterproofing and retardant flameproofing). Pollutants generated by textile mills include BOD, SS, oil and grease, sulfide, phenols and chromium. Insecticide residues in fleeces are a particular problem in treating waters generated in wool processing. Animal fats may be present in the wastewater, which if not contaminated, can be recovered for the production of tallow or further rendering.Textile dyeing plants generate wastewater that contain synthetic (e.g.,",1
"reactive dyes, acid dyes, basic dyes, disperse dyes, vat dyes, sulphur dyes, mordant dyes, direct dyes, ingrain dyes, solvent dyes, pigment dyes) and natural dyestuff, gum thickener (guar) and various wetting agents, pH buffers and dye retardants or accelerators. Following treatment with polymer-based flocculants and settling agents, typical monitoring parameters include BOD, COD, color (ADMI), sulfide, oil and grease, phenol, TSS and heavy metals (chromium, zinc, lead, copper).",1
"Wood preserving plants generate conventional and toxic pollutants, including arsenic, COD, copper, chromium, abnormally high or low pH, phenols, suspended solids, oil and grease. The various types of contamination of wastewater require a variety of strategies to remove the contamination. Most industrial processes, such as petroleum refineries, chemical and petrochemical plants have onsite facilities to treat their wastewaters so that the pollutant concentrations in the treated wastewater comply with the regulations regarding disposal of wastewaters into sewers or into rivers, lakes or oceans.:",1
"41–15 A roughing filter, to reduce the biochemical oxygen demand of wastewater.: 23–11 A carbon filtration plant, to remove toxic dissolved organic compounds from wastewater.: 210 An advanced electrodialysis reversal (EDR) system with ion-exchange membranes.",1
"Acids and alkalis can usually be neutralised under controlled conditions. Neutralisation frequently produces a precipitate that will require treatment as a solid residue that may also be toxic. In some cases, gases may be evolved requiring treatment for the gas stream. Some other forms of treatment are usually required following neutralisation. Waste streams rich in hardness ions as from de-ionisation processes can readily lose the hardness ions in a buildup of precipitated calcium and magnesium salts. This precipitation process can cause severe furring of pipes and can, in extreme cases, cause the blockage of disposal pipes.",1
A 1-metre diameter industrial marine discharge pipe serving a major chemicals complex was blocked by such salts in the 1970s. Treatment is by concentration of de-ionisation waste waters and disposal to landfill or by careful pH management of the released wastewater.,1
"Toxic materials including many organic materials, metals (such as zinc, silver, cadmium, thallium, etc.) acids, alkalis, non-metallic elements (such as arsenic or selenium) are generally resistant to biological processes unless very dilute. Metals can often be precipitated out by changing the pH or by treatment with other chemicals. Many, however, are resistant to treatment or mitigation and may require concentration followed by landfilling or recycling. Dissolved organics can be incinerated within the wastewater by the advanced oxidation process.",1
"Pipes may leak because of careless installation; they may also be damaged after installation by differential ground movement, heavy vehicle traffic on roadways above the sewer, careless construction practices in nearby trenches, or degradation of the sewer pipe materials. In general, volume of leakage will increase over time. Damaged and broken sewer cleanouts are a major cause of infiltration into municipal sewer systems.Infiltration will occur where local groundwater elevation is higher than the sewer pipe. Gravel bedding materials in sewer pipe trenches act as a French drain. Groundwater flows parallel to the sewer until it reaches the area of damaged pipe.",1
"Sources of inflow can sometimes be identified by smoke testing. Smoke is blown into the sewer during dry weather while observers watch for smoke emerging from yards, cellars, or roof gutters. Dilution of sewage directly increases costs of pumping and chlorination, ozonation, or ultraviolet disinfection. Physical treatment structures including screens and pumps must be enlarged to handle the peak flow. Primary clarifiers must also be enlarged to treat average flows, although primary treatment of peak flows may be accomplished in detention basins.",1
"Biological secondary treatment is effective only while the concentration of soluble and colloidal pollutants (typically measured as biochemical oxygen demand or BOD) remains high enough to sustain a population of microorganisms digesting those pollutants. In U.S. federal regulations, secondary treatment is expected to remove 85 percent of soluble and colloidal organic pollutants from sewage containing 200 mg/L BOD. BOD removal by conventional biological secondary treatment becomes less effective with dilution and practically ceases as BOD concentrations entering the treatment facility are diluted below about 20 mg/L. Unremoved organics are potentially converted to disinfection by-products by chemical disinfection prior to discharge.",1
"High rates of infiltration/inflow may make the sanitary sewer incapable of carrying sewage from the design service area. Sewage may back up into the lowest homes during wet weather, or street manholes may overflow. Smoke test results may not correlate well with flow volumes; although they can identify potential problem locations. Where sewage flow is expected to be relatively uniform, significance of infiltration and inflow may be estimated by comparison of sewage flow at the same point during wet and dry weather or at two sequential points within the sewer system.",1
Small areas with large flow differences can be identified if the sewer system provides adequate measuring locations. It may be necessary to replace a section of sewer line if flow differences cannot be corrected by removing identified connections.,1
"In March 2020, the organization has developed recommendations that each program or project establish and document a feasible Space Debris Mitigation Plan.",1
"The plan should include the following items: A management plan addressing space debris mitigation activities A plan for the assessment and mitigation of risks related to space debris, including applicable standards The measures minimising the hazard related to malfunctions that have a potential for generating space debris A plan for disposal of the spacecraft and/or orbital stages at end of mission Justification of choice and selection when several possibilities exist Compliance matrix addressing the recommendations of these Guidelines Members of the IADC include: Agenzia Spaziale Italiana (ASI) Centre National d'Etudes Spatiales (CNES) China National Space Administration (CNSA) Canadian Space Agency (CSA)",1
"German Aerospace Center (DLR) European Space Agency (ESA) Indian Space Research Organisation (ISRO) Japan Aerospace Exploration Agency (JAXA) Korea Aerospace Research Institute (KARI) National Aeronautics and Space Administration (NASA) Russian Federal Space Agency (ROSCOSMOS) State Space Agency of Ukraine (SSAU) United Kingdom Space Agency (UKSA) Orbital Debris Co-ordination Working Groupっっっっｍش Web Archive: Report of the IADC Activities on Space Debris Mitigation Measures (PDF, 129kB)",1
"Complex hydrocarbons and other contaminants trapped in soil and otherwise inaccessible can be broken down by ozone, a highly reactive gas, often with greater cost-effectiveness than could be had by digging out the affected area. Such systems are particularly useful in built-up urban environments where digging may be impractical due to overlying buildings.",1
"In the four years from 2010-2013 the number of earthquakes of magnitude 3.0 or greater in the central and eastern United States increased dramatically. After decades of a steady earthquake rate (average of 21 events/year), activity increased starting in 2001 and peaked at 188 earthquakes in 2011, including a record-breaking 5.7-magnitude earthquake near Prague, Oklahoma which was the strongest earthquake ever recorded in Oklahoma. USGS scientists have found that at some locations the increase in seismicity coincides with the injection of wastewater in deep disposal wells.",1
"Injection-induced earthquakes are thought to be caused by pressure changes due to excess fluid injected deep below the surface and are being dubbed “man-made” earthquakes. On September 3, 2016, a 5.8-magnitude earthquake occurred near Pawnee, Oklahoma, followed by nine aftershocks between magnitudes 2.6 and 3.6 within three and one-half hours. The earthquake broke the previous record set five years earlier. Tremors were felt as far away as Memphis, Tennessee, and Gilbert, Arizona. Mary Fallin, the Oklahoma governor, declared a local emergency and shutdown orders for local disposal wells were ordered by the Oklahoma Corporation Commission.",1
"This engine powered a boat on the Saône river in France. In the same year, Swiss engineer François Isaac de Rivaz invented a hydrogen-based internal combustion engine and powered the engine by electric spark. In 1808, De Rivaz fitted his invention to a primitive working vehicle – ""the world's first internal combustion powered automobile"". In 1823, Samuel Brown patented the first internal combustion engine to be applied industrially. In 1854 in the UK, the Italian inventors Eugenio Barsanti and Felice Matteucci obtained the certification: ""Obtaining Motive Power by the Explosion of Gases"".",1
"In 1857 the Great Seal Patent Office conceded them patent No.1655 for the invention of an ""Improved Apparatus for Obtaining Motive Power from Gases"". Barsanti and Matteucci obtained other patents for the same invention in France, Belgium and Piedmont between 1857 and 1859. In 1860, Belgian engineer Jean Joseph Etienne Lenoir produced a gas-fired internal combustion engine. In 1864, Nicolaus Otto patented the first atmospheric gas engine. In 1872, American George Brayton invented the first commercial liquid-fueled internal combustion engine. In 1876, Nicolaus Otto began working with Gottlieb Daimler and Wilhelm Maybach, patented the compressed charge, four-cycle engine.",1
"In 1879, Karl Benz patented a reliable two-stroke gasoline engine. Later, in 1886, Benz began the first commercial production of motor vehicles with an internal combustion engine, in which a three-wheeled, four-cycle engine and chassis formed a single unit. In 1892, Rudolf Diesel developed the first compressed charge, compression ignition engine. In 1926, Robert Goddard launched the first liquid-fueled rocket. In 1939, the Heinkel He 178 became the world's first jet aircraft. At one time, the word engine (via Old French, from Latin ingenium, ""ability"") meant any piece of machinery—a sense that persists in expressions such as siege engine.",1
"A ""motor"" (from Latin motor, ""mover"") is any machine that produces mechanical power. Traditionally, electric motors are not referred to as ""engines""; however, combustion engines are often referred to as ""motors"". (An electric engine refers to a locomotive operated by electricity.) In boating, an internal combustion engine that is installed in the hull is referred to as an engine, but the engines that sit on the transom are referred to as motors.",1
Wankel engine,1
"The base of a reciprocating internal combustion engine is the engine block, which is typically made of cast iron (due to its good wear resistance and low cost) or aluminum. In the latter case, the cylinder liners are made of cast iron or steel, or a coating such as nikasil or alusil. The engine block contains the cylinders.",1
"When an engine is working, the gas pressure in the combustion chamber exerts a force on the piston crown which is transferred through its web to a gudgeon pin. Each piston has rings fitted around its circumference that mostly prevent the gases from leaking into the crankcase or the oil into the combustion chamber. A ventilation system drives the small amount of gas that escapes past the pistons during normal operation (the blow-by gases) out of the crankcase so that it does not accumulate contaminating the oil and creating corrosion.",1
"A head gasket prevents the gas from leaking between the cylinder head and the engine block. The opening and closing of the valves is controlled by one or several camshafts and springs—or in some engines—a desmodromic mechanism that uses no springs. The camshaft may press directly the stem of the valve or may act upon a rocker arm, again, either directly or through a pushrod. The crankcase is sealed at the bottom with a sump that collects the falling oil during normal operation to be cycled again.",1
"A connecting rod is connected to offset sections of the crankshaft (the crankpins) in one end and to the piston in the other end through the gudgeon pin and thus transfers the force and translates the reciprocating motion of the pistons to the circular motion of the crankshaft. The end of the connecting rod attached to the gudgeon pin is called its small end, and the other end, where it is connected to the crankshaft, the big end. The big end has a detachable half to allow assembly around the crankshaft.",1
The exhaust system of an ICE may also include a catalytic converter and muffler. The final section in the path of the exhaust gases is the tailpipe.,1
"The top dead center (TDC) of a piston is the position where it is nearest to the valves; bottom dead center (BDC) is the opposite position where it is furthest from them. A stroke is the movement of a piston from TDC to BDC or vice versa, together with the associated process. While an engine is in operation, the crankshaft rotates continuously at a nearly constant speed. In a 4-stroke ICE, each piston experiences 2 strokes per crankshaft revolution in the following order.",1
"Compression: In this stroke, both valves are closed and the piston moves upward reducing the combustion chamber volume which reaches its minimum when the piston is at TDC. The piston performs work on the charge as it is being compressed; as a result, its pressure, temperature and density increase; an approximation to this behavior is provided by the ideal gas law. Just before the piston reaches TDC, ignition begins. In the case of a SI engine, the spark plug receives a high voltage pulse that generates the spark which gives it its name and ignites the charge.",1
"In the case of a CI engine, the fuel injector quickly injects fuel into the combustion chamber as a spray; the fuel ignites due to the high temperature. Power or working stroke: The pressure of the combustion gases pushes the piston downward, generating more kinetic energy than is required to compress the charge. Complementary to the compression stroke, the combustion gases expand and as a result their temperature, pressure and density decreases. When the piston is near to BDC the exhaust valve opens.",1
"In the blowdown, the combustion gases expand irreversibly due to the leftover pressure—in excess of back pressure, the gauge pressure on the exhaust port. Exhaust: The exhaust valve remains open while the piston moves upward expelling the combustion gases. For naturally aspirated engines a small part of the combustion gases may remain in the cylinder during normal operation because the piston does not close the combustion chamber completely; these gases dissolve in the next charge. At the end of this stroke, the exhaust valve closes, the intake valve opens, and the sequence repeats in the next cycle.",1
The intake valve may open before the exhaust valve closes to allow better scavenging.,1
"The defining characteristic of this kind of engine is that each piston completes a cycle every crankshaft revolution. The 4 processes of intake, compression, power and exhaust take place in only 2 strokes so that it is not possible to dedicate a stroke exclusively for each of them. Starting at TDC the cycle consists of: Power: While the piston is descending the combustion gases perform work on it, as in a 4-stroke engine. The same thermodynamic considerations about the expansion apply. Scavenging: Around 75° of crankshaft rotation before BDC the exhaust valve or port opens, and blowdown occurs.",1
Shortly thereafter the intake valve or transfer port opens. The incoming charge displaces the remaining combustion gases to the exhaust system and a part of the charge may enter the exhaust system as well. The piston reaches BDC and reverses direction. After the piston has traveled a short distance upwards into the cylinder the exhaust valve or port closes; shortly the intake valve or transfer port closes as well. Compression: With both intake and exhaust closed the piston continues moving upwards compressing the charge and performing work on it.,1
"As in the case of a 4-stroke engine, ignition starts just before the piston reaches TDC and the same consideration on the thermodynamics of the compression on the charge apply.While a 4-stroke engine uses the piston as a positive displacement pump to accomplish scavenging taking 2 of the 4 strokes, a 2-stroke engine uses the last part of the power stroke and the first part of the compression stroke for combined intake and exhaust. The work required to displace the charge and exhaust gases comes from either the crankcase or a separate blower.",1
"For scavenging, expulsion of burned gas and entry of fresh mix, two main approaches are described: Loop scavenging, and Uniflow scavenging. SAE news published in the 2010s that 'Loop Scavenging' is better under any circumstance than Uniflow Scavenging.",1
"The reed valve opens when the crankcase pressure is slightly below intake pressure, to let it be filled with a new charge; this happens when the piston is moving upwards. When the piston is moving downwards the pressure in the crankcase increases and the reed valve closes promptly, then the charge in the crankcase is compressed. When the piston is moving downwards, it also uncovers the exhaust port and the transfer port and the higher pressure of the charge in the crankcase makes it enter the cylinder through the transfer port, blowing the exhaust gases.",1
"4-stroke engines have the benefit of forcibly expelling almost all of the combustion gases because during exhaust the combustion chamber is reduced to its minimum volume. In crankcase scavenged 2-stroke engines, exhaust and intake are performed mostly simultaneously and with the combustion chamber at its maximum volume.The main advantage of 2-stroke engines of this type is mechanical simplicity and a higher power-to-weight ratio than their 4-stroke counterparts. Despite having twice as many power strokes per cycle, less than twice the power of a comparable 4-stroke engine is attainable in practice.",1
"The operation of the Day cycle engine begins when the crankshaft is turned so that the piston moves from BDC upward (toward the head) creating a vacuum in the crankcase/cylinder area. The carburetor then feeds the fuel mixture into the crankcase through a reed valve or a rotary disk valve (driven by the engine). There are cast in ducts from the crankcase to the port in the cylinder to provide for intake and another from the exhaust port to the exhaust pipe. The height of the port in relationship to the length of the cylinder is called the ""port timing"".",1
"On the first upstroke of the engine there would be no fuel inducted into the cylinder as the crankcase was empty. On the downstroke, the piston now compresses the fuel mix, which has lubricated the piston in the cylinder and the bearings due to the fuel mix having oil added to it. As the piston moves downward it first uncovers the exhaust, but on the first stroke there is no burnt fuel to exhaust. As the piston moves downward further, it uncovers the intake port which has a duct that runs to the crankcase.",1
"The battery's charged state is maintained by an automotive alternator or (previously) a generator which uses engine power to create electrical energy storage. The battery supplies electrical power for starting when the engine has a starting motor system, and supplies electrical power when the engine is off. The battery also supplies electrical power during rare run conditions where the alternator cannot maintain more than 13.8 volts (for a common 12V automotive electrical system). As alternator voltage falls below 13.8 volts, the lead-acid storage battery increasingly picks up electrical load.",1
"The reduction in the size of the swept area of the cylinder and taking into account the volume of the combustion chamber is described by a ratio. Early engines had compression ratios of 6 to 1. As compression ratios were increased, the efficiency of the engine increased as well. With early induction and ignition systems the compression ratios had to be kept low. With advances in fuel technology and combustion management, high-performance engines can run reliably at 12:1 ratio.",1
"In order to produce more power, as rpm rises the spark is advanced sooner during piston movement. The spark occurs while the fuel is still being compressed progressively more as rpm rises.The necessary high voltage, typically 10,000 volts, is supplied by an induction coil or transformer. The induction coil is a fly-back system, using interruption of electrical primary system current through some type of synchronized interrupter. The interrupter can be either contact points or a power transistor. The problem with this type of ignition is that as RPM increases the availability of electrical energy decreases.",1
"This spark, via the spark plug, ignites the air-fuel mixture in the engine's cylinders. While gasoline internal combustion engines are much easier to start in cold weather than diesel engines, they can still have cold weather starting problems under extreme conditions. For years, the solution was to park the car in heated areas. In some parts of the world, the oil was actually drained and heated overnight and returned to the engine for cold starts.",1
"In the early 1950s, the gasoline Gasifier unit was developed, where, on cold weather starts, raw gasoline was diverted to the unit where part of the fuel was burned causing the other part to become a hot vapor sent directly to the intake valve manifold. This unit was quite popular until electric engine block heaters became standard on gasoline engines sold in cold climates.",1
"This is also why diesel and HCCI engines are more susceptible to cold-starting issues, although they run just as well in cold weather once started. Light duty diesel engines with indirect injection in automobiles and light trucks employ glowplugs (or other pre-heating: see Cummins ISB#6BT) that pre-heat the combustion chamber just before starting to reduce no-start conditions in cold weather.",1
"Most diesels also have a battery and charging system; nevertheless, this system is secondary and is added by manufacturers as a luxury for the ease of starting, turning fuel on and off (which can also be done via a switch or mechanical apparatus), and for running auxiliary electrical components and accessories. Most new engines rely on electrical and electronic engine control units (ECU) that also adjust the combustion process to increase efficiency and reduce emissions.",1
"The connecting rod big end caps may have an attached scoop to enhance this effect. The valve train may also be sealed in a flooded compartment, or open to the crankshaft in a way that it receives splashed oil and allows it to drain back to the sump. Splash lubrication is common for small 4-stroke engines. In a forced (also called pressurized) lubrication system, lubrication is accomplished in a closed-loop which carries motor oil to the surfaces serviced by the system and then returns the oil to a reservoir.",1
"On its bottom, the sump contains an oil intake covered by a mesh filter which is connected to an oil pump then to an oil filter outside the crankcase. From there it is diverted to the crankshaft main bearings and valve train. The crankcase contains at least one oil gallery (a conduit inside a crankcase wall) to which oil is introduced from the oil filter. The main bearings contain a groove through all or half its circumference; the oil enters these grooves from channels connected to the oil gallery.",1
"Specifically, the lubricant system helps to move heat from the hot engine parts to the cooling liquid (in water-cooled engines) or fins (in air-cooled engines) which then transfer it to the environment. The lubricant must be designed to be chemically stable and maintain suitable viscosities within the temperature range it encounters in the engine.",1
"It is desirable to have the pistons' cycles uniformly spaced (this is called even firing) especially in forced induction engines; this reduces torque pulsations and makes inline engines with more than 3 cylinders statically balanced in its primary forces. However, some engine configurations require odd firing to achieve better balance than what is possible with even firing.",1
"For instance, a 4-stroke I2 engine has better balance when the angle between the crankpins is 180° because the pistons move in opposite directions and inertial forces partially cancel, but this gives an odd firing pattern where one cylinder fires 180° of crankshaft rotation after the other, then no cylinder fires for 540°. With an even firing pattern, the pistons would move in unison and the associated forces would add. Multiple crankshaft configurations do not necessarily need a cylinder head at all because they can instead have a piston at each end of the cylinder called an opposed piston design.",1
"In 1879, Nicolaus Otto manufactured and sold a double expansion engine (the double and triple expansion principles had ample usage in steam engines), with two small cylinders at both sides of a low-pressure larger cylinder, where a second expansion of exhaust stroke gas took place; the owner returned it, alleging poor performance. In 1906, the concept was incorporated in a car built by EHV (Eisenhuth Horseless Vehicle Company); and in the 21st century Ilmor designed and successfully tested a 5-stroke double expansion internal combustion engine, with high power output and low SFC (Specific Fuel Consumption).",1
"The very first internal combustion engines did not compress the mixture. The first part of the piston downstroke drew in a fuel-air mixture, then the inlet valve closed and, in the remainder of the down-stroke, the fuel-air mixture fired. The exhaust valve opened for the piston upstroke. These attempts at imitating the principle of a steam engine were very inefficient. There are a number of variations of these cycles, most notably the Atkinson and Miller cycles. Split-cycle engines separate the four strokes of intake, compression, combustion and exhaust into two separate but paired cylinders.",1
"Gas turbine cycle engines employ a continuous combustion system where compression, combustion, and expansion occur simultaneously at different places in the engine—giving continuous power. Notably, the combustion takes place at constant pressure, rather than with the Otto cycle, constant volume. The Wankel engine (rotary engine) does not have piston strokes. It operates with the same separation of phases as the four-stroke engine with the phases taking place in separate locations in the engine. In thermodynamic terms it follows the Otto engine cycle, so may be thought of as a ""four-phase"" engine.",1
"The combustion process typically results in the production of a great quantity of thermal energy, as well as the production of steam and carbon dioxide and other chemicals at very high temperature; the temperature reached is determined by the chemical make up of the fuel and oxidizers (see stoichiometry), as well as by the compression and other factors.",1
"Engine types vary greatly in a number of different ways: energy efficiency fuel/propellant consumption (brake specific fuel consumption for shaft engines, thrust specific fuel consumption for jet engines) power-to-weight ratio thrust to weight ratio torque curves (for shaft engines), thrust lapse (jet engines) compression ratio for piston engines, overall pressure ratio for jet engines and gas turbines",1
"Once ignited and burnt, the combustion products—hot gases—have more available thermal energy than the original compressed fuel-air mixture (which had higher chemical energy). This available energy is manifested as a higher temperature and pressure that can be converted into kinetic energy by the engine. In a reciprocating engine, the high-pressure gases inside the cylinders drive the engine's pistons. Once the available energy has been removed, the remaining hot gases are vented (often by opening a valve or exposing the exhaust outlet) and this allows the piston to return to its previous position (top dead center, or TDC).",1
"The thermal efficiency of a theoretical cycle cannot exceed that of the Carnot cycle, whose efficiency is determined by the difference between the lower and upper operating temperatures of the engine. The upper operating temperature of an engine is limited by two main factors; the thermal operating limits of the materials, and the auto-ignition resistance of the fuel. All metals and alloys have a thermal operating limit, and there is significant research into ceramic materials that can be made with greater thermal stability and desirable structural properties.",1
"Higher thermal stability allows for a greater temperature difference between the lower (ambient) and upper operating temperatures, hence greater thermodynamic efficiency. Also, as the cylinder temperature rises, the fuel becomes more prone to auto-ignition. This is caused when the cylinder temperature nears the flash point of the charge. At this point, ignition can spontaneously occur before the spark plug fires, causing excessive cylinder pressures. Auto-ignition can be mitigated by using fuels with high auto-ignition resistance (octane rating), however it still puts an upper bound on the allowable peak cylinder temperature.",1
"The thermodynamic limits assume that the engine is operating under ideal conditions: a frictionless world, ideal gases, perfect insulators, and operation for infinite time. Real world applications introduce complexities that reduce efficiency. For example, a real engine runs best at a specific load, termed its power band. The engine in a car cruising on a highway is usually operating significantly below its ideal load, because it is designed for the higher loads required for rapid acceleration. In addition, factors such as wind resistance reduce overall system efficiency.",1
"Vehicle fuel economy is measured in miles per gallon or in liters per 100 kilometers. The volume of hydrocarbon assumes a standard energy content. Even when aided with turbochargers and stock efficiency aids, most engines retain an average efficiency of about 18–20%. However, the latest technologies in Formula One engines have seen a boost in thermal efficiency past 50%. There are many inventions aimed at increasing the efficiency of IC engines. In general, practical engines are always compromised by trade-offs between different properties such as efficiency, weight, power, heat, response, exhaust emissions, or noise.",1
"Sometimes economy also plays a role in not only the cost of manufacturing the engine itself, but also manufacturing and distributing the fuel. Increasing the engine's efficiency brings better fuel economy but only if the fuel cost per energy content is the same.",1
"Carbon dioxide emissions from internal combustion engines (particularly ones using fossil fuels such as gasoline and diesel) contribute to human-induced climate change. Increasing the engine's fuel efficiency can reduce, but not eliminate, the amount of CO2 emissions as carbon-based fuel combustion produces CO2. Since removing CO2 from engine exhaust is impractical, there is increasing interest in alternatives. Sustainable fuels such as biofuels, synfuels, and electric motors powered by batteries are examples. Not all of the fuel is completely consumed by the combustion process.",1
"A small amount of fuel is present after combustion, and some of it reacts to form oxygenates, such as formaldehyde or acetaldehyde, or hydrocarbons not originally present in the input fuel mixture. Incomplete combustion usually results from insufficient oxygen to achieve the perfect stoichiometric ratio. The flame is ""quenched"" by the relatively cool cylinder walls, leaving behind unreacted fuel that is expelled with the exhaust. When running at lower speeds, quenching is commonly observed in diesel (compression ignition) engines that run on natural gas. Quenching reduces efficiency and increases knocking, sometimes causing the engine to stall.",1
"Internal combustion engines continue to consume fuel and emit pollutants while idling. Idling is reduced by stop-start systems. A good way to estimate the mass of carbon dioxide that is released when one litre of diesel fuel (or gasoline) is combusted can be found as follows:As a good approximation the chemical formula of diesel is CnH2n. In reality diesel is a mixture of different molecules. As carbon has a molar mass of 12 g/mol and hydrogen (atomic) has a molar mass of about 1 g/mol, the fraction by weight of carbon in diesel is roughly 12⁄14.",1
The reaction of diesel combustion is given by: 2CnH2n + 3nO2 ⇌ 2nCO2 + 2nH2O Carbon dioxide has a molar mass of 44 g/mol as it consists of 2 atoms of oxygen (16 g/mol) and 1 atom of carbon (12 g/mol). So 12 g of carbon yields 44 g of carbon dioxide. Diesel has a density of 0.838 kg per litre. Putting everything together the mass of carbon dioxide that is produced by burning 1 litre of diesel can be calculated as: 0.838 k g / L ⋅ 12 14 ⋅ 44 12 = 2.63 k g / L {\displaystyle 0.838kg/L\cdot,1
"{\frac {12}{14}}\cdot {\frac {44}{12}}=2.63kg/L} The figure obtained with this estimation is close to the values found in the literature. For gasoline, with a density of 0.75 kg/L and a ratio of carbon to hydrogen atoms of about 6 to 14, the estimated value of carbon dioxide emission from burning 1 litre of gasoline is: 0.75 k g / L ⋅ 6 ⋅ 12 6 ⋅ 12 + 14 ⋅ 1 ⋅ 44 12 = 2.3 k g / L {\displaystyle 0.75kg/L\cdot {{\frac {6\cdot 12}{6\cdot 12+14}}\cdot 1}\cdot {\frac {44}{12}}=2.3kg/L}",1
"The term parasitic loss is often applied to devices that take energy from the engine in order to enhance the engine's ability to create more energy or convert energy to motion. In the internal combustion engine, almost every mechanical component, including the drivetrain, causes parasitic loss and could thus be characterized as a parasitic load.",1
"Another example of an engine parasitic load is a supercharger, which derives its power from the engine and creates more power for the engine. The power that the supercharger consumes is parasitic loss and is usually expressed in kilowatt or horsepower. While the power that the supercharger consumes in comparison to what it generates is small, it is still measurable or calculable. One of the desirable features of a turbocharger over a supercharger is the lower parasitic loss of the former.Drivetrain parasitic losses include both steady state and dynamic loads.",1
"Steady state loads occur at constant speeds and may originate in discrete components such as the torque converter, the transmission oil pump, and/or clutch drag, and in seal/bearing drag, churning of lubricant and gear windage/friction found throughout the system. Dynamic loads occur under acceleration and are caused by inertia of rotating components and/or increased friction.",1
"While rules of thumb such as a 15% power loss from drivetrain parasitic loads have been commonly repeated, the actual loss of energy due to parasitic loads varies between systems. It can be influenced by powertrain design, lubricant type and temperature and many other factors. In automobiles, drivetrain loss can be quantified by measuring the difference between power measured by an engine dynamometer and a chassis dynamometer. However, this method is primarily useful for measuring steady state loads and may not accurately reflect losses due to dynamic loads.",1
"The reduction in parasitic loss from these changes may be due to reduced friction or many other variables that cause the design to be more efficient. Anyebe, E.A (2009). Combustion Engine and Operations, Automobile Technology Handbook. Vol. 2. Denton, T. (2011). Automobile Mechanical and Electrical Systems. Automobile Mechanical and Electrical Systems: Automotive Technology : Vehicle Maintenance and Repair. Taylor & Francis. ISBN 978-1-136-27038-3. Heywood, J. (2018). Internal Combustion Engine Fundamentals 2E. McGraw-Hill Education. ISBN 978-1-260-11611-3. Nunney, Malcolm J. (2007). Light and Heavy Vehicle Technology (4th ed.). Elsevier Butterworth-Heinemann. ISBN 978-0-7506-8037-0. Ricardo, Harry (1931). The High-Speed Internal Combustion Engine. Singal, R.K.",1
"Internal Combustion Engines. New Delhi, India: Kataria Books. ISBN 978-93-5014-214-1. Stone, Richard (1992). Introduction to Internal Combustion Engines (2nd ed.). Macmillan. ISBN 978-0-333-55083-0. Yamagata, H. (2005). The Science and Technology of Materials in Automotive Engines. Woodhead Publishing in materials The science and technology of materials in automotive engines. Elsevier Science. ISBN 978-1-84569-085-4. Patents: ES 433850, Ubierna Laciana, ""Perfeccionamientos en Motores de Explosion, con Cinco Tiem-Pos y Doble Expansion"", published 1976-11-01 ES 230551, Ortuno Garcia Jose, ""Un Nuevo Motor de Explosion"", published 1957-03-01 ES 249247, Ortuno Garcia Jose, ""Motor de Carreras Distintas"", published 1959-09-01 Singer, Charles Joseph; Raper, Richard (1978).",1
"Charles, Singer; et al. (eds.). A History of Technology: The Internal Combustion Engine. Clarendon Press. pp. 157–176. ISBN 978-0-19-858155-0. Setright, LJK (1975). Some unusual engines. London: The Institution of Mechanical Engineers. ISBN 978-0-85298-208-2. Suzuki, Takashi (1997). The Romance of Engines. US: Society of Automotive Engineers. ISBN 978-1-56091-911-7. Hardenberg, Horst O. (1999). The Middle Ages of the Internal Combustion Engine. US: Society of Automotive Engineers. Gunston, Bill (1999). Development of Piston Aero Engines. PSL. ISBN 978-1-85260-619-0.",1
"Combustion video – in-cylinder combustion in an optically accessible, 2-stroke engine Animated Engines – explains a variety of types Intro to Car Engines – Cut-away images and a good overview of the internal combustion engine Walter E. Lay Auto Lab – Research at The University of Michigan YouTube – Animation of the components and built-up of a 4-cylinder engine YouTube – Animation of the internal moving parts of a 4-cylinder engine Next generation engine technologies retrieved May 9, 2009 How Car Engines Work Unusual Internal-Combustion Engines Aircraft Engine Historical Society (AEHS) – AEHS Home",1
"IVHHN has created a range of evidence-based audio-visual and printable products on the health hazards of volcanic emissions and community protection, for the general public and humanitarian agencies, which can be distributed at the onset of new eruptions. These include: Videos Life with Ash – Accounts from the 2010 Merapi Eruption. This film shares the experiences of communities living near Merapi volcano, Indonesia and how they coped with the volcanic ash which fell during the 2010 explosive eruption. The film aims to help people learn about eruptions and what it is like to experience ashfall.",1
"Products The Health Hazards of Volcanic Ash - A guide for the public. This pamphlet is available in nine languages. Guidelines on Preparedness Before, During and After an Ashfall. This pamphlet is available in nine languages. How to protect yourself from breathing volcanic ash pamphlet. This pamphlet is currently only available in English but Spanish and Bahasa text versions can be found at: www.ivhhn.org/ash-protection. Ash Protection poster. Currently available in English and Spanish. Fitting a facemask leaflet. The How to Fit a Facemask leaflet is designed to be handed out by agencies, along with facemasks.",1
"It is currently available in English and Spanish.The IVHHN website also hosts a set of scientific protocols for the collection and analysis of volcanic ash, and a comprehensive library of academic papers and books published on the health hazards and impacts of volcanic eruptions. IVHHN was founded in 2003 by its Director, Claire Horwell, a Professor at Durham University. The network is a Commission of the International Association of Volcanology and Chemistry of the Earth's Interior (IAVCEI). IVHHN advises governmental agencies on preparing communities for eruptions and works closely with humanitarian agencies such as the Pan American Health Organization.",1
"IVHHN also administers the Hawaii Interagency Vog Dashboard, an online portal for information about volcanic emissions from Kilauea volcano. IVHHN was cited, by Forbes Magazine, as being an excellent source of information during the 2018 eruption crisis at Kilauea volcano, Hawaii. IVHHN website Hawaii Interagency Vog Dashboard Volcanic ash impacts and preparedness website, USGS Volcanic Impacts Network website",1
"Most 131I production is from neutron irradiation of a natural tellurium target in a nuclear reactor. Irradiation of natural tellurium produces almost entirely 131I as the only radionuclide with a half-life longer than hours, since most lighter isotopes of tellurium become heavier stable isotopes, or else stable iodine or xenon. However, the heaviest naturally occurring tellurium nuclide, 130Te (34% of natural tellurium) absorbs a neutron to become tellurium-131, which beta decays with a half-life of 25 minutes to 131I.",1
"A tellurium compound can be irradiated while bound as an oxide to an ion exchange column, with evolved 131I then eluted into an alkaline solution. More commonly, powdered elemental tellurium is irradiated and then 131I separated from it by dry distillation of the iodine, which has a far higher vapor pressure. The element is then dissolved in a mildly alkaline solution in the standard manner, to produce 131I as iodide and hypoiodate (which is soon reduced to iodide).131I is a fission product with a yield of 2.878% from uranium-235, and can be released in nuclear weapons tests and nuclear accidents.",1
"However, the short half-life means it is not present in significant quantities in cooled spent nuclear fuel, unlike iodine-129 whose half-life is nearly a billion times that of 131I. It is discharged to the atmosphere in small quantities by some nuclear power plants. 131I decays with a half-life of 8.02 days with beta minus and gamma emissions. This isotope of iodine has 78 neutrons in its nucleus, while the only stable nuclide, 127I, has 74.",1
"On decaying, 131I most often (89% of the time) expends its 971 keV of decay energy by transforming into stable xenon-131 in two steps, with gamma decay following rapidly after beta decay: I 53 131 ⟶ β + ν ¯ e + Xe ∗ 54 131 + 606 keV {\displaystyle {\ce {^{131}_{53}I->\beta +{\bar {\nu }}_{e}+{^{131}_{54}Xe^{\ast }}+606keV}}} Xe ∗ 54 131 ⟶ Xe 54 131 + γ + 364 keV {\displaystyle {\ce {^{131}_{54}Xe^{\ast }->{^{131}_{54}Xe}+\gamma +364keV}}} The primary emissions of 131I decay are thus electrons with a maximal energy of 606 keV (89% abundance, others 248–807 keV) and 364 keV gamma rays (81%",1
"abundance, others 723 keV). Beta decay also produces an antineutrino, which carries off variable amounts of the beta decay energy. The electrons, due to their high mean energy (190 keV, with typical beta-decay spectra present) have a tissue penetration of 0.6 to 2 mm. Iodine in food is absorbed by the body and preferentially concentrated in the thyroid where it is needed for the functioning of that gland. When 131I is present in high levels in the environment from radioactive fallout, it can be absorbed through contaminated food, and will also accumulate in the thyroid.",1
"As it decays, it may cause damage to the thyroid. The primary risk from exposure to 131I is an increased risk of radiation-induced cancer in later life. Other risks include the possibility of non-cancerous growths and thyroiditis.The risk of thyroid cancer in later life appears to diminish with increasing age at time of exposure. Most risk estimates are based on studies in which radiation exposures occurred in children or teenagers. When adults are exposed, it has been difficult for epidemiologists to detect a statistically significant difference in the rates of thyroid disease above that of a similar but otherwise-unexposed group.The",1
"risk can be mitigated by taking iodine supplements, raising the total amount of iodine in the body and, therefore, reducing uptake and retention in the face and chest and lowering the relative proportion of radioactive iodine. However, such supplements were not consistently distributed to the population living nearest to the Chernobyl nuclear power plant after the disaster, though they were widely distributed to children in Poland. Within the US, the highest 131I fallout doses occurred during the 1950s and early 1960s to children having consumed fresh milk from sources contaminated as the result of above-ground testing of nuclear weapons.",1
"The National Cancer Institute provides additional information on the health effects from exposure to 131I in fallout, as well as individualized estimates, for those born before 1971, for each of the 3070 counties in the USA. The calculations are taken from data collected regarding fallout from the nuclear weapons tests conducted at the Nevada Test Site.On 27 March 2011, the Massachusetts Department of Public Health reported that 131I was detected in very low concentrations in rainwater from samples collected in Massachusetts, USA, and that this likely originated from the Fukushima power plant.",1
"Farmers near the plant dumped raw milk, while testing in the United States found 0.8 pico-curies per liter of iodine-131 in a milk sample, but the radiation levels were 5,000 times lower than the FDA's ""defined intervention level"". The levels were expected to drop relatively quickly",1
"The most common method of treatment is to give potassium iodide to those at risk. The dosage for adults is 130 mg potassium iodide per day, given in one dose, or divided into portions of 65 mg twice a day. This is equivalent to 100 mg of iodine, and is about 700 times bigger than the nutritional dose of iodine, which is 0.150 mg per day (150 micrograms per day). See potassium iodide for more information on prevention of radioiodine absorption by the thyroid during nuclear accident, or for nuclear medical reasons.",1
"The FDA-approved dosing of potassium iodide for this purpose are as follows: infants less than 1 month old, 16 mg; children 1 month to 3 years, 32 mg; children 3 years to 18 years, 65 mg; adults 130 mg. However, some sources recommend alternative dosing regimens.",1
"milligrams per kilogram per day (mg/(kg·d)), perchlorate begins to temporarily inhibit the thyroid gland's ability to absorb iodine from the bloodstream (""iodide uptake inhibition"", thus perchlorate is a known goitrogen). The reduction of the iodide pool by perchlorate has dual effects—reduction of excess hormone synthesis and hyperthyroidism, on the one hand, and reduction of thyroid inhibitor synthesis and hypothyroidism on the other. Perchlorate remains very useful as a single dose application in tests measuring the discharge of radioiodide accumulated in the thyroid as a result of many different disruptions in the further metabolism of iodide in the thyroid gland.",1
This may well be attributable to sufficient daily exposure or intake of healthy iodine-127 among the workers and the short 8-hr biological half life of perchlorate in the body.,1
"This occurs because when the radioactive iodine destroys the thyroid cells, they can release thyroid hormone into the blood stream. For this reason, sometimes patients are pre-treated with thyrostatic medications such as methimazole, and/or they are given symptomatic treatment such as propranolol. Radioactive iodine treatment is contraindicated in breast-feeding and pregnancy",1
"European guidelines recommend administration of a capsule, due to ""greater ease to the patient and the superior radiation protection for caregivers"".",1
"Ablation doses are usually administered on an inpatient basis, and IAEA International Basic Safety Standards recommend that patients are not discharged until the activity falls below 1100 MBq. ICRP advice states that ""comforters and carers"" of patients undergoing radionuclide therapy should be treated as members of the public for dose constraint purposes and any restrictions on the patient should be designed based on this principle.Patients receiving I-131 radioiodine treatment may be warned not to have sexual intercourse for one month (or shorter, depending on dose given), and women told not to become pregnant for six months afterwards.",1
"""This is because a theoretical risk to a developing fetus exists, even though the amount of radioactivity retained may be small and there is no medical proof of an actual risk from radioiodine treatment. Such a precaution would essentially eliminate direct fetal exposure to radioactivity and markedly reduce the possibility of conception with sperm that might theoretically have been damaged by exposure to radioiodine."" These guidelines vary from hospital to hospital and will depend on national legislation and guidance, as well as the dose of radiation given.",1
"Some also advise not to hug or hold children when the radiation is still high, and a one- or two- metre distance to others may be recommended.I-131 will be eliminated from the body over the next several weeks after it is given. The majority of I-131 will be eliminated from the human body in 3–5 days, through natural decay, and through excretion in sweat and urine. Smaller amounts will continue to be released over the next several weeks, as the body processes thyroid hormones created with the I-131.",1
"When it was first discovered, it was quickly found that the object was in an orbit around Earth. Astronomers were surprised at this, as the Moon is the only large object in orbit around the Earth, and anything else would have been ejected long ago due to perturbations with the Earth, the Moon and the Sun. Therefore, it probably entered into Earth orbit very recently, yet there was no recently launched spacecraft that matched the orbit of J002E3.",1
"One explanation could have been that it was a 30 meter-wide piece of rock, but University of Arizona astronomers found that spectral observations of the object indicated a strong correlation of absorption features with a combination of human-made materials including white paint, black paint, and aluminum, consistent with Saturn V rockets. Back-tracing its orbit showed that the object had been orbiting the Sun for 31 years and had last been in the vicinity of the Earth in 1971.",1
"NASA had originally planned to direct the S-IVB into a solar orbit, but an extra long burn of the ullage motors meant that venting the remaining propellant in the tank of the S-IVB did not give the rocket stage enough energy to escape the Earth–Moon system, and instead the stage ended up in a semi-stable orbit around the Earth after passing by the Moon on 18 November 1969. It is thought that J002E3 left Earth orbit in June 2003, and that it may return to orbit the Earth in the mid-2040s.",1
"The object's Earth orbital paths occasionally take it within the radius of the Moon's orbit, and could result in eventual entry into Earth's atmosphere, or collision with the Moon. The Apollo 12 empty S-IVB, Instrument Unit, and spacecraft adapter base, had a mass of about 14 tonnes; 15 short tons (30,000 lb). This is less than one-fifth of the 77.1-tonne; 85.0-short-ton (169,900 lb) mass of the Skylab space station, which was constructed from a similar S-IVB and fell out of orbit on 11 July 1979.",1
"Objects with a mass of about 10 tonnes (22,000 lb; 11 short tons) enter Earth's atmosphere approximately 10 times a year, one of which impacts the Earth's surface approximately once every 10 years.Ten essentially similar empty S-IVB stages from Apollo, Skylab and Apollo-Soyuz Test Project missions have re-entered the atmosphere from 1966 to 1975. In all cases (including the Skylab station), the objects burned in the atmosphere and broke into relatively small pieces, rather than striking the Earth as a single mass.",1
"On the other hand, these objects entered from low Earth orbit or a ballistic trajectory, with less energy than J002E3 might possibly have if it were to enter from solar orbit. 6Q0B44E, space debris originally thought to be a meteoroid 2006 RH120, a meteoroid originally thought to be space debris 2007 VN84, an asteroid designation mistakenly given to the Rosetta spacecraft 3753 Cruithne 2020 SO Space debris J002E3 Animations, CNEOS Mystery Object J002E3 Gallery, NASA Mystery Object Orbits Earth, NASA Astronomers Discover That Earth's Second Moon Wears Apollo Paint at the Wayback Machine (archived 20 August 2007), University of Arizona",1
"Radon is a colorless, odorless, and tasteless gas and therefore is not detectable by human senses alone. At standard temperature and pressure, it forms a monatomic gas with a density of 9.73 kg/m3, about 8 times the density of the Earth's atmosphere at sea level, 1.217 kg/m3. It is one of the densest gases at room temperature and is the densest of the noble gases. Although colorless at standard temperature and pressure, when cooled below its freezing point of 202 K (−71 °C; −96 °F), it emits a brilliant radioluminescence that turns from yellow to orange-red as the temperature lowers.",1
"Radon is a member of the zero-valence elements that are called noble gases, and is chemically not very reactive. The 3.8-day half-life of radon-222 makes it useful in physical sciences as a natural tracer. Because radon is a gas at standard conditions, unlike its decay-chain parents, it can readily be extracted from them for research.It is inert to most common chemical reactions, such as combustion, because the outer valence shell contains eight electrons. This produces a stable, minimum energy configuration in which the outer electrons are tightly bound.",1
"Its first ionization energy—the minimum energy required to extract one electron from it—is 1037 kJ/mol. In accordance with periodic trends, radon has a lower electronegativity than the element one period before it, xenon, and is therefore more reactive. Early studies concluded that the stability of radon hydrate should be of the same order as that of the hydrates of chlorine (Cl2) or sulfur dioxide (SO2), and significantly higher than the stability of the hydrate of hydrogen sulfide (H2S).Because",1
"Because of the short half-life of radon and the radioactivity of its compounds, it has not been possible to study the compound in any detail. Theoretical studies on this molecule predict that it should have a Rn–F bond distance of 2.08 ångström (Å), and that the compound is thermodynamically more stable and less volatile than its lighter counterpart xenon difluoride (XeF2). The octahedral molecule RnF6 was predicted to have an even lower enthalpy of formation than the difluoride.",1
"Radon is also oxidised by dioxygen difluoride to RnF2 at 173 K (−100 °C; −148 °F).Radon oxides are among the few other reported compounds of radon; only the trioxide (RnO3) has been confirmed. The higher fluorides RnF4 and RnF6 have been claimed and are calculated to be stable, but their identification is unclear. They may have been observed in experiments where unknown radon-containing products distilled together with xenon hexafluoride: these may have been RnF4, RnF6, or both.",1
"is likely that the difficulty in identifying higher fluorides of radon stems from radon being kinetically hindered from being oxidised beyond the divalent state because of the strong ionicity of radon difluoride (RnF2) and the high positive charge on radon in RnF+; spatial separation of RnF2 molecules may be necessary to clearly identify higher fluorides of radon, of which RnF4 is expected to be more stable than RnF6 due to spin–orbit splitting of the 6p shell of radon (RnIV would have a closed-shell 6s26p21/2 configuration).",1
"Therefore, while RnF4 should have a similar stability to xenon tetrafluoride (XeF4), RnF6 would likely be much less stable than xenon hexafluoride (XeF6): radon hexafluoride would also probably be a regular octahedral molecule, unlike the distorted octahedral structure of XeF6, because of the inert pair effect. Because radon is quite electropositive for a noble gas, it is possible that radon fluorides actually take on highly fluorine-bridged structures and are not volatile.",1
"Extrapolation down the noble gas group would suggest also the possible existence of RnO, RnO2, and RnOF4, as well as the first chemically stable noble gas chlorides RnCl2 and RnCl4, but none of these have yet been found.Radon carbonyl (RnCO) has been predicted to be stable and to have a linear molecular geometry. The molecules Rn2 and RnXe were found to be significantly stabilized by spin-orbit coupling. Radon caged inside a fullerene has been proposed as a drug for tumors.",1
"Despite the existence of Xe(VIII), no Rn(VIII) compounds have been claimed to exist; RnF8 should be highly unstable chemically (XeF8 is thermodynamically unstable). It is predicted that the most stable Rn(VIII) compound would be barium perradonate (Ba2RnO6), analogous to barium perxenate. The instability of Rn(VIII) is due to the relativistic stabilization of the 6s shell, also known as the inert pair effect.Radon reacts with the liquid halogen fluorides ClF, ClF3, ClF5, BrF3, BrF5, and IF7 to form RnF2.",1
"In halogen fluoride solution, radon is nonvolatile and exists as the RnF+ and Rn2+ cations; addition of fluoride anions results in the formation of the complexes RnF−3 and RnF2−4, paralleling the chemistry of beryllium(II) and aluminium(III). The standard electrode potential of the Rn2+/Rn couple has been estimated as +2.0 V, although there is no evidence for the formation of stable radon ions or compounds in aqueous solution.",1
"Radon has no stable isotopes. Thirty-nine radioactive isotopes have been characterized, with mass numbers ranging from 193 to 231. The most stable isotope is 222Rn, which is a decay product of 226Ra, a decay product of 238U. A trace amount of the (highly unstable) isotope 218Rn is also among the daughters of 222Rn. Three other radon isotopes have a half-life of over an hour: 211Rn, 210Rn and 224Rn. The 220Rn isotope is a natural decay product of the most stable thorium isotope (232Th), and is commonly referred to as thoron. It has a half-life of 55.6",1
"seconds and also emits alpha radiation. Similarly, 219Rn is derived from the most stable isotope of actinium (227Ac)—named ""actinon""—and is an alpha emitter with a half-life of 3.96 seconds. No radon isotopes occur significantly in the neptunium (237Np) decay series, though a trace amount of the (extremely unstable) isotope 217Rn is produced.",1
"222Rn belongs to the radium and uranium-238 decay chain, and has a half-life of 3.8235 days. Its first four products (excluding marginal decay schemes) are very short-lived, meaning that the corresponding disintegrations are indicative of the initial radon distribution. Its decay goes through the following sequence: 222Rn, 3.82 days, alpha decaying to... 218Po, 3.10 minutes, alpha decaying to... 214Pb, 26.8 minutes, beta decaying to... 214Bi, 19.9 minutes, beta decaying to... 214Po, 0.1643 ms, alpha decaying to... 210Pb, which has a much longer half-life of 22.3 years, beta decaying to... 210Bi, 5.013 days, beta decaying to... 210Po, 138.376 days, alpha decaying to...",1
"206Pb, stable.The radon equilibrium factor is the ratio between the activity of all short-period radon progenies (which are responsible for most of radon's biological effects), and the activity that would be at equilibrium with the radon parent. If a closed volume is constantly supplied with radon, the concentration of short-lived isotopes will increase until an equilibrium is reached where the overall decay rate of the decay products equals that of the radon itself.",1
"The equilibrium factor found in epidemiological studies is 0.4. Radon was the fifth radioactive element to be discovered, in 1899 by Ernest Rutherford and Robert B. Owens at McGill University in Montreal, after uranium, thorium, radium, and polonium. In 1899, Pierre and Marie Curie observed that the gas emitted by radium remained radioactive for a month. Later that year, Rutherford and Owens noticed variations when trying to measure radiation from thorium oxide.",1
"Rutherford noticed that the compounds of thorium continuously emit a radioactive gas that remains radioactive for several minutes, and called this gas ""emanation"" (from Latin: emanare, to flow out, and emanatio, expiration), and later ""thorium emanation"" (""Th Em""). In 1900, Friedrich Ernst Dorn reported some experiments in which he noticed that radium compounds emanate a radioactive gas he named ""radium emanation"" (""Ra Em""). In 1901, Rutherford and Harriet Brooks demonstrated that the emanations are radioactive, but credited the Curies for the discovery of the element.",1
"In 1903, similar emanations were observed from actinium by André-Louis Debierne, and were called ""actinium emanation"" (""Ac Em""). Several shortened names were soon suggested for the three emanations: exradio, exthorio, and exactinio in 1904; radon (Ro), thoron (To), and akton or acton (Ao) in 1918; radeon, thoreon, and actineon in 1919, and eventually radon, thoron, and actinon in 1920. (The name radon is not related to that of the Austrian mathematician Johann Radon.)",1
"The likeness of the spectra of these three gases with those of argon, krypton, and xenon, and their observed chemical inertia led Sir William Ramsay to suggest in 1904 that the ""emanations"" might contain a new element of the noble-gas family.In the early 20th century in the US, gold contaminated with the radon daughter 210Pb entered the jewelry industry. This was from gold seeds that had held 222Rn that had been melted down after the radon had decayed.In 1909, Ramsay and Robert Whytlaw-Gray isolated radon and determined its melting temperature and approximate density.",1
"In 1910, they determined that it was the heaviest known gas. They wrote that ""L'expression l'émanation du radium est fort incommode"" (""the expression 'radium emanation' is very awkward"") and suggested the new name niton (Nt) (from Latin: nitens, shining) to emphasize the radioluminescence property, and in 1912 it was accepted by the International Commission for Atomic Weights. In 1923, the International Committee for Chemical Elements and International Union of Pure and Applied Chemistry (IUPAC) chose among the names radon (Rn), thoron (Tn), and actinon (An).",1
"Later, when isotopes were numbered instead of named, the element took the name of the most stable isotope, radon, while Tn was renamed 220Rn and An was renamed 219Rn. This has caused some confusion in the literature regarding the element's discovery as while Dorn had discovered radon the isotope, he had not been the first to discover radon the element.As late as the 1960s, the element was also referred to simply as emanation. The first synthesized compound of radon, radon fluoride, was obtained in 1962.",1
"Beginning in the 1970s, research was initiated to address sources of indoor radon, determinants of concentration, health effects, and mitigation approaches. In the US, the problem of indoor radon received widespread publicity and intensified investigation after a widely publicized incident in 1984. During routine monitoring at a Pennsylvania nuclear power plant, a worker was found to be contaminated with radioactivity. A high concentration of radon in his home was subsequently identified as responsible.",1
"All discussions of radon concentrations in the environment refer to 222Rn. While the average rate of production of 220Rn (from the thorium decay series) is about the same as that of 222Rn, the amount of 220Rn in the environment is much less than that of 222Rn because of the short half-life of 220Rn (55 seconds, versus 3.8 days respectively).Radon concentration in the atmosphere is usually measured in becquerel per cubic meter (Bq/m3), the SI derived unit. Another unit of measurement common in the US is picocuries per liter (pCi/L); 1 pCi/L = 37 Bq/m3.",1
"× 10−3 J·h/m3. An exposure to 1 WL for 1 working-month (170 hours) equals 1 WLM cumulative exposure. A cumulative exposure of 1 WLM is roughly equivalent to living one year in an atmosphere with a radon concentration of 230 Bq/m3.222Rn decays to 210Pb and other radioisotopes. The levels of 210Pb can be measured. The rate of deposition of this radioisotope is weather-dependent. Radon concentrations found in natural environments are much too low to be detected by chemical means. A 1,000 Bq/m3 (relatively high) concentration corresponds to 0.17 picogram per cubic meter (pg/m3).",1
"Radon is produced by the radioactive decay of radium-226, which is found in uranium ores, phosphate rock, shales, igneous and metamorphic rocks such as granite, gneiss, and schist, and to a lesser degree, in common rocks such as limestone. Every square mile of surface soil, to a depth of 6 inches (2.6 km2 to a depth of 15 cm), contains approximately 1 gram of radium, which releases radon in small amounts to the atmosphere. On a global scale, it is estimated that 2.4 billion curies (90 EBq) of radon are released from soil annually. This is equivalent to some 15.3",1
"High concentrations of radon in homes were discovered by chance in 1985 after the stringent radiation testing conducted at the new Limerick Generating Station nuclear power plant revealed that Stanley Watras, a construction engineer at the plant, was contaminated by radioactive substances even though the reactor had never been fueled. Typical domestic exposures are of approximately 100 Bq/m3 (2.7 pCi/L) indoors. Some level of radon will be found in all buildings. Radon mostly enters a building directly from the soil through the lowest level in the building that is in contact with the ground.",1
"The soil characteristics of the dwellings are the most important source of radon for the ground floor and higher concentration of indoor radon observed on lower floors. Most of the high radon concentrations have been reported from places near fault zones; hence the existence of a relation between the exhalation rate from faults and indoor radon concentrations is obvious.The distribution of radon concentrations will generally differ from room to room, and the readings are averaged according to regulatory protocols. Indoor radon concentration is usually assumed to follow a log-normal distribution on a given territory.",1
In the UK under the Housing Health & Safety Rating System (HHSRS) property owners have an obligation to evaluate potential risks and hazards to health and safety in a residential property.,1
"commercialization is regulated, but it is available in small quantities for the calibration of 222Rn measurement systems, at a price, in 2008, of almost US$6,000 (equivalent to $8,155 in 2022) per milliliter of radium solution (which only contains about 15 picograms of actual radon at any given moment). Radon is produced by a solution of radium-226 (half-life of 1,600 years).",1
"Radium-226 decays by alpha-particle emission, producing radon that collects over samples of radium-226 at a rate of about 1 mm3/day per gram of radium; equilibrium is quickly achieved and radon is produced in a steady flow, with an activity equal to that of the radium (50 Bq). Gaseous 222Rn (half-life of about four days) escapes from the capsule through diffusion.",1
"The gold seeds were produced by filling a long tube with radon pumped from a radium source, the tube being then divided into short sections by crimping and cutting. The gold layer keeps the radon within, and filters out the alpha and beta radiations, while allowing the gamma rays to escape (which kill the diseased tissue). The activities might range from 0.05 to 5 millicuries per seed (2 to 200 MBq). The gamma rays are produced by radon and the first short-lived elements of its decay chain (218Po, 214Pb, 214Bi, 214Po).",1
"After 11 half-lives (42 days), radon radioactivity is at 1/2,048 of its original level. At this stage, the predominant residual activity of the seed originates from the radon decay product 210Pb, whose half-life (22.3 years) is 2,000 times that of radon and its descendants 210Bi and 210Po.",1
"For this reason, it has been hypothesized that increases in radon concentration is due to the generation of new cracks underground, which would allow increased groundwater circulation, flushing out radon. The generation of new cracks might not unreasonably be assumed to precede major earthquakes. In the 1970s and 1980s, scientific measurements of radon emissions near faults found that earthquakes often occurred with no radon signal, and radon was often detected with no earthquake to follow. It was then dismissed by many as an unreliable indicator. As of 2009, it was under investigation as a possible precursor by NASA.Radon",1
"Other X-ray sources, which became available after World War II, quickly replaced radon for this application, as they were lower in cost and had less hazard of alpha radiation.",1
"Radon-222 decay products have been classified by the International Agency for Research on Cancer as being carcinogenic to humans, and as a gas that can be inhaled, lung cancer is a particular concern for people exposed to elevated levels of radon for sustained periods. During the 1940s and 1950s, when safety standards requiring expensive ventilation in mines were not widely implemented, radon exposure was linked to lung cancer among non-smoking miners of uranium and other hard rock materials in what is now the Czech Republic, and later among miners from the Southwestern US and South Australia.",1
"In recent years, the average annual exposure of uranium miners has fallen to levels similar to the concentrations inhaled in some homes. This has reduced the risk of occupationally-induced cancer from radon, although health issues may persist for those who are currently employed in affected mines and for those who have been employed in them in the past. As the relative risk for miners has decreased, so has the ability to detect excess risks among that population.Residues from processing of uranium ore can also be a source of radon.",1
"Radon resulting from the high radium content in uncovered dumps and tailing ponds can be easily released into the atmosphere and affect people living in the vicinity.In addition to lung cancer, researchers have theorized a possible increased risk of leukemia due to radon exposure. Empirical support from studies of the general population is inconsistent, and a study of uranium miners found a correlation between radon exposure and chronic lymphocytic leukemia.Miners",1
(as well as milling and ore transportation workers) who worked in the uranium industry in the US between the 1940s and 1971 may be eligible for compensation under the Radiation Exposure Compensation Act (RECA). Surviving relatives may also apply in cases where the formerly employed person is deceased. Not only uranium mines are affected by elevated levels of radon. Coal mines in particular are affected as well since coal may contain more uranium and thorium than commercially operational uranium mines.,1
"Prolonged exposure to higher concentrations of radon has been linked to an increase in lung cancer. Since 1999, there have been investigations worldwide on how radon concentrations are estimated. In the United States alone averages have been recorded to be at least 40 Bq/meters cubed. Steck et al. did a study on the variation between indoor and outdoor radon in Iowa and Minnesota. Higher radiation was found in a populated region rather than in unpopulated regions in Central America as a whole. In some northwestern Iowa and southwestern Minnesota counties, the outdoor radon concentrations exceed the national average indoor radon concentrations.",1
"Despite the above average, both Minnesota and Iowa's numbers were exceptionally close, regardless of the distance. Accurate doses of radon is heavily needed to further understand the problems radon in total can have on a community. It is understood that radon poisoning does lead to bad health, and lung cancer, but with further research, controls could change results in radon emissions both inside and outside of housing units.Radon exposure (mostly radon daughters) has been linked to lung cancer in numerous case-control studies performed in the US, Europe and China. There are approximately 21,000 deaths per year in the US (0.0063%",1
"of a population of 333 million) due to radon-induced lung cancers. In Slovenia, a country with a high concentration of radon, about 120 people (0.0057% of a population of 2.11 million) yearly die because of radon. One of the most comprehensive radon studies performed in the US by epidemiologist R. William Field and colleagues found a 50% increased lung cancer risk even at the protracted exposures at the EPA's action level of 4 pCi/L. North American and European pooled analyses further support these findings.",1
"WHO presented in 2009 a recommended reference level (the national reference level), 100 Bq/m3, for radon in dwellings. The recommendation also says that where this is not possible, 300 Bq/m3 should be selected as the highest level. A national reference level should not be a limit, but should represent the maximum acceptable annual average radon concentration in a dwelling.The",1
"actionable concentration of radon in a home varies depending on the organization doing the recommendation, for example, the EPA encourages that action be taken at concentrations as low as 74 Bq/m3 (2 pCi/L), and the European Union recommends action be taken when concentrations reach 400 Bq/m3 (11 pCi/L) for old houses and 200 Bq/m3 (5 pCi/L) for new ones. On 8 July 2010, the UK's Health Protection Agency issued new advice setting a ""Target Level"" of 100 Bq/m3 whilst retaining an ""Action Level"" of 200 Bq/m3.",1
"Similar levels (as in UK) are published by Norwegian Radiation and Nuclear Safety Authority (DSA) with the maximum limit for schools, kindergartens, and new dwellings set at 200 Bq/m3, where 100 Bq/m3 is set as the action level. In all new housings preventative measures should be taken against radon accumulation.",1
"Results from epidemiological studies indicate that the risk of lung cancer increases with exposure to residential radon. A well known example of source of error is smoking, the main risk factor for lung cancer. In the US, cigarette smoking is estimated to cause 80% to 90% of all lung cancers.According to the EPA, the risk of lung cancer for smokers is significant due to synergistic effects of radon and smoking. For this population about 62 people in a total of 1,000 will die of lung cancer compared to 7 people in a total of 1,000 for people who have never smoked.",1
"It cannot be excluded that the risk of non-smokers should be primarily explained by an effect of radon. Radon, like other known or suspected external risk factors for lung cancer, is a threat for smokers and former smokers. This was demonstrated by the European pooling study. A commentary to the pooling study stated: ""it is not appropriate to talk simply of a risk from radon in homes. The risk is from smoking, compounded by a synergistic effect of radon for smokers. Without smoking, the effect seems to be so small as to be insignificant.""",1
"This is also supported by new discussion about the calculation method, the linear no-threshold model, which routinely has been used.A study from 2001, which included 436 non-smokers and a control group of 1649 non-smokers, showed that exposure to radon increased the risk of lung cancer in non-smokers. The group that had been exposed to tobacco smoke in the home appeared to have a much higher risk, while those who were not exposed to passive smoking did not show any increased risk with increasing radon exposure.",1
"The kit includes a collector that the user hangs in the lowest habitable floor of the house for two to seven days. The user then sends the collector to a laboratory for analysis. Long term kits, taking collections for up to one year or more, are also available. An open-land test kit can test radon emissions from the land before construction begins. Radon concentrations can vary daily, and accurate radon exposure estimates require long-term average radon measurements in the spaces where an individual spends a significant amount of time.Radon",1
"levels fluctuate naturally, due to factors like transient weather conditions, so an initial test might not be an accurate assessment of a home's average radon level. Radon levels are at a maximum during the coolest part of the day when pressure differentials are greatest. Therefore, a high result (over 4 pCi/L) justifies repeating the test before undertaking more expensive abatement projects. Measurements between 4 and 10 pCi/L warrant a long-term radon test. Measurements over 10 pCi/L warrant only another short-term test so that abatement measures are not unduly delayed.",1
"Purchasers of real estate are advised to delay or decline a purchase if the seller has not successfully abated radon to 4 pCi/L or less.Because the half-life of radon is only 3.8 days, removing or isolating the source will greatly reduce the hazard within a few weeks. Another method of reducing radon levels is to modify the building's ventilation. Generally, the indoor radon concentrations increase as ventilation rates decrease. In a well-ventilated place, the radon concentration tends to align with outdoor values (typically 10 Bq/m3, ranging from 1 to 100 Bq/m3).The",1
"Randall Schumann Home Buyer's and Seller's Guide to Radon An article by the International Association of Certified Home Inspectors (InterNACHI) Toxicological Profile for Radon, Draft for Public Comment, Agency for Toxic Substances and Disease Registry, September 2008 Health Effects of Exposure to Radon: BEIR VI. Committee on Health Risks of Exposure to Radon (BEIR VI), National Research Council available online UNSCEAR 2000 Report to the General Assembly, with scientific annexes: Annex B: Exposures from natural radiation sources. Should you measure the radon concentration in your home?, Phillip N. Price, Andrew Gelman, in Statistics: A Guide to the Unknown, January 2004.",1
Radon in the Home- An Invisible Killer How serious can high levels of radon be in the home? Kevin Vitali,1
"Sewage treatment is less effective when sanitary waste is diluted with stormwater, and combined sewer overflows occur when runoff from heavy rainfall or snowmelt exceeds the hydraulic capacity of sewage treatment plants. To overcome these disadvantages, some cities built separate sanitary sewers to collect only municipal wastewater and exclude stormwater runoff, which is collected in separate storm drains. The decision to build a combined sewer system or two separate systems is mainly based on the need for sewage treatment and the cost of providing treatment during heavy rain events.",1
"Many cities with combined sewer systems built their systems prior to installing sewage treatment plants, and have not subsequently replaced those sewer systems.",1
"conveying sewage from an individual building to a common gravity sewer line are called laterals. Branch sewers typically run under streets receiving laterals from buildings along that street and discharge by gravity into trunk sewers at manholes. Larger cities may have sewers called interceptors, receiving flow from multiple trunk sewers.Design and sizing of sanitary sewers considers the population to be served over the anticipated life of the sewer, per capita wastewater production, and flow peaking from timing of daily routines.",1
"Minimum sewer diameters are often specified to prevent blockage by solid materials flushed down toilets; and gradients may be selected to maintain flow velocities generating sufficient turbulence to minimize solids deposition within the sewer. Commercial and industrial wastewater flows are also considered, but diversion of surface runoff to storm drains eliminates wet weather flow peaks of inefficient combined sewers.",1
Force mains are substantially different from pressure sewers which serve individual properties or groups of properties and provide a means of injecting sewage into a local gravity main.,1
"The pipes have small diameters, typically 1.5 to 4 inches (4 to 10 cm). Because the waste stream is pressurized, they can be laid just below the ground surface along the land's contour.",1
"Where it is impossible or impractical to discharge sewage from a property into a gravity sanitary sewer, a pressure sewer may provide an alternative means of connection. A macerator pump in a pumping well close to the property ejects sewage through a small diameter high pressure pipe into the nearest gravity sewer.",1
"The maintenance requirements vary with the type of sanitary sewer. In general, all sewers deteriorate with age, but infiltration and inflow are problems unique to sanitary sewers, since both combined sewers and storm drains are sized to carry these contributions. Holding infiltration to acceptable levels requires a higher standard of maintenance than necessary for structural integrity considerations of combined sewers. A comprehensive construction inspection program is required to prevent inappropriate connection of cellar, yard, and roof drains to sanitary sewers.",1
"All the individuals and organizations which worry about the ecological problems of Armenia and can make a contribution on a voluntary basis within the framework of the movement were welcome to take part in this campaign. They called everyone (individuals, ecological, youth and other organizations, schools, HEIs) to join the movement, coordinate and carry out clean-up and educational activities in their favorite places. Let's do it! Armenia was going to unite and carry out the biggest Pan-Armenian clean-up under the slogan ""Armenia Without Garbage"" on 15 September 2012.",1
"The dark night sky has a scientific importance for astronomy research and viewing.Urban sky glow is taking away the view of the stars and night sky that was so common to the ancestors of the land. In the city of Honolulu, only about 20 stars can be seen on the nightly, and in places with a dark night sky, up to 2,000 stars can be seen nightly. Hawai'i has two major astronomical observatories and the dark sky is immensely important for the telescopes to be able to see faint objects in space.",1
"The dark night sky over the island of Hawai'i, is a known tourist attraction with over 100,000 visitors every year. The visitors come to watch the night sky and participate in the stargazing program at the Mauna Kea observatory. Mauna Kea's sky is one of the darkest in the world.",1
"Newell's shearwater fledglings can be dazed and disoriented by intense lighting in the night, which can lead to an unfortunate ending for the young birds because they can be killed by cars or prey animals. Artificial light is about two hundred times more bright than natural illumination experienced in the raw environment.",1
"Apart from that, a survey by four students from Worcester Polytechnic Institute in Massachusetts discovered that the light of the neon signs from buildings in Causeway Bay was 176 lux bright and Mong Kok was about 150 to 500 lux, which is far higher than British agencies recommend. Even at the Wetland Park in Tin Shui Wai, the brightness was 130 times higher than the International Astronomical Union standard. The rise of complaints also reveals the seriousness of the problem. The number of complaints has increased from 87 in 2007 to 377 in 2009.",1
"In heavily mixed residential developments such as Mong Kok and Sham Shui Po, some residents have trouble sleeping as they have strong neon lights shining through their bedroom windows, emitted by billboards. Some precincts have been described as being lit up like football stadiums.",1
Excessive amounts of light can disrupt the biological clock (Circadian rhythm) of humans and affect their brains and hormone functions.,1
"Instead, a Task Force on External Lighting set up by the Environment Bureau has issued the ""Guidelines on Industry Best Practices for External Lighting Installations"". However, it is carried out on a voluntary basis by the industry and is thus criticized as ""toothless."" The lawmakers are still investigating the need to set up specific laws in regulating external lighting. Yet, opinions are divided. While residents generally welcome the idea, the tourism and advertising industries both rely on lighting to boost business.",1
"Committee chairman Kenneth Chan said the government had given in to pressure from the commercial sector, which was opposed to any curbs on external lighting. Lights Out Hong Kong",1
Cs-137 activity was much smaller in leaves of larch and sycamore maple than of spruce: spruce > larch > sycamore maple.,1
Center for Orbital and Reentry Debris Studies Space Shuttle external tank List of heaviest spacecraft List of space debris producing events,1
"Photoinitators can create reactive species by different pathways including photodissociation and electron transfer. As an example of dissociation, hydrogen peroxide can undergo homolytic cleavage, with the O-O bond cleaving to form two hydroxyl radicals. H2O2 → 2 ·OHCertain azo compounds (such as azobisisobutyronitrile), can also photolytically cleave, forming two alkyl radicals and nitrogen gas: RCH2-N=N-H2CR → 2 RCH2 + N2These free radicals can now promote other reactions.",1
"Since molecular oxygen can abstract H atoms from certain radicals, the HOO· radical is easily created. This particular radical can further abstract H atoms, creating H2O2, or hydrogen peroxide; peroxides can further cleave photolytically into two hydroxyl radicals. More commonly, HOO can react with free oxygen atoms to yield a hydroxyl radical (·OH) and oxygen gas. In both cases, the ·OH radicals formed can serve to oxidize organic compounds in the atmosphere. H2O2 → 2 ·OH HOO· + O → O2 + ·OH·OH + CH4 → ·CH3 + H2O",1
"In the stratosphere, molecular oxygen (O2) is an important photoinitiator that begins the ozone-production process in the ozone layer. Oxygen can be photolyzed into atomic oxygen by light with wavelength less than 240 nm. O2 → 2OAtomic oxygen can then combine with more molecular oxygen to form ozone. O + O2 → O3However, ozone can also be photolyzed back into O and O2. O3 → O + O2Furthermore, atomic oxygen and ozone can combine into O2. O + O3 → 2 O2This set of reactions govern the production of ozone and can be combined to calculate its equilibrium concentration.",1
"Pollutants, towards which the environment has low absorptive capacity are called stock pollutants. Examples include persistent organic pollutants like PCBs, non-biodegradable plastics and heavy metals. Stock pollutants accumulate in the environment over time. The damage they cause increases as more pollutant is emitted, and persists as the pollutant accumulates. Stock pollutants can create a burden for the future generations, bypassing on the damage that persists well after the benefits received from incurring that damage, have been forgotten. Scientists have officially deemed that the planetary boundaries safe chemical pollutant levels (novel entities) have been surpassed.",1
"In contrast to stock pollutants, for which the environment has low absorptive capacity, fund pollutants are those for which the environment has a moderate absorptive capacity. Fund pollutants do not cause damage to the environment unless the emission rate exceeds the receiving environment's absorptive capacity (e.g. carbon dioxide, which is absorbed by plants and oceans). Fund pollutants are not destroyed, but rather converted into less harmful substances, or diluted/dispersed to non-harmful concentrations.",1
The horizontal zone refers to the area that is damaged by a pollutant. Local pollutants cause damage near the emission source. Regional pollutants cause damage further from the emission source.,1
The vertical zone refers to whether the damage is ground-level or atmospheric. Surface pollutants cause damage by accumulating near the Earth's surface. Global pollutants cause damage by concentrating on the atmosphere.,1
"The European Pollutant Emission Register is a type of PRTR providing access to information on the annual emissions of industrial facilities in the Member States of the European Union, as well as Norway.",1
The material to be vaporized is typically heated until its vapor pressure is high enough to produce a flux of several Angstroms per second by using an electrically resistive heater or bombardment by a high voltage beam. Freeze drying List of waste-water treatment technologies Vacuum deposition Vacuum evaporation manufacturer,1
"The Convention for the Protection of the Marine Environment of the North-East Atlantic was opened for signature at the Ministerial Meeting of the Oslo and Paris Commissions in Paris on 22 September 1992. The Convention has been signed and ratified by all of the Contracting Parties to the original Oslo or Paris Conventions (Belgium, Denmark, the European Community, Finland, France, Germany, Iceland, Ireland, the Netherlands, Norway, Portugal, Spain, Sweden and the United Kingdom of Great Britain and Northern Ireland) and by Luxembourg and Switzerland.",1
"The OSPAR Convention entered into force on 25 March 1998, and replaced the Oslo and Paris Conventions, but decisions and other agreements adopted under those conventions remained applicable unless they are terminated by new measures adopted under the OSPAR Convention. The first Ministerial Meeting of the OSPAR Commission at Sintra, Portugal, in 1998 adopted Annex V to the Convention, extending the cooperation of the signatory parties to cover ""all human activities that might adversely affect the marine environment of the North East Atlantic"".",1
"This was supported by five smaller reports on the different parts of the OSPAR maritime area –the Arctic, the Greater North Sea, the Celtic Seas, the Bay of Biscay/Golfe de Gascogne and Iberian waters, and the Wider Atlantic. According to the fr :Association pour le contrôle de la radioactivité dans l'Ouest, if tritium and iodine 129 discharges from the La Hague site into the Alderney Race do not diminish significantly, it will be difficult to achieve the objective of zero radioelement concentrations in the North Atlantic by 2020.In",1
"Let c 1 , c 2 , . . . c 12 {\displaystyle c_{1},c_{2},...c_{12}} represent the hourly PM concentrations for the most recent 12-hour period, with c 1 {\displaystyle c_{1}} the most recent hourly value, and let c m i n {\displaystyle c_{min}} and c m a x {\displaystyle c_{max}} represent the minimum and maximum hourly concentration for the 12-hour period.",1
Define: w ∗ = 1 − c m a x − c m i n c m a x = c m i n c m a x {\displaystyle w^{*}=1-{\frac {c_{max}-c_{min}}{c_{max}}}={\frac {c_{min}}{c_{max}}}} and let w = { w ∗ if w ∗ > 1 2 1 2 if w ∗ ≤ 1 2 {\displaystyle w={\begin{cases}w^{*}&{\mbox{if }}w^{*}>{\frac {1}{2}}\\{\frac {1}{2}}&{\mbox{if }}w^{*}\leq {\frac {1}{2}}\\\end{cases}}} With these definitions the PM NowCast is given by: N o w C a s t = ∑ i = 1 12 w i − 1 c i ∑ i = 1 12 w i − 1 .,1
"{\displaystyle NowCast={\frac {\sum _{i=1}^{12}w^{i-1}c_{i}}{\sum _{i=1}^{12}w^{i-1}}}.} For the special case where there is no variability in the hourly values, c m i n = c m a x , w = 1 {\displaystyle c_{min}=c_{max},w=1} , and the NowCast reduces to the twelve-hour average: N o w C a s t = ∑ i = 1 12 c i 12 . {\displaystyle NowCast={\frac {\sum _{i=1}^{12}c_{i}}{12}}.} For the special case where w=1/2: N o w C a s t = c 1 + ( 1 2 ) c 2 + . . .",1
"+ ( 1 2 ) 11 c 12 1 + 1 2 + ( 1 2 ) 2 + . . . + ( 1 2 ) 11 {\displaystyle NowCast={\frac {c_{1}+({\frac {1}{2}})c_{2}+...+{({\frac {1}{2}}})^{11}{c_{12}}}{1+{\frac {1}{2}}+({\frac {1}{2}})^{2}+...+{({\frac {1}{2}}})^{11}}}} But 1/(1-x)=1 + x + x2+ ... , x < 1, so to a good approximation, when w = 1/2: N o w C a s t = 1 2 c 1 + ( 1 2 ) 2 c 2 + . . . + ( 1 2 ) 12 c 12 {\displaystyle NowCast={\frac {1}{2}}c_{1}+({\frac {1}{2}})^{2}c_{2}+...+{({\frac",1
"{1}{2}}})^{12}{c_{12}}} Because the most recent hours of data are weighted so heavily in the NowCast when PM levels are changing, EPA does not report the NowCast when data is missing for c1 or c2. Consider a day when the hourly average PM2.5 concentration is zero for all hours of the day, except for a single hour from noon to 1 pm, where a monitor records a concentration pulse of 71 micrograms per cubic meter (µg/m3). According to the equation above, the Nowcast is 71/2 µg/m3=35.5 µg/m3 the hour after the pulse, two hours later it is 71/4 µg/m3=17.8",1
"µg/m3 and three hours later it is 71/8 µg/m3= 8.9 µg/m3. To calculate the corresponding AQI values, each NowCast concentration is substituted into the AQI equation in place of the 24-hour average PM2.5 concentration: I = C − C l o w C h i g h − C l o w ( I h i g h − I l o w ) + I l o w {\displaystyle I={\frac {C-C_{low}}{C_{high}-C_{low}}}(I_{high}-I_{low})+I_{low}} where: I {\displaystyle I} = the AQI, C {\displaystyle C} = the 24-hour average PM2.5",1
"pollutant concentration, C l o w {\displaystyle C_{low}} = the concentration breakpoint that is ≤ C {\displaystyle C} , C h i g h {\displaystyle C_{high}} = the concentration breakpoint that is ≥ C {\displaystyle C} , I l o w {\displaystyle I_{low}} = the index breakpoint corresponding to C l o w {\displaystyle C_{low}} , I h i g h {\displaystyle I_{high}} = the index breakpoint corresponding to C h i g h {\displaystyle C_{high}} .and:",1
"EPA has developed a calculator to compute the PM NowCast, AQI, and AQI category and color from the most recent 12 hours of monitoring data.",1
"All of these elements have low volatility, meaning they prefer to stay in a liquid or solid state rather than condensing into the atmosphere and existing as vapor. Cerium and Lanthanum can cause irreversible damage to marine life by deteriorating cell membranes, affecting reproductive capability, as well as crippling the nervous system. Strontium in its non-nuclear isotope is stable and harmless, however, when the radioactive isotope, Sr90, is released into the atmosphere it can lead to anemia, cancers, and cause shortages in oxygen.",1
"of these elements only deteriorate through radioactive decay, which is also known as a half-life. Half-lives of the nuclides previously discussed can range from mere hours, to decades. The shortest half-life for the previous elements is Zr95, an isotope of zirconium which takes 1.4 hours to decay. The longest is Pu235, which takes approximately 24,000 years to decay. While the initial release of these particles and elements was rather large, there were multiple low-level releases for at least a month after the initial incident at Chernobyl.",1
"Surrounding wildlife and fauna were drastically affected by Chernobyl's explosions. Coniferous trees, which are plentiful in the surrounding landscape, were heavily affected due to their biological sensitivity to radiation exposure. Within days of the initial explosion many pine trees in a 4 km radius died, with lessening yet still harmful effects being observed up to 120 km away. Many trees experienced interruptions in their growth, reproduction was crippled, and there were multiple observations of morphological changes. Hot particles also landed on these forests, causing holes and hollows to be burned into the trees.",1
"The surrounding soil was covered in radionuclides, which prevented substantial new growth. Deciduous trees such as Aspen, Birch, Alder, and Oak trees are more resistant to radiation exposure than coniferous trees, however they aren't immune. Damage seen on these trees was less harsh than observed on the pine trees. A lot of new deciduous growth suffered from necrosis, death of living tissue, and foliage on existing trees turned yellow and fell off. Deciduous trees resilience has allowed them to bounce back and they have populated where many coniferous trees, mostly pine, once stood. Herbaceous vegetation was also affected by radiation fallout.",1
"There were many observations of color changes in the cells, chlorophyll mutation, lack of flowering, growth depression, and vegetation death.Mammals are a highly radio-sensitive class, and observations of mice in the surrounding area of Chernobyl showed a population decrease. Embryonic mortality increased as well, however, migration patterns of the rodents made the damaged population number increase once again. Among the small rodents affected, it was observed that there were increasing issues in the blood and livers, which is a direct correlation to radiation exposure.",1
"Issues such as liver cirrhosis, enlarged spleens, increased peroxide oxidation of tissue lipids, and a decrease in the levels of enzymes were all present in the rodents exposed to the radioactive blasts. Larger wildlife didn't fare much better. Although most livestock were relocated a safe distance away, horses and cattle located on an isolated island 6 km away from the Chernobyl radioactivity were not spared. Hyperthyroidism, stunted growth, and, of course, death plagued the animals left on the island.The loss of human population in Chernobyl, sometimes referred to as the ""exclusion zone,"" has allowed the ecosystems to recover.",1
"Factors such as rainfall, wind currents, and the initial explosions at Chernobyl themselves caused the nuclear fallout to spread throughout Europe, Asia, as well as parts of North America. Not only was there a spread of these various radioactive elements previously mentioned, but there were also problems with what are known as hot particles. The Chernobyl reactor didn't just expel aerosol particles, fuel particles, and radioactive gases, but there was an additional expulsion of Uranium fuel fused together with radionuclides.",1
"Møller & Mousseau 2011 find that individuals carrying deleterious mutations will not be selected out immediately but will instead survive for many generations. As such they are expected to have descendants far away from contamination sites that created them, contaminating those populations, and causing fitness decline.",1
"order to gauge how to best prevent eutrophication from occurring, specific sources that contribute to nutrient loading must be identified. There are two common sources of nutrients and organic matter: point and nonpoint sources.",1
"and catchment data, including hydrogeological characteristics.",1
"2000 and 2010 EPA published federal-level nutrient criteria for rivers/streams, lakes/reservoirs, estuaries and wetlands; and related guidance. ""Ecoregional"" nutrient criteria for 14 ecoregions across the U.S. were included in these publications. While states may directly adopt the EPA-published criteria, in many cases the states need to modify the criteria to reflect site-specific conditions. In 2004, EPA stated its expectations for numeric criteria (as opposed to less-specific narrative criteria) for total nitrogen (TN), total phosphorus (TP), chlorophyll a(chl-a), and clarity, and established ""mutually-agreed upon plans"" for state criteria development.",1
"In 2007, the agency stated that progress among the states on developing nutrient criteria had been uneven. EPA reiterated its expectations for numeric criteria and promised its support for state efforts to develop their own criteria.After the EPA had introduced watershed-based NPDES permitting in 2007, interest in nutrient removal and achieving regional Total Maximum Daily Load (TMDL) limitations led to the development of nutrient trading schemes.In 2008 EPA published a progress report on state efforts to develop nutrient standards.",1
"Many point source dischargers in the U.S., while not necessarily the largest sources of nutrients in their respective watersheds, are required to comply with nutrient effluent limitations in their permits, which are issued through the National Pollutant Discharge Elimination System (NPDES), pursuant to the CWA. Some large municipal sewage treatment plants, such as the Blue Plains Advanced Wastewater Treatment Plant in Washington, D.C. have installed biological nutrient removal (BNR) systems to comply with regulatory requirements. Other municipalities have made adjustments to the operational practices of their existing secondary treatment systems to control nutrients.Discharges",1
"The sum of the atomic mass of the two atoms produced by the fission of one fissile atom is always less than the atomic mass of the original atom. This is because some of the mass is lost as free neutrons, and once kinetic energy of the fission products has been removed (i.e., the products have been cooled to extract the heat provided by the reaction), then the mass associated with this energy is lost to the system also, and thus appears to be ""missing"" from the cooled fission products.",1
"Since the nuclei that can readily undergo fission are particularly neutron-rich (e.g. 61% of the nucleons in uranium-235 are neutrons), the initial fission products are often more neutron-rich than stable nuclei of the same mass as the fission product (e.g. stable zirconium-90 is 56% neutrons compared to unstable strontium-90 at 58%). The initial fission products therefore may be unstable and typically undergo beta decay to move towards a stable configuration, converting a neutron to a proton with each beta emission. (Fission products do not decay via alpha decay.)",1
"A few neutron-rich and short-lived initial fission products decay by ordinary beta decay (this is the source of perceptible half life, typically a few tenths of a second to a few seconds), followed by immediate emission of a neutron by the excited daughter-product. This process is the source of so-called delayed neutrons, which play an important role in control of a nuclear reactor. The first beta decays are rapid and may release high energy beta particles or gamma radiation.",1
"However, as the fission products approach stable nuclear conditions, the last one or two decays may have a long half-life and release less energy. Fission products have half-lives of 90 years (samarium-151) or less, except for seven long-lived fission products that have half lives of 211,100 years (technetium-99) or more. Therefore, the total radioactivity of a mixture of pure fission products decreases rapidly for the first several hundred years (controlled by the short-lived products) before stabilizing at a low level that changes little for hundreds of thousands of years (controlled by the seven long-lived products).",1
"This behavior of pure fission products with actinides removed, contrasts with the decay of fuel that still contains actinides. This fuel is produced in the so-called ""open"" (i.e., no nuclear reprocessing) nuclear fuel cycle. A number of these actinides have half lives in the missing range of about 100 to 200,000 years, causing some difficulty with storage plans in this time-range for open cycle non-reprocessed fuels.",1
"The amount of any particular isotope produced per fission is called its yield, typically expressed as percent per parent fission; therefore, yields total to 200%, not 100%. (The true total is in fact slightly greater than 200%, owing to rare cases of ternary fission.) While fission products include every element from zinc through the lanthanides, the majority of the fission products occur in two peaks. One peak occurs at about (expressed by atomic number) strontium to ruthenium while the other peak is at about tellurium to neodymium.",1
"The yield is somewhat dependent on the parent atom and also on the energy of the initiating neutron. In general the higher the energy of the state that undergoes nuclear fission, the more likely that the two fission products have similar mass. Hence, as the neutron energy increases and/or the energy of the fissile atom increases, the valley between the two peaks becomes more shallow. For instance, the curve of yield against mass for 239Pu has a more shallow valley than that observed for 235U when the neutrons are thermal neutrons.",1
"Because of the stability of nuclei with even numbers of protons and/or neutrons, the curve of yield against element is not a smooth curve but tends to alternate. Note that the curve against mass number is smooth. Small amounts of fission products are naturally formed as the result of either spontaneous fission of natural uranium, which occurs at a low rate, or as a result of neutrons from radioactive decay or reactions with cosmic ray particles.",1
"These fission products were important in providing proof that the natural reactor had occurred. Fission products are produced in nuclear weapon explosions, with the amount depending on the type of weapon. The largest source of fission products is from nuclear reactors. In current nuclear power reactors, about 3% of the uranium in the fuel is converted into fission products as a by-product of energy generation. Most of these fission products remain in the fuel unless there is fuel element failure or a nuclear accident, or the fuel is reprocessed.",1
"Commercial nuclear fission reactors are operated in the otherwise self-extinguishing prompt subcritical state. Certain fission products decay over seconds to minutes, producing additional delayed neutrons crucial to sustaining criticality. An example is bromine-87 with a half-life of about a minute. Operating in this delayed critical state, power changes slowly enough to permit human and automatic control. Analogous to fire dampers varying the movement of wood embers towards new fuel, control rods are moved as the nuclear fuel burns up over time. In a nuclear power reactor, the main sources of radioactivity are fission products along with actinides and activation products.",1
"This decay heat requires removal after shutdown; loss of this cooling damaged the reactors at Three Mile Island and Fukushima. If the fuel cladding around the fuel develops holes, fission products can leak into the primary coolant. Depending on the chemistry, they may settle within the reactor core or travel through the coolant system and chemistry control systems are provided to remove them. In a well-designed power reactor running under normal conditions, coolant radioactivity is very low. The isotope responsible for most of the gamma exposure in fuel reprocessing plants (and the Chernobyl site in 2005) is caesium-137.",1
"Iodine-129 is a major radioactive isotope released from reprocessing plants. In nuclear reactors both caesium-137 and strontium-90 are found in locations away from the fuel because they're formed by the beta decay of noble gases (xenon-137, with a 3.8-minute half-life, and krypton-90, with a 32-second half-life) which enable them to be deposited away from the fuel, e.g. on control rods.",1
"Some fission products decay with the release of delayed neutrons, important to nuclear reactor control. Other fission products, such as xenon-135 and samarium-149, have a high neutron absorption cross section. Since a nuclear reactor must balance neutron production and absorption rates, fission products that absorb neutrons tend to ""poison"" or shut the reactor down; this is controlled with burnable poisons and control rods. Build-up of xenon-135 during shutdown or low-power operation may poison the reactor enough to impede restart or interfere with normal control of the reaction during restart or restoration of full power.",1
This played a major role in the Chernobyl disaster.,1
"For example, the 134Cs/137Cs ratio provides an easy method of distinguishing between fallout from a bomb and the fission products from a power reactor. Almost no caesium-134 is formed by nuclear fission (because xenon-134 is stable). The 134Cs is formed by the neutron activation of the stable 133Cs which is formed by the decay of isotopes in the isobar (A = 133). So in a momentary criticality, by the time that the neutron flux becomes zero too little time will have passed for any 133Cs to be present.",1
"While in a power reactor plenty of time exists for the decay of the isotopes in the isobar to form 133Cs, the 133Cs thus formed can then be activated to form 134Cs only if the time between the start and the end of the criticality is long. According to Jiri Hala's textbook, the radioactivity in the fission product mixture in an atom bomb is mostly caused by short-lived isotopes such as iodine-131 and barium-140. After about four months, cerium-141, zirconium-95/niobium-95, and strontium-89 represent the largest share of radioactive material.",1
"After two to three years, cerium-144/praseodymium-144, ruthenium-106/rhodium-106, and promethium-147 are responsible for the bulk of the radioactivity. After a few years, the radiation is dominated by strontium-90 and caesium-137, whereas in the period between 10,000 and a million years it is technetium-99 that dominates.",1
"In a similar way the release of radio-iodine in a serious power reactor accident could be retarded by adsorption on metal surfaces within the nuclear plant. Much of the other work on the iodine chemistry which would occur during a bad accident has been done. For fission of uranium-235, the predominant radioactive fission products include isotopes of iodine, caesium, strontium, xenon and barium. The threat becomes smaller with the passage of time.",1
"Locations where radiation fields once posed immediate mortal threats, such as much of the Chernobyl Nuclear Power Plant on day one of the accident and the ground zero sites of U.S. atomic bombings in Japan (6 hours after detonation) are now relatively safe because the radioactivity has decreased to a low level. Many of the fission products decay through very short-lived isotopes to form stable isotopes, but a considerable number of the radioisotopes have half-lives longer than a day.",1
"The radioactivity in the fission product mixture is initially mostly caused by short lived isotopes such as 131I and 140Ba; after about four months 141Ce, 95Zr/95Nb and 89Sr take the largest share, while after about two or three years the largest share is taken by 144Ce/144Pr, 106Ru/106Rh and 147Pm. Later 90Sr and 137Cs are the main radioisotopes, being succeeded by 99Tc.",1
"It has been shown that the active iodine released from Chernobyl and Mayak has resulted in an increase in the incidence of thyroid cancer in the former Soviet Union. One measure which protects against the risk from radio-iodine is taking a dose of potassium iodide (KI) before exposure to radioiodine. The non-radioactive iodide ""saturates"" the thyroid, causing less of the radioiodine to be stored in the body. Administering potassium iodide reduces the effects of radio-iodine by 99% and is a prudent, inexpensive supplement to fallout shelters. A low-cost alternative to commercially available iodine pills is a saturated solution of potassium iodide.",1
"Studies involving healthy adult volunteers determined that at levels above 0.007 milligrams per kilogram per day (mg/(kg·d)), perchlorate begins to temporarily inhibit the thyroid gland's ability to absorb iodine from the bloodstream (""iodide uptake inhibition"", thus perchlorate is a known goitrogen). The reduction of the iodide pool by perchlorate has dual effects – reduction of excess hormone synthesis and hyperthyroidism, on the one hand, and reduction of thyroid inhibitor synthesis and hypothyroidism on the other.",1
"when the average perchlorate absorption in perchlorate plant workers subjected to the highest exposure has been estimated as approximately 0.5 mg/kg-day, as in the above paragraph, a 67% reduction of iodine uptake would be expected. Studies of chronically exposed workers though have thus far failed to detect any abnormalities of thyroid function, including the uptake of iodine. this may well be attributable to sufficient daily exposure or intake of healthy iodine-127 among the workers and the short 8 hr biological half life of perchlorate in the body.To",1
"of its initial quantity, at which time the danger from biouptake of iodine-131 is essentially over.In the event of a radioiodine release, the ingestion of prophylaxis potassium iodide, if available, or even iodate, would rightly take precedence over perchlorate administration, and would be the first line of defense in protecting the population from a radioiodine release.",1
"In all these cases however, despite the risks, the prophylaxis benefits of intervention with iodide, iodate, or perchlorate outweigh the serious cancer risk from radioiodine bioaccumulation in regions where radioiodine has sufficiently contaminated the environment.",1
"The Chernobyl accident released a large amount of caesium isotopes which were dispersed over a wide area. 137Cs is an isotope which is of long-term concern as it remains in the top layers of soil. Plants with shallow root systems tend to absorb it for many years. Hence grass and mushrooms can carry a considerable amount of 137Cs, which can be transferred to humans through the food chain. One of the best countermeasures in dairy farming against 137Cs is to mix up the soil by deeply ploughing the soil.",1
"In livestock farming, another countermeasure against 137Cs is to feed to animals prussian blue. This compound acts as an ion-exchanger. The cyanide is so tightly bonded to the iron that it is safe for a human to consume several grams of prussian blue per day. The prussian blue reduces the biological half-life (different from the nuclear half-life) of the caesium. The physical or nuclear half-life of 137Cs is about 30 years. Caesium in humans normally has a biological half-life of between one and four months.",1
"The addition of lime to soils which are poor in calcium can reduce the uptake of strontium by plants. Likewise in areas where the soil is low in potassium, the addition of a potassium fertilizer can discourage the uptake of cesium into plants. However such treatments with either lime or potash should not be undertaken lightly as they can alter the soil chemistry greatly, so resulting in a change in the plant ecology of the land. For introduction of radionuclides into organism, ingestion is the most important route.",1
"Insoluble compounds are not absorbed from the gut and cause only local irradiation before they are excreted. Soluble forms however show wide range of absorption percentages. Fission product yield Fission products (by element) Long-lived fission products Paul Reuss, Neutron Physics, chp 2.10.2, p 75 Iodine fallout studies in the United States The Live Chart of Nuclides - IAEA Color-map of product yields, and detailed data by click on a nuclide.",1
"On the other hand, the standard model for most erosion assessment and conservation planning is the empirically based USLE, and there continues to be active research and development of USLE-based erosion prediction technology. The USLE was developed from erosion plot and rainfall simulator experiments. The USLE is composed of six factors to predict the long-term average annual soil loss (A). The equation includes the rainfall erosivity factor (R), the soil erodibility factor (K), the topographic factors (L and S) and the cropping management factors (C and P).",1
"The equation takes the simple product form: A = R K L S C P {\displaystyle A=RKLSCP} The USLE has another concept of experimental importance, the unit plot concept. The unit plot is defined as the standard plot condition to determine the soil's erodibility. These conditions are when the LS factor = 1 (slope = 9% and length = 22.1 m (72.6 ft) where the plot is fallow and tillage is up and down slope and no conservation practices are applied (CP=1).",1
"In this state: K = A / R {\displaystyle K=A/R} A simpler method to predict K was presented by Wischmeier et al. which includes the particle size of the soil, organic matter content, soil structure and profile permeability. The soil erodibility factor K can be approximated from a nomograph if this information is known. The LS factors can easily be determined from a slope effect chart by knowing the length and gradient of the slope. The cropping management factor (C) and conservation practices factor (P) are more difficult to obtain and must be determined empirically from plot data.",1
"practice of creating field boundaries, such as stone walls, hedgerows, earth banks, and lynchets, was effective in preventing or reducing soil erosion in pre-industrial agriculture. Recently a novel P-factor model for Europe has been developed from the data retrieved during a statistical survey that recorded the occurrence of stone walls and grass margins in EU countries. While this is one of the first efforts to incorporate cultural landscape features into a soil erosion model on a continental scale, the authors of the study pointed out several limitations, such as the small number of surveyed points and the chosen interpolation technique.",1
"It has been demonstrated that landscape archaeology has the potential to fill this gap in the data about soil conservation practices using a GIS-based tool called Historic Landscape Characterisation (HLC). Starting from the assumptions that the construction of field boundaries has always represented an effective method to limit soil erosion and that the efficiency of any conservation measures to mitigate soil erosion increases with the increasing of the slope, a new P factor equation has been developed integrating the HLC within the RUSLE model.",1
"Census, of Richmond's 103,701 person populations, “one in six residents lives below the federal poverty level, and more than eight in 10 are people of color. In North Richmond, next to one of the nation’s largest refineries, 97 percent of residents are non-white and nearly one in four live in poverty”. Low-income communities have differential access to political power, and their collective political voice is often less able to contest decisions impacting industrial operations.",1
"On July 23, 1947, the United States Atomic Energy Commission announced the establishment of the Pacific Proving Grounds.105 atmospheric (i.e., not underground) nuclear tests were conducted there, many of which were of extremely high yield. While the Marshall Islands testing composed 14% of all U.S. tests, it composed nearly 80% of the total yields of those detonated by the U.S.,",1
"with an estimated total yield of around 210 megatons, with the largest being the 15 Mt Castle Bravo shot of 1954 which spread considerable nuclear fallout on many of the islands, including several which were inhabited, and some that had not been evacuated.Many of the islands which were part of the Pacific Proving Grounds continue to be contaminated by nuclear fallout, and many of those who were living on the islands at the time of testing has suffered from an increased incidence of various health problems.",1
"Through the Radiation Exposure Compensation Act of 1990, at least $759 million has been paid to Marshall Islanders as compensation for their exposure to U.S. nuclear testing. Following the Castle Bravo accident, $15.3 million was paid to Japan.",1
"The Nevada Test Site (NTS), is a United States Department of Energy reservation located in southeastern Nye County, Nevada, about 65 miles (105 km) northwest of the city of Las Vegas. Formerly known as the Nevada Proving Grounds, the site was established on 11 January 1951 for the testing of nuclear devices, covering approximately 1,360 square miles (3,500 km2) of desert and mountainous terrain. Nuclear testing at the Nevada Test Site began with a 1-kiloton-of-TNT (4.2 TJ) bomb dropped on Frenchman Flat on 27 January 1951. Many of the iconic images of the nuclear era come from the NTS.",1
"During the 1950s, the mushroom clouds from atmospheric tests could be seen for almost 100 mi (160 km). The city of Las Vegas experienced noticeable seismic effects, and the distant mushroom clouds, which could be seen from the downtown hotels, became tourist attractions. St. George, Utah, received the brunt of the fallout of above-ground nuclear testing in the Yucca Flats/Nevada Test Site. Winds routinely carried the fallout of these tests directly through St. George and southern Utah.",1
"Marked increases in cancers, such as leukemia, lymphoma, thyroid cancer, breast cancer, melanoma, bone cancer, brain tumors, and gastrointestinal tract cancers, were reported from the mid-1950s through 1980.From 1986 through 1994, two years after the United States put a hold on full-scale nuclear weapons testing, 536 anti-nuclear protests were held at the Nevada Test Site involving 37,488 participants and 15,740 arrests, according to government records. Those arrested included the astronomer Carl Sagan and the actors Kris Kristofferson, Martin Sheen, and Robert Blake.",1
"The Nevada Test Site contains 28 areas, 1,100 buildings, 400 miles (640 km) of paved roads, 300 miles of unpaved roads, ten heliports, and two airstrips. The most recent test was a sub-critical test of the properties of plutonium, conducted underground on December 7, 2012.",1
"The Semipalatinsk Test Site, also known as ""The Polygon"", was the primary testing venue for the Soviet Union's nuclear weapons. It is located on the steppe in northeast Kazakhstan (then the Kazakh SSR), south of the valley of the Irtysh River. The scientific buildings for the test site were located around 150 km west of the town of Semipalatinsk (later renamed Semey), near the border of East Kazakhstan Province and Pavlodar Province with most of the nuclear tests taking place at various sites further to the west and south, some as far as into Karagandy Province.",1
"The Soviet Union conducted 456 nuclear tests at Semipalatinsk from 1949 until 1989 with little regard for their effect on the local people or environment. The full impact of radiation exposure was hidden for many years by Soviet authorities and has only come to light since the test site closed in 1991. From 1996 to 2012, a secret joint operation of Kazakh, Russian, and American nuclear scientists and engineers secured the waste plutonium in the tunnels of the mountains.",1
"One of the oldest known zombie satellites is Transit 5B-5. It was launched in 1965 as part of the Transit system, one of the first satellite navigation systems. Transit 5B-5 is nuclear powered and still in a stable polar orbit, though operators are unable to control it.",1
"AMSAT-OSCAR 7 is an amateur-radio communications satellite which was launched into Low Earth Orbit on November 15, 1974 and remained operational until a battery failure in 1981. Then after 21 years of apparent silence, the satellite was heard again on June 21, 2002 – 27 years after launch.",1
"Galaxy 15 is a U.S. telecommunications satellite launched in 2005. In April 2010, only five years into a planned 15 year mission, its operator, Intelsat, lost control of the satellite and it drifted out of its orbital slot. Several months later, on December 27, 2010, the satellite rebooted itself and began responding to commands again. Intelsat re-positioned it back to its original orbital slot in April 2011.",1
"Launched in 2000, IMAGE (Imager for Magnetopause-to-Aurora Global Exploration), a NASA spacecraft studying the Earth's magnetosphere, unexpectedly ceased operations in December 2005. It was a zombie satellite until Scott Tilley, an amateur radio operator living in Canada tracked it down in January 2018. On February 25, contact with IMAGE was again lost. It was reestablished in March but lost again in August. NASA is currently evaluating a recovery mission.",1
"On March 24, 2020, contact with another lost Lincoln Experimental Satellite, LES-5, was made by Scott Tilley. The satellite is only in operation when its solar panels are receiving sunlight. Space debris Skylab 4 Space Liability Convention List of spaceflight-related accidents and incidents Laser broom Kessler syndrome",1
"Experiments in pig show that urinary 1-hydroxypyrene is a metabolite of pyrene, when given orally.A Mycobacterium sp. strain isolated from mangrove sediments produced 1-hydroxypyrene during the degradation of pyrene. Highly significant differences and dose-response relationships with regard to cigarettes smoked per day were found for 2-, 3- and 4-hydroxyphenanthrene and 1-hydroxypyrene, but not for 1-hydroxyphenanthrene.",1
"Declan Desmond, an opinionated British documentary film producer, films a documentary at Springfield Elementary School on the students' lives. He interviews Bart as he gets hit by a ball of dirt thrown by Nelson and breaks down in tears. Later, Declan belittles Lisa as she talks about the multiplicity of her interests, insinuating that she could neither be happy nor successful juggling too many hobbies or passions. Hurt by his criticism, Lisa resolves to find a single passion to which she can devote herself; astronomy.",1
Milhouse and Bart are foiled on their first attempt because Quimby is pressured to switch the lights back on due to rising crime.,1
"Executive producer Al Jean said, ""We figured that if we said it first, then they couldn't say it"". The writers included a line where Carl Carlson mentions his Icelandic heritage, as well as the fact that Homer, Moe and Lenny show absolutely no interest in what he's saying.",1
"This would later become both the basis and an explicit reference point in the episode The Saga of Carl, where Carl rips off the winnings from a lottery ticket he jointly purchased with the gang before returning to Iceland, and telling them when they track him down that he did steal the money and isn't sorry because they're not friends, as ""friends care that their friends are from Iceland!"" The episode's title alludes to a line from the song Purple Haze by Jimi Hendrix, i.e. ""'scuse me while I kiss the sky"".",1
2020 Beirut explosion was one of the biggest non-nuclear explosions in history. It happened when approximately 2750 tons of ammonium nitrate inside a warehouse at the port exploded.,1
"In the European Union, incidents such as the Flixborough disaster and the Seveso disaster led to legislation such as the Seveso Directive, which mandates safety reports to be prepared by process and storage plants and issued to local and regional authorities.",1
"In the United States, concern about chemical accidents after the Bhopal disaster led to the passage of the 1986 Emergency Planning and Community Right-to-Know Act. The EPCRA requires local emergency planning efforts throughout the country, including emergency notifications. The law also requires companies to make publicly available information about their storage of toxic chemicals. Based on such information, citizens can identify the vulnerable zones in which severe toxic releases could cause harm or even in some cases death. In 1990 the Chemical Safety and Hazard Investigation Board (CSB) was established by the Congress, though it did not become operational until 1998.",1
"The Board's mission is to determine the root causes of chemical accidents and issue safety recommendations to prevent future chemical accidents. Note that the CSB does not issue fines or citations since the Congress designed the agency to be non-regulatory. It also organizes workshops on a number of issues related to preparing for, preventing, and responding to chemical accidents.",1
"Chemical safety Process safety Process safety management 24-7 Response Brandweerinformatiecentrum voor gevaarlijke stoffen/Fire services information centre for dangerous goods OECD Programme on Chemical Accidents: Environment Directorate Guiding Principles for Chemical Accident Prevention, Preparedness and Response Preventing Chemical Accidents – How to Prevent Chemicals From Contaminating Your Workplace – Safety Storage Systems U.S. Chemical Safety Board",1
"During packaging, chemical liquid waste containers are filled to no further than 75% capacity to allow for vapor expansion and to reduce potential spills which can occur from transporting or moving overfilled containers. Containers for chemical liquid waste are typically constructed from materials compatible with the hazardous waste being stored, such as inert materials like polypropylene (PP) or polytetrafluoroethylene (PTFE). These containers are also constructed of mechanically robust materials in order to minimize leakage during storage or transit. In addition to the general packaging requirements mentioned above, precipitates, solids, and other non-fluid wastes are typically stored separately from liquid waste.",1
Chemically contaminated glassware is disposed of separately from other chemical waste in containers that cannot be punctured by broken glass.,1
Containers are labelled with the group name from the chemical waste category and an itemized list of the contents. All chemicals or materials contaminated by chemicals pose a significant hazard. All waste must be appropriately packaged.,1
"Chemical waste containers are kept closed to prevent spillage, except for when waste is being added. Suitable containers are labeled in order to inform disposal specialists of the contents, as well as to prevent addition of incompatible chemicals. Liquid waste is stored in containers with secure screw-top or similar lids that cannot be easily dislodged in transit. Solid waste is stored in various sturdy, chemically inert containers, such as large sealed buckets or thick plastic bags. A secondary containment (e.g., flammable cabinet or large plastic bin, etc.)",1
"Many chemicals react adversely when combined. Incompatible chemicals are therefore stored in separate areas of laboratories.Acids are separated from alkalis, metals, cyanides, sulfides, azides, phosphides, and oxidizers, as when acids combine with these types of compounds, violent exothermic reactions can occur. In addition, some of these reactions produce flammable gases, which, combined with the heat produced, may cause explosions. In the case of cyanides, sulfides, azides, phosphides, etc. Toxic gases are also produced.",1
"Oxidizers are separated from acids, organic materials, metals, reducing agents, and ammonia, as when oxidizers combine with these types of compounds, flammable and sometimes toxic compounds can be created. Oxidizers also increase the likelihood that any flammable material present will ignite, seen most readily in research laboratories with improper storage of organic solvents.",1
"These factors include flat terrain, abundant precipitation and highly permeable sandy sediments Main natural factors of nuclides migration in the region can be divided into four groups, including: weather and climate-related (evaporation and precipitation frequency, intensity and distribution); geological (sediment permeability, drainage regimes, forms of vegetation); soil-borne (physical, hydrological and mechanical properties of lands); and lithological (terrain structures and types of rock). In meliorated areas migration processes are additionally influenced by anthropogenic drivers related to human agricultural activities.",1
"This leads to internal irradiation of animals and people during consumption of contaminated vegetables This situation is aggravated by a predominantly rural type of settlement in the Chernobyl area, with most of population engaged in active agricultural production. It makes the authorities either remove the contaminated areas near Chernobyl from agricultural activities or spend funds for excavation and treatment of surface layers. These problems of damage to initially intact soils puts a heavy burden primarily on the Ukrainian and especially the Belarusian economy. Nearly one-quarter of the entire territory of Belarus was seriously contaminated with isotopes of Cesium.",1
"The health impacts of groundwater contamination for population of Ukraine, Belarus and bordering states are usually perceived as extremely negative. The Ukrainian government initially implemented a costly and sophisticated remediation program.",1
"When the updated survey information showed negligible risks of excessive nuclides migration, remediation program was stopped. However, to this moment Ukraine already spent giant monetary funds equal to nearly 20 million dollars for this project, as well as exposed relief workers to needless danger of irradiation.In 1990-2000s, the focus of protective measures shifted from remediation to construction of protective systems for the complete isolation of contaminated areas along Pripyat River and Chernobyl Nuclear Power Plant from the rest of the region. Since it was done, local authorities were advised to concentrate efforts on the permanent monitoring of the situation.",1
"New monitoring wells are constructed with poli-vinylcloride materials instead of steel, with shortened screening sections, 1–2 m Additionally, in 1999-2012 there was created an experimental monitoring site in proximity to radioactive waste dumps area westward Chernobyl Nuclear Power Plant, called “Chernobyl Red Forest”. The elements of the new monitoring system include laboratory module, station for unsaturated zone monitoring, network of monitoring boreholes and meteorological station Its primary objectives include monitoring of such processes as: radionuclides extraction from “hot fuel particles” (HFP) dispersed in surface layer; their subsequent transition through the unsaturated aquifer, and condition of phreatic (saturation) zone.",1
"Without accurate real-time data and adjusted emergency management plans, the government spent enormous funds for groundwater remediation, which later proved to be needless. At the same time, really crucial top-priority measures, such as reliable isolation of the damaged 4th reactor, were performed on a poor-quality level.",1
"If the “Shelter” had been constructed without deficiencies as completely hermetic and isolating the 4th reactor from contact with external aerial, soil and groundwater mediums, it would make much greater contribution to prevent entering nuclides in and their migration throughout groundwater network Taking these failures into account, the following are lessons learned from Chernobyl tragedy for groundwater management: The necessity of consistent and technologically reliable monitoring system capable to produce high-quality real-time data; Exact monitoring data as a primary basis for any remedial practices and melioration policies; Criteria and purposes of groundwater management activities, be it remediation, construction works or agricultural",1
"The more complex models were able to address nuances in micrometeorology, soil particle size distributions and micro-terrain variation. Bridge scour Burned area emergency response Certified Professional in Erosion and Sediment Control Coastal management Dust Bowl Natural Resources Conservation Service (United States) Tillage erosion Universal Soil Loss Equation Vetiver System ""Saving Runaway Farm Land"", November 1930, Popular Mechanics One of the first articles on the problem of soil erosion control Erosion Control Technology Council - a trade organization that mission is to educate and standardize the erosion control industry International Erosion Control Association - Professional Association, Publications, Training WatchYourDirt.com",1
- Erosion Control Educational Video Resource Soil Bioengineering and Biotechnical Slope Stabilization - Erosion Control subsection of a website on Riparian Habitat Restoration,1
"Active systems are mostly employed on commercial properties because of the associated costs. There are two main practical types of active systems to prevent the ingress of gases into buildings: positive pressurization, and forced ventilation. Both passive and active systems require ""gas integrity testing"", most often using the NHBC traffic light system. This is because the conditions under which gas membranes are installed are often difficult and can adversely compromise the integrity required by the manufacturer or client. The purpose of the test is to ensure integrity and allow the installation to be certified if the method of protection performs correctly.",1
"Any leaks are identified and sealed, and the membrane is re-tested before it passes and the certificate is issued.",1
"Active systems require a test of the alarm in case of failure of the system or power supply and possible buildup of gas. BS8485. Department of the Environment, The control of landfill gas, Waste management paper No 27. Department of Environment, Landfill sites development control. Guidance on evaluation of development proposals on sites where Methane and Carbon dioxide are present, incorporating Traffic Lights. Rep Ref.10627-R01-(02) Milton Keynes; National House Building Council.",1
"When industrial plant equipment items are over-pressured, the pressure relief valve is an essential safety device that automatically release gases and sometimes liquids. Those pressure relief valves are required by industrial design codes and standards as well as by law. The released gases and liquids are routed through large piping systems called flare headers to a vertical elevated flare. The released gases are burned as they exit the flare stacks. The size and brightness of the resulting flame depends upon the flammable material's flow rate in joules per hour (or btu per hour).Most",1
"industrial plant flares have a vapor-liquid separator (also known as a knockout drum) upstream of the flare to remove any large amounts of liquid that may accompany the relieved gases. Steam is very often injected into the flame to reduce the formation of black smoke. When too much steam is added, a condition known as ""over steaming"" can occur resulting in reduced combustion efficiency and higher emissions. To keep the flare system functional, a small amount of gas is continuously burned, like a pilot light, so that the system is always ready for its primary purpose as an over-pressure safety system.",1
"The height of a flare stack, or the reach of a flare boom, is determined by the thermal radiation that is permissible or tolerable for equipment or personnel to be exposed to. For continuous exposure of personnel wearing appropriate industrial clothing a maximum radiation level of 1.58 kW/m2 (500 Btu/hr.ft²) is recommended. Higher radiation levels are permissible but for reduced exposure times: 4.73 kW/m2 (1500 Btu/hr.ft²) would limit exposure to 3 to 4 minutes 6.31 kW/m2 (2000 Btu/hr.ft²) would limit exposure to 30 seconds. Ground flares are designed to hide the flame from sight and to reduce thermal radiation and noise.",1
"× 1012 cubic feet) of associated gas have been flared globally each year since at least the mid 1990s until 2020. In 2011, that was equivalent to about 25 percent of the annual natural gas consumption in the United States or about 30 per cent of the annual gas consumption in the European Union. At market, this quantity of gas—at a nominal value of $5.62 per 1000 cubic feet—would be worth US$29.8 billion. Additionally, the waste is a significant source of carbon dioxide (CO2) and other greenhouse gas emissions.",1
"Flare specification usually demands that enclosed flares must operate at >1000 °C and <1200 °C; this in order to ensure a 98% destruction efficient and avoid the formation of NOx. The natural gas that is not combusted by a flare is vented into the atmosphere as methane. Methane's estimated global warming potential is 28-36 times greater than that of CO2 over the course of a century, and 84-87 times greater over two decades.",1
"Therefore, to the extent that gas flares convert methane to CO2 before it is released into the atmosphere, they reduce the amount of global warming that would otherwise occur.Flaring emissions contributed to 270 Mt (megatonnes) of CO2 in 2017 and reducing flaring emissions is thought to be an important component in curbing global warming. An increasing number of governments and industries have pledged to eliminate or reduce flaring.",1
"The Global Methane Pledge signed at COP26, in which 111 nations committed to reducing methane emissions by at least 30 percent from 2020 levels by 2030, is also playing a role in raising the global focus on methane. Additional noxious fumes emitted by flaring may include, aromatic hydrocarbons (benzene, toluene, xylenes) and benzo(a)pyrene, which are known to be carcinogenic. A 2013 study found that gas flares contributed over 40% of the black carbon deposited in the Arctic.Flaring can affect wildlife by attracting birds and insects to the flame.",1
"Approximately 7,500 migrating songbirds were attracted to and killed by the flare at the liquefied natural gas terminal in Saint John, New Brunswick, Canada on September 13, 2013. Similar incidents have occurred at flares on offshore oil and gas installations. Moths are known to be attracted to lights. A brochure published by the Secretariat of the Convention on Biological Diversity describing the Global Taxonomy Initiative describes a situation where ""a taxonomist working in a tropical forest noticed that a gas flare at an oil refinery was attracting and killing hundreds of these [hawk or sphinx] moths.",1
"Over the course of the months and years that the refinery was running a vast number of moths must have been killed, suggesting that plants could not be pollinated over a large area of forest"".",1
"Flares release several different chemicals including: benzene, particulates, nitrogen oxides, heavy metals, black carbon, and carbon monoxide. Several of these pollutants correlate with preterm birth and reduced newborn birth weight. According to one study from 2020, pregnant women living near flaring natural gas and oil wells have reportedly experienced a 50% greater premature birth rate. Flares may emit methane and other volatile organic compounds as well as sulfur dioxide and other sulfur compounds, which are known to exacerbate asthma and other respiratory disease.A 2021 study found that a 1% increase in flared natural gas increases the respiratory-related hospitalization rate by 0.73%.",1
Blowdown stack Flue-gas stack Gas venting Flare and Vent Disposal Systems on PetroWiki,1
EPA has listed recommended steps that consumers may take to reduce possible exposure to GenX and other PFAS chemicals. Perfluorinated alkylated substances (PFAS) Timeline of events related to per- and polyfluoroalkyl substances (PFAS),1
"In many LEZs, vehicles that do not meet the emission standards set by the LEZ are not barred from entry into the LEZ (i.e. using automated boom barriers), but rather simply fined if they enter the zone. A fine is not issued if entering the LEZ with a vehicle that does not meet the emission standards, when a fee (LEZ daily charge, ...) has been paid.",1
"In some LEZs, such as the one in London, this is done by automatic number-plate recognition (ANPR) cameras which read the vehicle registration number plate as they enter the LEZ and then compare it against a database of vehicles which: either meet the LEZ emissions standards, or are either exempt or registered for a 100 percent discount, or if the LEZ daily charge has been paidThis fee/fine works as a deterrent for those having a vehicle that does not meet the LEZ emission standard for entering the city, and those having such vehicles will hence try to avoid paying this fee/fine",1
"Some people (such as workers on night shift or carrying heavy tools or cargo) however can't do without a car, but might not be able to afford to purchase unsubsidized cleaner vehicles. Therefore in some places the LEZ is only enforced when public transport is available, or electric taxis or cargobikes are subsidized.The European Federation for Transport and Environment is of the opinion that LEZs should be gradually turned into zero-emission mobility zones and complement policies promoting a switch to clean alternatives, including walking and cycling, among others.Most",1
"Although common in Europe the continent's largest cities are lacking: Istanbul has no LEZ and Moscow's is not enforced.Different vehicles may be regulated, depending on local conditions. All LEZs apply to heavy vehicles, some to diesel vans, others also to diesel and petrol cars; in Italy, motor cycles and three-wheelers are also liable to control. A publicly funded website run by a network of cities and ministries operating or preparing LEZs gives up-to-date information on LEZs, such as which cities have LEZs, the vehicle types affected, the required emissions standards and their application dates.",1
"Antwerp: Since 2017, there has been a LEZ in Antwerp, 24/7. Only diesel vehicles above Euro 3/III norm and petrol vehicles above Euro 1/I norm are allowed to enter the LEZ. Brussels: Since 2018, the entire Brussels Capital Region has been a LEZ. Only diesel vehicles above Euro 4/IV norm are allowed to enter Brussels. Since 2019 petrol or gas-powered vehicles need to be Euro 2/II or more. Ghent introduced a LEZ on 1 January 2020.",1
An LEZ is present in Beijing.,1
"Denmark has LEZs that are applicable to vehicles over 3.5 t. In Denmark, LEZs exist in Aalborg, Aarhus, Copenhagen, Frederiksberg and Odense.",1
A LEZ is present in Helsinki.,1
"France has LEZs in Greater Paris, Grenoble, Lyon, Paris and Strasbourg",1
"that, LEZ is also implemented at the surrounding area of Tebet Eco Park in South Jakarta. Unlike the previous one in Kota Tua, LEZ in Tebet Eco Park is only implemented on weekends and public holidays. Residence or workers in the surrounding area of the park have to place a sticker with QR code on their vehicle.",1
"In Tokyo, the municipal government decided to tackle controlling diesel vehicle emissions (particulate matter emissions, ...) far ahead of the national government.",1
"Amsterdam, The Hague, Utrecht and Arnhem have LEZs (milieuzone) applying to passenger cars and delivery vans. Only diesel passenger cars and diesel delivery vans meeting the emission standards of Euro 4 and above are allowed to enter the LEZs. Diesel trucks and diesel Buses/coaches have to meet Euro VI (6) or above to enter the LEZs. The LEZ of Arnhem does not apply to buses/coaches.The LEZ of Amsterdam covers practically the entire area within the A10 highway. The highway itself is not part of the LEZ.The LEZ of The Hague covers the area enclosed by the Centrumring (S100) and Professor B.M.",1
"Teldersweg (S200). These roads themselves, as well as the road from Lijnbaan to the visitors’ car park and the parking garage of the HMC Westeinde hospital, are not part of the LEZ.Rotterdam has an LEZ applying to trucks only. Diesel trucks have to meet the Euro VI (6) emission standard or above.",1
Norway has LEZs in Bergen and Oslo.,1
Portugal has an LEZ in Lisbon.,1
"Pontevedra was the first Spanish city to ban traffic in its core, in 1999. Málaga and Seville were the next cities to establish low emission zones, with traffic only allowed for residents, in 2009. Seville rolled back its low-emission zone under the mayorship of Juan Ignacio Zoido in 2011, but at date of August 2021 a new system was in the process of implementation.Madrid established its LEZ in 2018 in its city center, and Barcelona approved it in 2020.",1
"The London low emission zone came into effect in 2008 covering almost all of Greater London – the largest such zone in the world. The Low Emission Zone targets emissions of these pollutants from older diesel-engined lorries, buses, coaches, vans, minibuses and other heavy vehicles that are derived from lorries and vans such as motor caravans and motorised horse boxes. There was a phased introduction of the scheme from 2008 through to 2012. Different vehicles were affected over time and increasingly tougher emissions standards applied.The",1
"London Ultra Low Emission Zone started on 8 April 2019 and initially covered Central London, the same area as the existing congestion charge. On 25 October 2021, the zone was extended to cover the Inner London area within the North Circular and South Circular roads. It was expanded again on 29 August 2023 to coincide with the London low emission zone, covering almost all of Greater London. Glasgow introduced a Low Emission Zone (LEZ) at the end of 2018. Initially, only local buses in the centre of the city are affected.",1
"of June 2020, Oxford is claiming to become the first city to implement a Zero Emission Zone (ZEZ) scheme, beginning with a small area to go into effect by mid 2021. It was postponed from a 2020 start due to the economic impacts of the COVID-19 pandemic. However, the proposals can more accurately be described as a Low Emission Zone or Ultra Low Emission Zone as any vehicle can enter on payment of a charge. The plan is to expand the ZEZ gradually into a much larger zone, until the ZEZ encompasses the majority of the city centre by 2035.",1
Low-emission zones in Europe,1
"An introduced species is one that is not native to a given population that is either intentionally or accidentally brought into a given ecosystem. Effects of introduction are highly variable, but if an introduced species has a major negative impact on its new environment, it can be considered an invasive species. One such example is the introduction of the Asian Longhorned beetle in North America, which was first detected in 1996 in Brooklyn, New York. It is believed that these beetles were introduced through cargo at trade ports.",1
"The beetles are highly damaging to the environment, and are estimated to cause risk to 35% of urban trees, excluding natural forests. These beetles cause severe damage to the wood of trees by larval funneling. Their presence in the ecosystem destabilizes community structure, having a negative influence on many species in the system. Introduced species are not always disruptive to an environment, however.",1
"Tomás Carlo and Jason Gleditch of Penn State University found that the number of ""invasive"" honeysuckle plants in the area correlated with the number and diversity of the birds in the Happy Valley Region of Pennsylvania, suggesting introduced honeysuckle plants and birds formed a mutually beneficial relationship. Presence of introduced honeysuckle was associated with higher diversity of the bird populations in that area, demonstrating that introduced species are not always detrimental to a given environment and it is completely context dependent.",1
"In these populations, local adaptations can be disrupted by the introduction of new genes that may not be as suitable for the small island environments. For example, the Cercocarpus traskiae of the Catalina Island off the coast of California has faced near extinction with only a single population remaining due to the hybridization of its offspring with Cercocarpus betuloides.",1
"Increased contact between wild and domesticated populations of organisms can lead to reproductive interactions that are detrimental to the wild population's ability to survive. A wild population is one that lives in natural areas and is not regularly looked after by humans. This contrasts with domesticated populations that live in human controlled areas and are regularly, and historically, in contact with humans. Genes from domesticated populations are added to wild populations as a result of reproduction. In many crop populations this can be the result of pollen traveling from farmed crops to neighboring wild plants of the same species.",1
"'By hybridization, dogs can easily absorb the wolf genes and destroy the wolf, as it is,' he said. The wolf might survive as a more doglike animal, better adapted to living close to people, he said, but it would not be 'what we today call a wolf.'""",1
"The reason these escapes are considered dangers is the impact they pose for the wild population they reproduce with after escaping. In many instances the wild population experiences a decreased likelihood of survival after reproducing with domesticated populations of salmon.The Washington Department of Fish and Wildlife cites that ""commonly expressed concerns surrounding escaped Atlantic salmon include competition with native salmon, predation, disease transfer, hybridization, and colonization."" A report done by that organization in 1999 did not find that escaped salmon posed a significant risk to wild populations.",1
"Crops refer to groups of plants grown for consumption. Despite domestication over many years, these plants are not so far removed from their wild relatives that they could reproduce if brought together. Many crops are still grown in the areas they originated and gene flow between crops and wild relatives impacts the evolution of wild populations. Farmers can avoid reproduction between the different populations by timing their planting of crops so that crops are not flowering when wild relatives would be. Domesticated crops have been changed through artificial selection and genetic engineering.",1
"The genetic make-ups of many crops is different from those of their wild relatives, but the closer they grow to one another the more likely they are to share genes through pollen. Gene flow persists between crops and wild counterparts.",1
"There are corn and soybean varieties that are resistant to herbicides like glyphosate and corn that produces neonicotinoid pesticide within all of its tissues. These genetic modifications are meant to increase yields of crops but there is little evidence that yields actually increase. While scientists are concerned genetically engineered organisms can have negative effects on surrounding plant and animal communities, the risk of gene flow between genetically engineered organisms and wild populations is yet another concern. Many farmed crops may be weed resistant and reproduce with wild relatives.",1
"More research is necessary to understand how much gene flow between genetically engineered crops and wild populations occurs, and the impacts of genetic mixing.",1
"Mutations within organisms can be executed through the process of exposing the organism to chemicals or radiation in order to generate mutations. This has been done in plants in order to create mutants that have a desired trait. These mutants can then be bred with other mutants or individuals that are not mutated in order to maintain the mutant trait. However, similar to the risks associated with introducing individuals to a certain environment, the variation created by mutated individuals could have a negative impact on native populations as well.",1
"Mitigation involves linking the positive trait (beneficial to fitness) to a trait that is negative (harmful to fitness) to wild but not domesticated individuals. In this case, if the protection trait was introduced to a weed, the negative trait would also be introduced in order to decrease overall fitness of the weed and decrease possibility of the individual’s reproduction and thus propagation of the transgene.",1
"The scientific journal that originally published the study concluded that ""the evidence available is not sufficient to justify the publication of the original paper."" More recent attempts to replicate the original studies have concluded that genetically modified corn is absent from southern Mexico in 2003 and 2004. A 2009 study verified the original findings of the controversial 2001 study, by finding transgenes in about 1% of 2000 samples of wild maize in Oaxaca, Mexico, despite Nature retracting the 2001 study and a second study failing to back up the findings of the initial study.",1
"The study found that the transgenes are common in some fields, but non-existent in others, hence explaining why a previous study failed to find them. Furthermore, not every laboratory method managed to find the transgenes. A 2004 study performed near an Oregon field trial for a genetically modified variety of creeping bentgrass (Agrostis stolonifera) revealed that the transgene and its associate trait (resistance to the glyphosate herbicide) could be transmitted by wind pollination to resident plants of different Agrostis species, up to 14 kilometres (8.7 mi) from the test field.",1
"In 2007, the Scotts Company, producer of the genetically modified bentgrass, agreed to pay a civil penalty of $500,000 to the United States Department of Agriculture (USDA). The USDA alleged that Scotts ""failed to conduct a 2003 Oregon field trial in a manner which ensured that neither glyphosate-tolerant creeping bentgrass nor its offspring would persist in the environment"".Not only are there risks in terms of genetic engineering, but there are risks that emerge from species hybridization.",1
These environmentalist groups stand in complete opposition to the development and production of genetically engineered organisms.,1
"In the best case of project designs, planners are encouraged to work with design engineers to examine trade-offs of roadway design and architectural design. These techniques include design of exterior walls, party walls, and floor and ceiling assemblies; moreover, there are a host of specialized means for damping reverberation from special-purpose rooms such as auditoria, concert halls, entertainment and social venues, dining areas, audio recording rooms, and meeting rooms. Many of these techniques rely upon material science applications of constructing sound baffles or using sound-absorbing liners for interior spaces.",1
"Industrial noise control is a subset of interior architectural control of noise, with emphasis on specific methods of sound isolation from industrial machinery and for protection of workers at their task stations. Sound masking is the active addition of noise to reduce the annoyance of certain sounds, the opposite of soundproofing. Organizations each have their own standards, recommendations/guidelines, and directives for what levels of noise workers are permitted to be around before noise controls must be put into place.",1
"OSHA's requirements state that when workers are exposed to noise levels above 90 A-weighted decibels (dBA) in 8-hour time-weighted averages (TWA), administrative controls and/or new engineering controls must be implemented in the workplace. OSHA also requires that impulse noises and impact noises must be controlled to prevent these noises reaching past 140 dB peak sound pressure levels (SPL).",1
"MSHA requires that administrative and/or engineering controls must be implemented in the workplace when miners are exposed to levels above 90 dBA TWA. If noise levels exceed 115 dBA, miners are required to wear hearing protection. MSHA, therefore, requires that noise levels be reduced below 115 dB TWA. Measuring noise levels for noise control decision making must integrate all noises from 90dBA to 140 dBA.",1
"The FRA recommends that worker exposure to noise should be reduced when their noise exposure exceeds 90 dBA for an 8-hour TWA. Noise measurements must integrate all noises, including intermittent, continuous, impact, and impulse noises of 80 dBA to 140 dBA.",1
The Department of Defense (DoD) suggests that noise levels be controlled primarily through engineering controls. The DoD requires that all steady-state noises be reduced to levels below 85 dBA and that impulse noises be reduced below 140 dB peak SPL. TWA exposures are not considered for the DoD's requirements.,1
"The European Parliament and Council directive require noise levels to be reduced or eliminated using administrative and engineering controls. This directive requires lower exposure action levels of 80 dBA for 8 hours with 135 dB peak SPL, along with upper exposure action levels of 85 dBA for 8 hours with 137 peak dBSPL. Exposure limits are 87 dBA for 8 hours with peak levels of 140 peak dBSPL. An effective model for noise control is the source, path, and receiver model by Bolt and Ingard.",1
"Hazardous noise can be controlled by reducing the noise output at its source, minimizing the noise as it travels along a path to the listener, and providing equipment to the listener or receiver to attenuate the noise.",1
A variety of measures aim to reduce hazardous noise at its source. Programs such as Buy Quiet and the National Institute for Occupational Safety and Health (NIOSH) Prevention through design promote research and design of quiet equipment and renovation and replacement of older hazardous equipment with modern technologies.,1
"The principle of noise reduction through pathway modifications applies to the alteration of direct and indirect pathways for noise. Noise that travels across reflective surfaces, such as smooth floors, can be hazardous. Pathway alterations include physical materials, such as foam, absorb sound and walls to provide a sound barrier that modifies existing systems that decrease hazardous noise. Sound dampening enclosures for loud equipment and isolation chambers from which workers can remotely control equipment can also be designed. These methods prevent sound from traveling along a path to the worker or other listeners.",1
"In the industrial or commercial setting, workers must comply with the appropriate Hearing conservation program. Administrative controls, such as the restriction of personnel in noisy areas, prevents unnecessary noise exposure. Personal protective equipment such as foam ear plugs or ear muffs to attenuate sound provide a last line of defense for the listener. Sound insulation: prevent the transmission of noise by the introduction of a mass barrier. Common materials have high-density properties such as brick, thick glass, concrete, metal etc. Sound absorption: a porous material which acts as a ‘noise sponge’ by converting the sound energy into heat within the material.",1
"Other contributions to the reduction of noise at the source are: improved tire tread designs for trucks in the 1970s, better shielding of diesel stacks in the 1980s, and local vehicle regulation of unmuffled vehicles.The most fertile areas for roadway noise mitigation are in urban planning decisions, roadway design, noise barrier design, speed control, surface pavement selection, and truck restrictions. Speed control is effective since the lowest sound emissions arise from vehicles moving smoothly at 30 to 60 kilometers per hour. Above that range, sound emissions double with every five miles per hour of speed.",1
"They are one of the most effective actions taken in retrofitting existing roadways and commonly can reduce adjacent land-use sound levels by up to ten decibels. A computer model is required to design the barrier since terrain, micrometeorology and other locale-specific factors make the endeavor a very complex undertaking. For example, a roadway in cut or strong prevailing winds can produce a setting where atmospheric sound propagation is unfavorable to any noise barrier.",1
"In 1979, the US Congress authorized the FAA to devise technology and programs to attempt to insulate homes near airports. While this obviously does not aid the exterior environment, the program has been effective for residential and school interiors. Some of the airports at which the technology was applied early on were San Francisco International Airport, Seattle-Tacoma International Airport, John Wayne International Airport and San Jose International Airport in California. The underlying technology is a computer model which simulates the propagation of aircraft noise and its penetration into buildings.",1
"Architectural acoustics noise control practices include interior sound reverberation reduction, inter-room noise transfer mitigation, and exterior building skin augmentation. In the case of construction of new (or remodeled) apartments, condominiums, hospitals, and hotels, many states and cities have stringent building codes with requirements of acoustical analysis, in order to protect building occupants. With regard to exterior noise, the codes usually require measurement of the exterior acoustic environment in order to determine the performance standard required for exterior building skin design.",1
"Since many mechanical sounds are inherently loud, the principal design element is to require the wall or ceiling assembly to meet certain performance standards, (typically Sound transmission class of 50), which allows considerable attenuation of the sound level reaching occupants. The second type of interior sound is called Impact Insulation Class (IIC) transmission. This effect arises not from airborne transmission, but rather from the transmission of sound through the building itself. The most common perception of IIC noise is from the footfall of occupants in living spaces above. Low-frequency noise is transferred easily through the ground and buildings.",1
"The ideal acoustical panels are those without a face or finish material that could interfere with the performance of the acoustical infill, but aesthetic and safety concerns typically lead to fabric coverings or other finishing materials to minimize impedance. Panel finishings are occasionally made of a porous configuration of wood or metal. The effectiveness of post-construction acoustic treatment is limited by the amount of space able to be allocated to acoustic treatment, and so on-site acoustical wall panels are frequently made to conform to the shape of the preexisting space.",1
"This is done by ""framing"" the perimeter track into shape, infilling the acoustical substrate and then stretching and tucking the fabric into the perimeter frame system. On-site wall panels can be constructed to work around door frames, baseboard, or any other intrusion. Large panels (generally greater than 50 feet) can be created on walls and ceilings with this method. Double-glazed and thicker windows can also prevent sound transmission from the outdoors.",1
"Industrial noise is traditionally associated with manufacturing settings where industrial machinery produces intense sound levels, often upwards of 85 decibels. While this circumstance is the most dramatic, there are many other work environments where sound levels may lie in the range of 70 to 75 decibels, entirely composed of office equipment, music, public address systems, and even exterior noise intrusion. Either type of environment may result in noise health effects if the sound intensity and exposure time is too great.",1
"In the case of industrial equipment, the most common techniques for noise protection of workers consist of shock mounting source equipment, creation of acrylic glass or other solid barriers, and provision of ear protection equipment. In certain cases the machinery itself can be re-designed to operate in a manner less prone to produce grating, grinding, frictional, or other motions that induce sound emissions. In recent years, Buy Quiet programs and initiatives have arisen in an effort to combat occupational noise exposures. These programs promote the purchase of quieter tools and equipment and encourage manufacturers to design quieter equipment.In",1
"the case of more conventional office environments, the techniques in architectural acoustics discussed above may apply. Other solutions may involve researching the quietest models of office equipment, particularly printers and photocopy machines. Impact printers and other equipment were often fitted with ""acoustic hoods"", enclosures to reduce emitted noise. One source of annoying, if not loud, sound level emissions are lighting fixtures (notably older fluorescent globes). These fixtures can be retrofitted or analyzed to see whether over-illumination is present, a common office environment issue. If over-illumination is occurring, de-lamping or reduced light bank usage may apply.",1
Photographers can quieten noisy still cameras on a film set using sound blimps.,1
"and worldwide.It is less clear how humans adapt to noise subjectively. Tolerance for noise is frequently independent of decibel levels. Murray Schafer's soundscape research was groundbreaking in this regard. In his work, he makes compelling arguments about how humans relate to noise on a subjective level, and how such subjectivity is conditioned by culture. Schafer notes that sound is an expression of power, and as such, material culture (e.g., fast cars or Harley Davidson motorcycles with aftermarket pipes) tend to have louder engines not only for safety reasons, but for expressions of power by dominating the soundscape with a particular sound.Other",1
"Anthropogenic noise reduced the species richness of birds found in Neotropical urban parks.Zebra finches become less faithful to their partners when exposed to traffic noise. This could alter a population's evolutionary trajectory by selecting traits, sapping resources normally devoted to other activities and thus leading to profound genetic and evolutionary consequences.",1
"Therefore, it is suggested that marine invertebrates are likely perceiving the effects of noise differently than marine mammals. It is reported that invertebrates can detect a large range of sounds, but noise sensitivity varies substantially between each species. Generally, however, invertebrates depend on frequencies under 10 kHz. This is the frequency at which a great deal of ocean noise occurs.Therefore, not only does anthropogenic noise often mask invertebrate communication, but it also negatively impacts other biological system functions through noise-induced stress.",1
"Many of the studies that were conducted on invertebrate exposure to noise found that a physiological or behavioral response was triggered. Most of the time, this related to stress, and provided concrete evidence that marine invertebrates detect and respond to noise. Some of the most informative studies in this category focus on hermit crabs. In one study, it was found that the behavior of the hermit crab Pagurus bernhardus, when attempting to choose a shell, was modified when subjected to noise.Proper selection of hermit crab shells strongly contributes to their ability to survive.",1
"Shells offer protection against predators, high salinity and desiccation. However, researchers determined that approach to shell, investigation of shell, and habitation of shell, occurred over a shorter time duration with anthropogenic noise as a factor. This indicated that assessment and decision-making processes of the hermit crab were both altered, even though hermit crabs are not known to evaluate shells using any auditory or mechanoreception mechanisms.In another study that focused on Pagurus bernhardus and the blue mussel, (Mytilus edulis) physical behaviors exhibited a stress response to noise.",1
"When the hermit crab and mussel were exposed to different types of noise, significant variation in the valve gape occurred in the blue mussel. The hermit crab responded to the noise by lifting the shell off of the ground multiple times, then vacating the shell to examine it before returning inside. The results from the hermit crab trials were ambiguous with respect to causation; more studies must be conducted in order to determine whether the behavior of the hermit crab can be attributed to the noise produced.",1
"Another study that demonstrates a stress response in invertebrates was conducted on the squid species Doryteuthis pealeii. The squid was exposed to sounds of construction known as pile driving, which impacts the sea bed directly and produces intense substrate-borne and water-borne vibrations. The squid reacted by jetting, inking, pattern change and other startle responses. Since the responses recorded are similar to those identified when faced with a predator, it is implied that the squid initially viewed the sounds as a threat.",1
"However, it was also noted that the alarm responses decreased over a period of time, signifying that the squid had likely acclimated to the noise. Regardless, it is apparent that stress occurred in the squid, and although further investigation has not been pursued, researchers suspect that other implications exist that may alter the squid's survival habits.An additional study examined the impact noise exposure had on the Indo-Pacific humpbacked dolphin (Sousa chinensis). The dolphins were exposed to elevated noise levels due to construction in the Pearl River Estuary in China, specifically caused by the world's largest vibration hammer—the OCTA-KONG.",1
"The study suggested that while the dolphin's clicks were not affected, their whistles were because of susceptibility to auditory masking. The noise from the OCTA-KONG was found to have been detectable by the dolphins up to 3.5 km away from the original source, and while the noise was not found to be life-threatening it was indicated that prolonged exposure to this noise could be responsible for auditory damage.",1
"Terrestrial anthropogenic noise affects the acoustic communications in grasshoppers while producing sound to attract a mate. The fitness and reproductive success of a grasshopper is dependent on its ability to attract a mating partner. Male Corthippus biguttulus grasshoppers attract females by using stridulation to produce courtship songs. The females produce acoustic signals that are shorter and primarily low frequency and amplitude, in response to the male's song. Research has found that this species of grasshopper changes its mating call in response to loud traffic noise.",1
"Lampe and Schmoll (2012) found that male grasshoppers from quiet habitats have a local frequency maximum of about 7319 Hz.In contrast, male grasshoppers exposed to loud traffic noise can create signals with a higher local frequency maximum of 7622 Hz. The higher frequencies are produced by the grasshoppers to prevent background noise from drowning out their signals. This information reveals that anthropogenic noise disturbs the acoustic signals produced by insects for communication. Similar processes of behavior perturbation, behavioral plasticity, and population level shifts in response to noise likely occur in sound-producing marine invertebrates, but more experimental research is needed.",1
"In the study, recordings of boat noise were made by using a hydrophone. In addition, recordings of ambient noise were made that did not contain boat noise. In contrast to ambient noise playbacks, mollusks exposed to boat noise playbacks had a 21% reduction in embryonic development. Additionally, newly hatched larvae experienced an increased mortality rate of 22% when exposed to boat noise playbacks.",1
"The three invertebrates in the experiment were exposed to continuous broadband noise and impulsive broadband noise. The anthropogenic noise impeded the bioirrigation and burying behavior of Nephrops norvegicus. In addition, the decapod exhibited a reduction in movement. Ruditapes philippinarum experienced stress which caused a reduction in surface relocation. The anthropogenic noise caused the clams to close their valves and relocate to an area above the interface of the sediment-water. This response inhibits the clam from mixing the top layer of the sediment profile and hinders suspension feeding.",1
"Sound causes Amphiura filiformis to experience changes in physiological processes which results in irregularity of bioturbation behavior.These invertebrates play an important role in transporting substances for benthic nutrient cycling. As a result, ecosystems are negatively impacted when species cannot perform natural behaviors in their environment. Locations with shipping lanes, dredging, or commercial harbors are known as continuous broadband sound. Pile-driving, and construction are sources that exhibit impulsive broadband noise. The different types of broadband noise have different effects on the varying species of invertebrates and how they behave in their environment.Another",1
"Researchers measure noise in terms of pressure, intensity, and frequency. Sound pressure level (SPL) represents the amount of pressure relative to atmospheric pressure during sound wave propagation that can vary with time; this is also known as the sum of the amplitudes of a wave. Sound intensity, measured in Watts per meters-squared, represents the flow of sound over a particular area. Although sound pressure and intensity differ, both can describe the level of loudness by comparing the current state to the threshold of hearing; this results in decibel units on the logarithmic scale.",1
"LAeq can be further broken up into different types of noise based on time of day; however, cutoffs for evening and nighttime hours may differ between countries, with the United States, Belgium, and New Zealand noting evening hours from 19:00-22:00 or 7:00pm–10:00pm and nighttime hours from 22:00-7:00 or 10:00pm–7:00am and most European countries noting evening hours from 19:00-23:00 or 7:00pm–11:00pm and nighttime hours from 23:00-7:00 or 11:00pm–7:00am).",1
"LAeq terms include: Day-night average level, DNL or LDN: This measurement assesses the cumulative exposure to sound for a 24-hour period (Leq over 24 hrs) of the year, with a 10 dB(A) penalty or weight added to nighttime noise measurements given the increased sensitivity to noise at night.",1
"dB penalty to evening and 10 dB penalty to nighttime hours. This is calculated from the following equation (most of Europe): L d e n = 10 ⋅ log 10 ⁡ 1 24 ( 12 ⋅ 10 L d a y 10 + 4 ⋅ 10 L e v e n i n g + 5 10 + 8 ⋅ 10 L n i g h t + 10 10 ) {\displaystyle L_{den}=10\cdot \log _{10}{\frac {1}{24}}\left(12\cdot 10^{\frac {L_{day}}{10}}+4\cdot 10^{\frac {L_{evening}+5}{10}}+8\cdot 10^{\frac {L_{night}+10}{10}}\right)} Daytime level, LAeqD or Lday: This measurement assesses daytime noise, usually from 7:00-19:00 (7am-7pm), yet may vary by country.",1
"The difference between SEL and LAmax is that SEL is derived using multiple time points of a particular event in calculating sound levels rather than the peak value. Percentile-derived measurements (L10, L50, L90, etc.): Noise may be described in terms of its statistical distribution over a set time, in which investigators may obtain values, or cut-points, at any percentile level. The L90 is the sound level that exceeds 90% of the time period; this is commonly referred to as background noise.Researchers",1
"with the US National Park Service found that human activity doubles the background-noise levels in 63 percent of protected spaces like national parks, and increases them tenfold in 21 percent. In the latter places, ""if you could have heard something 100 feet away, now you can only hear it 10 feet away,""",1
"In recent years, scientists and audio engineers have been developing smartphone apps to conduct sound measurements, similar to the standalone sound level meters and dosimeters. In 2014, the National Institute for Occupational Safety and Health (NIOSH) within the Centers for Disease Control and Prevention (CDC) published a study examining the efficacy of 192 sound measurement apps on Apple and Android smartphones.The authors found that only 10 apps, all of which were on the App Store, met all acceptability criteria. Of these 10 apps, only 4 apps met accuracy criteria within 2 dB(A) from the reference standard.",1
"As a result of this study, they created the NIOSH Sound Level Meter App to increase accessibility and decrease costs of monitoring noise using crowdsourcing data with a tested and highly accurate application. The app is compliant with ANSI S1.4 and IEC 61672 requirements.The app calculates the following measures: total run time, instantaneous sound level, A-weighted equivalent sound level (LAeq), maximum level (LAmax), C-weighted peak sound level, time-weighted average (TWA), dose, and projected dose.",1
"Dose and projected dose are based on sound level and duration of noise exposure in relation to the NIOSH recommended exposure limit of 85 dB(A) for an eight-hour work shift. Using the phone's internal microphone (or an attached external microphone), the NIOSH Sound Level Meter measures instantaneous sound levels in realtime and converts sound into electrical energy to calculate measurements in A-, C-, or Z-weighted decibels. App users are able to generate, save, and e-mail measurement reports. The NIOSH Sound Level Meter is currently only available on Apple iOS devices.",1
"Costs of building-in mitigation can be modest, provided these solutions are sought in the planning stage of a roadway project. Aircraft noise can be reduced by using quieter jet engines. Altering flight paths and time of day runway has benefited residents near airports.",1
"In 2007, the Egyptian National Research Center found that the average noise level in central Cairo was 90 decibels and that the noise never fell below 70 decibels. Noise limits set by law in 1994 are not enforced. In 2018, the World Hearing Index declared Cairo to be the world's second-noisiest city.",1
"Westminster City Council has received more complaints per head of population than any other district in the UK with 9,814 grievances about noise, which equates to 42.32 complaints per thousand residents. Eight of the top 10 councils ranked by complaints per 1,000 residents are located in London.",1
"However, the Noise Control Act of 1972 and the Quiet Communities Act of 1978 were never rescinded by Congress and remain in effect today, although essentially unfunded.The National Institute for Occupational Safety and Health (NIOSH) at the Centers for Disease Control and Prevention (CDC) researches noise exposure in occupational settings and recommends a Recommended Exposure Limit (REL) for an 8-hour time-weighted average (TWA) or work shift of 85 dB(A) and for impulse noise (instant events such as bangs or crashes) of 140 dB(A).",1
"The agency published this recommendation along with its origin, noise measurement devices, hearing loss prevention programs, and research needs in 1972 (later revised June 1998) as an approach in preventing occupational noise-related hearing loss.The Occupational Safety and Health Administration (OSHA) within the Department of Labor issues enforceable standards to protect workers from occupational noise hazards. The permissible exposure limit (PEL) for noise is a TWA of 90 dB(A) for an eight-hour work day. However, in manufacturing and service industries, if the TWA is greater than 85 dB(A), employers must implement a Hearing Conservation Program.The",1
"Federal Aviation Administration (FAA) regulates aircraft noise by specifying the maximum noise level that individual civil aircraft can emit through requiring aircraft to meet certain noise certification standards. These standards designate changes in maximum noise level requirements by ""stage"" designation. The U.S. noise standards are defined in the Code of Federal Regulations (CFR) Title 14 Part 36 – Noise Standards: Aircraft Type and Airworthiness Certification (14 CFR Part 36). The FAA also pursues a program of aircraft noise control in cooperation with the aviation community.",1
"Locations where the DNL is above 75 dB are considered ""Unacceptable"" and require approval by the Assistant Secretary for Community Planning and Development.The Department of Transportation's Bureau of Transportation Statistics has created a to provide access to comprehensive aircraft and road noise data on national and county levels. The map aims to assist city planners, elected officials, scholars, and residents to gain access to up-to-date aviation and Interstate highway noise information.States and local governments typically have very specific statutes on building codes, urban planning, and roadway development.",1
"Noise laws and ordinances vary widely among municipalities and indeed do not even exist in some cities. An ordinance may contain a general prohibition against making noise that is a nuisance, or it may set out specific guidelines for the level of noise allowable at certain times of the day and for certain activities. Noise laws classify sound into three categories. First is ambient noise, which refers to sound pressure of all-encompassing noise associated with a given environment. The second is continuous noise, which could be steady or fluctuating, but continues for more than an hour.",1
"The third is cyclically varying noise, which could be steady or fluctuating, but occurs repetitively at reasonably uniform intervals of time.New York City instituted the first comprehensive noise code in 1985. The Portland Noise Code includes potential fines of up to $5000 per infraction and is the basis for other major U.S. and Canadian city noise ordinances.",1
"In 1995, the World Health Organization (WHO) European Region released guidelines on regulating community noise. The WHO European Region subsequently released other versions of the guidelines, with the most recent version circulated in 2018. The guidelines provide the most up-to-date evidence from research conducted in Europe and other parts of the world on non-occupational noise exposure and its relationship to physical and mental health outcomes. The guidelines provide recommendations for limits and preventive measures regarding various noise sources (road traffic, railway, aircraft, wind turbine) for day-evening-night average and nighttime average levels.",1
"August 23, 2022.",1
"Each motile mature cell has an intertwined bundle of flagella appearing as a single flagellum consisting of a long filament with a short hook and a basal body complex, but it is distinguishable by electron microscope as 10 to 30 strands with diameters of 12.5 to 16 nm each. S. natans stores reserves of poly- beta -hydroxybutyrate as internal globules making up 30 to 40% of the dry weight of a colony. Gram and Neisser staining reactions are negative. S.",1
"natans requires dissolved simple sugars or organic acids as a food supply, but needs less phosphorus than many competing organisms and can tolerate low oxygen concentrations. Capability to deposit elemental sulfur intracellularly in the presence of hydrogen sulfide is believed to be a detoxifying mechanism. S. natans requires either cobalamin or methionine as a trace nutrient. S. natans filaments can aid development of a periphyton biofilm trapping suspended particles and stabilizing colonies of other organisms including Klebsiella and Pseudomonas.",1
"Data are from IAEA-TECDOC-1105, pages 3–4. 1946 First dumping operation at Northeast Pacific Ocean (about 80 km off the coast of California) 1957 First IAEA Advisory Group Meeting on Radioactive Waste Disposal into the Sea 1958 First United Nations Conference on the Law of the Sea (UNCLOS I) 1964 On the 21 April, a satellite failed carrying a SNAP-9A radiothermal generator. 17,000 Ci (630 TBq) plutonium metal fuel burned up.",1
"The countries involved – listed in order of total contributions measured in TBq (TBq=1012 becquerel) – were the Soviet Union, the United Kingdom, Switzerland, the United States, Belgium, France, the Netherlands, Japan, Sweden, Russia, New Zealand, Germany, Italy and South Korea. Together, they dumped a total of 85,100 TBq (85.1x1015 Bq) of radioactive waste at over 100 ocean sites, as measured in initial radioactivity at the time of dump. For comparison: Global fallout of nuclear weapon tests – 2,566,087x1015 Bq. 1986 Chernobyl disaster total release – 12,060x1015 Bq.",1
"Data are from IAEA-TECDOC-1105.: 6–7, 14",1
unpackaged and diluted in surface waters contained in package but not solidified,1
without nuclear fuel containing damaged spent nuclear fuel solidified with polymer agent special container with damaged spent nuclear fuel (icebreaker Lenin by the former Soviet Union),1
Data are from IAEA-TECDOC-1105.: 27–120 There are three dump sites in the Pacific Ocean.,1
"Mainly at the east coast of Novaya Zemlya at Kara Sea and relatively small proportion at Barents Sea by the Soviet Union. Dumped at 20 sites from 1959 to 1992, total of 222,000 m3 including reactors and spent fuel.",1
"Dumping occurred from 1948 to 1982. The UK accounts for 78% of dumping in the Atlantic (35,088 TBq), followed by Switzerland (4,419 TBq), the United States (2,924 TBq) and Belgium (2,120 TBq). Sunken Soviet nuclear submarines are not included; see List of sunken nuclear submarines There were 137,000 tonnes dumped by eight European countries. The United States reported neither tonnage nor volume for 34,282 containers.",1
The Soviet Union dumped 749 TBq. Japan dumped 15.1 TBq south of main island. South Korea dumped 45 tonnes (unknown radioactivity value). Data are from IAEA-TECDOC-1105.: 7,1
"Joint Russian-Norwegian expeditions (1992–94) collected samples from four dump sites. At immediate vicinity of waste containers, elevated levels of radionuclide were found, but had not contaminated the surrounding area.",1
"The most recent version of the London Convention now bans all materials from marine dumping, except a thoroughly researched list of certain wastes. It also prohibits waste from being exported to other countries for disposal, as well as incinerating waste in the ocean. While smaller organizations like the Nuclear Energy Agency of the European Organization for Economic Cooperation and Development have produced similar regulations, the London Convention remains the central international figure of radioactive waste policies.Although there are many existing regulations that ban ocean dumping, it is still a prevalent issue.",1
"Different countries enforce the ban on radioactive waste dumping on different levels, resulting in an inconsistent implementation of the agreed upon policies. Because of these discrepancies, it is hard to judge the effectiveness of international regulations like the London Convention. Horizontal drillhole disposal Ocean floor disposal Deep borehole disposal Yucca Mountain nuclear waste repository Waste Isolation Pilot Plant Grigory Pasko Nuclear fuel cycle Radioactive waste Great Lakes Basin § Nuclear power plants Decommissioning of Russian nuclear-powered vessels",1
"The suspended sediment may interfere with the food gathering of filtering organisms, and the sediment accumulation on the bottom may bury organisms to the point that they starve or even die. It is only if the concentration is extreme that it decreases the light level sufficiently for impacting primary productivity. An accumulation of as little as 1 mm (0.039 in) may kill coral polyps.",1
"While the effect of the siltation on the biota (once the harm is already done) can be studied by repeated inspection of selected test plots, the magnitude of the siltation process in the impact area may be measured directly by monitoring in real time. Parameters to measure are sediment accumulation, turbidity at the level of the filtering biota, and optionally incident light.Siltation of the magnitude that it affects shipping can also be monitored by repeated bathymetric surveys. In rural areas, the first line of defense is to maintain land cover and prevent soil erosion in the first place.",1
"Since all replenished beaches are eroding or they would not need replenishment, they will contribute to nearshore siltation almost for as long as it takes to erode away what was added, albeit with somewhat decreasing intensity over time. Since the leakage is detrimental to coral reefs, the practice leads to a direct conflict between the public interest of saving beaches, and preserving any nearshore coral reefs. To minimize the conflict, beach replenishment should not be done with sand containing any silt or clay fractions.",1
"In practice the sand is often taken from offshore areas, and since the proportion of fines in sediments typically increases in the offshore direction, the deposited sand will inevitably contain a significant percentage of siltation-contributing fines. It is desirable to minimize the siltation of irrigation channels by hydrologic design, the objective being not to create zones with falling sediment transport capacity, as that is conducive to sedimentation. Once sedimentation has occurred, in irrigation or navigation channels, dredging is often the only remedy.",1
"As of 2022, the convention had been ratified by 47 states. Text. Ratifications.",1
Gábor Horváth and his team have proposed that this new term needs to be better described and understood in order to better address the specific ecological consequences (direct or delayed in space and time) of light that was polarized (at source or by interacting with objects made or modified by humans). A representative example is the ecological trap caused by asphalt surfaces polarizing light in a similar way as ponds do. Research has shown swarms of mayflies are laying their eggs on roads rather than rivers or ponds.,1
"This species is referred to as S. oneidensis MR-1, indicating ""manganese reducing"", a special feature of this organism. It is a common misconception to think that MR-1 refers to ""metal-reducing"" instead of the original intended ""manganese-reducing"" as observed by Kenneth H. Nealson, who first isolated the organism.",1
"Shewanella oneidensis MR-1 belongs to a class of bacteria known as ""Dissimilatory Metal-Reducing Bacteria (DMRB)"" because of their ability to couple metal reduction with their metabolism. The means of reducing the metals is of particular controversy, as research using scanning electron microscopy and transmission electron microscopy revealed abnormal structural protrusions resembling bacterial filaments that are thought to be involved in the metal reduction. This process of producing an external filament is completely absent from conventional bacterial respiration and is the center of many current studies.",1
"In a developed pellicle, a number of substances between the cells (extracellular polymeric substances) help maintain the pellicle matrix. The process of pellicle formation involves significant microbial activities and related substances. For the extracellular polymeric substances, many proteins and other bio-macromolecules are required. Many metal cations are also required in the process. EDTA control and extensive cation presence/absence tests show that Ca(II), Mn(II), Cu(II) and Zn(II) are all essential in this process, probably functioning as a part of a coenzyme or prosthetic group. Mg(II) has partial effect, while Fe(II) and Fe(III) are inhibitory to some degree.",1
"Flagella are considered to contribute to pellicle formation. The biofilm needs bacterial cells to move in a certain manner, while flagella is the organelle which has locomotive function. Mutant strains lacking flagella can still form pellicle, albeit much less rapidly.",1
"Shewanella oneidensis MR-1 can change the oxidation state of metals. These microbial processes allow exploration of novel applications, for example, the biosynthesis of metal nanomaterials. In contrast to chemical and physical methods, microbial processes for synthesizing nanomaterials can be achieved in aqueous phase under gentle and environmentally benign conditions. Many organisms can be utilized to synthesize metal nanomaterials. S. oneidensis is able to reduce a diverse range of metal ions extracellularly and this extracellular production greatly facilitates the extraction of nanomaterials.",1
"The extracellular electron transport chains responsible for transferring electrons across cell membranes are relatively well characterized, in particular outer membrane c-type cytochromes MtrC and OmcA. A 2013 study suggested that it is possible to alter particle size and activity of extracellular biogenic nanoparticles via controlled expression of the genes encoding surface proteins. An important example is the synthesis of silver nanoparticle by S. oneidensis, where its antibacterial activity can be influenced by the expression of outer membrane c-type cytochromes.",1
"Silver nanoparticles are considered to be a new generation of antimicrobial as they exhibit biocidal activity towards a broad range of bacteria, and are gaining importance with the increasing resistance in antibiotics by pathogenic bacteria. Shewanella has been seen in laboratory settings to bioreduce a substantial amount of palladium and dechlorinate near 70% of polychlorinated biphenyls (PCBs). The production of nanoparticles by S. oneidensis MR-1 are closely associated to the MTR pathway (e.g. silver nanoparticles), or the hydrogenase pathway (e.g. palladium nanoparticles).",1
"New bacterial behavior observed PNAS study documents puzzling movement of electricity-producing bacteria near energy sources, abstract at Eurekalert 'Rock-Breathing' Bacteria Could Generate Electricity and Clean Up Oil Spills, ScienceDaily (Dec. 15, 2009) Bacteria that can form electric circuits? Type strain of Shewanella oneidensis at BacDive – the Bacterial Diversity Metadatabase",1
"The area, roughly centered on ""Point Nemo"", the oceanic pole of inaccessibility, is furthest away from any land. The nearest islands are over 2,600 kilometres (1,600 mi) away from the center. This location has been chosen for its remoteness and limited shipping traffic so as not to endanger human life with any falling debris. At least 264 spacecraft were disposed in this area between 1971 and 2016. The defunct space station Mir and six Salyut stations are among the nearly 200 pieces of Russian spacecraft debris in this region, making Russia the largest contributor of spacecraft in the cemetery.",1
"The remaining pieces of debris in the cemetery belong to the United States, Europe, Japan, as well as certain private organizations. Among American spacecraft, remnants of the Skylab space station were deposited into the spacecraft cemetery.The decommissioning of Tiangong-1, the first Chinese space station, was an unsuccessful targeted re-entry at Point Nemo. During an extended mission phase, control was lost due to a power failure, leading to an uncontrolled landing outside of the spacecraft cemetery.According to the U.S.",1
"Currently more than 27,000 pieces of space debris are orbiting earth at high velocities, threatening the safety of human and robotic missions, as well as causing damage to spacecraft. There are few space debris removal processes, one of which is depositing large spacecraft in the spacecraft cemetery on earth, although, due to exhausted maneuvering fuel reserves, in the past this was rarely done.",1
"Currently, new processes for space debris removal are being developed to reduce the exponential growth of space debris orbiting earth, such as nets, magnetized collecting arms, and more. Aircraft boneyard Atmospheric reentry Graveyard orbit Ship graveyard Space archaeology Space debris Wrecking yard Space sustainability",1
"The measuring instruments for radiation protection are both ""installed"" (in a fixed position) and portable (hand-held or transportable).",1
"Installed instruments are fixed in positions which are known to be important in assessing the general radiation hazard in an area. Examples are installed ""area"" radiation monitors, Gamma interlock monitors, personnel exit monitors, and airborne particulate monitors. The area radiation monitor will measure the ambient radiation, usually X-ray, Gamma or neutrons; these are radiations which can have significant radiation levels over a range in excess of tens of metres from their source, and thereby cover a wide area.",1
"Such instruments are often installed on trolleys to allow easy deployment, and are associated with temporary operational situations. In the United Kingdom the HSE has issued a user guidance note on selecting the correct radiation measurement instrument for the application concerned. This covers all radiation instrument technologies, and is a useful comparative guide.",1
Local contamination from radium-based radioluminescent paints having been improperly disposed of is not unknown.,1
"Eben Byers was a wealthy American socialite whose death in 1932 from using a radioactive quackery product called Radithor is a prominent example of a death caused by radium. Radithor contained ~1 μCi (40 kBq) of 226Ra and 1 μCi of 228Ra per bottle. Radithor was taken by mouth and radium, being a calcium mimic, has a very long biological halflife in bone. Most of the dose is due to the decay of the polonium (218Po) and lead (214Pb) daughters of 222Rn.",1
"By controlling exposure to the daughters the radioactive dose to the skin and lungs can be reduced by at least 90%. This can be done by wearing a dust mask, and wearing a suit to cover the entire body. Note that exposure to smoke at the same time as radon and radon daughters will increase the harmful effect of the radon. In uranium miners radon has been found to be more carcinogenic in smokers than in non-smokers.",1
"Rainwater can be highly radioactive due to high levels of radon and its decay progenies 214Bi and 214Pb; the concentrations of these radioisotopes can be high enough to seriously disrupt radiation monitoring at nuclear power plants. The highest levels of radon in rainwater occurs during thunderstorms, and it is hypothesized that radon is concentrated in thunderstorms on account of the atom's positive electrical charge. Estimates of the age of rain drops have been obtained from measuring the isotopic abundance of radon's short-lived decay progeny in rainwater.",1
"Because uranium minerals emit radon gas, and their harmful and highly radioactive decay products, uranium mining is considerably more dangerous than other (already dangerous) hard rock mining, requiring adequate ventilation systems if the mines are not open pit. In the 1950s, a significant number of American uranium miners were Navajo, as many uranium deposits were discovered on Navajo reservations. A statistically significant subset of these miners later developed small-cell lung cancer, a type of cancer usually not associated with smoking, after exposure to uranium ore and radon-222, a natural decay product of uranium.",1
"mSv, the International Commission on Radiological Protection (ICRP) consider 1 WLM to be a 5 mSv lung dose for professional workers (and 4 mSv lung dose for the general public). Lastly the United Nations Scientific Committee on the Effects of Atomic Radiation (UNSCEAR) consider that the exposure of the lungs to 1 Bq of 222Rn (in equilibrium with its decay products) for one year will cause a dose of 61 μSv.In humans a relationship between lung cancer and radon has been shown to exist (beyond all reasonable doubt) for exposures of 100 WLM and above.",1
By using the data from several studies it has been possible to show that an increased risk can be caused by a dose as low as 15 to 20 WLM. Sadly these studies have been difficult as the random errors in the data are very large. It is likely that the miners are also subject to other effects which can harm their lungs while at work (for example dust and diesel fumes).,1
"They were shocked to find that the source was astonishingly high levels of radon in his basement and it was not related to the nuclear plant. The risks associated with living in his house were estimated to be equivalent to smoking 135 packs of cigarettes every day.Depending how houses are built and ventilated, radon may accumulate in basements and dwellings. The European Union recommends that mitigation should be taken starting from concentrations of 400 Bq/m3 for old houses, and 200 Bq/m3 for new ones.The",1
The Streeter–Phelps equation determines the relation between the dissolved oxygen concentration and the biological oxygen demand over time and is a solution to the linear first order differential equation ∂ D ∂ t = k 1 L t − k 2 D {\displaystyle {\frac {\partial D}{\partial t}}=k_{1}L_{t}-k_{2}D} This differential equation states that the total change in oxygen deficit (D) is equal to the difference between the two rates of deoxygenation and reaeration at any time.,1
"The Streeter–Phelps equation, assuming a plug-flow stream at steady state is then D = k 1 L a k 2 − k 1 ( e − k 1 t − e − k 2 t ) + D a e − k 2 t {\displaystyle D={\frac {k_{1}L_{a}}{k_{2}-k_{1}}}(e^{-k_{1}t}-e^{-k_{2}t})+D_{a}e^{-k_{2}t}} where D {\displaystyle D} is the saturation deficit, which can be derived from the dissolved oxygen concentration at saturation minus the actual dissolved oxygen concentration ( D = D O s a t − D O {\displaystyle D=DO_{sat}-DO} ).",1
"L t {\displaystyle L_{t}} is the oxygen demand remaining at time t, L t = L a e − k 1 t {\displaystyle L_{t}=L_{a}e^{-k_{1}t}} . D a {\displaystyle D_{a}} is the initial oxygen deficit [ g m 3 ] {\displaystyle [{\tfrac {\mathrm {g} }{\mathrm {m} ^{3}}}]} . t {\displaystyle t} is the elapsed time, usually [ d ] {\displaystyle [d]} . k 1 {\displaystyle k_{1}} lies typically within the range 0.05-0.5 d − 1 {\displaystyle d^{-1}} and k 2 {\displaystyle k_{2}} lies typically within the range 0.4-1.5 d − 1 {\displaystyle d^{-1}} .",1
The Streeter–Phelps equation is also known as the DO sag equation. This is due to the shape of the graph of the DO over time.,1
"On the DO sag curve a minimum concentration occurs at some point, along a stream.",1
"If the Streeter–Phelps equation is differentiated with respect to time, and set equal to zero, the time at which the minimum DO occurs is expressed by t c r i t = 1 k 2 − k 1 ln ⁡ [ k 2 k 1 ( 1 − D a ( k 2 − k 1 ) L a k 1 ) ] {\displaystyle t_{crit}={\frac {1}{k_{2}-k_{1}}}\ln {\left[{\frac {k_{2}}{k_{1}}}\left({1-{\frac {D_{a}(k_{2}-k_{1})}{L_{a}k_{1}}}}\right)\right]}} To find the value of the critical oxygen deficit, D c r i t {\displaystyle D_{crit}} , the Streeter–Phelps equation is combined with the equation above, for the critical time, t c",1
"r i t {\displaystyle t_{crit}} . Then the minimum dissolved oxygen concentration is D O c r i t = D O s a t − D c r i t {\displaystyle DO_{crit}=DO_{sat}-D_{crit}} Mathematically it is possible to get a negative value of D O c r i t {\displaystyle DO_{crit}} , even though it is not possible to have a negative amount of DO in reality.The",1
"Several estimations of the reaeration rate exist, which generally follow the equation k 2 = K v a H − b {\displaystyle k_{2}=Kv^{a}H^{-b}} where K {\displaystyle K} is a constant. v {\displaystyle v} is the flow velocity [m/s]. H {\displaystyle H} is the depth [m]. a {\displaystyle a} is a constant. b {\displaystyle b} is a constant.The constants depend on the system to which the equation is applied, i.e. the flow velocity and the size of the stream or river. Different values are available in the literature.",1
"Both the deoxygenation rate, k 1 {\displaystyle k_{1}} and reaeration rate, k 2 {\displaystyle k_{2}} can be temperature corrected, following the general formula. k = k 20 θ ( T − 20 ) {\displaystyle k=k_{20}\theta ^{(T-20)}} where k 20 {\displaystyle k_{20}} is the rate at 20 degrees Celsius. θ is a constant, which differs for the two rates. T {\displaystyle T} is the actual temperature in the stream in degC.Normally θ has the value 1.048 for k 1 {\displaystyle k_{1}} and 1.024 for k 2 {\displaystyle k_{2}} .",1
"An increasing temperature has the most impact on the deoxygenation rate, and results in an increased critical deficit ( D c r i t {\displaystyle D_{crit}} ), and x c r i t {\displaystyle x_{crit}} decreases. Furthermore, a decreased D O s a t {\displaystyle DO_{sat}} concentration occurs with increasing temperature, which leads to a decrease in the DO concentration.",1
"The two streams are considered as dilutions of each other thus the initial BOD and DO will be L a = L s Q s + L b Q b Q s + Q b {\displaystyle L_{a}={\frac {L_{s}Q_{s}+L_{b}Q_{b}}{Q_{s}+Q_{b}}}} and D O 0 = D O s Q s + D O b Q b Q s + Q b {\displaystyle DO_{0}={\frac {DO_{s}Q_{s}+DO_{b}Q_{b}}{Q_{s}+Q_{b}}}} where L a {\displaystyle L_{a}} is the initial concentration of BOD in the river downstream of the mixing, also called BOD(0).",1
The unit of L a {\displaystyle L_{a}} is g m 3 {\displaystyle {\tfrac {\mathrm {g} }{\mathrm {m} ^{3}}}} . L b {\displaystyle L_{b}} is the background BOD of the concentration in the river [ g m 3 ] {\displaystyle [{\tfrac {\mathrm {g} }{\mathrm {m} ^{3}}}]} . L s {\displaystyle L_{s}} is the BOD of the content of the merging river [ g m 3 ] {\displaystyle [{\tfrac {\mathrm {g} }{\mathrm {m} ^{3}}}]} .,1
D O 0 {\displaystyle DO_{0}} is the initial concentration of the dissolved oxygen in the river downstream of the conjoining point [ g m 3 ] {\displaystyle [{\tfrac {\mathrm {g} }{\mathrm {m} ^{3}}}]} . D O b {\displaystyle DO_{b}} is the background concentration of the dissolved oxygen content in the river [ g m 3 ] {\displaystyle [{\tfrac {\mathrm {g} }{\mathrm {m} ^{3}}}]} . D O s {\displaystyle DO_{s}} is the background concentration of the dissolved oxygen content in the merging river [ g m 3 ] {\displaystyle [{\tfrac {\mathrm {g} }{\mathrm {m} ^{3}}}]} .,1
Q b {\displaystyle Q_{b}} is the flow in the river upstream from the mixing point [ m 3 s ] {\displaystyle [{\tfrac {m^{3}}{s}}]} . Q s {\displaystyle Q_{s}} is the flow in the merging river upstream from the mixing point [ m 3 s ] {\displaystyle [{\tfrac {m^{3}}{s}}]} .,1
"complex versions of the Streeter–Phelps model were introduced during the 1960s, where computers made it possible to include further contributions to the oxygen development in streams. At the head of this development were O'Connor (1960) and Thomann (1963). O'Connor added the contributions from photosynthesis, respiration and sediment oxygen demand (SOD). Thomann expanded the Streeter–Phelps model to allow for multi segment systems. The simple Streeter–Phelps model is based on the assumptions that a single BOD input is distributed evenly at the cross section of a stream or river and that it moves as plug flow with no mixing in the river.",1
"Furthermore, only one DO sink (carbonaceous BOD) and one DO source (reaeration) is considered in the classical Streeter–Phelps model. These simplifications will give rise to errors in the model. For example the model does not include BOD removal by sedimentation, that suspended BOD is converted to a dissolved state, that sediment has an oxygen demand and that photosynthesis and respiration will impact the oxygen balance. In addition to the oxidation of organic matter and the reaeration process, there are many other processes in a stream which affect the DO.",1
"In order to make a more accurate model it is possible to include these factors using an expanded model. The expanded model is a modification of the traditional model and includes internal sources (reaeration and photosynthesis) and sinks (BOD, background BOD, SOD and respiration) of DO. It is not always necessary to include all of these parameters. Instead relevant sources and sinks can be summed to yield the overall solution for the particular model. Parameters in the expanded model can be either measured in the field or estimated theoretically.",1
"Background BOD or benthic oxygen demand is the diffuse source of BOD represented by the decay of organic matter that has already settled on the bottom. This will give rise to a constant diffuse input thus the change in BOD over time will be d L d t = − k 1 L + L b {\displaystyle {\frac {dL}{dt}}=-k_{1}L+L_{b}} where k 1 {\displaystyle k_{1}} is the rate for oxygen consumption by BOD, usually in d − 1 {\displaystyle d^{-1}} .",1
"Sedimented BOD does not directly consume oxygen and this should therefore be taken into account. This is done by introducing a rate of BOD removal combined with a rate of oxygen consumption by BOD. Giving a total rate for oxygen removal by BOD k r = k 1 + k 3 {\displaystyle k_{r}=k_{1}+k_{3}} where k 1 {\displaystyle k_{1}} is the rate of oxygen consumption by BOD, usually in d − 1 {\displaystyle d^{-1}} . k 3 {\displaystyle k_{3}} is the rate of settling of BOD, usually in d − 1 {\displaystyle d^{-1}} .The",1
Oxygen can be consumed by organisms in the sediment. This process is referred to as sediment oxygen demand (SOD). Measurement of SOD can be undertaken by measuring the change of oxygen in a box on the sediment (benthic respirometer).,1
The change in oxygen deficit due to consumption by sediment is described as d D d t = − k 2 D + S H {\displaystyle {\frac {dD}{dt}}=-k_{2}D+{\frac {S}{H}}} where H {\displaystyle H} is the depth of the river [m] S {\displaystyle S} is the SOD [ g m 2 d ] {\displaystyle [{\tfrac {g}{m^{2}d}}]} D is the saturation deficit [ g m 3 ] {\displaystyle [{\tfrac {\mathrm {g} }{\mathrm {m} ^{3}}}]} . k 2 {\displaystyle k_{2}} is the reaeration rate [ d − 1 {\displaystyle d^{-1}} ].The range of the SOD is typically in the range of 0.1,1
"Ammonium is oxidized to nitrate under aerobic conditions NH4+ + 2O2 → NO3− + H2O + 2H+Ammonium oxidation can be treated as part of BOD, so that BOD = CBOD + NBOD, where CBOD is the carbonaceous biochemical oxygen demand and NBOD is nitrogenous BOD. Usually CBOD is much higher than the ammonium concentration and thus NBOD often does not need to be considered. The change in oxygen deficit due to oxidation of ammonium is described as d D d t = k N N − k 2 D {\displaystyle {\frac {dD}{dt}}=k_{N}N-k_{2}D} where D is the saturation deficit.",1
k N {\displaystyle k_{N}} is the nitrification rate [ d − 1 ] {\displaystyle [d^{-1}]} . N {\displaystyle N} is ammonium-nitrogen concentration.The range of k N {\displaystyle k_{N}} is typically 0.05-0.5 d − 1 {\displaystyle d^{-1}} .,1
Photosynthesis and respiration are performed by algae and by macrophytes. Respiration is also performed by bacteria and animals. Assuming steady state (net daily average) the change in deficit will be d D d t = − k 2 D + ( R + P ) a v g {\displaystyle {\frac {dD}{dt}}=-k_{2}D+(R+P)_{avg}} where R {\displaystyle R} is the respiration [ m g L d ] {\displaystyle [{\tfrac {mg}{Ld}}]} . P {\displaystyle P} is the photosynthesis [ m g L d ] {\displaystyle [{\tfrac {mg}{Ld}}]} .Note that BOD only includes respiration of microorganisms e.g. algae and bacteria and not by macrophytes and animals.,1
"Due to the variation of light over time, the variation of the photosynthetic oxygen can be described by a periodical function over time, where time is after sunrise and before sunset P ( t ) = P m a x s i n ( π f + ( t − t s ) ) {\displaystyle P(t)=P_{max}sin\left({\frac {\pi }{f}}+(t-t_{s})\right)} where P ( t ) {\displaystyle P(t)} is the photosynthesis at a given time [ m g L d ] {\displaystyle [{\tfrac {mg}{Ld}}]} .",1
"P m a x {\displaystyle P_{max}} is the daily maximum of the photosynthesis [ m g L d ] {\displaystyle [{\tfrac {mg}{Ld}}]} . f {\displaystyle f} is the fraction of day with sunlight, usually 1 2 {\displaystyle {\tfrac {1}{2}}} day. t s {\displaystyle t_{s}} is the time at which sun rises [ d ] {\displaystyle [d]} .The range of the daily average value of primary production ( P − R ) {\displaystyle (P-R)} is typically 0.5-10 m g L d {\displaystyle {\tfrac {mg}{Ld}}} .",1
"Sea glass begins as normal shards of broken glass that are then persistently tumbled and ground until the sharp edges are smoothed and rounded. In this process, the glass loses its slick surface but gains a frosted appearance over many years. Naturally produced sea glass (""genuine sea glass"") originates as pieces of glass from broken bottles, broken tableware, or even shipwrecks, which are rolled and tumbled in the ocean for years until all of their edges are rounded off, and the slickness of the glass has been worn to a frosted appearance.",1
"These colors are found once for every 200 to 1,000 pieces found.Extremely rare colors include gray, pink (often from Great Depression-era plates), teal (often from Mateus wine bottles), black (older, very dark olive green glass), yellow (often from 1930s Vaseline containers), turquoise (from tableware and art glass), red (often from old Schlitz bottles, car tail lights, dinnerware, or nautical lights, it is found once in about every 5,000 pieces), and orange (the least common type of sea glass, found once in about 10,000 pieces). These colors are found once for every 1,000 to 10,000 pieces collected.",1
"Some shards of black glass are quite old, originating from thick eighteenth-century gin, beer, and wine bottles.",1
"Old black glass bottles that had iron slag added during production to increase strength and opaqueness were at times broken in shipment. In order to make artificial sea glass, a tumbler, sand, and glass are necessary.A number of characteristics highlight the differences between artificial sea glass and natural sea glass, starting with the coloration and surface texture of each piece. An example of natural sea glass will usually have a frosty, almost powdery texture at different points. One of the most reliable indicators for natural sea glass is a ""C"" shaped design all over the outside of the sample.",1
"If the design is located on the piece, it is authentic sea glass, since artificial glass will typically not have that particular design. Sea glass usually comes from broken glass bottles or other household items, so pieces found on beaches will not be perfectly shaped, unlike artificial sea glass, often sold as beach glass. Glass Beach (Fort Bragg, California) Sea pottery Park, Elizabeth. ""Where Does Beach Glass Come From?"". USA Today. Retrieved November 6, 2014. National Geographic magazine, ""Environment"" section: ""The Shard Way"", August 2008 http://www.microscopy-uk.org.uk/mag/artnov11macro/JosephineWyman/JW_SeaGlassArticle.pdf",1
North American Sea Glass Association Fortune Small Business magazine article on sea glass collection Washington Post article on sea glass collection and sales Photographic Exploration of Sea Glass- Josephine Wyman Brief summary/discussion about Sea Glass / Beach Glass,1
"The film documents the lives of the people in Ozyorsk, Chelyabinsk Oblast, also known as Ozersk, code named ""City 40"". The town is near Mayak, the birthplace of the Soviet Union's nuclear weapons program as well as the location of the Kyshtym disaster. The town was modeled after plans stolen from the United States, who created their own secret atomic cities. The people living in Ozersk believe that they are saving the world.",1
"Nadezhda Kutepova, an attorney and civil rights activist in Ozersk whose beliefs changed from thinking the town was doing its patriotic duty for the state to being confronted with the ecological damage being caused by radioactive waste, defends its citizens who have been affected by the radiation. Vladimir Kuznetsov, a member of the Russian Atomic Energy Corporation, gives details of how the factory is heavily guarded.",1
"Journalists, scientists and other interviewees, some with their faces obscured, tell of life in the factory and the town and how their families have suffered from early deaths due to the unsecure handling of the radioactive substances.An epilogue tells of how Kutepova and her family later fled the area and were granted asylum in France after being persecuted by the Russian government for her activities. It also lists a number of secret cities, past and present, around the world. The Frontline Club hosted a screening and question and answer session with Goetschel and journalist Luke Harding on 14 June 2016.",1
"Goetschel said she and her crew were in a sanitarium outside of Ozersk and tried to make contact with residents in order to gain access. The film crew and the residents that spoke with them were under risk of death. Goetschel said ""They have been told they would be killed. But then there was a click that made them decide to talk. The most important thing was that they knew they were risking their lives. They were thinking we are dying anyway and they trusted me for whatever reason."" City 40 on Facebook City 40 at IMDb Trailer",1
"ClearSign was formed in Seattle, Washington in 2008. Its first chief executive officer was Richard Rutkowski, who also became chairman of the board of directors. Rutkowski was a co-founder of projection technology company Microvision and nanotechnology company Lumera.In 2012 ClearSign held an initial public offering which, according to the company, raised $13.8 million. ClearSign chose to delay adopting accounting standards required of publicly traded companies under the Sarbanes-Oxley Act, taking advantage of exemptions in the JOBS Act designed to make it cheaper for development-stage companies to raise capital. It is believed ClearSign may have been the first company in the U.S.",1
"to do so.In December 2014, Rutkowski resigned as CEO. He was replaced by board member Stephen Pirnat. The following September, the company was named ""Technology Company of the Year"" by Petroleum Economist.On November 12, 2019, ClearSign Combustion Corporation (Nasdaq: CLIR) (“ClearSign” or the “Company”), announced that the Company has changed its name to ClearSign Technologies Corporation. The Company’s ticker “CLIR” will remain the same. 2013 MIT Technology Review article on ClearSign's Electrodynamic Combustion Control",1
"Clean Up Australia Day was first held in January 1989. The idea developed from an Australian Bicentenary event, ""Clean-Up Lake Macquarie"", which was instigated in 1987 by Ivan Welsh as Mayor of Lake Macquarie. Then followed the local ""Clean Up Sydney Harbour"" event in 1989, organised by Ian Kiernan and Kim McKay, with more than 40,000 volunteers who collected approximately 5,000 tonnes of rubbish. The 1990 Clean Up Australia Day event was launched by the then prime minister, Bob Hawke, over the initial opposition of the then state premier, Nick Greiner.",1
"Greiner later reversed his position and offered his support for the event.Clean Up Australia has evolved into an organisation that works with community, government and businesses to ""provide practical solutions to help Australians all live more sustainably every day of the year.""Today the organisation's focuses are equal in preventing new rubbish from entering the environment as well as removing what rubbish is already present. ""The Rubbish Report"" is produced each year from data collected by surveying participants. As of 1990, 94% of rubbish was from packaging.",1
"Clean Up the World was established in 1994 after Ian Kiernan and Kim McKay approached the United Nations Environment Programme, with an idea to take his Clean Up concept global.Clean Up the World is an international campaign that encourages communities to clean up, fix up and conserve their environment through the Clean Up the World Membership program. A Clean Up the World weekend is held on the third weekend of September each year and, by 2007, the event attracted more than 35 million people from over 120 countries to volunteer.",1
"Business Clean Up Day provides Australian businesses with an opportunity to contribute to waste reduction and the improvement of the environment. Businesses register their commitment to implement at least one environment-friendly initiative in their workplace, giving them an opportunity to work as a team and make a difference to their local environment.",1
Schools Clean Up Day is designed to allow students to participate in Clean Up Australia as part of a school activity.,1
"Clean Up the Kimberley is a series of community action-based projects focussed on the Kimberley region of Western Australia. The primary objectives of this initiative are to clean up rubbish hot spots, increase awareness of the scale and impact of rubbish in the region, change tourist and local community behaviour and improve local recycling and waste management infrastructure.",1
"Corresponding to its half-life, the radioactive activity of one gram of 60Co is 44 TBq (1,200 Ci). The absorbed dose constant is related to the decay energy and time. For 60Co it is equal to 0.35 mSv/(GBq h) at one meter from the source. This allows calculation of the equivalent dose, which depends on distance and activity. For example, a 60Co source with an activity of 2.8 GBq, which is equivalent to 60 μg of pure 60Co, generates a dose of 1 mSv at one meter distance within one hour.",1
"The probability for population of the middle energy level of 2.1 MeV by β-decay is 0.0022%, with a maximum energy of 665.26 keV. Energy transfers between the three levels generate six different gamma-ray frequencies. In the diagram the two important ones are marked. Internal conversion energies are well below the main energy levels. 60mCo is a nuclear isomer of 60Co with a half-life of 10.467 minutes. It decays by internal transition to 60Co, emitting 58.6 keV gamma rays, or with a low probability (0.22%) by β-decay into 60Ni.",1
"The main uses for 60Co are: As a tracer for cobalt in chemical reactions Sterilization of medical equipment. Radiation source for medical radiotherapy. Cobalt therapy, using beams of gamma rays from 60Co teletherapy machines to treat cancer. Radiation source for industrial radiography. Radiation source for leveling devices and thickness gauges. Radiation source for pest insect sterilization. As a radiation source for food irradiation and blood irradiation.Cobalt has been discussed as a ""salting"" element to add to nuclear weapons, to produce a cobalt bomb, an extremely ""dirty"" weapon which would contaminate large areas with 60Co nuclear fallout, rendering them uninhabitable.",1
"The remainder is taken up by tissues, mainly the liver, kidneys, and bones, where the prolonged exposure to gamma radiation can cause cancer. Over time, the absorbed cobalt is eliminated in urine.",1
"These observations appear to be compatible with the radiation hormesis model.In August 2012, Petco recalled several models of steel pet food bowls after US Customs and Border Protection determined that they were emitting low levels of radiation. The source of the radiation was determined to be 60Co that had contaminated the steel.In May 2013, a batch of metal-studded belts sold by online retailer ASOS were confiscated and held in a US radioactive storage facility after testing positive for 60Co.",1
"A radioactive contamination incident occurred in 1984 in Ciudad Juárez, Mexico, originating from a radiation therapy unit illegally purchased by a private medical company and subsequently dismantled for lack of personnel to operate it. The radioactive material, 60Co, ended up in a junkyard, where it was sold to foundries that inadvertently smelted it with other metals and produced about 6,000 tons of contaminated rebar. These were distributed in 17 Mexican states and several cities in the United States. It is estimated that 4,000 people were exposed to radiation as a result of this incident.In",1
"the Samut Prakan radiation accident in 2000, a disused radiotherapy head containing a 60Co source was stored at an unsecured location in Bangkok, Thailand and then accidentally sold to scrap collectors. Unaware of the dangers, a junkyard employee dismantled the head and extracted the source, which remained unprotected for a period of days at the junkyard. Ten people, including the scrap collectors and workers at the junkyard, were exposed to high levels of radiation and became ill. Three of the junkyard workers subsequently died as a result of their exposure, which was estimated to be over 6 Gy.",1
"Afterward, the source was safely recovered by Thai authorities.In December 2013, a truck carrying a disused 111 TBq 60Co teletherapy source from a hospital in Tijuana to a radioactive waste storage center was hijacked at a gas station near Mexico City. The truck was soon recovered, but the thieves had removed the source from its shielding. It was found intact in a nearby field.",1
"Despite early reports with lurid headlines asserting that the thieves were ""likely doomed"", the radiation sickness was mild enough that the suspects were quickly released to police custody, and no one is known to have died from the incident. In 1957, Chien-Shiung Wu et al. discovered the β-decay process violated parity, implying nature has a handedness.In the Wu experiment her group aligned radioactive 60Co nuclei by cooling the source to low temperatures in a magnetic field. Wu's observation was that more β-rays were emitted in the opposite direction to the nuclear spin. This asymmetry violates parity conservation.",1
"While resistivity is an important phenomenon in the inter-electrode region where most particle charging takes place, it has a particularly important effect on the dust layer at the collection electrode where discharging occurs. Particles that exhibit high resistivity are difficult to charge. But once charged, they do not readily give up their acquired charge on arrival at the collection electrode. On the other hand, particles with low resistivity easily become charged and readily release their charge to the grounded collection plate. Both extremes in resistivity impede the efficient functioning of ESPs. ESPs work best under normal resistivity conditions.",1
"Resistivity, which is a characteristic of particles in an electric field, is a measure of a particle's resistance to transferring charge (both accepting and giving up charges). Resistivity is a function of a particle's chemical composition as well as flue gas operating conditions such as temperature and moisture. Particles can have high, moderate (normal), or low resistivity. Bulk resistivity is defined using a more general version of Ohm’s Law, as given in Equation (1) below: Where: E is the Electric field strength.Unit:-(V/cm); j is the Current density.Unit:-(A/cm2); and ρ is the Resistivity.Unit:-(Ohm-cm)",1
"A better way of displaying this would be to solve for resistivity as a function of applied voltage and current, as given in Equation (2) below: Where: ρ = Resistivity.Unit:-(Ohm-cm) V = The applied DC potential.Unit:-(Volts); I = The measured current.Unit:-(Amperes); l = The ash layer thickness.Unit:-(cm); and A = The current measuring electrode face area.Unit:-(cm2). Resistivity is the electrical resistance of a dust sample 1.0 cm2 in cross-sectional area, 1.0 cm thick, and is recorded in units of ohm-cm. A method for measuring resistivity will be described in this article.",1
"The table below, gives value ranges for low, normal, and high resistivity.",1
"Resistance affects electrical conditions in the dust layer by a potential electric field (voltage drop) being formed across the layer as negatively charged particles arrive at its surface and leak their electrical charges to the collection plate. At the metal surface of the electrically grounded collection plate, the voltage is zero, whereas at the outer surface of the dust layer, where new particles and ions are arriving, the electrostatic voltage caused by the gas ions can be quite high. The strength of this electric field depends on the resistance and thickness of the dust layer.",1
"In high-resistance dust layers, the dust is not sufficiently conductive, so electrical charges have difficulty moving through the dust layer. Consequently, electrical charges accumulate on and beneath the dust layer surface, creating a strong electric field. Voltages can be greater than 10,000 volts. Dust particles with high resistance are held too strongly to the plate, making them difficult to remove and causing trapping problems. In low resistance dust layers, the corona current is readily passed to the grounded collection electrode. Therefore, a relatively weak electric field, of several thousand volts, is maintained across the dust layer.",1
"Collected dust particles with low resistance do not adhere strongly enough to the collection plate. They are easily dislodged and become retained in the gas stream. The electrical conductivity of a bulk layer of particles depends on both surface and volume factors. Volume conduction, or the motions of electrical charges through the interiors of particles, depends mainly on the composition and temperature of the particles. In the higher temperature regions, above 500 °F (260 °C), volume conduction controls the conduction mechanism. Volume conduction also involves ancillary factors, such as compression of the particle layer, particle size and shape, and surface properties.",1
"Volume conduction is represented in the figures as a straight-line at temperatures above 500 °F (260 °C). At temperatures below about 450 °F (230 °C), electrical charges begin to flow across surface moisture and chemical films adsorbed onto the particles. Surface conduction begins to lower the resistivity values and bend the curve downward at temperatures below 500 °F (260 °C). These films usually differ both physically and chemically from the interiors of the particles owing to adsorption phenomena. Theoretical calculations indicate that moisture films only a few molecules thick are adequate to provide the desired surface conductivity.",1
"The following discussion of normal, high, and low resistance applies to ESPs operated in a dry state; resistance is not a problem in the operation of wet ESPs because of the moisture concentration in the ESP. The relationship between moisture content and resistance is explained later in this work.",1
"As stated above, ESPs work best under normal resistivity conditions. Particles with normal resistivity do not rapidly lose their charge on arrival at the collection electrode. These particles slowly leak their charge to grounded plates and are retained on the collection plates by intermolecular adhesive and cohesive forces. This allows a particulate layer to be built up and then dislodged from the plates by rapping. Within the range of normal dust resistivity (between 107 and 2 × 1010 ohm-cm), fly ash is collected more easily than dust having either low or high resistivity.",1
"Another problem that occurs with high resistivity dust layers is called back corona. This occurs when the potential drop across the dust layer is so great that corona discharges begin to appear in the gas that is trapped within the dust layer. The dust layer breaks down electrically, producing small holes or craters from which back corona discharges occur. Positive gas ions are generated within the dust layer and are accelerated toward the ""negatively charged"" discharge electrode.",1
"The positive ions reduce some of the negative charges on the dust layer and neutralize some of the negative ions on the ""charged particles"" heading toward the collection electrode. Disruptions of the normal corona process greatly reduce the ESP's collection efficiency, which in severe cases, may fall below 50% . When back corona is present, the dust particles build up on the electrodes forming a layer of insulation. Often this can not be repaired without bringing the unit offline. The third, and generally most common problem with high resistivity dust is increased electrical sparking.",1
"When the sparking rate exceeds the ""set spark rate limit,"" the automatic controllers limit the operating voltage of the field. This causes reduced particle charging and reduced migration velocities toward the collection electrode. High resistivity can generally be reduced by doing the following: Adjusting the temperature; Increasing moisture content; Adding conditioning agents to the gas stream; Increasing the collection surface area; and Using hot-side precipitators (occasionally and with foreknowledge of sodium depletion).Thin dust layers and high-resistivity dust especially favor the formation of back corona craters. Severe back corona has been observed with dust layers as thin as 0.1",1
"mm, but a dust layer just over one particle thick can reduce the sparking voltage by 50%. The most marked effects of back corona on the current-voltage characteristics are: Reduction of the spark over voltage by as much as 50% or more; Current jumps or discontinuities caused by the formation of stable back-corona craters; and Large increase in maximum corona current, which just below spark over corona gap may be several times the normal current.The Figure below and to the left shows the variation in resistivity with changing gas temperature for six different industrial dusts along with three coal-fired fly ashes.",1
"The Figure on the right illustrates resistivity values measured for various chemical compounds that were prepared in the laboratory. Results for Fly Ash A (in the figure to the left) were acquired in the ascending temperature mode. These data are typical for a moderate to high combustibles content ash. Data for Fly Ash B are from the same sample, acquired during the descending temperature mode. The differences between the ascending and descending temperature modes are due to the presence of unburned combustibles in the sample.",1
"As voltage is increased from small amounts (e.g. 20 V), no current is measured. Then, a threshold voltage level is reached. At this level, current surges through the sample... so much so that the voltage supply unit can trip off. After removal of the unburned combustibles during the above-mentioned annealing procedure, the descending temperature mode curve shows the typical inverted “V” shape one might expect.",1
"Particles that have low resistivity are difficult to collect because they are easily charged (very conductive) and rapidly lose their charge on arrival at the collection electrode. The particles take on the charge of the collection electrode, bounce off the plates, and become re-entrained in the gas stream. Thus, attractive and repulsive electrical forces that are normally at work at normal and higher resistivities are lacking, and the binding forces to the plate are considerably lessened. Examples of low-resistivity dusts are unburned carbon in fly ash and carbon black.",1
"As the percentage of moisture in the gas stream increases from 6 to 20%, the resistivity of the dust dramatically decreases. Also, raising or lowering the temperature can decrease cement dust resistivity for all the moisture percentages represented. The presence of SO3 in the gas stream has been shown to favor the electrostatic precipitation process when problems with high resistivity occur. Most of the sulfur content in the coal burned for combustion sources converts to SO2. However, approximately 1% of the sulfur converts to SO3.",1
"If injection of ammonium sulfate occurs at a temperature greater than about 600 °F (320 °C), dissociation into ammonia and sulfur trioxide results. Depending on the ash, SO2 may preferentially interact with fly ash as SO3 conditioning. The remainder recombines with ammonia to add to the space charge as well as increase cohesiveness of the ash. More recently, it has been recognized that a major reason for loss of efficiency of the electrostatic precipitator is due to particle buildup on the charging wires in addition to the collection plates (Davidson and McKinney, 1998).",1
"ppm sulfuric acid vapor lowers that value to about 7 × 109 ohm-cm. ESPs continue to be excellent devices for control of many industrial particulate emissions, including smoke from electricity-generating utilities (coal and oil fired), salt cake collection from black liquor boilers in pulp mills, and catalyst collection from fluidized bed catalytic cracker units in oil refineries to name a few. These devices treat gas volumes from several hundred thousand ACFM to 2.5 million ACFM (1,180 m³/s) in the largest coal-fired boiler applications.",1
"electrostatic precipitators, if the collection plates are allowed to accumulate large amounts of particulate matter, the particles can sometimes bond so tightly to the metal plates that vigorous washing and scrubbing may be required to completely clean the collection plates. The close spacing of the plates can make thorough cleaning difficult, and the stack of plates often cannot be easily disassembled for cleaning. One solution, suggested by several manufacturers, is to wash the collector plates in a dishwasher.",1
All verification reports and statements are made publicly available on the ETV Website.,1
"ETV has verified over 400 technologies and developed more than 90 protocols. A survey of participating vendors completed in 2001 showed overwhelming support for the ETV program. Responses indicated that 73 percent of the vendors were using ETV information in product marketing, and 92 percent of those surveyed responded that they would recommend ETV to other vendors.In 2006, EPA published a two-volume set of case studies which document actual and projected outcomes from verifications of technologies in 15 technology categories (ETV Program Case Studies Vol 1 EPA/600/R-06/001 and ETV Program Case Studies Vol II EPA/600/R-06/082).",1
"Envirofuels Diesel Fuel Catalyzer: verified on tier 0 locomotive engine - verification report specifies an increase in total particulate (TPM) emissions on the treated fuel, as compared to the baseline fuel, even though the gaseous emissions and visible smoke opacity decreased significantly. Envirofuels diesel fuel catalyzer showed a verified fuel consumption reduction.",1
"The composition of TPM (total diesel particulate matter) is the sum of ""dry"" particulates, and ""wet"" particulates. ""Dry"" Particulate emissions are also known as inorganic soot, black carbon, or elemental carbon. ""Wet"" particulates are also known as organic carbon, soluble organic fractions (SOFs) and volatile organic compounds (VOCs). The exact ratio of ""wet to dry"" diesel particulate matter will vary by engine load, duty cycle, fuel composition and specification, and engine tuning. An opacity reading is a measurement of the level of visible inorganic carbon, also known as soot.",1
"The ETV verification program (and other verification pathways) publish the verification reports, technology options charts, and technical summaries, once testing has been completed. The ETV testing facility will issue press releases on behalf of the technology vendor, upon completion of testing. The ETV verification program reports all outcomes, and leaves the ultimate decision regarding the suitability and applicability of a given technology to the discretion of the end user. Additional research may be necessary in order to adequately address specific situations. ETV has been developed in different European countries as part of government initiatives and/or as part of funded research projects.",1
"Emerging evidence shows that HAP is also a risk factor for cataracts, the leading cause of blindness in lower-middle-income countries, and low birth weight. Cooking with open fires or unsafe stoves is a leading cause of burns among women and children in developing countries.",1
"Health effects are concentrated among women, who are likely to be responsible for cooking, and young children. The work of gathering fuel exposes women and children to safety risks and often consumes 15 or more hours per week, constraining their available time for education, rest, and paid work. Women and girls must often walk long distances to obtain cooking fuel, and, as a result, face increased risk of physical and sexual violence. Many children, particularly girls, may not attend school in order to help their mothers with firewood collection and food preparation.",1
"Its definition includes what the WHO refers to as ""improved cookstoves"", i.e. stoves that burn biomass fuel more efficiently than traditional stoves. As of 2020, the vast majority of stoves that burn biomass fuel do not qualify as clean under WHO standards even if they are more efficient than traditional stoves.The WHO has criticized the marketing of biomass cookstoves as ""improved"" when they have not been tested against standards and their health benefits are unclear. A high priority in global sustainable development is to make clean cooking facilities universally available and affordable.According",1
"Improved cook stoves (ICS), often marketed as ""clean cookstoves"", are biomass stoves that generally burn biomass more efficiently than traditional stoves and open fires. Compared to traditional cook stoves, ICS are usually more fuel-efficient and aim to reduce the negative health impacts associated with exposure to toxic smoke. As of 2016, no widely-available biomass stoves meet the standards for clean cooking as defined by the WHO. A 2020 review found only one biomass stove on the market that met WHO standards in field conditions.Despite",1
"This means, for example, that a 50 percent reduction in exposure would not halve the health risk. A 2020 systematic review found that ICS usage led to modest improvements in terms of blood pressure, shortness of breath, emissions of cancer-causing substances, and cardiovascular diseases, but no improvements in pregnancy outcomes or children's health.Substantial variations in emissions and fuel consumption have been observed across ranges of cookstove designs and between laboratory and field test conditions. At present, a standard testing mechanism does not exist to establish the true impact of alternative cookstove designs as well as descriptive language for exposure.",1
"Cookstove implementation efforts have often achieved mixed results because of technical and social complexities, such as the need to involve both women (who typically are responsible for cooking) and men (who typically control household spending).Efforts to improve access to clean cooking fuels and stoves have barely kept up with population growth, and current and planned policies would still leave 2.4 billion people without access in 2030. Transitioning to cleaner cooking methods is expected to either slightly raise greenhouse gas emissions or decrease emissions, even if the replacement fuels are fossil fuels.",1
"There is evidence that switching to LPG and PNG has a smaller climate effect than the combustion of solid fuels, which emits methane and black carbon. The burning of residential solid fuels accounts for up to 58 percent of global black carbon emissions. The Intergovernmental Panel on Climate Change stated in 2018, ""The costs of achieving nearly universal access to electricity and clean fuels for cooking and heating are projected to be between 72 and 95 billion USD per year until 2030 with minimal effects on GHG emissions.""Universal",1
"access to clean cooking is an element of the UN Sustainable Development Goal 7, whose first target is: ""By 2030, ensure universal access to affordable, reliable and modern energy services"". Progress in clean cooking would facilitate progress in other Sustainable Development goals, such as eliminating poverty (Goal 1), good health and well-being (Goal 3), gender equality (Goal 5), and climate action (Goal 13). An indicator of Goal 7 is the proportion of population with primary reliance on clean fuels and technologies for cooking, heating, and lighting, using the WHO's definition of ""clean"".",1
"Energy Sector Management Assistance Program (ESMAP) (2020). The State of Access to Modern Energy Cooking Services. Washington, DC: World Bank. This article incorporates text available under the CC BY 3.0 license. Tester, Jefferson (2012). Sustainable Energy : Choosing Among Options. Cambridge, Massachutetts: MIT Press. ISBN 978-0-262-01747-3. OCLC 892554374. World Health Organization (2016). Burning opportunity : clean household energy for health, sustainable development, and wellbeing of women and children. Geneva, Switzerland. Archived from the original on November 24, 2017.{{cite book}}: CS1 maint: location missing publisher (link) Roy, J.; Tschakert, P.; Waisman, H.; Abdul Halim, S.; et al. (2018).",1
"""Chapter 5: Sustainable Development, Poverty Eradication and Reducing Inequalities"" (PDF). Special Report: Global Warming of 1.5 °C. pp. 445–538.",1
"Methamphetamine or meth is a synthetic drug which can be produced on a domestic scale. The dumping of toxic waste is a major issue associated with the production of meth. It has been approximated that for each pound of meth produced, five pounds of toxic waste are also generated. The methods of disposal of these substances can be extremely damaging to the environment as producers may simply pour them down the sink or toilet.",1
"Furthermore, as governments policies restrict the movement of traffickers, they must find alternate and more remote routes to transport their materials. These alternate routes typically require further land clearing and habitat destruction, thus further harming the environment.Drug policy can further inhibit biodiversity conservation. As drug policy can displace the actions of traffickers and producers into more biodiverse locations, their impact on global biodiversity is magnified. As producers relocate into more remote locations, their actions of deforestation and dumping of toxic materials such as kerosene and hydrochloric acid can greatly damage biodiversity.",1
"However, even if such a response fails to stem demand, shedding light on these issues may foster voter concerns who still may appeal to legislators.",1
"Current supporters of global waste trade argue that importing waste is an economic transaction which can benefit countries with little to offer the global economy. Countries which do not have the production capacity to manufacture high quality products can import waste to stimulate their economy. Lawrence Summers, former President of Harvard University and Chief Economist of the World Bank, issued a confidential memo arguing for global waste trade in 1991. The memo stated: ""I think the economic logic behind dumping a load of toxic waste in the lowest wage country is impeccable and we should face up to that...",1
"Elaborating on this point, the article argues that ""people in developing countries would rationally accept increased exposure to hazardous pollutants in exchange for opportunities to increase their productivity—and, hence, their income.""Overall, the argument for global waste trade rests largely upon a perception that developing countries need to further their economic development. Supporters suggest that in engaging in global waste trade, developing countries of the Global South will expand their economies and increase profits.",1
Critics of global waste trade argue that lack of regulation and failed policies have allowed developing nations to become toxic dump yards for hazardous waste. The ever-increasing amounts of hazardous waste being shipped to developing countries increases the disproportionate risk that the people in these nations face. Critics of the effects of the global waste trade emphasize the enormous amount of hazardous wastes that people in poorer countries must deal with.,1
"Arguing that the detrimental effects of hazardous waste trade affect the disadvantaged more than others, critics of global waste trade suggest that the implications of dumping hazardous waste has significant consequences for people of color, women, and low-income people in particular. Critiquing the global waste trade for reproducing inequality on a global scale, many activists, organizers, and environmentalists from regions affected in the Global South have vocalized their disappointment with global waste trade policies. Evo Morales, former President of Bolivia, argues against the current economic system forcing the exploitation of his country and people.",1
"He claims:""If we want to save the planet earth, to save life and humanity, we have a duty to put an end to the capitalist system. Unless we put an end to the capitalist system, it is impossible to imagine that there will be equality and justice on this planet earth.",1
"This is why I believe that it is important to put an end to the exploitation of human beings and to the pillage of natural resources, to put an end to destructive wars for markets and raw materials, to the plundering of energy, particularly fossil fuels, to the excessive consumption of goods and to the accumulation of waste. The capitalist system only allows us to heap up waste."" Jean Francois Kouadio, an African native living near a toxic dump site in the Ivory Coast, explains his experience with the effects of toxic substances lingering throughout his community.",1
"With major Western corporations dumping their toxic wastes in the Ivory Coast, Kuoadio has lost two children to the effects of toxic wastes. He describes the loss of his second daughter Ama Grace, and how the doctors ""said she suffered from acute glycemia caused by the toxic waste."" In addition to critics from the Global South, researchers and scholars in the West have begun critiquing the uneven distribution of negative effects these hazardous waste dumpings are causing.",1
"Dorceta Taylor, Professor at the University of Michigan, argues how Women of Color in the United States are disproportionately affected by these policies: ""Women of color have been at the forefront of the struggle to bring attention to the issues that are devastating minority communities – issues such as hazardous waste disposal; exposure to toxins; ...Their communities, some of the most degraded environments ... are repositories of the waste products of capitalist production and excessive consumption.",1
"Using the historical premises of colonialism, toxic colonialism reproduces these same arguments by defining Global South land as expendable for Western wastes.",1
"Heavy metals, toxins, and chemicals leak from these discarded products into surrounding waterways and groundwater, poisoning the local people. People who work in these dumps, local children searching for items to sell, and people living in the surrounding communities are all exposed to these deadly toxins. One city suffering from the negative results of the hazardous waste trade is Guiyu, China, which has been called the electronic waste dump of the world. It may be the world's largest e-waste dump, with workers dismantling over 1.5 million pounds of junked computers, cell phones and other electronic devices per year.",1
"An example of incinerator ash being dumped onto the Global South from the Global North in an unjust trade exchange is the Khian Sea waste disposal incident. Carrying 14,000 tons of ash from an incinerator in Philadelphia, the cargo ship, Khian Sea, was to dispose of its waste. However, upon being rejected by the Dominican Republic, Panama, Honduras, Bermuda, Guinea Bissau, and the Dutch Antilles, the crew finally dumped a portion of the ash near Haiti.",1
"After changing the name of the ship twice to try and conceal the original identity, Senegal, Morocco, Yemen, Sri Lanka, and Singapore still banned the ship's entry. Upon consistent rejections, the ash is believed to have been disposed of in the Atlantic and Indian Oceans. Following this disaster of handling hazardous waste, the Haitian government banned all waste imports leading a movement to recognize all of the disastrous consequences of this global waste trade. Based on the Khian Sea waste disposal incident and similar events, the Basel Convention was written to resist what is known to developing countries as 'toxic colonialism.'",1
"It was open for signature in March 1989 and went into effect in May 1992. The U.S. has signed the treaty, but has yet to ratify it. Chemical waste is the excess and unusable waste from hazardous chemicals, mainly produced by large factories. It is extremely difficult and costly to dispose of. It poses many problems and health risks upon exposure, and must be carefully treated in toxic waste processing facilities.",1
"One example of chemical waste being exported from the Global North onto the Global South was the event of an Italian business man seeking to avoid European economic regulations. Allegedly exporting 4,000 tons of toxic waste, containing 150 tons of polychlorinated biphenyls, or PCBs, the Italian businessman made $4.3 million in shipping hazardous waste to Nigeria.",1
"This is just one example of how the traditional trade flow, from developed Western countries has severely, unfairly, and disproportionately impacted developing countries in the Global South.",1
"For one, the older ships contain health-damaging substances such as asbestos, lead oxide, zinc chromates, mercury, arsenic, and tributyltin. In addition, shipbreaking workers in China and in other developing countries traditionally lack proper equipment or protective gear when handling these toxic substances. The trade in plastic waste has been identified as the main cause of marine litter. Countries importing the waste plastics often lack the capacity to process all the material. As a result, the United Nations has imposed a ban on waste plastic trade unless it meets certain criteria.",1
"The global waste trade has had negative effects for many people, particularly in poorer, developing nations. These countries often do not have safe recycling processes or facilities, and people process the toxic waste with their bare hands. Hazardous wastes are often not properly disposed of or treated, leading to poisoning of the surrounding environment and resulting in illness and death in people and animals. Many people have experienced illnesses or death due to the unsafe way these hazardous wastes are handled.",1
"The hazardous waste trade has serious damaging effects upon the health of humans. People living in developing countries may be more vulnerable to the dangerous effects of the hazardous waste trade, and are particularly at risk from developing health problems. The methods of disposal of these toxic wastes in developing countries expose the general population (including future generations) to the highly toxic chemicals. These toxic wastes are often disposed of in open landfills, burned in incinerators, or in other dangerous processes.",1
"On April 24, 2018, President Rodrigo Duterte of the Philippines threatened to declare war if Canada failed again to retrieve the 64 tonnes of garbages that they mistakenly labelled as recyclable. The said cargos of garbages from Canada was shipped by a private company that recycled plastic material last 2016. Duterte is already known for blatant comments and aggressive behaviour. During the ASEAN Summit hosted in Manila, Philippines, the Prime Minister Justin Trudeau attended and was controversially ask what actions they can do to solve this issue.",1
"Trudeau promised that they will bring back the Canadian garbage from Philippines but two years later it was compromised. Duterte gave the Canadian government until May 30 or the Philippine government supreme court will escalate it in international court of justice. This is also known as the Philippine-Canada waste war. After a month, Malaysia is the second Asian nation who escalate the illegal garbage trading from Canada, UK, Japan and US.",1
"According to the Malaysian Minister of Environment; Yeo Bee Yin made a strong statement that Malaysians will not accept garbages from developed countries because this is against to Malaysian human rights. China also restricts imports of garbages from developed countries and now Asian nations such Thailand, Indonesia, Vietnam and Myanmar became the next garbage dump of the developed countries which is unethical. There have been various international responses to the problems associated with the global waste trade and multiple attempts to regulate it for over thirty years.",1
"The hazardous waste trade has proven difficult to regulate as there is so much waste being traded, and laws are often difficult to enforce. Furthermore, there are often large loopholes in these international agreements that allow countries and corporations to dump hazardous wastes in dangerous ways. The most notable attempt to regulate the hazardous waste trade has been the Basel Convention.",1
"The Basel Convention on the Control of Transboundary Movements of Hazardous Wastes and Their Disposal, usually known as the Basel Convention, is an international treaty that plays a crucial role in regulating the transnational movement of hazardous wastes. The Basel Convention was created in 1989 and attempts to regulate the hazardous waste trade, specifically to prevent the dumping of hazardous waste from more developed countries into less developed countries. The Basel Convention was developed following a series of high-profile cases in which large amounts of toxic waste were dumped into less developed countries, poisoning the people and environment.",1
"The Convention seeks to reduce the creation of hazardous wastes, and to control and reduce its trade across borders. The Convention was opened for signatures on 22 March 1989, and officially entered into force on 5 May 1992. As of May 2014, 180 states and the European Union are parties to the Convention. Haiti and the United States have signed the Convention but not ratified it.",1
"In 1999 the Basel Convention passed the Protocol on Liability and Compensation that sought to improve regulatory measures and better protect people from hazardous waste. The Protocol on Liability and Compensation attempts to “assign appropriate liability procedures when the transboundary movements of hazardous wastes result in damages to human health and the environment”. The Protocol “imposes strict liability for damages in situations involving Parties to the Basel Convention, but only while they maintain control of the hazardous waste through their respective notifying, transporting, or disposing entities.” It seeks to regulate and ensure countries’ and corporations’ compliance with the Basel Convention laws.",1
"However, this Protocol remains unsigned by most countries, so its applicability is limited.",1
"In an effort to protect themselves against unfair hazardous waste dumping, the African, Caribbean, and Pacific States (ACP) signed the Lome IV Convention, which is a supplement to the Basel Convention and prohibits the “export of hazardous wastes from the European Community to ACP States.” This Convention is one attempt by developing countries to protect themselves from Western countries exporting their waste to poorer nations through the hazardous waste trade.",1
"When the Lomé IV Convention expired in 2000, the ACP countries and the European countries entered into a new agreement known as the Cotonou Agreement, which “recognizes the existence of disproportionate risks in developing countries and desires to protect against inappropriate hazardous waste shipments to these countries.”",1
"In 1991 multiple developing nations in Africa met to discuss their dissatisfaction with the Basel Convention in regulating the dumping of hazardous waste into their countries, and designed a ban on the import of hazardous wastes into their countries called the Bamako Convention. The Bamako Convention is different from the Basel Convention in that Bamako “essentially bans the import of all hazardous waste generated outside of the OAU [the Organization of African Unity] for disposal or recycling and deems any import from a non-Party to be an illegal act.”",1
"However, these countries could not effectively implement the stipulations of the Convention and could not prevent the dump of toxic wastes due to limited resources and a lack of powerful enforcement. Therefore, the application of the Bamako Convention was very limited.",1
"Laura Pratt, expert on the hazardous waste trade, claims that despite local and international attempts to regulate the hazardous waste trade, the “current international agreements, both the widespread, legally binding agreements and the ad hoc agendas among smaller groups of countries, have not been as successful at eliminating toxic waste colonialism as proponents would have hoped.” She explains that there are various loopholes in the current system that allow toxic waste to continue being dumped, and toxic colonialism to go unchecked. Some of the problems with these international agreements include continued illegal shipments and unclear definitions of terms.",1
"Pratt explains that despite attempts to regulate illegal dumping, “[o]ftentimes hazardous waste is simply moved under false permits, bribes, improper labels, or even the pretext of 'recycling,' which is a growing trend.” Companies often export their hazardous wastes to poorer countries through illegal smuggling. International agencies have raised concerns about illegal waste dumping, but attempts to regulate this market have been hindered by a lack of ability to monitor the trade, as many countries do not have any authoritative legislative bodies in place to prevent or punish the illegal trafficking of hazardous wastes.",1
"Furthermore, Pratt explains that without coordinated international methods to enforce the regulations, it is extremely difficult for countries to ""control the illegal trade of hazardous waste, due to the disparity between enforcement resources and regulation uniformity.” Developing nations continue to bear the brunt of this illegal activity, and often do not have the resources or capability to protect themselves.",1
"In a recent study, Wistar rats were administered 1/50 of LD50 dosage of monocrotophos (0.36 mg/kg body weight) orally via gavage daily for three weeks. Animals administered Monocrotophos exhibited mild hyperglycemia and dyslipidemia in the blood. Cardiac oxidative stress was conferred by accumulation of protein carbonyls, lipid peroxidation and glutathione production. The cardiac markers (cTn-I, CK-MB and LDH) showed elevated levels in blood plasma, which indicates cardiac tissue damage. The histopathology of the heart tissue authenticated the monocrotophos induced tissue damage by showing signs of nonspecific inflammatory changes and edema between muscle fibres.",1
"Nerve growth factor (50 ng/ml) induced functional differentiation in PC12 cells has been reported. The studies have been carried out showing mitochondria mediated apoptosis in PC12 cells exposed to monocrotophos. A significant induction in reactive oxygen species, lipid peroxides, and the ratio of glutathione disulfide/reduced glutathione was observed in cells exposed to selected doses of monocrotophos. Following the exposure of PC12 cells to monocrotophos, the levels of protein and mRNA expression of caspase-3, caspase-9, BAX, p53, p21, PUMA, and cytochrome-c were significantly upregulated, whereas the levels of Bcl-2, Bcl-w, and Mcl-1 were downregulated.",1
"TUNEL assay, DNA laddering, and micronuclei induction show that long-term exposure of PC12 cells to monocrotophos at higher concentration (10−5 M) decreases the number of apoptotic events due to an increase in the number of necrotic cells. Monocrotophos-induced translocation of BAX and cytochrome-c proteins between the cytoplasm and mitochondria confirmed the role of monocrotophos in the permeability of the mitochondrial membrane. Mitochondria mediated apoptosis induction was confirmed by the increased activity of caspase cascade. These apoptotic changes could be correlated with elevated levels of expression of selected cytochrome P450s (CYP1A1/1A2, 2B1/2B2, 2E1) in PC12 cells exposed to monocrotophos (10−5 M).",1
Monocrotophos in the Pesticide Properties DataBase (PPDB),1
"Some power plants operate a dry disposal system with landfills. In the United States, coal ash is a major component of the nation's industrial waste stream. In 2017, 38.2 million short tons (34.7×10^6 t) of fly ash, and 9.7 million short tons (8.8×10^6 t) of bottom ash were generated. Coal contains trace levels of arsenic, barium, beryllium, boron, cadmium, chromium, thallium, selenium, molybdenum and mercury, many of which are highly toxic to humans and other life. Coal ash, a product of combustion, concentrates these elements and can contaminate groundwater or surface waters if there are leaks from an ash pond.Most U.S.",1
Cars Light Duty and Heavy Duty Trucks Buses Motorbikes,1
"Carbon monoxide is harmful because it reduces oxygen delivery to the body's organs and tissues. It is most harmful to those who suffer from heart and respiratory disease. Carbon Dioxide: Carbon dioxide is one of the most prominent greenhouse gasses emitted by motor vehicles. In 2006, 23.6% of the total inventory of U.S. greenhouse gasses were derived from motor vehicles. The compound is generated as a byproduct of the combustion of any fuel source containing carbon. Nitrogen Oxides: Nitrogen oxides form when fuel burns at high temperatures, such as in motor vehicle engines.",1
"These compounds are emitted by mobile sources, mostly due to the chemical nature of the fuel source. These compounds are known or expected to cause serious physical damages including cancer, reproductive, and developmental side effects.",1
"Department of TransportationFederal Aviation Administration: Practically all aviation emission sources are independently regulated through equipment specific regulations, standards and recommended practices, and operational guidelines, which are established by a variety of organizations. For example, on-road vehicles, which take passengers to and from the airport, meet stringent Federal tailpipe standards set by EPA. Stationary sources on the airport, like power boilers and refrigeration chillers, must meet independent state regulations. And FAA certification is required for essentially all aviation equipment and processes.",1
"For example there are more than 60 standards that apply to aircraft engine design, materials of construction, durability, instrumentation and control, and safety, among others. These are in addition to the Fuel Venting and Exhaust Emission Requirements for Turbine Engine Powered Airplanes (FAR Part 34), which guide compliance with EPA’s aircraft exhaust emission standards. The International Civil Aviation Organization (ICAO) is a United Nations intergovernmental body responsible for worldwide planning, implementation, and coordination of civil aviation. ICAO sets emission standards for jet engines. These are the basis of FAA’s aircraft engine performance certification standards, established through EPA regulations.Federal",1
"EPA and NHTSA are redesigning the labels to provide even more information to consumers. The new labels will, for the first time, provide information about each vehicle's greenhouse gas emissions, as required by the Energy Independence and Security Act of 2007. The agencies are proposing two different label designs and are seeking public comments about which labels will be most helpful to consumers. Consumers can submit comments about the two proposed label styles on EPA's website here and here.",1
"The tax does not apply to minivans, sport utility vehicles, or pick-up trucks, as these made up a small portion of the US fleet when the tax was established in 1978. Manufacturers pay a level of tax based upon the average fuel economy for each particular vehicle produced, ranging from $1,000 for vehicles achieving at least 21.5 but less than 22.5 MPG, to $7,000 for each vehicle achieving less than 12.5 MPG. Vehicles that achieve a minimum average fuel economy of 22.5 MPG are not subject to the gas guzzler tax.",1
"Governments may also offer tax credits to encourage certain types of behavior within market economies. For example, if a government wants to encourage consumers to purchase more fuel-efficient vehicles, the government could offer tax credits to effectively lower the price of each vehicle. The logic of this approach is consistent with the laws of supply and demand, namely, that as the price of a good decreases, the quantity demanded of that good will increase. This is true given that other important factors, such as current levels of supply and demand, remain constant.",1
"The US federal government currently utilizes numerous tax credits to reduce emissions from mobile sources. One of the more common tax credits is the ""Qualified Plug-In Electric Drive Motor Vehicle Tax Credit."" This credit is available ""for the purchase of a new qualified plug-in electric drive motor vehicle that draws propulsion using a traction battery that has at least four kilowatt hours of capacity, uses an external source of energy to recharge the battery, has a gross vehicle weight rating of up to 14,000 pounds, and meets specified emission standards.""",1
"For example, ""Advanced Biofuel Production Payments"" are available to ""eligible producers of advanced biofuels,"" or for fuels derived from ""renewable biomass other than corn kernel starch."" Such producers ""may receive payments to support expanded production of advanced biofuels,"" dependent upon the ""quantity and duration of production by the eligible producer; the net nonrenewable energy content of the advanced biofuel, if sufficient data is available; the number of producers participating in the program; and the amount of funds available.""",1
"While many critics have argued that biofuels can actually increase greenhouse gas emissions, research from the US Department of Energy indicates that biofuels ""burn cleaner than gasoline, resulting in fewer greenhouse gas emissions, and are fully biodegradable, unlike some fuel additives.""",1
"According to the Corporate Average Fuel Economy standard (CAFE) regulation, which was enacted in 1975, every seller of automobiles in the US had to achieve by 1985 a minimum sales-weighted average fuel efficiency of 27.5 miles per gallon (MPG). This standard had to be achieved for domestically produced and imported cars separately. Failure to meet the prescribed standard incurred a penalty of $5 per car per 1/10 of a gallon that the corporate average fuel economy fell below the standard.",1
"An estimated 20 percent of refineries participated in trading early in the program, eventually rising to 60 percent of refineries.",1
"The EPA has listed certain technologies that can be utilized in order to achieve the new standards, but refiners can petition the EPA to approve additional technologies. Refiners and importers could earn credits by reducing benzene levels below 0.62% before 2011. These credits could be auctioned to other companies, essentially creating a marketable allowance approach for reducing benzene content in gasoline. The nationwide banking and trading system does nave some limitations. No individual refiner or importer could produce gasoline with benzene concentrations exceeding 1.3% by volume, even with credits.",1
"for commercial customers, and $0.0002/kWh for industrial customers. The city council has the authority to increase the tax after the first year up to a maximum permitted tax rate of $0.0049/kWh for residential customers; $0.0009/kWh for commercial customers; and $0.0003/kWh for industrial customers. Voluntary purchases of utility-provided wind power are exempt from the tax. Charge: March 2010 rates for electricity customers: Total Fund: $860,265 in the first year and up to $1,342,000/year thereafter through March 31, 2013Purpose: Renewable energy, energy efficiency, transportation.",1
Authority 1: Ballot Issue 202 (Climate Action Plan Tax) Date Enacted:11/7/2006Authority 2: Boulder Revised Code 3-12 Date Effective: 4/1/2007 Expiration Date: 3/31/2013 Carbon pricing Global Action Plan Transition Towns Greenhouse gas emissions by the United States Chicago Climate Action Plan San Francisco Climate Action Plan Biodiversity Action Plan Obama’s Climate Action Plan Boulder's Climate Commitment (City of Boulder Climate action in Boulder County DSIRE Database of State Incentives for Renewables & Efficiency.,1
"Two primary considerations are: Scientific – to examine the accuracy of predictions and explain errors Management – to assess the success of mitigation in reducing impactsAudits can be performed either as a rigorous assessment of the null hypothesis or with a simpler approach comparing what actually occurred against the predictions in the EIA document.After an EIA, the precautionary and polluter pays principles may be applied to decide whether to reject, modify or require strict liability or insurance coverage to a project, based on predicted harms.The",1
"Overlap between federal and state requirements is addressed via bilateral agreements or one-off accreditation of state processes, as provided for in the EPBC Act.",1
"million for a body corporate, or for criminal penalty (maximum) of seven years imprisonment and/or penalty of $46,200.",1
"EIA provisions within Ministerial Authorities in the ACT are found in the Chapters 7 and 8 of the Planning and Development Act 2007 (ACT). EIA in ACT was previously administered with the help of Part 4 of the Land (Planning and Environment) Act 1991 (Land Act) and Territory Plan (plan for land-use). Note that some EIA may occur in the ACT on Commonwealth land under the EPBC Act (Cth). Further provisions of the Australian Capital Territory (Planning and Land Management) Act 1988 (Cth) may also be applicable particularly to national land and ""designated areas"".",1
"In New South Wales, the Environment Planning and Assessment Act 1979 (EP&A Act) establishes two pathways for EIA. The first is under Division 5.2 of the EP&A Act, which provides for EIA of 'State Significant Infrastructure' projects (from June 2011, this Part replaced the previous Part 3A, which previously covered EIA of major projects). The second is under Part 4 of the EP&A Act dealing with development assessments for local, regional, and State Significant Developments (other than State Significant Infrastructure).",1
must be performed for new establishments or projects and for expansions or renovations of existing establishments according to the Law for the Environment.,1
"the developer with this section as they know the project best Using the windfarm example again, construction might take place outside of bird nesting seasons, or removal of hardstanding on a potentially contaminated land site might take place outside of the rainy season.",1
"The EU started enforcing the Sustainable Finance Disclosures Regulation (SFDR), which was created with the purpose of unifying climate risk disclosures across the private sector by 2023. It also requires businesses to report on ""principal adverse impacts"" for society and the environment.",1
"However, it was estimated that this EIA court case had increased the construction cost of the Hong Kong section of the bridge by HK$6.5 billion in money-of-the-day prices.",1
"While there is no duty to consult any person when making a resource consent application (Sections 36A and Schedule 4), proof of consultation is almost certain required by local councils when they decide whether or not to publicly notify the consent application under Section 93.",1
Business entity is forbidden to conduct or to start its planned activity without the conclusion of impact on surroundings.,1
"plus a listing of studies conducted and agencies and stakeholders consulted to reach these conclusions. The action agency must approve an EA before it is made available to the public. The EA is made public through notices of availability by local, state, or regional clearing houses, often triggered by the purchase of a public notice advertisement in a newspaper of general circulation in the proposed activity area.",1
"The Chernobyl disaster, precipitated by a nuclear accident on April 26, 1986, is a stark reminder of the devastating effects of transboundary nuclear pollution.Environmental protection is inherently a cross-border issue and has led to the creation of transnational regulation via multilateral and bilateral treaties.",1
"There is growing dissent about them as their influence on decisions is limited. Improved training for practitioners, guidance on bestpractice and continuing research have all been proposed.EIAs have been criticized for excessively limiting their scope in space and time. No accepted procedure exists for determining such boundaries. The boundary refers to 'the spatial and temporal boundary of the proposal's effects'. This boundary is determined by the applicant and the lead assessor, but in practice, almost all EIAs address only direct and immediate on-site effects.Development causes both direct and indirect effects.",1
"recent analyses indicated that the persistent problem may have its roots in socio-cultural settings, and environment-nurturing cultural value should be regarded as one among major progressive cultures, and its implementation will need to engage the corporate sector.",1
"The NASA-LMT was a 3 m (9.8 ft) aperture liquid-mirror telescope located in NODO's main dome. It consisted of a 3 m diameter parabolic dish that held 4 U.S. gallons (15 L) of a highly reflective liquid metal, mercury, spinning at a rate of 10 rpm, with sensors mounted above on a fixed structure. Due to the primary mirror's material, the NASA-LMT was configured as a zenith telescope. Using 20 narrowband filters, it cataloged space debris in Earth's orbit.",1
"Dunn and his fiancée Rhonda Rouer traveled from their home in Brevard County to attend Dunn's son's wedding in Orange Park, near Jacksonville, Florida. Dunn and Rouer left the wedding early in order to return to their hotel and take care of their six-month-old puppy. On the way back to their hotel, the two decided to stop at the Gate Petroleum gas station to purchase a bottle of wine.Tommie",1
"Stornes, Leland Brunson, Jordan Davis, and Tevin Thompson had been spending the day traveling to various malls when they decided to go to the Gate Petroleum gas station in order to buy gum and cigarettes. The shooting of Jordan Davis took place in Jacksonville in Duval County. Around 7:30 p.m., four teenage boys (Leland Brunson, Jordan Davis, Tommie Stornes, and Tevin Thompson) stopped at a Gate Petroleum gas station. Stornes left his red Dodge Durango SUV running while he went into the store. Brunson, Davis, and Thompson remained in the vehicle listening to music which was described as ""very loud.""",1
"Stornes returned to the SUV, Davis' protests continued and an independent witness overheard Dunn say ""No, you're not gonna talk to me that way."" Dunn, who had a concealed weapons permit, took a handgun out of his glove compartment and started firing at Davis' door, hitting him in the legs, lungs, and aorta. As the SUV backed up to evade his gunshots, Dunn opened his own door and continued firing at the car in shooter's stance, as the boys ducked for cover.",1
"Dunn later testified that he still feared for his safety as well as that of Rouer who was to return to the vehicle imminently.After the shooting, Stornes drove the SUV away to a nearby parking lot and stopped to find Davis ""gasping for air"".Rouer returned to Dunn's car. They returned to their hotel where they ordered pizza. Dunn did not contact the police. The next morning Rouer saw a report about the shooting on the news indicating that Jordan Davis had died.",1
"Dunn testified that on the drive home he called a neighbor who works in law enforcement to arrange to speak to him about the shooting, but phone records indicate that the neighbor actually called him, and Rouer testified that the shooting was never mentioned during the call. Dunn returned to his home in Satellite Beach the following day at 10:30 a.m., where he was arrested after an eyewitness reported his license plate to police.After his arrest, Dunn claimed that Davis threatened him with a ""gun or a stick"".",1
"Dunn's fiancée, who served as an adversarial witness, said no such item was mentioned to her at any point. Investigators later searched the teenagers' SUV and found no weapons. Forensic scientists determined that in the short distance the boys traveled, a weapon could not have been stashed in a place that would not have been immediately visible to crime scene investigators. Contrary to Dunn's claim that he mentioned a weapon to Rouer, she testified that he never mentioned a gun either that night or the next day.",1
"Shortly after Davis's death, his parents, Ron Davis and Lucy McBath, and some of the other vehicle occupants, filed civil complaints against Dunn. They were represented by John Michael Phillips in wrongful death and defamation lawsuits against Dunn. The cases were settled for an undisclosed amount in January 2014. Dunn's insurance company, Progressive Select Insurance, challenged its duty to cover the lawsuit, but dismissed its lawsuit in conjunction with the settlement. In his criminal trial, Dunn had been declared ""broke.""In closing arguments at the first trial, the defense lawyer for Dunn cited the language of Florida's stand-your-ground law.On",1
"February 15, 2014, after more than 30 hours of deliberation, the jury found Dunn guilty on the three counts of attempted murder. The jury could not reach an agreement on the charge of first-degree murder, and the judge declared a mistrial on that count. Former Florida state attorney Angela Corey stated that her office would seek a retrial for this charge. Dunn's attorney subsequently requested that sentencing on the four counts of which Dunn already had been convicted be delayed until after Dunn's retrial.",1
"Dunn faced a minimum of 75 years in prison on the following counts: a minimum mandatory sentence of 20 years for each count of attempted second-degree murder, and up to 15 years for firing into a moving vehicle.Jury selection in Dunn's retrial began on September 22, 2014, and opening statements took place on September 25. Dunn was found guilty on October 1, 2014, at the conclusion of the retrial. Dunn was given a sentence of life in prison without parole plus 90 years.Following",1
"the trial, Dunn's attorney filed for appeal with the First District Court of Appeal for the State of Florida. On November 17, 2016, his appeal was denied.On June 22, 2020, the Florida Supreme Court rejected Dunn's appeal and refused to take the case. Dunn stated that he received ""ineffective assistance of counsel"". The justices did not explain their reasons behind the refusal.",1
"Dunn's former neighbor, Charles Hendrix, said he was not surprised by his behavior. Hendrix described Dunn as arrogant and controlling, adding that Dunn's ex-wives told him that Dunn was violent and abusive toward them, although he never personally witnessed this. Hendrix spoke of a previous discussion where Dunn asked him if he knew anyone who would ""take care of"" someone who infuriated him in an unrelated incident, and Hendrix interpreted further discussion as Dunn wanting to put a hit on this person.Davis'",1
"father Ron Davis said, ""I'm in constant contact with Tracy Martin, Trayvon's father, and I text Sybrina [Trayvon's mother] all the time and I just want to let them know, every time I get justice for Jordan, it's going to be justice for Trayvon, for us."" He said he wanted to confront Dunn in jail about his son's murder.Rebecca Dunn, Dunn's daughter, defended her father's story, by her statement during an interview, ""He is going to protect himself if he sees no other way than to bring out his gun, then that's what he's going to do.""",1
"She described Dunn as ""a good man. He's not a racist. He's very loving.""Davis' mother, Lucy McBath, ran for Congress in Georgia's 6th congressional district in 2018, running on a platform that included reform of gun laws. McBath cited the activism of students after the Stoneman Douglas High School shooting as a reason for her run. She defeated incumbent Karen Handel, winning 160,139 votes (50.5%) to Handel's 156,875 (49.5%). In 2020, she defeated Handel in a rematch to win reelection to a second term.",1
"Davis' murder is one of many referenced by social justice activists (including many black parents) as a reminder that unarmed children who died at the hands of police or white men mattered as individual human beings. ABC News, Australia says the case has become part of the national conversation about the dangers facing young black men in America today. The murder is believed to have inspired activism of the Black Lives Matter movement. During the 2016 Democratic National Convention, Davis' mother, Lucy McBath, talked about supporting the Black Lives Matter movement and said, ""His death doesn't overshadow his life.""The",1
"murder was one of the primary inspirations for the award-winning young adult novel Dear Martin, by Nic Stone. In January 2015, the documentary 3 ½ Minutes, 10 Bullets (originally titled 3 ½ Minutes) premiered at the Sundance Film Festival. The documentary, directed by Marc Silver, explores the shooting, the trial, and Florida's Stand Your Ground laws. The documentary won the U.S. Documentary Special Jury Award for Social Impact at the 2015 Sundance Film Festival. The film distribution was sold to HBO.Davis's story also features in the 2015 documentary film The Armor of Light, the directorial debut of Disney heir Abigail Disney.",1
"The film follows Rob Schenck, a pro-life Evangelical minister; Lucy McBath, the mother of teenager Jordan Davis; and attorney John Michael Phillips as they interact in the years after the shooting. The film debates the question: ""Is it possible to be both pro-gun and pro-life?"" The Armor of Light premiered at the Tribeca Film Festival in April 2015 before opening theatrically on October 30, 2015. Crime in Florida Mothers of the Movement Arrest and Booking Report of Incident, michaeldunntrial.com; archived from the original February 15, 2014. The Jordan Davis Foundation",1
"The composition of municipal solid waste varies greatly from municipality to municipality, and it changes significantly with time. In municipalities which have a well-developed waste recycling system, the waste stream mainly consists of intractable wastes such as plastic film and non-recyclable packaging materials. At the start of the 20th century, the majority of domestic waste (53%) in the UK consisted of coal ash from open fires. In developed areas without significant recycling activity it predominantly includes food wastes, market wastes, yard wastes, plastic containers and product packaging materials, and other miscellaneous solid wastes from residential, commercial, institutional, and industrial sources.",1
"Most definitions of municipal solid waste do not include industrial wastes, agricultural wastes, medical waste, radioactive waste or sewage sludge. Waste collection is performed by the municipality within a given area. The term residual waste relates to waste left from household sources containing materials that have not been separated out or sent for processing.",1
"Waste can be classified in several ways, but the following list represents a typical classification: Biodegradable waste: food and kitchen waste, green waste, paper (most can be recycled, although some difficult to compost plant material may be excluded) Recyclable materials: paper, cardboard, glass, bottles, jars, tin cans, aluminum cans, aluminium foil, metals, certain plastics, textiles, clothing, tires, batteries, etc. Inert waste: construction and demolition waste, dirt, rocks, debris Electrical and electronic waste (WEEE) – ⁣electrical appliances, light bulbs, washing machines, TVs, computers, screens, mobile phones, alarm clocks, watches, etc.",1
"Composite wastes: waste clothing, Tetra Pack food and drink cartons, waste plastics such as toys and plastic garden furniture Hazardous waste including most paints, chemicals, tires, batteries, light bulbs, electrical appliances, fluorescent lamps, aerosol spray cans, and fertilizers Toxic waste including pesticides, herbicides, and fungicides Biomedical waste, expired pharmaceutical drugs, etc.For example, typical municipal solid waste in China is composed of 55.9% food residue, 8.5% paper, 11.2% plastics, 3.2% textiles, 2.9% wood waste, 0.8% rubber, and 18.4% non-combustibles. The municipal solid waste industry has four components: recycling, composting, disposal, and waste-to-energy via incineration.",1
"The functional element of collection includes not only the gathering of solid waste and recyclable materials, but also the transport of these materials, after collection, to the location where the collection vehicle is emptied. This location may be a materials processing facility, a transfer station or a landfill disposal site.",1
Waste handling and separation involves activities associated with waste management until the waste is placed in storage containers for collection. Handling also encompasses the movement of loaded containers to the point of collection. Separating different types of waste components is an important step in the handling and storage of solid waste at the source of collection.,1
"This element involves two main steps. First, the waste is transferred from a smaller collection vehicle to larger transport equipment. The waste is then transported, usually over long distances, to a processing or disposal site.",1
"Landfills are created by land dumping. Land dumping methods vary, most commonly it involves the mass dumping of waste into a designated area, usually a hole or sidehill. After the waste is dumped, it is then compacted by large machines. When the dumping cell is full, it is then ""sealed"" with a plastic sheet and covered in several feet of dirt. This is the primary method of dumping in the United States because of the low cost and abundance of unused land in North America.",1
"has been a massive increase in construction and demolition waste created over the last 30 years in the United States. In 1990, 135 million tons of construction and demolition debris by weight were created and had risen to 600 million tons by the year 2018. This is a 300% increase, but it is important to note that since 2015 the EPA has kept records of how the waste is disposed of. In 2018, 600 million tons of waste was created due to construction and demolition, and 143 million tons of it resides in landfills.",1
"This means that about 76% of waste is now retained and repurposed in the industry, but there is still more waste being exported to landfills than the entire amount of waste created in 1990. This unsustainable consumption of raw materials creates increasing business risks. This includes higher material costs or disruptions in the supply chains. In 2010, the EPA created the Sustainable Materials Management (SMM) Program Strategic Plan which marked a strategic shift by the EPA to move emphasis from broad resource recovery initiative to sustainable materials management.",1
"Since material management regulations largely exist at a state and local level, this is no real standard practice across the nation for responsible waste mitigation strategies for construction materials. The EPA aims to increase access to collection, processing, and recycling infrastructure in order to meet this issue head on.",1
"Construction waste can be categorized as follows: Design, Handling, Worker, Management, Site condition, Procurement and External. These categories were derived from data collected from past research concerning the frequency of different types of waste noted during each type of these activities. Examples of this type of waste are as follows:",1
"Premixed concrete has one of the lowest waste indices when compared to other building materials. Many site managers site the difficulties controlling concrete delivery amounts as a major issue in accurately quantifying concrete needed for a site. The deviations from actually constructed concrete slabs and beams and the design amounts necessary were found to be 5.4% and 2.7% larger than expected, respectively, when comparing the data from 30 Brazilian sites. Many of these issues were attributed to inadequate form layout or lack of precision in excavation for foundation piles.",1
"Additionally, site managers know that additional concrete may be needed, and they will often order excess material to not interrupt the concrete pouring.",1
The second leading cause of construction waste production is inproper material storage. Exposure to the elements and miss handling by persons are due to human error. Part of this human error can lead to illegal dumping and illegal transportation volume of waste from a jobsite.,1
"Days after the chemicals were introduced to the community animals began dying. By the time the EPA deemed dioxins to be highly toxic in the 1980s, the CDC recommended the town be abandoned entirely due to contaminated waste products in the area. By 1985, the entire population of Times Beach had been relocated, prompting Missouri to build a new incinerator on the contaminated land. They continued to burn 265,000 tons of dioxin-contaminated waste until 1997. Dioxins are a family of chemicals produced as a byproduct during the manufacturing of many pesticides and construction materials like carpeting and PVC.",1
"These chemicals exist in the environment attached to soil or dust particles that are invisible to the naked eye. Dioxins break down slowly. It still threatens public health at low levels. Since industry has mostly stopped producing dioxins, one of the largest contributors releasing harmful dioxins left in the United States is waste incineration. Dioxins have been proven to cause cancer, reproductive and developmental issues, and immune system damage. Rates of cancer such as non-Hodgkin's lymphoma and soft tissue sarcoma rise significantly the closer one lives to the pollutants' source.",1
"Waste management fees, under the 'polluter pays principle', can help mitigate levels of construction waste. There is very little information on determining a waste management fee for construction waste created. Many models for this have been created in the past, but they are subjective and flawed. In 2019, a study method was proposed to optimize the construction waste management fee. The new model expands on previous ones by considering life-cycle costs of construction waste and weighs it against the willingness to improve construction waste management. The study was based out of China.",1
"China has a large waste management issue, and their landfills are mostly filled in urban areas. The results of the study indicated different waste management fees for metal, wood, and masonry waste as $9.30, $5.92, and $4.25, respectively. The cost of waste management per square meter, or just under 11 square feet, on average was found to be $0.12. This type of waste management system requires top-down legislative action. It is not a choice the contractor has the luxury of making on his/her own.",1
"In the European Union (EU), there is now significant emphasis on recycling building materials and adopting a cradle-to-grave ideology when it comes to building design, construction, and demolition. Their suggestions are much clearer and easier at the local or regional level, depending on government structure. In the 2016 EU Construction & Demolition Waste Management Protocol, they emphasize the benefits beyond financial gains for recycling such as job creation and reduced landfilling.",1
"The main points of how the Europeans choose to address this issue of waste management is through the utilization of the tools given to a governing body to keep its people safe. Unlike in the United States, the EU's philosophy on waste management is not that it is an optional good thing to do when you can but a mandatory part of construction in the 21st century to ensure a healthy future for generations to follow. Taxing landfill has been most effective in Belgium, Denmark and Austria, which have all decreased their landfill disposal by over 30% since introducing the tax.",1
"The United States has no national landfill tax or fee, but many states and local governments collect taxes and fees on the disposal of solid waste. The California Department of Resource Recycling and Recovery (CalRecycle) was created in 2010 to address the growing C&D waste problem in the United States. CalRecycle aids in the creation of C&D waste diversion model ordinance in local jurisdictions. They also provide information and other educational material on alternative C&D waste facilities. They promote these ordinances by creating incentive programs to encourage companies to participate in the waste diversion practices.",1
"There are also available grants and loans to aid organizations in their waste reduction strategies. According to a survey, financially incentivizing stakeholders to reduce construction waste demonstrates favorable results. This information provides an alternative way to reduce the cost so that the industry is more careful in their project decisions from beginning to end. Construction dust Demolition waste Recycling Concrete recycling Waste management COSHH Embodied carbon Construction Waste Management Database from the Whole Building Design Guide of the National Institute of Building Sciences",1
"Cyanotoxins can have both acute and chronic toxic effects, and there are often many consequences for the health of the environment where these occur as well.",1
"For some emerging contaminants, several advanced technologies—sonolysis, photocatalysis, Fenton-based oxidation and ozonation—have treated pollutants in laboratory experiments. Another technology is ""enhanced coagulation"" in which the treatment entity would work to optimize filtration by removing precursors to contamination through treatment. In the case of THMs, this meant lowering the pH, increasing the feed rate of coagulants, and encouraging domestic systems to operate with activated carbon filters and apparatuses that can perform reverse osmosis.",1
"The three main subsidiary bodies – the Working Group on Effects, the Steering Body to EMEP and the Working Group on Strategies and Review – as well as the Convention's Implementation Committee, report to the Executive Body each year. Currently, the Convention's priority activities include review and possible revision of its most recent protocols, implementation of the Convention and its protocols across the entire UNECE region (with special focus on Eastern Europe, the Caucasus and Central Asia and South-East Europe) and sharing its knowledge and information with other regions of the world.",1
"To calculate a critical load, the target ecosystem must first be defined and in that ecosystem (e.g. a forest) a sensitive ""element"" must be identified (e.g. forest growth rate). The next step is to link the status of that element to some chemical criterion (e.g. the base cation to aluminium ratio, Bc/Al) and a critical limit (e.g. Bc/Al=1) which should not be violated. Finally, a mathematical model (e.g. the Simple Mass Balance model, SMB) needs to be created so that the deposition levels that result in the chemical criterion reaching exactly the critical limit can be calculated.",1
"That deposition level is called the critical load and the difference between the current deposition level and the critical load is called exceedance. In the early days, critical loads were often calculated as a single value, e.g. critical load of acidity. Today a two-dimensional critical load function is often calculated, with the x-axis as N-deposition and the y-axis as S-deposition. The critical loads concept is a steady-state concept and that it therefore includes no information whatsoever regarding how long it takes before effects are visible.",1
"A simplified illustration of dynamic aspects is the target load function, which is the load at which the chemical criterion recovers before a chosen year, the target year. Thus, for target years in the near future the target load function is lower than the critical load and for target years in the distant future the target load function approaches the critical load function.",1
"Calculating critical load functions and target load functions include several simplifications and thus can be viewed as a risk concept: The higher the exceedance the higher the risk for adverse effects and there is a certain risk that zero exceedance will still lead to adverse effects. In the U.S., while various entities were discussing critical loads prior to 2000, efforts were independent and disjointed.",1
"The steady-state mass balance model calculates the critical load of an ecosystem over the long-term by defining acceptable values for elements leaching out of the ecosystem. Although empirical nitrogen critical loads have been well summarized for Europe and the United States, large uncertainties still exist in Asia due to very limited and short-term experimental studies by using relatively high levels of nitrogen application. In regions (e.g.,",1
"eastern and southern China) where historical nitrogen deposition has already been very high and perhaps even higher than the actual critical load, experimental studies may fail to quantify the critical loads because substantial ecosystem changes had already occurred. Moreover, the values of the critical loads can vary remarkably when based on different biological or chemical response of an ecosystem, such as physiological variation, reduced biodiversity, elevated nitrate leaching, and changes in soil microorganisms. Empirical critical loads have been assessed for some forests and grasslands in China, but the values for many other ecosystems remain unassessed.",1
"Modern cruise ships evolved from ocean liners, which were the most common mode of transportation between Europe and the Americas until the rise of commercial aviation in the 1950s. Airliners drastically cut trans-Atlantic travel times and formed unbeatable competition for ocean liners in terms of speed. To survive, the sector began to transform its ocean liners into cruise ships in the mid-1960s by attracting passengers by focusing the voyage on recreation and sightseeing, and less on getting travellers from A to B.",1
"Cruise lines such as Norwegian (1966), Royal Caribbean International (1968) and Carnival Cruise Line (1972) were founded in rapid succession, and over the course of years managed to expand by building ever larger cruise ships with more and more passengers (21 million globally in 2013), which increasingly negatively impacted the environment. According to a 2019 study by Transport & Environment, the following European port cities were most polluted by cruise ships docking there (data from 2017): Barcelona, Spain: 32.8 tonnes of SOx Palma de Mallorca, Spain: 28 tonnes of SOx Venice, Italy: 27.5",1
"tonnes of SOx Southampton (including Marchwood), United Kingdom: 27.1 tonnes of SOx Civitavecchia (near Rome), Italy: 22.3 tonnes of SOx Piraeus (near Athens), Greece: 21 tonnes of SOx Funchal (on Madeira), Portugal: 18 tonnes of SOx Livorno, Italy: 16.3 tonnes of SOx Lisbon, Portugal: 16.1 tonnes of SOx Santa Cruz de Tenerife, Spain: 15.6",1
"2018 study carried out by Naturschutzbund Deutschland (Nature Protection League Germany, NABU) reviewed the emissions of 77 cruise ships (almost the entire fleet in European waters), concluding that only one of them, AIDAnova, was not powered by highly polluting heavy fuel, but relatively 'clean' liquefied natural gas (LNG), which reduces NOx and particulate emissions by about 80%. However, even though shifting all cruise ships to LNG would be very beneficial to human health, LNG also contains methane, which is a very potent greenhouse gas and could increase global warming significantly through leaks and incomplete combustion.",1
The emissions contribute to ocean acidification and soil acidification. Nitrogen oxides also stimulate particle and ozone formation.,1
"That year, over 600 passenger ships docked in Venice, about 300 of which were categorised as mega-cruises (featuring thousands of passengers and ten decks), together carrying between 1.6 and 2 million passengers. In subsequent years, the city of Venice, for whom tourism is of critical importance, tried to reach a compromise with cruise lines, but in August 2014 the Italian government interfered by prohibiting ships surpassing the weight of 96,000 tonnes from getting near the historic centre in 2015.",1
"Plans to divert a third of the cruises were announced by Transport Minister Danilo Toninelli in August 2019, after MSC Opera crashed into a smaller river cruise ship and a quay in Venice on 2 June 2019, injuring five people; however, Toninelli's plans were criticised as unrealistic by activists and other politicians.",1
"Protesters in the Port of Antwerp, whose 2019 anti-cruise petition was supported by 15,000 citizens, noted the paradox that the city of Antwerp has a low-emission zone for cars and other road vehicles, but highly pollutive cruise ships can just dock close to the city centre with only minor restrictions.",1
"In 2016, Princess Cruises (a British-American subsidiary of Carnival Corporation that operates in Europe and North America) was condemned by the Court of Miami to pay 40 million U.S. dollars in damages for illegally dumping oil at sea in order to cut waste disposal costs. Initially, it was sued only for dumping 4,227 gallons (16,000 litres) of oil-contaminated waste about 20 miles (32 kilometres) off the coast of England on 26 August 2013 using a ""magic pipe"" from the Caribbean Princess.",1
"July 2018, for the first time in the French Mediterranean, the captain of a cruise ship, MS Azura, stood trial for breaking fuel emission limits in the port of Marseille.",1
"Catalytic converters could be installed to reduce the emissions of ships. In shipping, these are known as scrubbers. According to Cruise Lines International Association (CLIA), 60% of cruise ships already had a scrubber installed as of April 2019. This installation could be made mandatory by the EU. MSC Cruises claims that its MSC Grandiosa (built in 2016) has several filters which reduce its gas oil sulphur oxide emissions by 97%, and nitrogen oxide emissions by 80%.",1
"However, in October 2019 The Independent warned that most of the recently installed scrubbers (3,756 on ships, amongst which many cruise ships) were 'open-loop scrubbers', that enable sulphur extracted from the fumes to be transformed into a liquid that can be illegally discharged into the sea. These therefore constituted ""cheat devices"", intended to appear to comply with the IMO 2020 regulation, while violating it in reality. Only 65 out of the 3,756 scrubbers were closed-loop and could not be exploited for sulpher extract dumpings at sea, but only opened on land for the appropriately safe disposal there.There",1
"In 2014, the design replaced the central platform with a tower detached from the floating barriers. This platform would collect the plastic using a conveyor belt. The floating barrier was proposed to be 100 km long. They conducted and published a feasibility study.In 2015, this design won the London Design Museum Design of the Year, and the INDEX: Award. Later that year, scale model tests were conducted in wave pools at Deltares and MARIN, testing the dynamics and load of the barrier in ocean conditions, and gathering data for computational modeling.A",1
"100-metre segment went through a test in the North Sea in the summer of 2016. The test indicated that conventional oil containment booms would not stand up over time, and they changed the floater material to a hard-walled HDPE pipe.In May 2017, significant changes to the conceptual design were made: Dimensions were reduced from 100 km to 2-kilometre (1.2 mi), with the idea of using a fleet of 60 such systems.",1
"Seabed anchors were replaced with sea anchors, to drift with the currents, allowing the plastic to ""catch up"" with the cleanup system, and letting the system drift to locations with the highest concentration of debris. The lines to the anchor would keep the system in a U-shape. An automatic system for collecting plastic was replaced with a system for concentrating the plastic before removal by support vessels.",1
"Tests in 2018 led to sea anchors being removed, and the opening of the U turned to face the direction of travel, by creating more drag in the middle with a deeper underwater screen.On 9 September 2018, System 001 (nicknamed Wilson in reference to the floating volleyball in the 2000 film Cast Away) deployed from San Francisco. The ship Maersk Launcher towed the system to a position 240 nautical miles off the coast, where it was put through a series of sea trials. It consisted of a 600 m (2,000 ft) long barrier with a 3 m (9.8",1
"In December, mechanical stress caused an 18-meter section to detach, and the rig was moved to Hawaii for inspection and repair. During the two months of operation, it had captured 2 metric tons of plastic.In June 2019, after four months of root cause analyses and redesign, System 001/B was deployed, with a water-borne parachute to slow the system, and an extended cork line to hold the screen in place. This successfully captured smaller plastic, reduced the barrier size by two-thirds, and was easier to adjust offshore.",1
"In October 2019, The Ocean Cleanup unveiled a floating barrier for river cleanup, The Interceptor, to intercept river plastic and prevent it from reaching the ocean. Two systems were deployed in Jakarta (Indonesia) and Klang (Malaysia).In January 2020, flooding broke the barrier of Interceptor 001 in Jakarta. It was replaced with a newer model with a stronger screen, simpler design, and an adjustable better-defined weak link. A third Interceptor was deployed in Santo Domingo, in the Dominican Republic. In December, The Ocean Cleanup announced they would start large-scale production of the Interceptor series.In",1
"July 2022, an Interceptor Original was deployed near the mouth of Ballona Creek in southwestern Los Angeles County, California. This was the first Interceptor Original installed in the United States, and the second of its kind to be deployed globally.In May 2022, the Ocean Cleanup trialed a new Interceptor called Trashfence on the Rio Las Vacas in Guatemala. It was anchored to the riverbed, and the anchors washed out. In April 2023, they returned with a pair of new Interceptors, at a point on the river with slower current, anchored to the riverbank.",1
"This was successful, and soon became their most prolific site; by June 13, they had already removed 850 tonnes of plastic from the river.",1
"In July 2021, a new design called System 002, also known as ""Jenny"", was deployed in the Great Pacific Garbage Patch for testing. In October, the organization announced that the system had gathered 28,000 kilograms (62,000 lb) of trash. In October, the project announced plans for System 03, which would span up to 2.5 km (1.6 mi).By December, the project announced it had removed more than 150 tonnes of plastic from the Great Pacific Garbage Patch and announced it would transition to the new longer System 03 the following year.In",1
"System 03 was estimated to have 5x the capacity of System 002, which is why they dropped a 0 from the naming scheme: [O]ur modeling suggests it may be possible to clean the entire GPGP with as few as 10 systems. That’s why we knocked off one of the zeroes from ‘002’ when we named ‘03’ – we no longer need a three-figure amount of systems to clean all five ocean garbage patches around the world.",1
"Trash Wheel developed in 2008 for Maryland's Baltimore harbor. In 2021, The Ocean Cleanup began expanding their Interceptor systems to be able to tackle a wider range of rivers. The Interceptor Barricade developed for Rio Las Vacas in 2023 was the first model designed for very high-throughput rivers that may carry 10,000 kg of trash a day.",1
"September and October 2016, The Ocean Cleanup launched the Aerial Expedition, in which a C-130 Hercules aircraft conducted the first ever series of aerial surveys to map the Great Pacific Garbage Patch. The goal was specifically to quantify the amount of large debris, including ghosts nets in the patch. Slat stated that the crew saw more debris than expected.The project released an app called The Ocean Cleanup Survey App, which enables others to survey the ocean for plastic, and report their observations.",1
"In February 2015, the research team published a study in Biogeosciences about the vertical distribution of plastic, based on samples collected in the North Atlantic Gyre. They found that plastic concentration decreases exponentially with depth, with the highest concentration at the surface, and approaching zero just a few meters deeper. A follow-up paper was published in Scientific Reports in October 2016. In June 2017, researchers published a paper in Nature Communications, with a model of the river plastic input into the ocean. Their model estimates that between 1.15 and 2.41",1
"The study suggests that the amount of plastic in the patch increased exponentially since 1970.In September 2019, they published a paper in Scientific Reports studying why emissions into the ocean are higher than the estimates of debris accumulated at the surface layer of the ocean. They argue that debris circulation dynamics offer an explanation for this missing plastic and suggest that there is a significant amount of time between initial emissions and accumulation offshore. The study also indicated that current microplastics are mostly a result of the degradations of plastic produced in the 1990s or before.",1
"That's important, but when we head out on the ocean, that's not necessarily what we find."" The Ocean Cleanup raised over 2 million USD with the help of a crowdfunding campaign in 2014.As of 2019, it was mainly funded by donations and in-kind sponsors, including Maersk, Salesforce.com chief executive Marc Benioff, Peter Thiel, Julius Baer Foundation, The Coca-Cola Company and Royal DSM.In 2019, it received a 10 million AUD award from the Macquarie Group Foundation as part of its 50th anniversary celebration.In",1
"Criticisms and doubts about method, feasibility, efficiency and return on investment have been raised in the scientific community. Miriam Goldstein, director of ocean policy at the Center for American Progress, stated in 2019 that compared to the ocean system, devices closer to shore are easier to maintain, and would likely recover more plastic per dollar spent overall.The team has expressed their own concerns that the devices could imperil sea life, including neustons, communities of pleustons, Portuguese man-of-war, sea snails, and sail jellyfish that live near the ocean surface, and have monitored for such impacts.",1
"Corby became a steelmaking centre through the establishment of the Stewarts & Lloyds production site in the 1930s, and by 1960 had grown to become one of the most heavily industrialised areas in the Midlands. In 1981 however the plant had become unprofitable and owners British Steel Corporation closed the site. By then it was one of the largest steelmaking operations in Western Europe, covering 680 acres (280 ha), with four blast furnaces, two coke oven complexes and associated facilities. During its operation a huge quantity of industrial waste, including toxic waste, had been deposited there.Between",1
"1984 and 1999 Corby Borough Council undertook the demolition, excavation and redevelopment of the site as part of a program of urban regeneration. This involved transporting the waste through populated areas to a quarry north of the site, utilising up to 200 vehicle movements daily. The toxic waste was carried in open lorries, spilling sludge over the roads and releasing huge amounts of dust into the air.Subsequently,",1
"in the late 1980s and 1990s, the rates of upper-limb defects in babies born in Corby were found to be almost three times higher than those of children born in the surrounding area and ten times higher than a town with a population of 60,000 should expect. In all cases initially referred to the court there were no previous family histories of limb defect.",1
"In November 2005 expert evidence was submitted to the High Court in London by the mothers of thirty children who claimed that during their pregnancies they were exposed to contamination from the waste removal operations and who sought to bring a legal action to try to prove a link between the mismanagement of the toxic waste and the birth defects suffered by their children. The evidence presented included reports detailing the higher rate of birth defects, and alleging that exposure to the toxic waste was the likely cause of the children's deformities.",1
"reviewing the evidence presented by all parties to the case, an order approved by the then Lord Chief Justice, Lord Phillips of Worth Matravers, set out the terms of the litigation in relation to the council's management and execution of the ""land reclamation contracts"" between 1985 and 1999 and any duty they had to the families, and permission was given for the parents to pursue the claim against Corby Borough Council as a class action involving children born between 1985 and 1999.",1
"The case to be heard at the High Court in 2009 represented 18 young people who alleged that toxic waste dumped by Corby Borough Council between 1984 and 1999 was the cause of their deformities. All had serious disabilities, including missing or underdeveloped fingers and deformities of their feet. They alleged that their mothers ingested or inhaled the toxic substances that affected the development of their limbs while they were still in the womb. All of their mothers either lived in or regularly visited Corby between 1984 and 1999 when the work was carried out across the town.",1
"presence and locations of the toxic waste was known before work began, having been stored in purpose-built ""pits"" around the site by British Steel, ""in a form which was of no danger to anyone unless they fell in. But the effect of the works undertaken was to remove the majority of these materials and move them a long distance to other areas of Corby, and this involved vast numbers of vehicle movements.""Professor Louise Parker PhD, Professor of Pediatrics and Community Health and Epidemiology at Dalhousie University, Halifax, Nova Scotia, Canada, testified that between 1989 and 1998 children in Corby were 2.5",1
"times more likely to be born with upper limb defects than in the rest of the Kettering Health Authority area, which was statististically ""quite significant"". An internal report prepared by Corby Borough Council was uncovered which had raised the prospect of residents being exposed to high levels of zinc, arsenic, boron and nickel as a result of the reclamation works, and a separate report, from the council’s auditor, complained of incompetence and negligence by the council and said there was a ""cavalier approach"" to the operation.",1
"The families' counsel submitted that whether Corby Borough Council knew or should have known that the substances being transported around the town could have been hazardous to health was ""hardly rocket science"".Further, Wilby submitted that the Council committed a criminal act when they allowed the movement of toxic waste without a licence: in 1986 there was no proper permission in place for moving the contaminated waste, only for moving 'inert' waste. Inspectors were not told the true nature of the substances involved and so took only sporadic samples from the site.",1
"Wilby said that the council had deliberately ignored the advice from experts to properly analyse the site because it was going to be an expensive task. He said: ""They decided they were going to do this 'dig-and-dump'. They thought 'we have got this great deal of land and all this spoil on this site which must be contaminated, we have got to get it off there because we'll never be able to sell it.'"" Records demonstrated that in one test which took place in 1983 only five soil samples were collected to represent a 30-acre (120,000 m2) area.",1
"In his ruling, Mr Justice Akenhead said it was clear that the council had permitted toxic waste to disperse into the atmosphere. He also said that there was a ""statistically significant"" cluster of birth defects between 1989 and 1999, and that, ""toxicologically, there were present on and from the Corby Borough Council sites, over the whole period from 1985 (and possibly before) until 1997, the types of contaminants which could cause the birth defects complained of.""",1
"That negligence and, as from April 1, 1992, breach of statutory duty on the part of CBC permitted and led to the extensive dispersal of contaminated mud and dust over public areas of Corby and into and over private homes, with the result that the contaminants could realistically have caused the types of birth defects of which complaint has been made by the claimants (save in limited respects)...",1
"Corby Borough Council is liable in public nuisance, negligence and breach of statutory duty, obviously subject to it being established in later proceedings by individual claimants that their particular conditions were actually caused by the defaults identified in this judgment.""The two youngest claimants, nine-year-old India Harrison and ten-year-old Ashleigh Jane Custance, were unable at that time to proceed with their cases, however, because of the ruling that there were no breaches of duty after August 1997. Their parents indicated that they would appeal this cut-off date.",1
"The families' lawyer, Des Collins, said: ""Prior to the trial, the council maintained that a thorough investigation had led it to the conclusion that there was no link between the reclamation work and the children's birth defects. It also maintained that had any convincing evidence been shown that the children had good claims then the council would have wanted to compensate them appropriately without going to trial. Today that link has been established and the evidence provided. The children now call upon the council to fulfil their pre-trial promises without delay.""",1
"Collins said of the legal battle: ""I've been made out to be a shyster and an ambulance-chaser. The council has stonewalled, obstructed and prevaricated all the way through this. They didn't need to. If they'd ever said to us, 'Look, we're not admitting liability, but we'll co-operate with you to find out what really happened', I wouldn't have minded. Instead, they tried to shut us out and paint us as the baddies... They've tried at every turn to stop us getting at the truth. Now they claim they can't afford to pay. I'm not impressed.""Corby",1
"Borough Council's Chief Executive Chris Mallender said: ""We are obviously very disappointed and very surprised at the outcome of this trial. Our position has always been that there was no link between the reclamation work that was carried out in Corby in past decades and these children's birth defects. That is still our position."" He also said they were ""prepared to apologise for mistakes that had been made but could not apologise until a causal link was proved between the works and the defects... We are not yet at the point of saying sorry because nobody yet is responsible.""The",1
"council's legal representatives said they were asked to advise on an appeal but had over 400 pages of judgment to review and also their client had to consider its position. The firm said it would be a few weeks before it has instructions. The statement added: ""There are however some clear points to note at this stage. The case involves reclamation work going back to the 1980s. The judge concluded that this contamination affected pregnant women.",1
"A child, so affected, has 21 years from birth to make a claim and thus any work since the late 1980s which has not met the standard of care indicated in this judgment could be challenged in this way. For both local authorities and developers alike this is a significant concern because the standard of care has been drawn very highly, and could cause a rethink of the way that reclamation is carried out in the UK even though the facts of the case are historic.""Kelvin",1
"Unusually, the authority decided that openness and public opinion were required at the extraordinary full council sitting after which councillors will vote on whether to appeal or instead pay the compensation to 16 children who were born with birth defects.Chief Executive Chris Mallender stated: ""The council is doing the right thing by reaching the decision in public. We will be starting the meeting at 6pm so we can give the opportunity for [the public] to speak,"" a move he said would make sure councillors' decisions reflected public opinion.The council, which has an annual budget of £12m, has already spent £1.9m",1
"fighting the case and has now received a bill for £4.7m from the families' solicitor.At the meeting the council voted to appeal against the ruling but said that they would follow a ""twin track"" approach, preferring to attend independent mediation sessions to come to an out-of-court settlement with the families. They also stated that any mediation would include the cases of the two youngest claimants despite these not being covered by the ruling.",1
"The chief executive gave a statement that if a causal link between the toxins and the limb deformities was ever proven he would ""offer an unreserved apology"", however he believed ""that the judgement is unsound and will be found wanting on appeal."" The settlement was mediated by retired judge Sir Henry Brooke. Before settlement had been reached, Chris Mallender explained: ""We have reached a view that there are going to be no outright winners in this.",1
"In the circumstances we feel that it's better that we try and find a middle ground, we settle in a way that's fair to the families, but is also fair in terms of the residual burden on the council tax payer.""On 16 April 2010 the council released a joint statement with the families' solicitors announcing it was dropping its appeal and had agreed a financial settlement with 19 families. Chris Mallender said: ""The council recognises that it made mistakes in its clean-up of the former British Steel site years ago and extends its deepest sympathy to the children and their families.",1
"Although I accept that money cannot properly compensate these young people for their disabilities and for all that they have suffered to date and their problems in the future, the council sincerely hopes that this apology coupled with today's agreement will mean that they can now put their legal battle behind them and proceed with their lives with a greater degree of financial certainty."" The financial terms of the settlement remained confidential, and the agreement forbids disclosure of the financial arrangements.",1
"On the subject of cost, Mallender said: ""Every £1m of cost involves a payment £5 per household in Corby on average, per year, for the next 20 years. So, simple maths: if the overall bill is £5m, it's £25 per household for 20 years.""The settlement also encompassed three children not covered by the original ruling, including India Harrison and Ashleigh Custance.",1
"Paula Jefferson, head of Beachcroft LLP's Disease Group, said: ""Any organisation involved in any activity in the future, where there is the potential for release of harmful substances in to the atmosphere, should ensure that they have taken all necessary steps to identify the potential contamination and to then ensure that they either employ, or have themselves the necessary skills, to deal with that contamination. The principles in the judgment apply not just when there is demolition in progress, but to any activity where there is potential for exposure in to the atmosphere.",1
"Where there is any known potential for such exposure, then regard should be had to not just the onsite workforce but also to those living and working in the surrounding area. In the Corby case the area of risk was 4km from the demolition site. The area for potential exposure will clearly vary depending on the circumstances of each case.",1
"More than 46,000 commercial vessels — tankers, bulk carriers, container ships, barges, and passenger ships — travel the oceans and other waters of the world, carrying cargo and passengers for commerce, transport, and recreation. Their activities are regulated and scrutinized in a number of respects by international protocols and U.S. domestic laws, including those designed to protect against discharges of pollutants that could harm marine resources, other parts of the ambient environment, and human health. However, there are overlaps of some requirements, gaps in other areas, geographic differences in jurisdiction based on differing definitions, and questions about the adequacy of enforcement.Public",1
"Foreign-flag cruise vessels owned by six companies account for nearly 95% of passenger ships operating in U.S. waters. Each year, the industry adds new ships to the total fleet, vessels that are bigger, more elaborate and luxurious, and that carry larger numbers of passengers and crew. Over the past two decades, the average ship size has been increasing at the rate of roughly 90 feet (27 m) every five years. The average ship entering the market from 2008 to 2011 will be more than 1,050 feet (320 m) long and will weigh more than 130,000 tons.To",1
"the cruise ship industry, a key issue is demonstrating to the public that cruising is safe and healthy for passengers and the tourist communities that are visited by their ships. Cruise ships carrying several thousand passengers and crew have been compared to “floating cities,” in part because the volume of wastes produced and requiring disposal is greater than that of many small cities on land.",1
"However, particular types of wastes, such as sewage, graywater, and solid waste, may be of greater concern for cruise ships relative to other seagoing vessels, because of the large numbers of passengers and crew that cruise ships carry and the large volumes of wastes that they produce. Further, because cruise ships tend to concentrate their activities in specific coastal areas and visit the same ports repeatedly (especially Florida, California, New York City, Galveston, Seattle, and the waters of Alaska), their cumulative impact on a local scale could be significant, as can impacts of individual large-volume releases (either accidental or intentional).",1
"These procedures require substantial coordination between the Coast Guard, the State Department, and other flag states, and the response rate from flag states has been poor. In the United States, several federal agencies have some jurisdiction over cruise ships in U.S. waters, but no one agency is responsible for or coordinates all of the relevant government functions. The U.S. Coast Guard and EPA have principal regulatory and standard-setting responsibilities.Cruise ships that are 79 feet (24 m) in length or greater, are subject to the requirements of the EPA Vessel General Permit (VGP). The most recent VGP was published in 2013.",1
"In addition, the Department of State represents the United States at meetings of the IMO and in international treaty negotiations and is responsible for pursuing foreign-flag violations. Other federal agencies have limited roles and responsibilities. For example, the National Oceanic and Atmospheric Administration (NOAA, Department of Commerce) works with the Coast Guard and EPA to report on the effects of marine debris. The Animal and Plant Health Inspection Service (APHIS) is responsible for ensuring quarantine inspection and disposal of food-contaminated garbage (these APHIS responsibilities are part of the Department of Homeland Security).",1
"In some cases, states and localities have responsibilities as well.",1
"On some cruise ships, especially many of those that travel in Alaskan waters, sewage is treated using Advanced Wastewater Treatment (AWT) systems that generally provide improved screening, treatment, disinfection, and sludge processing as compared with traditional MSDs (marine sanitation devices). AWTs are believed to be very effective in removing pathogens, oxygen-demanding substances, suspended solids, oil and grease, and particulate metals from sewage, but only moderately effective in removing dissolved metals and nutrients (ammonia, nitrogen and phosphorus).States may also establish no-discharge zones (NDZs) for vessel sewage, under section 312.",1
"Graywater discharges from large cruise ships are regulated by the 2013 VGP.Pursuant to a state law in Alaska, greywater must be treated prior to discharge into that state's waters.",1
"Cruise ship discharges of solid waste are governed by two federal laws. Title I of the Marine Protection, Research and Sanctuaries Act makes it illegal to transport garbage from the United States for the purpose of dumping it into ocean waters without a permit or to dump material from outside the U.S. into U.S. waters. Beyond U.S. waters, no MPRSA permit is required for a cruise ship to discharge solid waste. The routine discharge of effluent incidental to the propulsion of vessels is explicitly exempted from the definition of dumping in the MPRSA.28The",1
"The Resource Conservation and Recovery Act (RCRA) is the primary federal law that governs hazardous waste management. The owner or operator of a cruise ship may be a generator and/or a transporter of hazardous waste, and thus subject to RCRA rules. Issues that the cruise ship industry may face relating to RCRA include ensuring that hazardous waste is identified at the point at which it is considered generated; ensuring that parties are properly identified as generators, storers, treaters, or disposers; and determining the applicability of RCRA requirements to each.",1
"RCRA rules that cover small-quantity generators (those that generate more than 100 kilograms but less than 1,000 kilograms of hazardous waste per month) are less stringent than those for large-quantity generators (generating more than 1,000 kilograms per month), and it is unclear whether cruise ships are classified as large or small generators of hazardous waste. Moreover, some cruise companies argue that they generate less than 100 kilograms per month and therefore should be classified in a third category, as “conditionally exempt small-quantity generators,” a categorization that allows for less rigorous requirements for notification, recordkeeping, and the like.In",1
"flagged ships anywhere in the world and to all foreign flagged vessels operating in the navigable waters of the United States, or while at a port under U.S. jurisdiction. To implement APPS, the Coast Guard has promulgated regulations prohibiting the discharge of oil or oily mixtures into the sea within 12 nautical miles (22 km) of the nearest land, except under limited conditions. However, because most cruise lines are foreign registered and because APPS only applies to foreign ships within U.S. navigable waters, the APPS regulations have limited applicability to cruise ship operations.",1
"In addition, most cruise lines have adopted policies that restrict discharges of machinery space waste within three miles (5 km) from shore.",1
"The TerraMar Project was founded on 26 September 2012 at the Blue Ocean Film Festival and Conservation Conference in Monterey, California, and focused on the 64% of the ocean that lies outside any single country's jurisdiction. Their mission was to create a ""global ocean community"" based around the idea of shared ownership of the global commons, also known as the high seas or international waters.In 2014, on behalf of the TerraMar Project, Maxwell gave a lecture at the University of Texas at Dallas and later that year, a TED talk, about the importance of ocean conservation.",1
"Maxwell also spoke at the United Nations as the founder of the TerraMar Project. She accompanied Stuart Beck, a 2013 TerraMar board member, to two United Nations meetings to discuss the project. Maxwell presented at the Arctic Circle Assembly in Reykjavík, Iceland in 2013.Scott Borgerson, listed on TerraMar's board of directors for 2013, appeared with Maxwell at the Arctic Circle conference. In June 2014, Maxwell and Borgerson spoke at an event in Washington, DC sponsored by the Council on Foreign Relations, titled “Governing the Ocean Commons: Growing Challenges, New Approaches”.",1
"TerraMar's commitment to advancing the Sustainable Development Goals (SDG) was showcased by the Clinton Global Initiative.Tax documents for U.S. organization the TerraMar Project consistently list Ghislaine Maxwell as the organization's President. The TerraMar Project's address was in New York City for Form 990 tax filings from 2012 through 2015, with later filings showing a Woburn, Massachusetts address for 2016 and 2017. The New York Times reported that TerraMar gave out no money in grants between 2012 and 2017 and that it was described as having unusually high accounting and legal fees for an organization of its size.Questions",1
"were also raised about what TerraMar entailed beyond the high profile appearance by Maxwell at the United Nations and on the TED stage. In 2017, an executive at a maritime firm made multiple requests for project funding to TerraMar's development director Brian Yuratsis that were ultimately denied despite Yuratsis professing interest in having TerraMar sponsor the project. The maritime executive who made the requests stated that “My impression was that TerraMar as a whole was pretty hollow”, and that “It seemed like Brian was the entire organization.”On",1
"the organization's IRS annual return, the organization reported that it owed $560,650 to Ghislane Maxwell, it owed $1,341 of credit card debt, and it had $10,252 of cash, as of 31 December 2018. During 2018, the organization had spent $5,365 for professional fees, $9,380 for website development, $11,157 for advertising, and $270 of bank fees, but it spent nothing toward program services.Epstein was charged with new sex trafficking crimes on 6 July 2019. Epstein was a close associate of Maxwell. The TerraMar Project announced its closure six days later, on 12 July 2019, via Twitter and a statement on its website.",1
"TerraMar (UK) was a separate private limited company in the United Kingdom. It was incorporated in August 2013 in England and Wales, with the directors being Maxwell, Lucy Clive and Catherine Vaughan-Edwards. The company was run by Maxwell with a similar mission to the TerraMar Project.The mission of the charity TerraMar (UK) was published as ""the conservation, protection, and improvement of the environment"" and, in particular, ""the oceans, seas, coastlines and tidal areas"", including ""the conservation and protection of endangered marine flora and fauna, and the education of the public in the fields of marine conservation, marine ecology and related areas"".TerraMar",1
"(UK) was reported by The Times to have joined the ""secretive messenger app service"" on 10 August 2019, the same date on which Epstein died in prison. The application for the UK organization to be officially closed was made on 4 September 2019, with the first notice in The London Gazette made on 17 September 2019.The company was listed as active, with a Salisbury address, until the company was listed as officially dissolved on 3 December 2019.",1
"TerraMar's founder, Ghislaine Maxwell, was arrested in July 2020 and charged with six counts related to the sexual abuse and trafficking of minors and lying to investigators. On 29 December 2021, Maxwell was convicted on five of six charges. The Board of Directors of the TerraMar Project (US) included former Executive Director of the United Nations Office for Partnerships (UNOP) Amir Dossal – who handles $1 billion in the form of a grant from Ted Turner for charities, media executive Steven Haft, and Ariadne Calvo-Platero, daughter of the peer Lord Beaumont of Whitley, Maxwell’s best friend from Oxford.",1
Global Commons International Waters Sustainable Development Goals Archive of past versions of The TerraMar Project,1
"FCV), the ESB (micrograms per gram OC) is calculated as: ESB = KOCFCV(1/1000) The calculated ESB is site-specific.",1
"The equation for the bioavailable concentration for cationic metals including cadmium, copper, nickel, lead, silver and zinc that incorporates the AVS phase is as follows: Cd = (SEM-AVS) / (ƒOCKOC) SEM = simultaneously extract metals",1
"The EPA Office of Research and Development (ORD) has published ESBs for approximately 65 pollutants or classes of pollutants. Five documents describing the derivation of 34 PAHs, nonionic organics, metal mixtures (e.g., cadmium, chromium, copper, nickel, lead, silver, and zinc), and pesticides dieldrin and endrin are available on EPA's SQG Technical Resources website. EPA recommends using the ESB approach for the above-mentioned classes of chemicals as well as other nonionic chemicals with hydrophobic chemicals with logKOW > 2.00 and sediments containing TOC ≥ 0.2% dry weight (ƒOC = 0.002).",1
"ESBs are different from other SQGs because they are mechanistically derived using chemical and physical properties. Other SQGs have been derived empirically using databases of synoptically collected sediment chemistry and biological effects. Other SQGs include the apparent effects threshold (AET), effects range low/effects range median (ERL/ERM), threshold effects level/probable effect level (TEL/PEL), and a logistical model. ESBs do not predict bioaccumulation or trophic transfer to wildlife and humans, which are important considerations in ecological risk assessment. Bioaccumulative chemicals like polychlorinated biphenyls (PCBs) and mercury often affect upper trophic level organisms more seriously than benthic organisms.",1
"ESBs, however, are specifically designed for the protection of benthic organisms. As a consequence, the broader ecological risks of bioaccumulative chemicals are not accounted for in the ESB approach. A second limitation is that the ESB approach assumes that nonionic organic contaminants are associated with the organic carbon portion of the sediment. Recent studies have shown that some organic contaminants are associated with another form of carbon called ""black carbon"". If black carbon constitutes a large fraction of sediment and is not accounted for because only TOC measurements are in the ESB calculation, then ESBs may be overprotective.",1
"A final limitations is that ESBs do not always consider the antagonistic, additive or synergistic effects of sediment contaminants. For the specific cases of metal mixtures and individual PAHs, ESBs do take into account additive effects.",1
"Thomas Midgley Jr. was born in Beaver Falls, Pennsylvania, on May 18, 1889, the son of Hattie Louise (née Emerson) (1865 – 1950) and Thomas Midgley Sr. (1840 – 1934). His family had a history of inventing; his father was an inventor in the field of automobile tires while his maternal grandfather, James Emerson, invented the inserted tooth saw. He grew up in Columbus, Ohio, and graduated from Cornell University in 1911 with a degree in mechanical engineering.",1
"In 1916, Midgley began working at General Motors. In December 1921, while working under the direction of Charles Kettering at Dayton Research Laboratories, a subsidiary of General Motors, he discovered (after discarding tellurium due to the difficult-to-eradicate smell) that the addition of tetraethyllead (TEL) to gasoline prevented knocking in internal combustion engines. The company named the substance ""Ethyl"", avoiding all mention of lead in reports and advertising.",1
"Over the course of the next year, eight more people died at DuPont's plant in Deepwater, New Jersey. In 1924, dissatisfied with the speed of DuPont's TEL production using the ""bromide process"", General Motors and the Standard Oil Company of New Jersey (now known as ExxonMobil) created the Ethyl Gasoline Corporation to produce and market TEL. Ethyl Corporation built a new chemical plant using a high-temperature ethyl chloride process at the Bayway Refinery in New Jersey. However, within the first two months of its operation, the new plant was plagued by more cases of lead poisoning, hallucinations, insanity, and five deaths.The",1
"However, the State of New Jersey ordered the Bayway plant to be closed a few days later, and Jersey Standard was forbidden to manufacture TEL again without state permission. Production was restarted in 1926 after intervention by the federal government. High-octane fuel, enabled by lead, was important to the military. Midgley later took a leave of absence from work after being diagnosed with lead poisoning. He was relieved of his position as vice president of GMCC in April 1925, reportedly due to his inexperience in organizational matters, but he remained an employee of General Motors.",1
"The Society of Chemical Industry awarded Midgley the Perkin Medal in 1937 for this work. In 1941, the American Chemical Society gave Midgley its highest award, the Priestley Medal. This was followed by the Willard Gibbs Award in 1942. He also held two honorary degrees and was elected to the United States National Academy of Sciences. In 1944, he was elected president and chairman of the American Chemical Society. In 1940, at the age of 51, Midgley contracted polio and was left severely disabled. He devised an elaborate system of ropes and pulleys to lift himself out of bed.",1
"Kettering, The American Weekly, Hearst Corporation, March 25, 1945. Midgley, T. (1942). ""A Critical Examination of Some Concepts in Rubber Chemistry"". Science. 96 (2485): 143–6. Bibcode:1942Sci....96..143M. doi:10.1126/science.96.2485.143. PMID 17833986. Biographical Memoir by Charles F. Kettering at the Wayback Machine (archived October 15, 2012) Giunta, Carmen J. (2006). ""Thomas Midgley Jr. and the Invention of Chlorofluorocarbon Refrigerants"" (PDF). Bulletin for the History of Chemistry. 31 (2): 66–74. The Man Who Accidentally Killed The Most People In History (video by YouTube producer Derek Muller on Thomas Midgley Jr., April 2022)",1
"Around 1986 John Joyce (of Bowin Cars fame), an influential Australian inventor, first learned about oxides of nitrogen (NOx) and their role in the production of smog and acid rain. His first introduction to the complexities of the subject was brought about by the work of Fred Barnes and Dr John Bromley from the state Energy Commission of Western Australia.The",1
"vast majority of the research and development stretching back over twenty years was about large scale industrial burners and complex mechanisms which, in the end, did not produce what one would consider low NOx (2 ng/J or ~ 4 ppm at 0% O2 on dry basis).In fact at that time, 15 ng/J NO2 appears to have been considered low NO2. The one clear message that did flow through all the mass of information he studied, was the effect of temperature on the formation of NOx.",1
"The Australian Gas Association in turn reduced the indoor emission rate of NO2 for unflued gas heaters from 15 to 5 ng/J and this remains the current limit. The New South Wales government, through the Public Works Department, also re-evaluated alternative methods of heating classrooms, to ensure a safe and healthy environment for students. It was in this context, that John Joyce's company Bowin Technology embarked on a major research & development program aimed at minimising nitrogen dioxide emissions from unflued gas heaters. Bowin Technology set itself the task of solving the emission problem at its source: the gas burner.",1
"Natural gas by composition has a distinct advantage over other fossil fuels in terms of carbon dioxide, particulate and sulfur dioxides produced when converting to useful energy. In the early 1990s numerous countries were in the process of substituting oil and coal with natural gas for their energy and electric power needs. To maintain this advantage as an ""environmentally friendly"" fuel, Australian gas utilities are effectively reducing gas losses (methane emissions) in their deliveries, and impose strict codes on appliance manufacturers and installers against gas leakage.",1
"It is well established that conventional ""blue flame"" or bunsen gas burners produce oxides of nitrogen at levels of 30-50 nanograms per joule and are as such not considered to have potential for NOx reduction. Surface combustion burners or radiant tile burners in comparison produce nitrogen oxides' levels 60-70% less. Therefore John Joyce's research into low NOx burners revolved primarily around surface combustion techniques. Another issue was the effect combustion temperatures have on the formation of NOx. John Joyce's task became even more challenging when he decided not to direct his development towards radiant type surface combustion tiles.",1
"The scientific innovative nature of John Joyce's LO-NOx technologies are confirmed by full patent protection in Australia, United States, United Kingdom, Japan, Italy and France. In 1993 John Joyce received an Australian Design Award and Powerhouse Museum Selection status for his ""SLE"" heater range, which incorporate LO-NOx burners.",1
"More tangible cost savings are defined when comparing the energy efficiencies of gas heaters with low NOx emissions with conventional flued types. Gas heaters with emission problems are flued and inherently lose substantial energies in the form of hot flue gases to the atmosphere. In addition, the choice of placement of flued heaters is greatly impaired due to flue installation restrictions. In contrast, dedicated low emission gas heaters do not require a flue system. Furthermore, with the introduction of oxygen depletion sensors and thermostatic controls, they do not place critical reliance on ventilation as had been the case.",1
"The Orbital Debris Co-ordination Working Group was formed by unanimous agreement at the May 2003 Plenary meeting of TC20/SC14. The ODCWG recognizes that the mitigation of orbital space debris is an international concern, thus international, comprehensive and cohesive standards (namely ISO TC20/SC14) must be adopted to address the issue.Currently six standards projects are in development, and a further seven project proposals are being prepared. The first debris mitigation standards were expected in 2008, with more International Standards, technical specifications or technical reports expected to be published through to 2011–2012.",1
Inter-Agency Space Debris Coordination Committee The ODCWG's public folder on the ISO website.,1
"The zone should include large native tree species that grow fast and can quickly act to perform these tasks. Although this is usually the smallest of the three zones and absorbs the fewest contaminants, most of the contaminants have been eliminated by Zone 2 and Zone 3.Zone 2 Usually made up of native shrubs, this zone provides a habitat for wildlife, including nesting areas for bird species. This zone also acts to slow and absorb contaminants that Zone 3 has missed. The zone is an important transition between grassland and forest.Zone",1
"This woody debris also increases habitat and cover for various aquatic species.The US National Agroforestry Center has developed a filter strip design tool called AgBufferBuilder, which is a GIS-based computer program for designing vegetative filter strips around agricultural fields that utilizes terrain analysis to account for spatially non-uniform runoff. Logging is sometimes recommended as a management practice in riparian buffers, usually to provide economic incentive. However, some studies have shown that logging can harm wildlife populations, especially birds.",1
"For example, the Nebraska system of Riparian Buffer Payments offers payments for the cost of setup, a sign up bonus, and annual rental payments. These incentives are offered to agriculturists to compensate them for their economic loss of taking this land out of production. If the land is highly erodible and produces little economic gain, it can sometimes be more economic to take advantage of these CRP programs. Riparian buffers have undergone much scrutiny about their effectiveness, resulting in thorough testing and monitoring.",1
"A study done by the University of Georgia, conducted over a nine-year period, monitored the amounts of fertilizers that reached the watershed from the source of the application. It found that these buffers removed at least 60% of the nitrogen in the runoff, and at least 65% of the phosphorus from the fertilizer application. The same study showed that the effectiveness of the Zone 3 was much greater than that of both Zone 1 and 2 at removing contaminants.",1
"But another study in 2017 did not find efficiency (or a very limiting capacity) for reducing glyphosate and AMPA leaching to streams; spontaneous herbaceous vegetation RBS is as efficient as Salix plantations and measures of glyphosate in runoff after a year, suggest an unexpected persistence and even a capacity of RBS to potentially favor glyphosate infiltration up to 70 cm depth in the soil. After the initial installation of the riparian buffer, relatively little maintenance needs to be performed to keep the buffer in good condition.",1
"Species selection based on an area in Nebraska, as an example: In Zone 1 Cottonwood, Bur Oak, Hackberry, Swamp White Oak, Siberian Elm, Honeylocust, Silver Maple, Black Walnut, and Northern Red Oak.In Zone 2 Manchurian apricot, Silver Buffaloberry, Caragana, Black Cherry, Chokecherry, Sandcherry, Peking Cotoneaster, Midwest Crabapple, Golden Currant, Elderberry, Washington Hawthorn, American Hazel, Amur Honeysuckle, Common Lilac, Amur Maple, American Plum, and Skunkbush Sumac.In Zone 3 Western Wheatgrass, Big Bluestem, Sand Bluestem, Sideoats Grama, Blue Grama, Hairy Grama, Buffalo Grass, Sand Lovegrass, Switchgrass, Little Bluestem, Indiangrass, Prairie Cordgrass, Prairie Dropseed, Tall Dropseed, Needleandthread, Green Needlegrass.",1
National Agroforestry Center (USDA) Filter Strip Design Tool (AgBufferBuilder; USDA) Extensive Riparian Buffer bibliography,1
"Operation Geranium occurred from 15 – 20 December 1948 and involved the dumping of approximately 3,150 tons of stockpiled lewisite into the Atlantic Ocean. ""Geranium"" was so called because lewisite has an odor reminiscent of geraniums. The materials dumped consisted of two types of bulk container, 60 were of the M14 variety, and another 3,700 bulk containers were dumped as well. The lewisite was shipped to Charleston from the Gulf Chemical Warfare Depot. The lewisite was then loaded aboard a World War II merchant ship, the SS Joshua Alexander.",1
"In the UK, a container of oil or fuel cannot be stored outside unless it is bundled in a secondary containment item (Oil Storage Regulations 2001). This means that if the container of oil leaks, it will be contained within the bund. The secondary containment item must be able to hold 110% of the largest container above.If a person were to store 4 x 200-litre drums on the sump pallet, the sump pallet must be able to hold 220 litres (48 imp gal; 58 US gal) of oil.",1
"Although there are no laws in the UK stating that a sump pallet must hold 110% of the largest container upon it, it is still considered good practice to do so. Sump pallets can be made in a variety of materials, but due to the nature of the oils or chemicals which will be stored upon it, they are typically made from either UV stabilised polyethylene, or steel that is galvanised for further protection from harsher chemicals. Also available in stainless and mild steels.",1
"Tracer compounds must then be of primary origins (not formed in the atmosphere), which are created through condensation and coagulation of mainly combustion and biological sources. Samples have been analyzed from many known biogenic and anthropogenic emissions sources such as diesel and gasoline vehicles, cigarette smoke, road dust, vegetative detritus, wood smoke, and meat cooking.",1
"Compounds containing nitrogen, potassium or phosphorus may encourage growth of aquatic plants and thus increase the available energy in the local food-web. this can lead to increased concentrations of suspended organic material. In some cases specific micro-nutrients may be required to allow the available nutrients to be fully utilised by living organisms. In other cases, the presence of specific chemical species may produce toxic effects limiting growth and abundance of living matter.",1
Fish are frequently the top level predators in a managed treatment eco-system and in some case may simply be a mono-culture of herbivorous species. Management of multi-species fisheries requires careful management and may involve a range of fish species including bottom-feeders and predatory species to limit population growth of the herbivorous fish.,1
Annelid worms are essential to the effective operation of trickling filters helping to remove excess bio-mass and enhancing natural sloughing of the bio-film. Supernumerary worms are very commonly found in the drainage troughs around trickling filters and in the final settlement sludge. Annelids also play a key role in lagoon treatment systems and in the effective working or engineered wet-lands. In this environment worms are a principal force in mixing in the upper few centimetres of the sediment layer exposing organic material to both oxidative and anoxic environments aiding the complete breakdown of most organics.,1
They are also a key ingredient in the food-chain transferring energy upwards to fish and aquatic birds.,1
The range of protozoan species found is very wide but may include species of the following genera: Amoeba Arcella Blepharisma Didinium Euglena Hypotrich Paramecium Suctoria Stylonychia Vorticella,1
"As it approached Earth, the trajectory indicated the geocentric orbital eccentricity was less than 1 by 15 October 2020, and the object became temporarily captured on 8 November when it entered Earth's Hill sphere. It entered via the outer Lagrange point L2 and will exit via Lagrange point L1. During its geocentric orbit around Earth, 2020 SO made a close approach to Earth on 1 December 2020 at a perigee distance of approximately 0.13 lunar distances (50,000 km; 31,000 mi). It also made another close approach on 2 February 2021, at a perigee distance of approximately 0.58",1
"LD (220,000 km; 140,000 mi). Since discovery the time of uncertainty for February 2021 closest approach to Earth was reduced from ±3 days to less than 1 minute. It left Earth's Hill sphere at around 8 March 2021. Paul Chodas of the Jet Propulsion Laboratory suspects 2020 SO of being the Surveyor 2 Centaur rocket booster, launched on 20 September 1966. The Earth-like orbit and low relative velocity suggest a possible artificial object. Spectroscopy may help determine if it is covered in white titanium dioxide paint.",1
"Goldstone radar will make bistatic observations transmitting from the 70-meter DSS-14 and receiving at the 34-meter DSS-13. As a result of the bistatic DSS-14/RT-32 radar observations, a rotation period of about 9.5 seconds was obtained, which corresponds to the photometric observations. Obtained range-Doppler radar images confirm that the object has an elongated shape with a length of about 10 meters and a width of about 3 meters. Around the time of closest approach on 1 December 2020, the object was only brightened to about apparent magnitude 14.1,",1
"and required a telescope with roughly a 150mm (6"") objective lens to be seen visually. It displays a large light curve amplitude of 2.5 magnitudes, signifying a highly elongated shape or albedo variations on its surface. It has a rotation period of approximately 9 seconds.At the time of its discovery, 2020 SO had unremarkable motion typical of a main-belt asteroid. However, the four observations that Pan-STARRS obtained over the course of 1.4 hours showed non-linear motion due to the rotation of the observer around Earth's axis, which is a signature of a nearby object.",1
"In January and February 2036, it will again approach Earth with a geocentric eccentricity less than 1 since the relative velocities will be small, but will not be within Earth's Hill sphere of 0.01 AU (1.5 million km).",1
"J002E3 – a near-Earth object discovered in 2002 that was identified as the S-IVB third stage of the Apollo 12 Saturn V rocket WT1190F – temporarily orbiting space debris that entered Earth's atmosphere in 2015 2018 AV2 – an artificial object discovered in a temporary orbit around Earth in 2018, now suspected to be the Snoopy module from Apollo 10 6Q0B44E – another artificial object discovered in orbit around Earth in 2018 Space debris Temporary satellite ""Pseudo-MPEC"" for 2020 SO = Surveyor 2 Centaur, Bill Gray, Project Pluto, 31 January 2021 Earth May Have Recaptured a 1960s-Era Rocket Booster, Tony Greicius,",1
"NASA, 12 November 2020 Animation of the Line of Variation (via clone orbits) stretching out from December 2020 to May 2021 01 Dec 2020 image and rotation – Virtual Telescope Project / G. Masi 01 Dec 2020 time-lapse and photometry – Virtual Telescope Project / G. Masi 2020 SO at NeoDyS-2, Near Earth Objects—Dynamic Site Ephemerides · Observation prediction · Orbital info · MOID · Proper elements · Observational info · Close approaches · Physical info · Orbit animation",1
"Light trespass occurs when unwanted light enters one's property, for instance, by shining over a neighbour's fence. A common light trespass problem occurs when a strong light enters the window of one's home from the outside, causing problems such as sleep deprivation. A number of cities in the U.S. have developed standards for outdoor lighting to protect the rights of their citizens against light trespass. To assist them, the International Dark-Sky Association has developed a set of model lighting ordinances.The",1
Dark-Sky Association was started to reduce the light going up into the sky which reduces the visibility of stars (see Skyglow below). This is any light that is emitted more than 90° above nadir. By limiting light at this 90° mark they have also reduced the light output in the 80–90° range which creates most of the light trespass issues. U.S. federal agencies may also enforce standards and process complaints within their areas of jurisdiction.,1
"Light trespass can be reduced by selecting light fixtures that limit the amount of light emitted more than 80° above the nadir. The IESNA definitions include full cutoff (0%), cutoff (10%), and semi-cutoff (20%). (These definitions also include limits on light emitted above 90° to reduce sky glow.)",1
"old lamps with more efficient LEDs using the same electrical power; and Indirect lighting techniques, such as illuminating a vertical wall to bounce light onto the ground. Institutions who illuminate their buildings not to improve navigation, but ""to show that its empire is inescapable"".Most of these issues can be readily corrected with available, inexpensive technology, and with the resolution of landlord/tenant practices that create barriers to rapid correction of these matters. Most importantly, public awareness would need to improve for industrialized countries to realize the large payoff in reducing over-illumination. In certain cases, an over-illumination lighting technique may be needed.",1
"Glare can be categorized into different types. One such classification is described in a book by Bob Mizon, coordinator for the British Astronomical Association's Campaign for Dark Skies, as follows: Blinding glare describes effects such as that caused by staring into the Sun. It is completely blinding and leaves temporary or permanent vision deficiencies. Disability glare describes effects such as being blinded by oncoming car lights, or light scattering in fog or in the eye, reducing contrast, as well as reflections from print and other dark areas that render them bright, with a significant reduction in sight capabilities.",1
"Discomfort glare does not typically cause a dangerous situation in itself, though it is annoying and irritating at best. It can potentially cause fatigue if experienced over extended periods.According to Mario Motta, president of the Massachusetts Medical Society, ""... glare from bad lighting is a public-health hazard—especially the older you become. Glare light scattering in the eye causes loss of contrast and leads to unsafe driving conditions, much like the glare on a dirty windshield from low-angle sunlight or the high beams from an oncoming car.""",1
"In essence bright and/or badly shielded lights around roads can partially blind drivers or pedestrians and contribute to accidents. The blinding effect is caused in large part by reduced contrast due to light scattering in the eye by excessive brightness, or to the reflection of light from dark areas in the field of vision, with luminance similar to the background luminance. This kind of glare is a particular instance of disability glare, called veiling glare. (This is not the same as loss of accommodation of night vision which is caused by the direct effect of the light itself on the eye.)",1
"Light clutter refers to excessive groupings of lights. Groupings of lights may generate confusion, distract from obstacles (including those that they may be intended to illuminate), and potentially cause accidents. Clutter is particularly noticeable on roads where the street lights are badly designed, or where brightly lit advertisements surround the roadways. Depending on the motives of the person or organization that installed the lights, their placement and design can even be intended to distract drivers, and can contribute to accidents.",1
"Measuring the effect of sky glow on a global scale is a complex procedure. The natural atmosphere is not completely dark, even in the absence of terrestrial sources of light and illumination from the Moon. This is caused by two main sources: airglow and scattered light. At high altitudes, primarily above the mesosphere, there is enough UV radiation from the sun at very short wavelengths to cause ionization. When the ions collide with electrically neutral particles they recombine and emit photons in the process, causing airglow.",1
"The degree of ionization is sufficiently large to allow a constant emission of radiation even during the night when the upper atmosphere is in the Earth's shadow. Lower in the atmosphere all the solar photons with energies above the ionization potential of N2 and O2 have already been absorbed by the higher layers and thus no appreciable ionization occurs. Apart from emitting light, the sky also scatters incoming light, primarily from distant stars and the Milky Way, but also the zodiacal light, sunlight that is reflected and backscattered from interplanetary dust particles.",1
"The amount of airglow and zodiacal light is quite varied (depending, amongst other things on sunspot activity and the Solar cycle) but given optimal conditions, the darkest possible sky has a brightness of about 22 magnitude/square arc second. If a full moon is present, the sky brightness increases to about 18 magnitude/sq. arcsecond depending on local atmospheric transparency, 40 times brighter than the darkest sky. In densely populated areas a sky brightness of 17 magnitude/sq. an arcsecond is not uncommon, or as much as 100 times brighter than is natural.",1
ranges from pristine (Capitol Reef National Park and Big Bend National Park) to severely degraded (Santa Monica Mountains National Recreation Area and Biscayne National Park). The National Park Service Night Sky Program monitoring database is available online (2015).,1
"For those who need to be awake at night, light at night also has an acute effect on alertness and mood.Outdoor artificial light at night – exposure to contemporary types such as current types of street lighting – has been linked to risks for obesity, mental disorders, diabetes, and potentially other health issues by preliminary studies.In 2007, ""shift work that involves circadian disruption"" was listed as a probable carcinogen by the World Health Organization's International Agency for Research on Cancer. (IARC Press release No. 180).",1
"While light at night can be beneficial, neutral, or damaging for individual species, its presence invariably disturbs ecosystems. For example, some species of spiders avoid lit areas, while other species are happy to build their webs directly on lamp posts. Since lamp posts attract many flying insects, the spiders that tolerate the light gain an advantage over the spiders that avoid it. This is a simple example of the way in which species frequencies and food webs can be disturbed by the introduction of light at night.",1
"With the exception of the finches, all the English songbirds may be said to be insectivorous, and their diet consists chiefly of vast numbers of very small insects which they collect from the grass and herbs before the dew is dry. As the electric light is finding its way for street illumination into the country parts of England, these poor winged atoms are slain by thousands at each light every warm summer evening. ...",1
"The fear is expressed, that when England is lighted from one end to the other with electricity the songbirds will die out from the failure of their food supply.",1
"By means of software, the stray light can be reduced, but at the same time, object detail will be lost in the image. The following picture of the area around the Pinwheel Galaxy (Messier 101) with the apparent magnitude of 7.5m with all stars down to an apparent magnitude of 10m was taken in Berlin in a direction close to the zenith with a fast lens (f-number 1.2)",1
"Light trespass also makes it hard for a visual observer to become sufficiently adapted to the dark. The usual measures to reduce this glare, if reducing the light directly is not an option, include flocking the telescope tube and accessories to reduce reflection, and putting a light shield (also usable as a dew shield) on the telescope to reduce light entering from angles other than those near the target. Under these conditions, some astronomers prefer to observe under a black cloth to ensure maximum adaptation to the dark.",1
"Since the time of the Industrial Revolution grew out of England and spread across the globe, major changes have been made in the way we live. Technological innovation is moving at a rapid pace. It is not uncommon to find 24-hour business, such as gas stations, convenience stores, and pharmacies. Hospitals and other healthcare facilities must be staffed 24 hours per day, seven days per week. With the rise of Amazon, many factories and shipping companies now operate 24x7 shifts to keep up with the demand of the new global consumer.",1
"In 2007 the International Agency for Research on Cancer (IARC) sought to bring notice to the risk from shift work as a probable risk for developing cancers. This move was the result of numerous studies that found increased risks of cancers in groups of shift workers. The 1998 Nurses Health Study found a link between breast cancer and nurses who had worked more than 30 years on rotating night shifts. However, it is not possible to halt shift work in these industries. Hospitals must be staffed around the clock.",1
"However, a recent article suggests that we may be able to find a happy medium. A 2021 article examined seasonal light changes and its effect on all animals, but specifically mollusks. The authors noted that light research primarily focuses on length of exposure to light. Based on their research they suggest that further research should examine the lowest quantifying the least amount of light, in terms of duration and intensity, that would allow both humans and animals to continue safely.",1
"According to design investigations, luminaires with full cutoff distributions (as opposed to cutoff or semi cutoff, compared here) have to be closer together to meet the same light level, uniformity and glare requirements specified by the IESNA. These simulations optimized the height and spacing of the lights while constraining the overall design to meet the IESNA requirements, and then compared total uplight and energy consumption of different luminaire designs and powers. Cutoff designs performed better than full cutoff designs, and semi-cutoff performed better than either cutoff or full cutoff.",1
"In 1980, for example, San Jose, California, replaced all street lamps with low pressure sodium lamps, whose light is easier for nearby Lick Observatory to filter out. Similar programs are now in place in Arizona and Hawaii. Such yellow light sources also have significantly less visual skyglow impact, so reduce visual sky brightness and improve star visibility for everyone. Disadvantages of low-pressure sodium lighting are that fixtures must usually be larger than competing fixtures, and that color cannot be distinguished, due to its emitting principally a single wavelength of light (see security lighting).",1
"According to Narisada and Schrueder (2004), another disadvantage of low-pressure sodium lamps is that some research has found that many people find the characteristic yellow light to be less pleasing aesthetically, although they caution that this research isn't thorough enough to draw conclusions from.Because of the increased sensitivity of the human eye to blue and green wavelengths when viewing low-luminances (the Purkinje effect) in the night sky, different sources produce dramatically different amounts of visible skyglow from the same amount of light sent into the atmosphere.",1
"In 2001 International Dark Sky Places Program was founded in order to encourage communities, parks and protected areas around the world to preserve and protect dark sites through responsible lighting policies and public education. As of January 2022, there are 195 certified International Dark Sky Places in the world. For example, in 2016 China launched its first dark sky reserve in the Tibet Autonomous Region's Ngari Prefecture which covers an area of 2,500 square kilometers. Such areas are important for astronomical observation. Roy Henry Garstang Introductory Save the night in Europe. (2021). What is light pollution?.Astronomy Luginbuhl, C. B., Walker, C.",1
"Cool, A. D. (2010). German skyglow for population by postcode according to Walker's law.",1
"Chlorinated paraffins are synthesized by reaction of chlorine gas with unbranched paraffin fractions (<2 % isoparaffins, <100 ppm aromatics) at a temperature of 80–100 °C. The radical substitution may be promoted by UV-light. CxH(2x+2) + y Cl2 → CxH(2x−y+2)Cly + y HClWhen the desired degree of chlorination is achieved, residues of hydrochloric acid and chlorine are blown off with nitrogen. Epoxidized vegetable oil, glycidyl ether or organophosphorous compounds may be added to the final product for improved stability at high temperatures.Commercial products have been classified as substances of unknown or variable composition.",1
"Therefore, it was concluded that SCCPs have PBT and vPvB properties and they were added to the Candidate List of substances of very high concern for Authorisation under REACH Regulation. SCCPs (average chain length of C12, chlorination degree 60 wt%) were categorised in group 2B as possibly carcinogenic to humans from the International Agency for Research on Cancer (IARC). In 2017, it was agreed to globally ban SCCPs under the Stockholm Convention on Persistent Organic Pollutants, effective December 2018.",1
"However, also MCCPs are toxic to the aquatic environment and persistent; MCCPs in soil, biota, and most of the sediment cores show increasing time trends over the last years to decades; MCCP concentrations in sediment close to local sources exceed toxicity thresholds such as the PNEC. In July 2021 also MCCPs were added to the Candidate List of Substances of Very High Concern (SVHC) under the REACH Regulation. Chlorinated paraffins have been detected in marine life such as cetaceans (whales) and bivalves (molluscs).",1
"Naturally occurring strontium is nonradioactive and nontoxic at levels normally found in the environment, but 90Sr is a radiation hazard. 90Sr undergoes β− decay with a half-life of 28.79 years and a decay energy of 0.546 MeV distributed to an electron, an antineutrino, and the yttrium isotope 90Y, which in turn undergoes β− decay with a half-life of 64 hours and a decay energy of 2.28 MeV distributed to an electron, an antineutrino, and 90Zr (zirconium), which is stable.",1
"Note that 90Sr/Y is almost a pure beta particle source; the gamma photon emission from the decay of 90Y is so infrequent that it can normally be ignored. 90Sr has a specific activity of 5.21 TBq/g. 90Sr is a product of nuclear fission. It is present in significant amount in spent nuclear fuel, in radioactive waste from nuclear reactors and in nuclear fallout from nuclear tests. For thermal neutron fission as in today's nuclear power plants, the fission product yield from uranium-235 is 5.7%, from uranium-233 6.6%, but from plutonium-239 only 2.0%.",1
"biological half-life of strontium-90 in humans has variously been reported as from 14 to 600 days, 1000 days, 18 years, 30 years and, at an upper limit, 49 years. The wide-ranging published biological half life figures are explained by strontium's complex metabolism within the body. However, by averaging all excretion paths, the overall biological half life is estimated to be about 18 years.The elimination rate of strontium-90 is strongly affected by age and sex, due to differences in bone metabolism.Together",1
"with the caesium isotopes 134Cs and 137Cs, and the iodine isotope 131I, it was among the most important isotopes regarding health impacts after the Chernobyl disaster. As strontium has an affinity to the calcium-sensing receptor of parathyroid cells that is similar to that of calcium, the increased risk of liquidators of the Chernobyl power plant to suffer from primary hyperparathyroidism could be explained by binding of strontium-90.",1
"Groves were also briefed, but Oppenheimer wanted to proceed with the plan only if enough food could be contaminated with the weapon to kill half a million people. Strontium-90 is not quite as likely as caesium-137 to be released as a part of a nuclear reactor accident because it is much less volatile, but is probably the most dangerous component of the radioactive fallout from a nuclear weapon.A study of hundreds of thousands of deciduous teeth, collected by Dr.",1
"Louise Reiss and her colleagues as part of the Baby Tooth Survey, found a large increase in 90Sr levels through the 1950s and early 1960s. The study's final results showed that children born in St. Louis, Missouri, in 1963 had levels of 90Sr in their deciduous teeth that was 50 times higher than that found in children born in 1950, before the advent of large-scale atomic testing. Reviewers of the study predicted that the fallout would cause increased incidence of disease in those who absorbed strontium-90 into their bones.",1
"However, no follow up studies of the subjects have been performed, so the claim is untested. An article with the study's initial findings was circulated to U.S. President John F. Kennedy in 1961, and helped convince him to sign the Partial Nuclear Test Ban Treaty with the United Kingdom and Soviet Union, ending the above-ground nuclear weapons testing that placed the greatest amounts of nuclear fallout into the atmosphere.The Chernobyl disaster released roughly 10 PBq, or about 5% of the core inventory, of strontium-90 into the environment. The Fukushima Daiichi disaster had from the accident until 2013 released 0.1",1
"WHO has classified the reported symptoms into broad categories, including: mucous membrane irritation (eye, nose, and throat irritation), neurotoxic effects (headaches, fatigue, and irritability), asthma and asthma-like symptoms (chest tightness and wheezing), skin dryness and irritation, gastrointestinal complaints and more.Several sick occupants may report individual symptoms which do not appear to be connected. The key to discovery is the increased incidence of illnesses in general with onset or exacerbation within a fairly close time frame – usually within a period of weeks. In most cases, SBS symptoms will be relieved soon after the occupants leave the particular room or zone.",1
"For example, higher light intensity was significantly related to skin dryness, eye pain, and malaise. Higher temperature has also been found to correlate with symptoms such as sneezing, skin redness, itchy eyes and headache, while lower relative humidity has been associated with sneezing, skin redness, and pain of the eyes.In 1973, in response to the oil crisis and conservation concerns, ASHRAE Standards 62-73 and 62-81 reduced required ventilation from 10 cubic feet per minute (4.7 L/s) per person to 5 cubic feet per minute (2.4 L/s) per person, but this was found to be a contributing factor to sick building syndrome.",1
"As of the 2016 revision, ASHRAE ventilation standards call for 5 to 10 cubic feet per minute of ventilation per occupant (depending on the occupancy type) in addition to ventilation based on the zone floor area delivered to the breathing zone.",1
"Other members of the suggested group include silicosis, macrophagic myofascitis, Gulf War syndrome, and post-vaccination phenomena.",1
"Greater effects were found with features of the psycho-social work environment including high job demands and low support. The report concluded that the physical environment of office buildings appears to be less important than features of the psycho-social work environment in explaining differences in the prevalence of symptoms. However, there is still a relationship between sick building syndrome and symptoms of workers regardless of workplace stress.Excessive",1
"Forestry, agriculture, and sales workers have the lowest rates of sick building syndrome symptoms.From the assessment done by Fisk and Mudarri, 21% of asthma cases in the United States were caused by wet environments with mold that exist in all indoor environments, such as schools, office buildings, houses and apartments. Fisk and Berkeley Laboratory colleagues also found that the exposure to the mold increases the chances of respiratory issues by 30 to 50 percent.",1
"Additionally, studies showing that health effects with dampness and mold in indoor environments found that increased risk of adverse health effects occurs with dampness or visible mold environments.Milton et al. determined the cost of sick leave specific for one business was an estimated $480 per employee, and about five days of sick leave per year could be attributed to low ventilation rates. When comparing low ventilation rate areas of the building to higher ventilation rate areas, the relative risk of short-term sick leave was 1.53 times greater in the low ventilation areas.",1
"Some studies have found that sick building syndrome may be associated with indoor mould or mycotoxin contamination. However, the attribution of sick building syndrome to mould is controversial and supported by little evidence.",1
"Indoor temperature under 18 °C (64 °F) has been shown to be associated with increased respiratory and cardiovascular diseases, increased blood levels, and increased hospitalization. While sick building syndrome (SBS) encompasses a multitude of non-specific symptoms, building-related illness (BRI) comprises specific, diagnosable symptoms caused by certain agents (chemicals, bacteria, fungi, etc.). These can typically be identified, measured, and quantified. There are usually 4 causal agents in BRI; 1.) Immunologic, 2.) Infectious, 3.) toxic, and 4.) irritant.",1
"For instance, Legionnaire's disease, usually caused by Legionella pneumophila, involves a specific organism which could be ascertained through clinical findings as the source of contamination within a building. Reduce the time you stay in the building If you live there, consider moving to a new place.",1
"Make sure you are not moving to a worse place though Fix any deteriorated paint or concrete deterioration Regular inspections to indicate for presence of mold or other toxins Adequate maintenance of all building mechanical systems Toxin-absorbing plants, such as sansevieria Roof shingle non-pressure cleaning for removal of algae, mold, and Gloeocapsa magma Using ozone to eliminate the many sources, such as VOCs, molds, mildews, bacteria, viruses, and even odors. However, numerous studies identify high-ozone shock treatment as ineffective despite commercial popularity and popular belief.",1
"For the individual, the recovery may be a process involved with targeting the acute symptoms of a specific illness, as in the case of mold toxins. Treating various building-related illnesses is vital to the overall understanding of SBS. Careful analysis by certified building professionals and Medical Doctors can help to identify the exact cause of the BRI, and help to illustrate a causal path to infection. With this knowledge one can, theoretically, remediate a building of contaminants and rebuild the structure with new materials.",1
"Office BRI may more likely than not be explained by three events: ""Wide range in the threshold of response in any population (susceptibility), a spectrum of response to any given agent, or variability in exposure within large office buildings.""Isolating any one of the three aspects of office BRI can be a great challenge, which is why those who find themselves with BRI should take three steps, history, examinations, and interventions. History describes the action of continually monitoring and recording the health of workers experiencing BRI, as well as obtaining records of previous building alterations or related activity.",1
"Using questionnaires, ergonomic investigations, building evaluations, as well as physical, biological, and chemical variables, the investigators obtained results that compare with past studies of SBS and gender. The study team found that across most test variables, prevalence rates were different in most areas, but there was also a deep stratification of working conditions between genders as well. For example, men's workplaces tend to be significantly larger and have all-around better job characteristics. Secondly, there was a noticeable difference in reporting rates, specifically that women have higher rates of reporting roughly 20% higher than men.",1
"This information was similar to that found in previous studies, thus indicating a potential difference in willingness to report.There might be a gender difference in reporting rates of sick building syndrome, because women tend to report more symptoms than men do. Along with this, some studies have found that women have a more responsive immune system and are more prone to mucosal dryness and facial erythema.",1
"The problem was highlighted increasingly in media and was described as a ""ticking time bomb"". Many studies were performed in individual buildings. In the 1990s ""sick buildings"" were contrasted against ""healthy buildings"". The chemical contents of building materials were highlighted. Many building material manufacturers were actively working to gain control of the chemical content and to replace criticized additives. The ventilation industry advocated above all more well-functioning ventilation. Others perceived ecological construction, natural materials, and simple techniques as a solution. At the end of the 1990s came an increased distrust of the concept of ""sick building"".",1
"Michelle Murphy, Sick Building Syndrome and the Problem of Uncertainty, 2006. Johan Carlson, ""Gemensam förklaringsmodell för sjukdomar kopplade till inomhusmiljön finns inte"" [Unified explanation for diseases related to indoor environment not found]. Läkartidningen 2006/12. Bulletin of the Transilvania University of Braşov, Series I: Engineering Sciences • Vol. 5 (54) No. 1 2012 ""Impact of Indoor Environment Quality on Sick Building Syndrome in Indian Leed Certified Buildings"".",1
"As in simpler alkanes, carbon in the CFCs bond with tetrahedral symmetry. Because the fluorine and chlorine atoms differ greatly in size and effective charge from hydrogen and from each other, the methane-derived CFCs deviate from perfect tetrahedral symmetry.The physical properties of CFCs and HCFCs are tunable by changes in the number and identity of the halogen atoms. In general, they are volatile but less so than their parent alkanes. The decreased volatility is attributed to the molecular polarity induced by the halides, which induces intermolecular interactions. Thus, methane boils at −161 °C whereas the fluoromethanes boil between −51.7",1
"(CF2H2) and −128 °C (CF4). The CFCs have still higher boiling points because the chloride is even more polarizable than fluoride. Because of their polarity, the CFCs are useful solvents, and their boiling points make them suitable as refrigerants. The CFCs are far less flammable than methane, in part because they contain fewer C-H bonds and in part because, in the case of the chlorides and bromides, the released halides quench the free radicals that sustain flames. The densities of CFCs are higher than their corresponding alkanes. In general, the density of these compounds correlates with the number of chlorides.",1
"Furthermore, many examples are known for higher numbers of carbon as well as related compounds containing bromine. Uses include refrigerants, blowing agents, aerosol propellants in medicinal applications, and degreasing solvents. Billions of kilograms of chlorodifluoromethane are produced annually as a precursor to tetrafluoroethylene, the monomer that is converted into Teflon. Chlorofluorocarbons (CFCs): when derived from methane and ethane these compounds have the formulae CClmF4−m and C2ClmF6−m, where m is nonzero. Hydro-chlorofluorocarbons (HCFCs): when derived from methane and ethane these compounds have the formula CClmFnH4−m−n and C2ClxFyH6−x−y, where m, n, x, and y are nonzero.",1
"and bromofluorocarbons have formulae similar to the CFCs and HCFCs but also include bromine. Hydrofluorocarbons (HFCs): when derived from methane, ethane, propane, and butane, these compounds have the respective formulae CFmH4−m, C2FmH6−m, C3FmH8−m, and C4FmH10−m, where m is nonzero.",1
"Another equation that can be applied to get the correct molecular formula of the CFC/R/Freon class compounds is this to take the numbering and add 90 to it. The resulting value will give the number of carbons as the first numeral, the second numeral gives the number of hydrogen atoms, and the third numeral gives the number of fluorine atoms. The rest of the unaccounted carbon bonds are occupied by chlorine atoms. The value of this equation is always a three figure number.",1
"An easy example is that of CFC-12, which gives: 90+12=102 -> 1 carbon, 0 hydrogens, 2 fluorine atoms, and hence 2 chlorine atoms resulting in CCl2F2. The main advantage of this method of deducing the molecular composition in comparison with the method described in the paragraph above is that it gives the number of carbon atoms of the molecule. Freons containing bromine are signified by four numbers. Isomers, which are common for ethane and propane derivatives, are indicated by letters following the numbers: The most important reaction of the CFCs is the photo-induced scission of a C-Cl bond: CCl3F → CCl2F.",1
"+ Cl.The chlorine atom, written often as Cl., behaves very differently from the chlorine molecule (Cl2). The radical Cl. is long-lived in the upper atmosphere, where it catalyzes the conversion of ozone into O2. Ozone absorbs UV-B radiation, so its depletion allows more of this high energy radiation to reach the Earth's surface. Bromine atoms are even more efficient catalysts; hence brominated CFCs are also regulated. CFCs were phased out via the Montreal Protocol due to their part in ozone depletion. The atmospheric impacts of CFCs are not limited to their role as ozone-depleting chemicals.",1
"Infrared absorption bands prevent heat at that wavelength from escaping earth's atmosphere. CFCs have their strongest absorption bands from C-F and C-Cl bonds in the spectral region of 7.8–15.3 µm—referred to as the “atmospheric window” due to the relative transparency of the atmosphere within this region.The strength of CFC absorption bands and the unique susceptibility of the atmosphere at wavelengths where CFCs (indeed all covalent fluorine compounds) absorb radiation creates a “super” greenhouse effect from CFCs and other unreactive fluorine-containing gases such as perfluorocarbons, HFCs, HCFCs, bromofluorocarbons, SF6, and NF3.",1
"This “atmospheric window” absorption is intensified by the low concentration of each individual CFC. Because CO2 is close to saturation with high concentrations and few infrared absorption bands, the radiation budget and hence the greenhouse effect has low sensitivity to changes in CO2 concentration; the increase in temperature is roughly logarithmic. Conversely, the low concentration of CFCs allow their effects to increase linearly with mass, so that chlorofluorocarbons are greenhouse gases with a much higher potential to enhance the greenhouse effect than CO2. Groups are actively disposing of legacy CFCs to reduce their impact on the atmosphere.According",1
"However, concern was beginning to be expressed about the impact of chloroalkanes and bromoalkanes on the ozone layer. The Vienna Convention for the Protection of the Ozone Layer did not cover bromofluoroalkanes as it was thought, at the time, that emergency discharge of extinguishing systems was too small in volume to produce a significant impact, and too important to human safety for restriction.",1
"The experiment did however provide the first useful data on the presence of CFCs in the atmosphere. The damage caused by CFCs was discovered by Sherry Rowland and Mario Molina who, after hearing a lecture on the subject of Lovelock's work, embarked on research resulting in the first publication suggesting the connection in 1974. It turns out that one of CFCs' most attractive features—their low reactivity—is key to their most destructive effects. CFCs' lack of reactivity gives them a lifespan that can exceed 100 years, giving them time to diffuse into the upper stratosphere.",1
"On 2 March 1989, 12 European Community nations agreed to ban the production of all CFCs by the end of the century. In 1990, diplomats met in London and voted to significantly strengthen the Montreal Protocol by calling for a complete elimination of CFCs by 2000. By 2010, CFCs should have been completely eliminated from developing countries as well. Because the only CFCs available to countries adhering to the treaty is from recycling, their prices have increased considerably. A worldwide end to production should also terminate the smuggling of this material.",1
"Possible reasons for continued CFC smuggling were also examined: the report noted that many banned CFC producing products have long lifespans and continue to operate. The cost of replacing the equipment of these items is sometimes cheaper than outfitting them with a more ozone-friendly appliance. Additionally, CFC smuggling is not considered a significant issue, so the perceived penalties for smuggling are low. In 2018 public attention was drawn to the issue, that at an unknown place in east Asia an estimated amount of 13,000 metric tons annually of CFCs have been produced since about 2012 in violation of the protocol.",1
"While the eventual phaseout of CFCs is likely, efforts are being taken to stem these current non-compliance problems. By the time of the Montreal Protocol, it was realised that deliberate and accidental discharges during system tests and maintenance accounted for substantially larger volumes than emergency discharges, and consequently halons were brought into the treaty, albeit with many exceptions.",1
DuPont representatives appeared before the Montreal Protocol urging that CFCs be banned worldwide and stated that their new HCFCs would meet the worldwide demand for refrigerants.,1
"However many countries still require aircraft to be fitted with halon fire suppression systems because no safe and completely satisfactory alternative has been discovered for this application. There are also a few other, highly specialized uses. These programs recycle halon through ""halon banks"" coordinated by the Halon Recycling Corporation to ensure that discharge to the atmosphere occurs only in a genuine emergency and to conserve remaining stocks. The interim replacements for CFCs are hydrochlorofluorocarbons (HCFCs), which deplete stratospheric ozone, but to a much lesser extent than CFCs. Ultimately, hydrofluorocarbons (HFCs) will replace HCFCs.",1
"Hydrofluorocarbons are included in the Kyoto Protocol and are regulated under the Kigali Amendment to the Montreal Protocol due to their very high Global Warming Potential and the recognition of halocarbon contributions to climate change.On September 21, 2007, approximately 200 countries agreed to accelerate the elimination of hydrochlorofluorocarbons entirely by 2020 in a United Nations-sponsored Montreal summit. Developing nations were given until 2030. Many nations, such as the United States and China, who had previously resisted such efforts, agreed with the accelerated phase out schedule. India successfully phased out HCFCs by 2020.",1
"While new production of these refrigerants has been banned, large volumes still exist in older systems and pose an immediate threat to our environment. Preventing the release of these harmful refrigerants has been ranked as one of the single most effective actions we can take to mitigate catastrophic climate change.",1
"CFCs dissolve in seawater at the ocean surface and are subsequently transported into the ocean interior. Because CFCs are inert, their concentration in the ocean interior reflects simply the convolution of their atmospheric time evolution and ocean circulation and mixing.",1
"Chlorofluorocarbons (CFCs) are anthropogenic compounds that have been released into the atmosphere since the 1930s in various applications such as in air-conditioning, refrigeration, blowing agents in foams, insulations and packing materials, propellants in aerosol cans, and as solvents. The entry of CFCs into the ocean makes them extremely useful as transient tracers to estimate rates and pathways of ocean circulation and mixing processes.",1
"The solubility measurements of CFC-11 and CFC-12 have been previously measured by Warner and Weiss Additionally, the solubility measurement of CFC-113 was measured by Bu and Warner and SF6 by Wanninkhof et al. and Bullister et al.",1
"Theses authors mentioned above have expressed the solubility (F) at a total pressure of 1 atm as: ln ⁡ F = a 1 + a 2 ( 100 T ) + a 3 ln ⁡ ( T 100 ) + a 4 ( T 100 ) 2 + S [ b 1 + b 2 ( T 100 ) + b 3 ( T 100 ) ] , {\displaystyle \ln F=a_{1}+a_{2}\left({\frac {100}{T}}\right)+a_{3}\ln \left({\frac {T}{100}}\right)+a_{4}\left({\frac {T}{100}}\right)^{2}+S\left[b_{1}+b_{2}\left({\frac {T}{100}}\right)+b_{3}\left({\frac {T}{100}}\right)\right],} where F = solubility expressed in either mol l−1 or mol kg−1 atm−1, T = absolute temperature, S = salinity in parts per thousand",1
"(ppt), a1, a2, a3, b1, b2, and b3 are constants to be determined from the least squares fit to the solubility measurements. This equation is derived from the integrated Van 't Hoff equation and the logarithmic Setchenow salinity dependence.It can be noted that the solubility of CFCs increase with decreasing temperature at approximately 1% per degree Celsius.Once the partial pressure of the CFC (or SF6) is derived, it is then compared to the atmospheric time histories for CFC-11, CFC-12, or SF6 in which the pCFC directly corresponds to the year with the same.",1
"In 2019, the company won a tender for a European Space Agency Space Safety program contract in the Active Debris Removal/In-Orbit Servicing (ADRIOS) project. It will target the ESA's VESPA from the 2013 Vega flight VV02 for de-orbiting. The mission contract, worth 86 million euros, was signed in November 2020. As of January 2023, ClearSpace-1 is expected to be launched in 2026 on a Vega-C launch vehicle.The VESPA that ClearSpace-1 hopes to capture is the size of a washing machine and weighs about 112 kilograms.",1
"ClearSpace-1's device has been described as a four-armed ""space claw"" that will grip VESPA and steer it back into the Earth's atmosphere, where both will be destroyed via destructive reentry. The ClearSpace-1 mission was preceded by e.Deorbit, a space debris removal mission under planning by ESA in 2010s. In the end, the e.Deorbit mission was not implemented, the satellite was not built and the whole e.Deorbit mission was cancelled. ClearSpace-1 continues the ESA space debris removal aspirations.",1
"Tokyo-based Astroscale is a space debris removal company testing a removal device called End-of-Life Services (ELSA-d) that successfully demonstrated many of the key technologies required for space debris removal in 2021 and 2022, including demonstrating magnetic docking with a client in 2021 and close approach RPO in 2022 and ELSA-d is now in its de-orbiting phase.In 2022, the UK Space Agency awarded £4 million to ClearSpace-1 and Astroscale to remove non-operational British satellites by 2026. ClearSpace official homepage",1
"Historically, clinker from coal-burning steamships simply was discarded overboard, leaving detectable trails on the seabed of some prominent steamship routes. As such, the deposits have proven to be of biological, historical and archaeological interest.Naturally occurring clinkers exist. For example, in the Powder River Basin is covered by clinkers from coal-seam fires, i.e., ""baked, welded and molded rocks formed by the natural burning of coal beds.""Distinguish, Cement clinker. Construction Dross Industrial furnace Metallurgy Recycling",1
"Closing the Loop has saved more than 2.2 million mobile phones from the dump in Africa and gave more than 145,000 mobile phones a second life. Mobile phones are bought from informal local collector networks. To date, Closing the Loop has helped more than 2,000 people in Africa to earn additional income through safe employment.The social enterprise sees e-waste as an opportunity. An opportunity to source companies with responsibly sourced metals, to make industries like telecom circular - by closing loops - and to create income for people in emerging markets.",1
"It aims to contribute to the circular economy and the Sustainable Development Goals. Closing the Loop was founded in 2012 by Joost de Kluijver. Joost started with an NGO to make the electronic industry aware of the impact of e-waste. Although all recognized that e-waste was a major problem, the industry clearly needed more than awareness on the topic of e-waste. Joost and his team therefore took own initiative and showed that the metals inside broken mobile phones still have a value as they contain gold, silver, copper and other recyclable metals.",1
"Closing the Loop set up a network of collectors in African countries and in 2015 the first container filled with mobile phones was shipped from Ghana to Europe for proper recycling. When at the end of their lifespan, scrap mobile phones are often dumped and become a hazard for the environment and human health. For example, in landfills like Agbogbloshie, e-waste is dumped and people try to make a living by burning electronics to extract metals. The fumes that are released are very toxic.",1
"Before the development of macadam as a paving material in the 19th century, paving systems were mostly porous, so that precipitation could soak away and not run off, and urban rooftop rainwater was often saved in rainwater tanks. Open sewers, consisting of gutters and urban streambeds, were common worldwide before the 20th century.",1
"136 It is generally infeasible to treat the volume of mixed sewage and surface runoff flowing in a combined sewer during peak runoff events caused by snowmelt or convective precipitation. As cities built sewage treatment plants, those plants were typically built to treat only the volume of sewage flowing during dry weather. Relief structures were installed in the collection system to bypass untreated sewage mixed with surface runoff during wet weather, protecting sewage treatment plants from damage caused if peak flows reached the headworks.",1
"These relief structures, called ""storm-water regulators"" (in American English - or ""combined sewer overflows"" in British English) are constructed in combined sewer systems to divert flows in excess of the peak design flow of the sewage treatment plant. Combined sewers are built with control sections establishing stage-discharge or pressure differential-discharge relationships which may be either predicted or calibrated to divert flows in excess of sewage treatment plant capacity.",1
"Pollutants like oil, grease, fecal coliform from pet and wildlife waste, and pesticides get flushed into the sewer system. In cold weather areas, pollutants from cars, people and animals also accumulate on hard surfaces and grass during the winter and then are flushed into the sewer systems during heavy spring rains.",1
"CSOs differ from sanitary sewer overflows in that the latter are caused by sewer system obstructions, damage, or flows in excess of sewer capacity (rather than treatment plant capacity.): Ch.4 Sanitary sewer overflows may occur at any low spot in the sewer system rather than at the CSO relief structures. Absence of a diversion outfall often causes sanitary sewer overflows to flood residential structures and/or flow over traveled road surfaces before reaching natural drainage channels.",1
"In 2009, the Canadian Council of Ministers of the Environment adopted a Canada-wide Strategy for the Management of Municipal Wastewater Effluent including national standards to (1) remove floating material from combined sewer overflows, (2) prevent combined sewer overflows during dry weather, and (3) prevent development or redevelopment from increasing the frequency of combined sewer overflows.Rehabilitation of combined sewer systems to mitigate CSOs require extensive monitoring networks which are becoming more prevalent with decreasing sensor and communication costs.",1
"These monitoring networks can identify bottlenecks causing the main CSO problem, or aid in the calibration of hydrodynamic or hydrological models to enable cost effective CSO mitigation. Municipalities in the US have been undertaking projects to mitigate CSO since the 1990s. For example, prior to 1990, the quantity of untreated combined sewage discharged annually to lakes, rivers, and streams in southeast Michigan was estimated at more than 30 billion US gallons (110,000,000 m3) per year. In 2005, with nearly $1 billion of a planned $2.4",1
"billion CSO investment put into operation, untreated discharges have been reduced by more than 20 billion US gallons (76,000,000 m3) per year. This investment that has yielded an 85 percent reduction in CSO has included numerous sewer separation, CSO storage and treatment facilities, and wastewater treatment plant improvements constructed by local and regional governments.Many other areas in the US are undertaking similar projects (see, for example, in the Puget Sound of Washington). Cities like Pittsburgh, Seattle, Philadelphia, and New York are focusing on these projects partly because they are under federal consent decrees to solve their CSO issues.",1
"Another solution is to build a CSO storage facility, such as a tunnel that can store flow from many sewer connections. Because a tunnel can share capacity among several outfalls, it can reduce the total volume of storage that must be provided for a specific number of outfalls. Storage tunnels store combined sewage but do not treat it. When the storm is over, the flows are pumped out of the tunnel and sent to a wastewater treatment plant. One of the main concerns with CSO storage is the length of time it is stored before it is released.",1
"The first segment of the tunnel system, 7 miles (11 km) in length, went online in 2018. The remaining segments of the storage system are scheduled for completion in 2023. (The city's overall ""Clean Rivers"" project, projected to cost $2.6 billion, includes other components, such as reducing stormwater flows.) The South Boston CSO Storage Tunnel is a similar project, completed in 2011. Indianapolis, Indiana, is building underground storage capacity in the form of a 28-mile (45 km) 18-foot (5.5",1
"Wayne, Indiana, is constructing a 4.5-mile (7.2 km), 14-foot (4.3 m) diameter, $180M tunnel under the 3RPORT (Three Rivers Protection and Overflow Reduction Tunnel) to address the myriad CSOs which outfall into the St. Mary's, St. Joseph, and Maumee Rivers. The 3RPORT is approximately 160 feet (49 m) below grade, and is anticipated to enter service in 2023.",1
"Some cities have expanded their basic sewage treatment capacity to handle some or all of the CSO volume. In 2002 litigation forced the city of Toledo, Ohio, to double its treatment capacity and build a storage basin in order to eliminate most overflows. The city also agreed to study ways to reduce stormwater flows into the sewer system. (See Reducing stormwater flows.)",1
"Retention treatment basins or large concrete tanks that store and treat combined sewage are another solution. These underground structures can range in storage and treatment capacity from 2 million US gallons (7,600 m3) to 120 million US gallons (450,000 m3) of combined sewage. While each facility is unique, a typical facility operation is as follows. Flows from the overloaded sewers are pumped into a basin that is divided into compartments. The first flush compartment captures and stores flows with the highest level of pollutants from the first part of a storm.",1
"These pollutants include motor oil, sediment, road salt, and lawn chemicals (pesticides and fertilizers) that are picked up by the stormwater as it runs off roads and lawns. The flows from this compartment are stored and sent to the wastewater treatment plant when there is capacity in the interceptor sewer after the storm. The second compartment is a treatment or flow-through compartment. The flows are disinfected by injecting sodium hypochlorite, or bleach, as they enter this compartment. It then takes about 20‑30 minutes for the flows to move to the end of the compartment.",1
"These facilities are generally designed to contain two inches of stormwater runoff, with the ability to disinfect overflows during extreme wet-weather rainfall events.",1
All of the materials removed by the screens are then sent to the sewage treatment plant through the interceptor sewer.,1
"CSO mitigating initiatives that are solely composed of sewer system reconstruction are referred to as gray infrastructure, while techniques like permeable pavement and rainwater harvesting are referred to as green infrastructure. Conflict often occurs between a municipality's sewage authority and its environmentally active organizations between gray and green infrastructural plans.The 2004 EPA Report to Congress on CSO's provides a review of available technologies to mitigate CSO impacts.: Ch. 8",1
"RT-DSS systems take advantage of storm temporal and spatial variability as well as varying concentration times due to diverse land uses across the sewershed to coordinate and optimize control assets. By maximizing storage and conveyance RT-DSS are able to minimize overflows using existing infrastructure. Successful implementations of RT-DSS have been carried out throughout the United States and Europe.Real-time control (RTC) can be either heuristic or model based. Model-based control is theoretically more optimal, but due to the ease of implementation, heuristic control is more commonly applied.",1
"Generating sufficient evidence that RTC is a suitable option for CSO mitigation remains problematic, although new performance methods might make this possible.",1
"The only survivors from the Warsaw Uprising and Warsaw Ghetto made their final escape through city sewers. Some have commented that the engravings of imaginary prisons by Piranesi were inspired by the Cloaca Maxima, one of the world's earliest sewers.",1
"The theme of traveling through, hiding, or even residing in combined sewers is a common plot device in media. Famous examples of sewer dwelling are the Teenage Mutant Ninja Turtles, Stephen King's It, Les Misérables, The Third Man, Ladyhawke, Mimic, The Phantom of the Opera, Beauty and the Beast, and Jet Set Radio Future. The Todd Strasser novel Y2K-9: the Dog Who Saved the World is centered on a dog thwarting terroristic threats to electronically sabotage American sewage treatment plants.",1
"A well-known urban legend, the sewer alligator, is that of giant alligators or crocodiles residing in combined sewers, especially of major metropolitan areas. Two public sculptures in New York depict an alligator dragging a hapless victim into a manhole.Alligators have been known to get into combined storm sewers in the southeastern United States. Closed-circuit television by a sewer repair company captured an alligator in a combined storm sewer on tape. Fatberg (sewer obstruction) Sanitary sewer overflow Thames Tideway Scheme Storm drain U.S. EPA – Combined Sewer Overflows",1
"The bill was the United States Senate companion to proposed legislation in the House of Representatives by Representative Anna Eshoo (D-CA), a member of the Energy and Commerce Committee. She said she was motivated to write the bill after a loud commercial interrupted conversation at a family dinner; when she turned to her brother-in-law, asking him to ""do something"" about the loud television, he replied, ""Well, you're the congresswoman. Why don't you do something about it?"". According to Eshoo, no one turned her down when she looked for supporters to the bill, and it passed the Communications Subcommittee.",1
"The technical requirements for measuring loudness were taken entirely from a formerly voluntary ""recommended practice"" issued by the Advanced Television Systems Committee (ATSC) on November 4, 2009. Eshoo told The Wall Street Journal that legislation to mitigate the volume of commercials on TV was among the most popular pieces of legislation she has sponsored in her 18 years in Congress.Prior to adjourning for the midterm recess, the United States Senate unanimously passed the bill on September 30, 2010.",1
"Before it was signed into law in December, minor differences between the two versions had to be worked out when Congress returned to Washington after the November 2 election. The reconciled bill was signed into law by President Barack Obama on December 15, 2010, as Public Law 111-311.On May 27, 2011, the FCC released a Notice of Proposed Rulemaking (NPRM), Media Bureau (MB) Docket 11-93, to implement the CALM Act. Twelve parties filed comments, which are now available in the FCC's Electronic Comment Filing System (ECFS).",1
"The FCC adopted its rules on December 13, 2011, and they took effect on December 13, 2012. Television viewers are asked to report loud commercials that violate this bill to the FCC. ""111th Congress Public Law 311"". From the U.S. Government Printing Office. FCC's Loud Commercials Page ""Loudness Measurements and the CALM Act"" (PDF). Qualis Audio. Retrieved March 10, 2011. ATSC Recommended Practice A/85 – Techniques for Establishing and Maintaining Audio Loudness for Digital Television ""Optimod 8685 - allowing stations to comply effortlessly with the requirements of the CALM act"". Orban. Archived from the original on February 27, 2011.",1
"Retrieved April 13, 2011. FCC Encyclopedia: Loud Commercials and the CALM Act ""Linear Acoustic - Helping broadcasters achieve CALM Act compliance by providing loudness control, metering, and monitoring solutions"". Linear Acoustic. ""Minntonka Audio - The New Loudness Dilemma"" (PDF). Minnetonka Audio Software, Inc. ""EBU Recommendation R 128 - Loudness normalisation and permitted maximum level of audio signals"" (PDF). EBU. ""EBU TECH Doc 3343 v.2 - Practical guidelines for Production and Implementation in accordance with EBU R 128"" (PDF). EBU.",1
"Computer liquidation is a sustainable solution and is environmentally friendly. Rapid technology change, low initial cost, and planned obsolescence have resulted in a fast-growing surplus of computers and other electronic components around the globe. The purpose of computer liquidators is to keep as many computers and electronic parts out of landfills. As newer and better technology replaces hardware at an ever-increasing speed, the amount of technical trash increases as the technology is being replaced. The speed at which hardware changes and innovates in the last few years follows, to some degree, Moore's Law.",1
"The option of liquidation actually incentivizes people to get rid of their electronic waste in a safer way, since recycling actually costs the owner money, so there are cases where people would rather throw it out to avoid the recycling fee.Computer liquidators effectively create a secondary market to meet the demand of those who are looking for a cheaper solution and do not require cutting edge technology. It is important to note that the IT equipment being liquidated ranges from new technology to old technology.",1
"The sellers are companies who are bankrupt and need to sell their assets, companies who are downsizing or expanding, and companies who are upgrading their technology. Usually, companies who are looking to sell their equipment will first conduct an information technology audit to review their systems and equipment. The process is generally fueled by the supply side, as computer liquidators rely on what is available on the market for them to liquidate and resell. Thus, there nearly always exists a shortage for buyers.",1
"Then, the devices or parts are resold to smaller companies and places like school districts, who are in need of these products. Most of the companies involved in the computer liquidation business are also heavily involved in the computer and electronic recycling industry which takes on a similar process of disassembling and testing. This process theoretically benefits both ends of the exchange, the seller gets money for equipment they no longer needs and the buyer gets cheap equipment that is necessary for their work.",1
A number of organizations have sprung up that provide technical guidelines to those handling or dealing in eWaste.,1
"Psychological noise results from preconceived notions brought to conversations, such as stereotypes, reputations, biases, and assumptions. When we come into a conversation with ideas about what the other person is going to say and why, we can easily become blinded to their original message. Most of the time it is difficult to distance oneself from psychological noise, recognizing that it exists and taking those distractions into account when we converse with others is important.",1
"Psychological noise occurs when the psychological state of the receiver(s) is such as to produce an unpredictable decoding (right after a major earthquake, an ""oldies"" radio station in Los Angeles plays Elvis Presley's ""I'm All Shook Up"" as part of a preprogrammed music session, and is condemned by listeners for mocking victims of the quake)(L Chirubvu, 2018) Psychological noise can also include factors such as one’s current mood and one’s interest in the conversation topic. For example, suppose the receiver has a general liking to the sender in the communication encounter.",1
"In that case, the receiver will be more successful in effectively listening to the sender’s message, and he or she will be able to respond effectively. Also, if the receiver is in either a bad or good mood, it will have an impact on how he or she receives the message. Although a positive emotion can increase the possibility of a successful communication encounter, it can also have a negative impact. It is crucial to recognize these emotions and analyze whether they are impacting the message transmission.",1
"In 2014, 505.1 million tons of demolition debris was generated in the US. Out of the 505.1 million tons, the debris was composed of 353.6 million tons of concrete, 76.6 million tons of asphalt concrete, 35.8 million tons of wood product, 12.7 million tons of asphalt shingles, 11.8 million tons of brick and clay tile, 10.3 million tons of drywall and plaster, and 4.3 million tons of steel. Before demolition debris is extracted, contamination from lead, asbestos or other hazardous materials must be resolved. Hazardous materials must be disposed of separately, according to federal regulation.",1
Construction waste – Unwanted material produced directly or incidentally by the construction industries Recycling – Converting waste materials into new products Concrete recycling – Re-use of rubble from demolished concrete structures Waste management – Activities and actions required to manage waste from its source to its final disposal Control of Substances Hazardous to Health Regulations 2002 – Uk Statutory Instrument 2002 No. 2677Pages displaying wikidata descriptions as a fallback Embodied carbon – Measure of greenhouse gas emissions List of solid waste treatment technologies Index of waste management articles,1
"It is slightly soluble in hexane and progressively more so in benzene, acetonitrile, methylene chloride, methanol, ethanol, and acetone. It is also soluble in aqueous alkali. The naturally occurring isomer trans-zearalenone (trans-ZEN) is transformed by ultraviolet irradiation to cis-zearalenone (cis-ZEN). Zearalenone is metabolically transformed to α-zearalenol (α-Zel) or (α-Zol), β-zearalenol (β-Zel) or (β-Zol), α-zearalanol (α-Zal), β-zearalanol (β-Zal), and zearalanone (ZAN) in animals. The relative composition of these metabolic products varies by species. In pigs, cows and ducks, α-Zel is the dominant form detected. In humans, both α-Zel and β-Zel are seen in urine samples, with the beta form being prevalent.",1
"In chickens, β-Zel is the dominant form and in plant cells, the metabolic product zeralenonne-14-O-β-glucoside has been detected. Additionally, in the organs of animals these metabolic products are further modified to yield zearalenone-14-glucuronide (ZEN-14GlcA), α-zearalenol-glucuronide (α-Zel-14G) and β-zearalenol-glucuronide (β-Zel-14G). Zearalenone can permeate through the human skin. However, no significant hormonal effects are expected after dermal contact in normal agricultural or residential environments. Zearalenone structure is similar to estrogens and α-zearalenol binds with an even greater affinity estrogen receptors, while β-zearalenol's affinity is lower than both the parent compound's and α-Zel's binding affinity. This identifies ZEN and its metabolites as xenoestrogens.",1
"The human and livestock exposure to ZEN through the diet poses health concern due to the onset of several sexual disorders and alterations in the development of sexual apparatus. There are reliable case reports of early puberty in girls chronically exposed to ZEN in various regions of the world. In mice, ZEN consumption was linked to a decline of potent sperm and egg cells, an increase to double-stranded breaks in DNA and activation of DNA repair mechanisms, followed by embryonic development challenges that reduced the viability of offspring.",1
"Another approach for the analysis of ZEA, without the requirement of expensive instrumentation, is developing specific peptide mimetic with the bioluminescent Gaussia luciferase fused as one protein that can bind specifically to ZEA. α-Zearalenol β-Zearalenol Taleranol Zeranol Zearalanone Media related to Zearalenone at Wikimedia Commons Eriksen GS, Pennington J, Schlatter J (2000). ""Zearalenone"". WHO International Programme on Chemical Safety - Safety Evaluation of Certain Food Additives and Contaminants. Inchem. WHO Food Additives Series.",1
"In example, for an Electric Vehicle, an hybrid method considering also the GHG due to the manufacturing and the end of life of the battery gives GHG emissions 10–13% higher, compared to the WTW Methods not considering LCA aspects but only the emissions occurring during a specific process; i.e. just the combustion of a fuel in a power plant, without considering the Upstream emissions.Different calculation methods can lead to different results. The results can largely vary also for different geographic regions and timeframes (see, in example, how C.I.",1
"of electricity varies, for different European countries, and how varied in a few years: from 2009 to 2013 the C.I. of electricity in the European Union fell on average by 20%, So while comparing different values of Carbon Intensity it is important to correctly consider all the boundary conditions (or initial hypotheses) considered for the calculations. For example, Chinese oil fields emit between 1.5 and more than 40 g of CO2e per MJ with about 90% of all fields emitting 1.5–13.5 g CO2e.",1
"Examples of these are particulates, NOx, a mixture of nitric oxide, NO, and nitrogen dioxide, NO2). Nitrous oxide (N2O) emissions from agricultural soils are highly uncertain because they depend very much on both the exact conditions of the soil, the application of fertilizers and meteorological conditions. A literature review of numerous total life cycle energy sources CO2 emissions per unit of electricity generated, conducted by the Intergovernmental Panel on Climate Change in 2011, found that the CO2 emission value, that fell within the 50th percentile of all total life cycle emissions studies were as follows. Note: 3.6",1
"Annual data between 1980 and 2009 are averaged over three decades: 1980–89, 1990–99, and 2000–09. In 2009 CO2 intensity of GDP in the OECD countries reduced by 2.9% and amounted to 0.33 kCO2/$05p in the OECD countries. (""$05p"" = 2005 US dollars, using purchasing power parities). The USA posted a higher ratio of 0.41 kCO2/$05p while Europe showed the largest drop in CO2 intensity compared to the previous year (−3.7%). CO2 intensity continued to be roughly higher in non-OECD countries. Despite a slight improvement, China continued to post a high CO2 intensity (0.81 kCO2/$05p).",1
CO2 intensity in Asia rose by 2% during 2009 since energy consumption continued to develop at a strong pace. Important ratios were also observed in countries in CIS and the Middle East.,1
"This shows that global emissions has grown rapidly, increasing by about 2.1% each year compared from the previous decade.The Commodity Exchange Bratislava (CEB) has calculated carbon intensity for Voluntary Emissions Reduction projects carbon intensity in 2012 to be 0.343 tn/MWh.According to data from the European Commission, in order to achieve the EU goal of decreasing greenhouse gas emissions by at least 55% by 2030 compared to 1990, EU-based energy investment has to double from the previous decade to more than €400 billion annually this decade.",1
"This includes the roughly €300 billion in yearly investment required for energy efficiency and the roughly €120 billion required for power networks and renewable energy facilities. One of the most important uses of emission factors is for the reporting of national greenhouse gas inventories under the United Nations Framework Convention on Climate Change (UNFCCC). The so-called Annex I Parties to the UNFCCC have to annually report their national total emissions of greenhouse gases in a formalized reporting format, defining the source categories and fuels that must be included.",1
"Natural gas, being methane (CH4), has 4 hydrogen atoms to burn for each one of carbon and thus has medium CO2 emission intensity.",1
2006 IPCC Guidelines for National Greenhouse Gas Inventories Revised 1996 IPCC Guidelines for National Greenhouse Gas Inventories (reference manual). IPCC Emission Factor Database National Inventory Report: Greenhouse Gas Sources and Sinks in Canada. United Kingdom's emission factor database.,1
"The Science study, which was conducted by Stanford University found that Canadian crude oil is the ""fourth-most greenhouse gas (GHG) intensive in the world"" behind Algeria, Venezuela and Cameroon.",1
Wayback Machine Electricity carbon intensity in European Member States: Impacts on GHG emissions of electric vehicles A hybrid LCA-WTW method to assess the carbon footprint of electric vehicles Carbon emissions intensity from different regions,1
"eGRID2021 was released by EPA on January 30, 2023. It contains year 2021 data. eGRID2020 was released by EPA on January 27, 2022. It contains year 2020 data. eGRID2019 was released by EPA on February 23, 2021. It contains year 2019 data. eGRID2018 was released by EPA on January 28, 2020 and eGRID2018v2 was released on March 9, 2020. It contains year 2018 data. eGRID2016 was released by EPA on February 15, 2018. It contains year 2016 data. eGRID2014 was released by EPA on January 13, 2017. It contains year 2014 data. eGRID2012 was released by EPA on October 8, 2015.",1
"It is the 10th edition and contains year 2012 data. eGRID2010 Version 1.0 with year 2010 data was released on February 24, 2014. eGRID2009 Version 1.0, with year 2009 data was released on May 10, 2012. eGRID2007 Version 1.0 was released on February 23, 2011 and Version 1.1 was released May 20, 2011. eGRID2005 Version 1.0 was released in October 2008 and Version 1.1 was released in January 2009. eGRID2004 Version 1.0 was released in December 2006; Version 2.0 was released in early April 2007; and Version 2.1, was released in late April 2007 and updated for typos in May 2007.",1
"eGRID2000 Version 1.0 was released in December 2002; Version 2.0 was released in April 2003; and Version 2.01 was released in May 2003. (eGRID2000 replaced eGRID versions 1996 through 1998). eGRID1998 was released in March and September 2001. eGRID1997 was released in December 1999. eGRID1996 was first released in December 1998. eGRID data include emissions, different types of emission rates, electricity generation, resource mix, and heat input. eGRID data also include plant identification, location, and structural information.",1
"eGRID data is presented as an Excel workbook with data worksheets and a table of contents. The eGRID workbook contains data at the unit, generator, and plant levels and aggregated data by state, power control area, eGRID subregion, NERC region, and U.S. The workbook also includes a worksheet that displays the grid gross loss (%). Additional documentation is also provided with each eGRID release such as, a Technical Guide (PDF), Summary Tables, eGRID subregion map (JPG), NERC region Map (JPG), and release notes (TXT).",1
"In 2010, Executive Order 13514 was issued, requiring Federal agencies to “measure, report, and reduce their greenhouse gas emissions from direct and indirect activities.” The Federal GHG Accounting and Reporting Guidance accompanied this order and recommended using eGRID non-baseload emission rates to estimate the Scope 2 (indirect) emission reductions from renewable energy.",1
"A consignment of Friendly Floatee toys, manufactured in China for The First Years Inc., departed from Hong Kong on a container ship, the Evergreen Ever Laurel, destined for Tacoma, Washington. On 10 January 1992, during a storm in the North Pacific Ocean close to the International Date Line, twelve 40-foot (12-m) intermodal containers were washed overboard. One of these containers held 28,800 Floatees, a child's bath toy which came in a number of forms: red beavers, green frogs, blue turtles and yellow ducks.",1
"The mass release of 28,800 objects into the ocean at one time offered significant advantages over the standard method of releasing 500–1000 drift bottles. The recovery rate of objects from the Pacific Ocean is typically around 2%, so rather than the 10 to 20 recoveries typically seen with a drift bottle release, the two scientists expected numbers closer to 600. They were already tracking various other spills of flotsam, including 61,000 Nike running shoes that had been lost overboard in 1990. Ten months after the incident, the first Floatees began to wash up along the Alaskan coast.",1
"The first discovery consisted of ten toys found by a beachcomber near Sitka, Alaska on 16 November 1992, about 3,200 kilometres (2,000 mi) from their starting point. Ebbesmeyer and Ingraham contacted beachcombers, coastal workers, and local residents to locate hundreds of the beached Floatees over a 850 kilometres (530 mi) shoreline. Another beachcomber discovered twenty of the toys on 28 November 1992, and in total 400 were found along the eastern coast of the Gulf of Alaska in the period up to August 1993. This represented a 1.4% recovery rate.",1
"Using the models they had developed, the oceanographers correctly predicted further landfalls of the toys in Washington state in 1996 and theorized that many of the remaining Floatees would have traveled to Alaska, westward to Japan, back to Alaska, and then drifted northwards through the Bering Strait and become trapped in the Arctic pack ice. Moving slowly with the ice across the Pole, they predicted it would take five or six years for the toys to reach the North Atlantic where the ice would thaw and release them. Between July and December 2003, The First Years Inc.",1
"offered a $100 US savings bond reward to anybody who recovered a Floatee in New England, Canada or Iceland. More of the toys were recovered in 2004 than in any of the preceding three years. However, still, more of these toys were predicted to have headed eastward past Greenland and make landfall on the southwestern shores of the United Kingdom in 2007. In July 2007, a retired teacher found a plastic duck on the Devon coast, and British newspapers mistakenly announced that the Floatees had begun to arrive.",1
"But the day after breaking the story, the Western Morning News, the local Devon newspaper, reported that Dr. Simon Boxall of the National Oceanography Centre in Southampton had examined the toy and determined that the duck was not in fact a Floatee.Bleached by sun and seawater, the ducks and beavers had faded to white, but the turtles and frogs had kept their original colors. At least two children's books have been inspired by the Floatees. In 1997, Clarion Books published Ducky (ISBN 0-395-75185-3), written by Eve Bunting and illustrated by Caldecott Medal winner David Wisniewski.",1
"Hans Christian Andersen Award winner Eric Carle wrote 10 Little Rubber Ducks (Harper Collins 2005, ISBN 978-0-00-720242-3).In 2003, Rich Eilbert wrote a song ""Yellow Rubber Ducks"" commemorating the ducks' journey. In 2011, he published the song as a YouTube video, Yellow Rubber Ducks.",1
"In 2011, Donovan Hohn published Moby-Duck: The True Story of 28,800 Bath Toys Lost at Sea and of the Beachcombers, Oceanographers, Environmentalists, and Fools, Including the Author, Who Went in Search of Them (Viking, ISBN 978-0-670-02219-9)On 20 June 2014, The Disney Channel and Disney Junior aired Lucky Duck, a Canadian-American animated TV movie that is loosely based on and inspired by the Friendly Floatees.In his 2014 poem collection The Cartographer Tries to Map a Way to Zion, poet Kei Miller dedicates a poem to the Friendly Floatees : ""When Considering the Long, Long Journey of 28,000 Rubber Ducks"".",1
"The spill was referenced in a 2022 game ""Placid Plastic Duck Simulator"" as an ""accidental duck experiment"", which can be heard on the radio in between music. The toys themselves have become collector's items, fetching prices as high as $1,000. Drifter (floating device) Great Pacific garbage patch Hansa Carrier Marine debris Message in a bottle Rye Riptides Keith C. Heidorn, 'Of Shoes And Ships And Rubber Ducks And A Message In A Bottle', The Weather Doctor (17 March 1999). Jane Standley, 'Ducks' odyssey nears end', BBC News, (12 July 2003).",1
"Duck ahoy, The Age, (7 August 2003) Marsha Walton, 'How Nikes, toys and hockey gear help ocean science', CNN.com (26 May 2003). ""Journey of the Floatees"", Spiegel magazine (1 July 2007) ""Timeline of Rubber Duck Voyage"", Rubaduck.com Donovan Hohn, ""Moby-Duck: Or, The Synthetic Wilderness of Childhood,"" Harper's Magazine, January (2007), pp. 39–62.",1
"Moby Duck: The True Story of 28,800 Bath Toys Lost at Sea and of the Beachcombers, Oceanographers, Environmentalists, and Fools, Including the Author, Who Went in Search of Them Archived 7 September 2013 at the Wayback Machine – follow up non-fiction book based on 2 years research after the Harper's Magazine article. Rich Eilbert, Yellow Rubber Ducks, YouTube.com, (March 2011).",1
"Evelyn was appointed to the newly formed Royal Society, and both Society and pamphlet are celebrated in the 1663 ""Ballad of Gresham College"". Stanza 23 (given here in modern English) describes how Evelyn [...] shows that 'tis the sea-coal smokeThat always London does environ, Which does our lungs and spirits choke, Our hanging spoil, and rust our iron. Let none at Fumifuge be scoffing Who heard at Church our Sunday's coughing. The sea-coal to which Evelyn referred was appropriately named because it came by sea from Newcastle.",1
"High levels of freshwater acidification is harmful to various aquatic organisms. Nonetheless, there are many freshwater systems, including the Great Lakes, where pH levels could be decreasing, most likely due to CO2 accumulation in the atmosphere, however, increased monitoring is necessary to determine the full effects of acidification on pH levels. The ocean and the atmosphere are constantly exchanging massive amounts of CO2. Over the last 800,000 years, the concentration of CO2 in the atmosphere has remained around 172-300 parts per million by volume (ppmv). With increases of anthropogenic CO2 emissions, this number has risen to 387 ppmv in 2009.",1
"However, in large amounts, not all of it can be taken up by vegetation so the excess gets washed away with runoff in the form of nitrate, contributing to acidification in the same manner as sulfate.",1
"The buffering capacity of ecosystems helps them resist changes in pH. When this is lacking, it can lead to the acidification of freshwater reservoirs. For example, the Atlantic region of Canada has the lowest acid deposition rates in Eastern North America, yet it has the most acidic waters on the continent. This is due to the low buffering capacity of the regional bedrock and the addition of natural organic acids produced from close by wetlands.",1
"For example, frogs and perches can withstand a pH level of 4. This allows these species to be unaffected by the acid deposition in their aquatic environment, allowing them to survive in these conditions. However, most aquatic species, such as clams and snails, are unable to withstand low pH levels which negatively impacts their growth and survival. The high acidic levels deteriorate their thick shells decreasing their protection from predators. Acidification of freshwater ecosystems may have significant negative effects.",1
"Changes in pH as a result of freshwater acidification imposes physiological challenges on individual organisms, may decrease native biodiversity, and can alter ecosystem structure and function entirely. Macro-invertebrates and large vertebrates alike are particularly sensitive to acidification as they exhibit higher mortality and lower reproductive rates under acidified conditions. These species are forced to expend more energy on buffering their body conditions to retain a livable pH and, therefore, must limit energy expenditure on processes such as hunting, sheltering, and reproducing. Thus, embryonic development, and species' success, is also compromised in acidified freshwaters.Conversely,",1
"There are processes that can remediate the acidification of freshwaters. Liming is one such practice, where calcium carbonate (CaCO3) is added to these systems. Liming aids freshwater chemical and biological recovery by increasing pH levels and essentially helping the habitat return to a similar condition to how it was prior to acidification. Otherwise, recovery on its own would be very extensive and take a lot longer to achieve. When added to rivers, liming showed some positive effects on wildlife, increasing the abundance of fish and acid-sensitive invertebrates. However, these effects are variable.",1
"Moreover, the practice of waste separation is fundamental as it allows for the breakdown of the chemicals that cause acid rain. And, finally, being altogether more aware of the effect human actions have on the environment to better protect the planet.",1
"A detailed inventory of greenhouse gas emissions from upstream oil and gas activities in Canada for the year 2000 estimated that fugitive equipment leaks had a global warming potential equivalent to the release of 17 million metric tonnes of carbon dioxide, or 12 percent of all greenhouse gases emitted by the sector, while another report put fugitive emissions at 5.2% of world greenhouse emissions in 2013. Venting of natural gas, flaring, accidental releases and storage losses accounted for an additional 38 percent.Fugitive emissions present other risks and hazards.",1
Gas flare Greenhouse gas Leaks Volatile organic compound Fugitive gas emissions,1
"IPCC AR5 WG1 (2013), Stocker, T.F.; et al. (eds.), Climate Change 2013: The Physical Science Basis. Working Group 1 (WG1) Contribution to the Intergovernmental Panel on Climate Change (IPCC) 5th Assessment Report (AR5), Cambridge University Press. Climate Change 2013 Working Group 1 website. 2006 IPCC Guidelines for National Greenhouse Gas Inventories (see Section 4.2).",1
"On the other hand, any algal bloom can cause dead zones due to low oxygen levels, and could therefore be called ""harmful"" in that sense. The usage of the term ""harmful algal blooms"" in the media and scientific literature is varied. In a broader definition, all ""organisms and events are considered to be HABs if they negatively impact human health or socioeconomic interests or are detrimental to aquatic systems"". A harmful algal bloom is ""a societal concept rather than a scientific definition"".A",1
"Harmful algal bloom in coastal areas are also often referred to as ""red tides"". The term ""red tide"" is derived from blooms of any of several species of dinoflagellate, such as Karenia brevis. However, the term is misleading since algal blooms can widely vary in color, and growth of algae is unrelated to the tides. Not all red tides are produced by dinoflagellates. The mixotrophic ciliate Mesodinium rubrum produces non-toxic blooms coloured deep red by chloroplasts it obtains from the algae it eats.",1
"As a technical term, it is being replaced in favor of more precise terminology, including the generic term ""harmful algal bloom"" for harmful species, and ""algal bloom"" for benign species. There are three main types of phytoplankton which can form into harmful algal blooms: cyanobacteria, dinoflagellates and diatoms. All three are made up of microscopic floating organisms which, like plants, can create their own food from sunlight by means of photosynthesis. That ability makes the majority of them an essential part of the food web for small fish and other organisms.: 246",1
"Harmful algal blooms in freshwater lakes and rivers, or at estuaries, where rivers flow into the ocean, are caused by cyanobacteria, which are commonly referred to as ""blue-green algae"", but are in fact prokaryotic bacteria, as opposed to algae which are eukaryotes. Some cyanobacteria, including the widespread genus Microsystis, can produce hazardous cyanotoxins such as microcystins, which are hepatotoxins that harm the liver of mammals. Other types of cyanobacteria can also produce hepatotoxins, as well as neurotoxins, cytotoxins, and endotoxins.",1
"The frequency and severity of HABs in some parts of the world have been linked to increased nutrient loading from human activities. In other areas, HABs are a predictable seasonal occurrence resulting from coastal upwelling, a natural result of the movement of certain ocean currents.The growth of marine phytoplankton (both non-toxic and toxic) is generally limited by the availability of nitrates and phosphates, which can be abundant in coastal upwelling zones as well as in agricultural run-off.",1
"The growth of marine phytoplankton is generally limited by the availability of nitrates and phosphates, which can be abundant in agricultural run-off as well as coastal upwelling zones. Other factors such as iron-rich dust influx from large desert areas such as the Sahara Desert are thought to play a major role in causing HAB events. Some algal blooms on the Pacific Coast have also been linked to occurrences of large-scale climatic oscillations such as El Niño events.",1
"Other factors such as iron-rich dust influx from large desert areas such as the Sahara are thought to play a role in causing HABs. Some algal blooms on the Pacific coast have also been linked to natural occurrences of large-scale climatic oscillations such as El Niño events. HABs are also linked to heavy rainfall. Although HABs in the Gulf of Mexico were witnessed in the early 1500s by explorer Cabeza de Vaca, it is unclear what initiates these blooms and how large a role nanthropogenic and natural factors play in their development.",1
"The number of reported harmful algal blooms (cyanobacterial) has been increasing throughout the world. It is unclear whether the apparent increase in frequency and severity of HABs in various parts of the world is in fact a real increase or is due to increased observation effort and advances in species identification technology.In 2008, the U.S. government prepared a report on the problem, ""Harmful Algal Bloom Management and Response: Assessment and Plan"". The report recognized the seriousness of the problem: It is widely believed that the frequency and geographic distribution of HABs have been increasing worldwide. All U.S.",1
"coastal states have experienced HABs over the last decade, and new species have emerged in some locations that were not previously known to cause problems. HAB frequency is also thought to be increasing in freshwater systems. Researchers have reported the growth of HABs in Europe, Africa and Australia. Those have included blooms on some of the African Great Lakes, such as Lake Victoria, the second largest freshwater lake in the world. India has been reporting an increase in the number of blooms each year. In 1977 Hong Kong reported its first coastal HAB.",1
"Eating fish or shellfish from lakes with a bloom nearby is not recommended. Potent toxins are accumulated in shellfish that feed on the algae. If the shellfish are consumed, various types of poisoning may result. These include amnesic shellfish poisoning (ASP), diarrhetic shellfish poisoning, neurotoxic shellfish poisoning, and paralytic shellfish poisoning. A 2002 study has shown that algal toxins may be the cause for as many as 60,000 intoxication cases in the world each year.In 1987 a new illness emerged: amnesic shellfish poisoning (ASP). People who had eaten mussels from Prince Edward Island were found to have ASP.",1
"The illness was caused by domoic acid, produced by a diatom found in the area where the mussels were cultivated. A 2013 study found that toxic paralytic shellfish poisoning in the Philippines during HABs has caused at least 120 deaths over a few decades. After a 2014 HAB incident in Monterey Bay, California, health officials warned people not to eat certain parts of anchovy, sardines, or crab caught in the bay. In 2015 most shellfish fisheries in Washington, Oregon and California were shut down because of high concentrations of toxic domoic acid in shellfish.",1
Those with suspected symptoms are told to call a doctor if symptoms persist or they can't hold down fluids after 24 hours.In studies at the population level bloom coverage has been significantly related to the risk of non-alcoholic liver disease death.,1
"Toxic algae blooms are thought to play a role in humans developing degenerative neurological disorders such as amyotrophic lateral sclerosis and Parkinson's disease.Less than one percent of algal blooms produce hazardous toxins, such as microcystins. Although blue-green or other algae do not usually pose a direct threat to health, the toxins (poisons) which they produce are considered dangerous to humans, land animals, sea mammals, birds and fish when the toxins are ingested. The toxins are neurotoxins which destroy nerve tissue which can affect the nervous system, brain, and liver, and can lead to death.",1
"Humans are affected by the HAB species by ingesting improperly harvested shellfish, breathing in aerosolized brevetoxins (i.e. PbTx or Ptychodiscus toxins) and in some cases skin contact. The brevetoxins bind to voltage-gated sodium channels, important structures of cell membranes. Binding results in persistent activation of nerve cells, which interferes with neural transmission leading to health problems. These toxins are created within the unicellular organism, or as a metabolic product. The two major types of brevetoxin compounds have similar but distinct backbone structures. PbTx-2 is the primary intracellular brevetoxin produced by K. brevis blooms.",1
"However, over time, the PbTx-2 brevetoxin can be converted to PbTx-3 through metabolic changes. Researchers found that PbTx-2 has been the primary intracellular brevetoxin that converts over time into PbTx-3.In the U.S., the seafood consumed by humans is tested regularly for toxins by the USDA to ensure safe consumption. Such testing is common in other nations. However, improper harvesting of shellfish can cause paralytic shellfish poisoning and neurotoxic shellfish poisoning in humans. Some symptoms include drowsiness, diarrhea, nausea, loss of motor control, tingling, numbing or aching of extremities, incoherence, and respiratory paralysis.",1
"Reports of skin irritation after swimming in the ocean during a HAB are common.When the HAB cells rupture, they release extracellular brevetoxins into the environment. Some of those stay in the ocean, while other particles get aerosolized. During onshore winds, brevetoxins can become aerosolized by bubble-mediated transport, causing respiratory irritation, bronchoconstriction, coughing, and wheezing, among other symptoms.It is recommended to avoid contact with wind-blown aerosolized toxin. Some individuals report a decrease in respiratory function after only 1 hour of exposure to a K. brevis red-tide beach and these symptoms may last for days.",1
People with severe or persistent respiratory conditions (such as chronic lung disease or asthma) may experience stronger adverse reactions.The National Oceanic and Atmospheric Administration's National Ocean Service provides a public conditions report identifying possible respiratory irritation impacts in areas affected by HABs.,1
"The hazards which accompany harmful algal blooms have hindered visitors' enjoyment of beaches and lakes in places in the U.S. such as Florida, California, Vermont, and Utah. Persons hoping to enjoy their vacations or days off have been kept away to the detriment of local economies. Lakes and rivers in North Dakota, Minnesota, Utah, California and Ohio have had signs posted warning about the potential of health risk.Similar blooms have become more common in Europe, with France among the countries reporting them. In the summer of 2009, beaches in northern Brittany became covered by tonnes of potentially lethal rotting green algae.",1
"A horse being ridden along the beach collapsed and died from fumes given off by the rotting algae.The economic damage resulting from lost business has become a serious concern. According to one report in 2016, the four main economic impacts from harmful algal blooms come from damage to human health, fisheries, tourism and recreation, and the cost of monitoring and management of area where blooms appear. EPA estimates that algal blooms impact 65 percent of the country's major estuaries, with an annual cost of $2.2 billion. In the U.S. there are an estimated 166 coastal dead zones.",1
"Because data collection has been more difficult and limited from sources outside the U.S., most of the estimates as of 2016 have been primarily for the U.S.In port cities in the Shandong Province of eastern China, residents are no longer surprised when massive algal blooms arrive each year and inundate beaches. Prior to the Beijing Olympics in 2008, over 10,000 people worked to clear 20,000 tons of dead algae from beaches.",1
"As early as 1976 a short-term, relatively small, dead zone off the coasts of New York and New Jersey cost commercial and recreational fisheries over $500 million. In 1998 a HAB in Hong Kong killed over $10 million in high-value fish.In 2009, the economic impact for the state of Washington's coastal counties dependent on its fishing industry was estimated to be $22 million. In 2016, the U.S. seafood industry expected future lost revenue could amount to $900 million annually.NOAA has provided a few cost estimates for various blooms over the past few years: $10.3",1
"closures applied to areas where this algae bloom occurs has a big negative impact of the fishing industries, add to that the high fish mortality that follows, the increase in price due to the shortage of fish available and decrease in the demand for seafood due to the fear of contamination by toxins. This causes a big economic loss for the industry. Economic costs are estimated to rise. In June 2015, for instance, the largest known toxic HAB forced the shutdown of the west coast shellfish industry, the first time that has ever happened.",1
"A record-breaking number and size of blooms have formed in the Pacific coast, in Lake Erie, in the Chesapeake Bay and in the Gulf of Mexico, where a number of dead zones were created as a result. In the 1960s the number of dead zones worldwide was 49; the number rose to over 400 by 2008.Among the largest dead zones were those in northern Europe's Baltic Sea and the Gulf of Mexico, which affects a $2.8 billion U.S. fish industry. Unfortunately, dead zones rarely recover and usually grow in size.",1
"During large blooms, the toxin accumulates in shellfish and small fish such as anchovies and sardines that feed on algae, forcing the closure of some fisheries and poisoning marine mammals and birds that feed on contaminated fish."" Similar fish die-offs from toxic algae or lack of oxygen have been seen in Russia, Colombia, Vietnam, China, Canada, Turkey, Indonesia, and France.",1
"Land animals, including livestock and pets have been affected. Dogs have died from the toxins after swimming in algal blooms. Warnings have come from government agencies in the state of Ohio, which noted that many dogs and livestock deaths resulted from HAB exposure in the U.S. and other countries. They also noted in a 2003 report that during the previous 30 years, they have seen more frequent and longer-lasting harmful algal blooms."" In 50 countries and 27 states that year there were reports of human and animal illnesses linked to algal toxins.",1
"In Australia, the department of agriculture warned farmers that the toxins from a HAB had the ""potential to kill large numbers of livestock very quickly."" Marine mammals have also been seriously harmed, as over 50 percent of unusual marine mammal deaths are caused by harmful algal blooms. In 1999, over 65 bottlenose dolphins died during a coastal HAB in Florida. In 2013 a HAB in southwest Florida killed a record number of Manatee. Whales have also died in large numbers.",1
"During the period from 2005 to 2014, Argentina reported an average 65 baby whales dying which experts have linked to algal blooms. A whale expert there expects the whale population to be reduced significantly. In 2003 off Cape Cod in the North Atlantic, at least 12 humpback whales died from toxic algae from a HAB. In 2015 Alaska and British Columbia reported many humpback whales had likely died from HAB toxins, with 30 having washed ashore in Alaska. ""Our leading theory at this point is that the harmful algal bloom has contributed to the deaths,"" said a NOAA spokesperson.Birds",1
"have died after eating dead fish contaminated with toxic algae. Rotting and decaying fish are eaten by birds such as pelicans, seagulls, cormorants, and possibly marine or land mammals, which then become poisoned. The nervous systems of dead birds were examined and had failed from the toxin's effect. On the Oregon and Washington coast, a thousand scoters, or sea ducks, were also killed in 2009. ""This is huge,"" said a university professor. As dying or dead birds washed up on the shore, wildlife agencies went into ""an emergency crisis mode.""It",1
"has even been suggested that harmful algal blooms are responsible for the deaths of animals found in fossil troves, such as the dozens of cetacean skeletons found at Cerro Ballena.",1
"Harmful algal blooms in marine ecosystems have been observed to cause adverse effects to a wide variety of aquatic organisms, most notably marine mammals, sea turtles, seabirds and finfish. The impacts of HAB toxins on these groups can include harmful changes to their developmental, immunological, neurological, or reproductive capacities. The most conspicuous effects of HABs on marine wildlife are large-scale mortality events associated with toxin-producing blooms. For example, a mass mortality event of 107 bottlenose dolphins occurred along the Florida panhandle in the spring of 2004 due to ingestion of contaminated menhaden with high levels of brevetoxin.",1
"Manatee mortalities have also been attributed to brevetoxin but unlike dolphins, the main toxin vector was endemic seagrass species (Thalassia testudinum) in which high concentrations of brevetoxins were detected and subsequently found as a main component of the stomach contents of manatees.Additional marine mammal species, like the highly endangered North Atlantic right whale, have been exposed to neurotoxins by preying on highly contaminated zooplankton. With the summertime habitat of this species overlapping with seasonal blooms of the toxic dinoflagellate Alexandrium fundyense, and subsequent copepod grazing, foraging right whales will ingest large concentrations of these contaminated copepods.",1
"Ingestion of such contaminated prey can affect respiratory capabilities, feeding behavior, and ultimately the reproductive condition of the population.Immune system responses have been affected by brevetoxin exposure in another critically endangered species, the loggerhead sea turtle. Brevetoxin exposure, from inhalation of aerosolized toxins and ingestion of contaminated prey, can have clinical signs of increased lethargy and muscle weakness in loggerhead sea turtles causing these animals to wash ashore in a decreased metabolic state with increases of immune system responses upon blood analysis.Examples",1
"HABs occur naturally off coasts all over the world. Marine dinoflagellates produce ichthyotoxins. Where HABs occur, dead fish wash up on shore for up to two weeks after a HAB has been through the area. In addition to killing fish, the toxic algae contaminate shellfish. Some mollusks are not susceptible to the toxin, and store it in their fatty tissues. By consuming the organisms responsible for HABs, shellfish can accumulate and retain saxitoxin produced by these organisms. Saxitoxin blocks sodium channels and ingestion can cause paralysis within 30 minutes.In",1
"Although these toxins do not harm epiphytes, they are extremely poisonous to marine creatures who consume (or accidentally consume) the exposed epiphytes, such as manatees. When manatees unknowingly consume exposed epiphytes while grazing on sea grass, the toxins are subsequently released from the epiphytes and ingested by the manatees. In addition to consumption, manatees may also become exposed to air-borne Brevetoxins released from harmful red-tide cells when passing through algal blooms. Manatees also have an immunoresponse to HABs and their toxins that can make them even more susceptible to other stressors.",1
"Due to this susceptibility, manatees can die from either the immediate, or the after effects of the HAB. In addition to causing manatee mortalities, red-tide exposure also causes severe sublethal health problems among Florida manatee populations. Studies have shown that red-tide exposure among free-ranging Florida manatees has been shown to negatively impact immune functioning by causing increased inflammation, a reduction in lymphocyte proliferation responses, and oxidative stress.",1
"Fish such as Atlantic herring, American pollock, winter flounder, Atlantic salmon, and cod were dosed orally with these toxins in an experiment, and within minutes the subjects started to exhibit a loss of equilibrium and began to swim in an irregular, jerking pattern, followed by paralysis and shallow, arrhythmic breathing and eventually death, after about an hour. HABs have been shown to have a negative effect also in the memory functions of sea lions.",1
"In addition to their anti-microalgal effects, the bioactive molecules found in these seaweeds also have antibacterial, antifungal, and antioxidant properties.",1
The process of flocculation will limit the bloom growth and reduce the impact in which the bloom can have on an area.,1
"Other experts have proposed building reservoirs to prevent the movement of algae downstream. However, that can lead to the growth of algae within the reservoir, which become sediment traps with a resultant buildup of nutrients. Some researchers found that intensive blooms in reservoirs were the primary source of toxic algae observed downstream, but the movement of algae has so far been less studied, although it is considered a likely cause of algae transport.",1
"The decline of filter-feeding shellfish populations, such as oysters, likely contribute to HAB occurrence. As such, numerous research projects are assessing the potential of restored shellfish populations to reduce HAB occurrence.",1
"Lingulodinium polyedrum produces brilliant displays of bioluminescence in warm coastal waters. Seen in Southern California regularly since at least 1901. The largest algal bloom on record was the 1991 Darling River cyanobacterial bloom in Australia, largely of Anabaena circinalis, between October and December 1991 over 1,000 kilometres (620 mi) of the Barwon and Darling Rivers. 1530: First alleged case off the Florida Gulf Coast is without foundation. According to Marine Lab at University of Miami, the first possible Red Tide in Florida was in 1844.",1
"Earlier ""signs"" were from boats sorting fish on their way to home port dumping trash fish overboard. Thus ""dead fish"" reports along the coast were not Red Tide. 1793: The first recorded case occurring in British Columbia, Canada. 1840: No deaths of humans have been attributed to Florida red tide, but people may experience respiratory irritation (coughing, sneezing, and tearing) when the red tide organism (Karenia brevis) is present along a coast and winds blow its aerosolized toxins. Swimming is usually safe, but skin irritation and burning is possible in areas of high concentration of red tide.",1
"The red tides caused by the dinoflagellate Gonyaulax are serious because this organism produces saxitoxin and gonyautoxins which accumulate in shellfish and if ingested may lead to paralytic shellfish poisoning (PSP) and can lead to death. 1972 and 1973: Red tides killed two villagers west of Port Moresby. In March 1973 a red tide invaded Port Moresby Harbour and destroyed a Japanese pearl farm. In 1972, a red tide was caused in New England by a toxic dinoflagellate Alexandrium (Gonyaulax) tamarense. 1976: The first PSP case in Sabah, Malaysian Borneo where 202 victims were reported to be suffering and 7 deaths.",1
"1987: A red algae bloom in Prince Edward Island caused over a million dollars in losses. 2005: The Canadian red tide was discovered to have come further south than it has in years prior by the ship (R/V) Oceanus, closing shellfish beds in Maine and Massachusetts and alerting authorities as far south as Montauk (Long Island, NY) to check their beds.",1
"Experts who discovered the reproductive cysts in the seabed warn of a possible spread to Long Island in the future, halting the area's fishing and shellfish industry and threatening the tourist trade, which constitutes a significant portion of the island's economy. In 2008 large blooms of the algae Cochlodinium polykrikoid were found along the Chesapeake Bay and nearby tributaries such as the James River, causing millions of dollars in damage and numerous beach closures.",1
"In 2009, Brittany, France experienced recurring macroalgal blooms caused by the high amount of fertilizer discharging in the sea due to intensive pig farming, causing lethal gas emissions that have led to one case of human unconsciousness and three animal deaths. In 2010, dissolved iron in the ash from the Eyjafjallajökull volcano triggered a plankton bloom in the North Atlantic. 2011: Northern California 2011: Gulf of Mexico In 2013, an algal bloom was caused in Qingdao, China, by sea lettuce. 2013: In January, a red tide occurred again on the West Coast Sea of Sabah in the Malaysian Borneo.",1
"brevis red tide algae with warnings not to swim, state of emergency declared, dead dolphin and manatee, worsened by Caloosahatchee River. Peaked in the summer of 2018. Toxic harmful algae bloom red tide in Southwest Florida. A rare harmful algal bloom along Florida's east coast of Palm Beach County occurred the weekend of September 30, 2018. In 2019, blue-green algae, or Cyanobacteria blooms, were again problematic on Lake Erie. In early August 2019, satellite images depicted a bloom stretching up to 1,300 square kilometers, with the epicentre near Toledo, Ohio.",1
"The event has caused the death of millions of pounds of fish, and led to the National Weather Service declaring a Beach Hazard. 2021: in October, the mass deaths of shellfish (specifically crabs and lobster) on the beaches of Northern England, led to and algal bloom being blamed as the cause by the UK Government. However, those who work in the fishing industry in the area, and some academics, have stated that pyridine poisoning is the cause.",1
"The Gulf of Maine frequently experiences blooms of the dinoflagellate Alexandrium fundyense, an organism that produces saxitoxin, the neurotoxin responsible for paralytic shellfish poisoning. The well-known ""Florida red tide"" that occurs in the Gulf of Mexico is a HAB caused by Karenia brevis, another dinoflagellate which produces brevetoxin, the neurotoxin responsible for neurotoxic shellfish poisoning. California coastal waters also experience seasonal blooms of Pseudo-nitzschia, a diatom known to produce domoic acid, the neurotoxin responsible for amnesic shellfish poisoning.",1
"These blooms have been documented since the 1800s, and occur almost annually along Florida's coasts.There was increased research activity of harmful algae blooms (HABs) in the 1980s and 1990s. This was primarily driven by media attention from the discovery of new HAB organisms and the potential adverse health effects of their exposure to animals and humans. The Florida red tides have been observed to have spread as far as the eastern coast of Mexico.",1
"related Alexandrium monilatum is found in subtropical or tropical shallow seas and estuaries in the western Atlantic Ocean, the Caribbean Sea, the Gulf of Mexico, and the eastern Pacific Ocean.",1
"This phenomenon has affected 33 reservoirs in Texas along major river systems, including the Brazos, Canadian, Rio Grande, Colorado, and Red River, and has resulted in the death of more than 27 million fish and caused tens of millions of dollars in damage.",1
"To make matters worse, harmful red tide blooms are historically common on Florida's coasts during these same summer months. Cyanobacteria in the rivers die as they reach saltwater but their nitrogen fixation feeds the red tide on the coast. Areas at the mouth of the estuaries such as Cape Coral and Port St. Lucie therefore experience the compounded effects of both types of harmful algal bloom. Cleanup crews hired by authorities in Lee County - where the Caloosahatchee meets the Gulf of Mexico - removed more than 1700 tons of dead marine life in August 2018.",1
"In 2020, a large harmful algal bloom closed beaches in Poland and Finland, brought on by a combination of fertilizer runoff and extreme heat, posing a risk to flounder and mussel beds. This is seen by the Baltic Sea Action Group as a threat to biodiversity and regional fishing stocks.",1
"Similarly, CO exposure levels have been measured to be as high as hundreds to greater than 1000 milligrams per cubic meter (mg/m3). A recent study of 163 households in two rural Chinese counties reported geometric mean indoor PM2.5 concentrations of 276 μg/m3 (combinations of different plant materials, including wood, tobacco stems, and corncobs), 327 μg/m3 (wood), 144 μg/m3 (smoky coal), and 96 μg/m3 (smokeless coal) for homes using a variety of different fuel types and stove configurations (e.g., vented, unvented, portable, fire pit, mixed ventilation stove).Rural",1
"Because many Kenyan women utilize a three-stone fire, the worst offender, one kilogram of burning wood produces tiny particles of soot which can clog and irritate the bronchial pathways. The smoke also contains various poisonous gases such as aldehydes, benzene, and carbon monoxide. Exposure to IAP from the combustion of solid fuels has been implicated, with varying degrees of evidence, as a causal agent of several diseases. Acute lower respiratory infections (ALRI) and chronic obstructive pulmonary disease (COPD) are the leading causes of disease and death from exposure to smoke.",1
"Cataracts and blindness, lung cancer, tuberculosis, premature births and low birth weight are also suspected of being caused by IAP.",1
"Unfortunately, finding an affordable solution to address the many effects of IAP – improving combustion, reducing smoke exposure, improving safety and reducing labor, reducing fuel costs, and addressing sustainability – is complex and in need of continual improvement. Efforts to improve cook stoves in the past, beginning in the 1950s, were primarily aimed at minimizing deforestation with no concern for IAP, though the effectiveness of these efforts to save firewood is debatable. Various attempts had various outcomes. For example, some improved stove designs in Kenya significantly reduced particulate emissions but produced higher CO2 and SO2 emissions.",1
Flues to remove smoke were difficult to design and were fragile.,1
Large-scale combustion of biomass is only feasible if carried out in a sustainable manner. The concern is paramount for regeneration of renewable and sustainable fuel-wood sources if it is to continue to be available long-term. Attempts at sustainable solutions in Kenya could include developing energy crops (trees and shrubs) which would also provide additional income for farmers. This solution would benefit cropland or rangeland prone to erosion and flooding as the root systems and leaf litter would enhance soil stability. Careful selection of regenerating varieties would be most sustainable because soil stability is not disrupted due to tilling and planting.,1
"LPG, though made from non-renewable fossil fuels, still has lower negative health impacts than traditional fuels – thus even though it is not a sustainable alternative, it creates far less emissions impacts than traditional fuels.",1
"On the demand side, challenges exist in terms of creating an enabling environment for cook stove acquisition. Incorporating culturally sensitive behavior change techniques (BCTs) into demand interventions is necessary to foster large-scale behavior change, as discussed below. The other prohibitive aspect of cook stove interventions that do not involve paternalistic good provision is the high up-front costs of improved stoves. Consumers at the bottom of the income pyramid are often the target end-users of these improved technologies, but due to a lack of collateral or isolation, they do not have access to traditional forms of consumer finance and credit.",1
"Innovations in business models and the increased proliferation of microfinance institutions (MFIs) are addressing these issues – however, MFIs face challenges of scaling up.",1
"Subsidies towards investment in R&D for cleaner technologies and fuels, as well as for the implementation of a baseline standards and testing framework for cleanliness and efficiency (also provision of a public good), is necessary to create an effective and sustainable supply chain. There have been significant developments in energy efficient cooking solutions (improved cookstoves), such as the Wonderbag, which can also significantly reduce fuel requirements for residential cooking.",1
"Its model successfully addresses a number of problems with stove adoption including prohibitively high upfront stove costs, consumer tendency to combine new and old cooking solutions, and lack of commercial viability of these enterprises. Additionally, innovations in mobile technology have allowed companies like PayGo Energy in Kenya and KopaGas in Tanzania to overcome the cost barrier that low-income consumers face, including the high up-front cost of stoves and the inaccessibility of purchasing fuels in small quantities (a form of the poverty penalty).",1
"Educational intervention can contribute to reducing exposure to smoke by implementing behaviour change techniques that people to the dangers and encourage a willingness to alter living and cultural practices which could have a significant impact on mitigating exposure to IAP. Behaviour change is one aspect of influencing demand that can be achieved through targeted social marketing campaigns, which are usually of two types: either mass-market campaigns or focused approaches at the local and household level that employ demonstrations and follow up visits.",1
"Long-term solutions rest on transition to modern cleaner fuels and alternative energy sources within a broad international and national policy and economic agenda. Government support for long-term solutions is feasible as witnessed by current efforts in Zambia to develop policy to promote biofuels. Kenya is the world leader in the number of solar power systems installed per capita (but not the number of watts added). More than 30,000 small solar panels, each producing 12 to 30 watts, are sold in Kenya annually.",1
"Community participation was the primary focus for this project and as a result, those involved indicated the results far exceeded their expectations. Local women's groups and, in the case of the project in West Kenya, men were actively involved. By involving the end-users the project resulted in more widespread acceptance and created the further benefit of providing local income. Three key interventions were discussed and disseminated; ventilation by enlarging windows or opening eaves spaces, adding smoke hoods over the cooking area, or the option of installing an improved cook stove such as the Upesi stove.",1
"The people reported less internal heat allowing for better sleep, fewer headaches and less fatigue, less eye irritation and coughs and dizziness. Safety increased due to the smoke hoods preventing goats and children from falling into the fire and less soot contamination was observed, along with snakes and rodents not entering the home. Windows allowed for the ability to view cattle from indoors, and also reduced kerosene needs due to improved interior lighting. Overall, the indoor environment improved greatly from various simple things that are taken for granted in modern western homes.",1
"Greater indoor light also allows for more income generation for women as they can do beadwork by the window when weather does not allow for this work outdoors. Children also benefit from increased lighting for homework. Interpersonal relationships developed among the women due to the project, and men better supported their wives initiative when the result benefited them as well.",1
"This initial pilot program has evolved into CRECER (Chronic Respiratory Effects of Early Childhood Exposure to Respirable Particulate Matter), which will attempt to follow children in intervention households for a longer period of time to determine whether the improved stoves also contribute to greater health over the lifespan.",1
"The program in China involved intervention on a large scale, but the cost of stoves was heavily subsidized so it is not known if its success could be replicated. Energy poverty and cooking Envirofit Guatemala Stove Project Rocket stove Rural electrification Sick building syndrome Renewable energy in China",1
"Persistent organic pollutants (POPs) were the focal point of the Stockholm Convention 2001 due to their persistence, ability to biomagnify and the threat posed to both human health and the environment. The goal of the Stockholm Convention was to determine the classification of POPs, create measures to eliminate production/use of POPs, and establish proper disposal of the compounds in an environmentally friendly manner. Currently the majority of the global community is actively involved with this program but a few still resist, most notably the US.",1
"Following the GLBNS, the Multimedia Strategy for Priority Persistent, Bioaccumulative and Toxic Pollutants (PBT Strategy) was drafted by the USEPA. The PBT Strategy led to the implementation of PBT criteria in several regulational policies. Two main policies that were changed by the PBT strategy were the Toxics Release Inventory (TRI), which required more rigid chemical reporting, and the New Chemical Program (NCP) under the Toxics Substances Control Act (TSCA), which required screening for PBTs and PBT properties.",1
"PBTs are a unique classification of chemicals that have and will continue to impact human health and the environment worldwide. The three main attributes of a PBT (persistence, bioaccumulative and toxic) each have a huge role in the risk posed by these compounds.",1
"These factors have resulted in global contamination, most notably in remote areas such as the arctic and high elevation areas, which are far from any source of PBTs.",1
Bioaccumulation of a toxicant can lead to biomagnification through a trophic web which has resulted in massive concern in areas with especially low trophic diversity. Biomagnification results in higher trophic organisms accumulating more PBTs than those of lower trophic levels through consumption of the PBT contaminated lower trophic organisms.,1
"The toxicity of this class of compounds is high, with very low concentrations of a PBT required to enact an effect on an organism compared to most other contaminants. This high toxicity along with the persistence allows for the PBT to have detrimental effects in remote areas around the globe where there is not a local source of PBTs. The bioaccumulation and magnification along with the high toxicity and persistence has the ability to destroy and/or irreparably damage trophic systems, especially the higher trophic levels, globally. For this reason, PBTs have become an area of focus in global politics.",1
"Ortho-PCBs may alter hormone regulation through disruption of the thyroid hormone transport by binding to transthyretin. Coplanar PCBs are similar to dioxins and furans, both bind to the aryl hydrocarbon receptor (AhR) in organisms and may exert dioxin-like effects, in addition to the effects shared with non-coplanar PCBs. The AhR is a transcription factor, therefore, abnormal activation may disrupt cellular function by altering gene transcription.Effects of PBTs may include increase in disease, lesions in benthic feeders, spawning loss, change in age-structured populations of fish, and tissue contamination in fish and shellfish.",1
"Humans and other organisms, which consume shellfish and/or fish contaminated with persistent bioaccumulative pollutants, have the potential to bioaccumulate these chemicals. This may put these organisms at risk of mutagenic, teratogenic, and/or carcinogenic effects. Correlations have been found between elevated exposure to PCB mixtures and alterations in liver enzymes, hepatomegaly, and dermatological effects such as rashes have been reported.",1
"From here, the DDT can travel many routes; for instance, when plants and vegetation are exposed to the chemical to protect from insects, the plants may absorb it. Then these plants may either be consumed by humans or other animals. These consumers ingest the chemical and begin metabolizing the toxicant, accumulating more through ingestion, and posing health risks to the organism, their offspring, and any predators. Alternatively the ingestion of the contaminated plant by insects may lead to tolerance by the organism.",1
"The sodium ions are what polarize the opposing synapse after it has depolarized from firing. This inhibition of closing the sodium ion channel can lead to a variety of problems including a dysfunctional nervous system, decreased motor abilities/function/control, reproductive impairment (egg-shell thinning in birds), and development deficiencies. Presently, DDT has been labeled as a possible human carcinogen based on animal liver tumor studies. DDT toxicity on humans have been associated with dizziness, tremors, irritability, and convulsions. Chronic toxicity has led to long term neurological and cognitive issues.",1
"InorganicInorganic mercury (elemental mercury) is less bioavailable and less toxic than that of organic mercury but is still toxic nonetheless. It is released into the environment through both natural sources as well as human activity, and it has the capability to travel long distances through the atmosphere. Around 2,700 to 6,000 tons of elemental mercury are released via natural activity such as volcanoes and erosion. Another 2,000–3,000 tons are released by human industrial activities such as coal combustion, metal smelting and cement production.",1
"Due to its high volatility and atmospheric residence time of around one year, mercury has the ability to travel across continents before being deposited. Inorganic mercury has a wide spectrum of toxicological effects that include damage to the respiratory, nervous, immune and excretory systems in humans. Inorganic mercury also possesses the ability to bioaccumulate individuals and biomagnify through trophic systems. OrganicOrganic mercury is significantly more detrimental to the environment than its inorganic form due to its widespread distribution as well as its higher mobility, general toxicity and rates of bioaccumulation than that of the inorganic form.",1
Ecological Impact of HgThe high toxicity of both forms of mercury (especially organic mercury) poses a threat to almost all organisms that comes in contact with it. This is one of the reasons that there is such high attention to mercury in the environment but even more so than its toxicity is both its persistence and atmospheric retention times. The ability of mercury to readily volatilize allows it to enter the atmosphere and travel far and wide.,1
"Unlike most other PBTs that have atmospheric half-lives between 30 min and 7 days mercury has an atmospheric residence time of at least 1 year. This atmospheric retention time along with mercury's resistance to degradation factors such as electromagnetic radiation and oxidation, which are two of the main factors leading to degradation of many PBTs in the atmosphere, allows mercury from any source to be transported extensively. This characteristic of mercury transportation globally along with its high toxicity is the reasoning behind its incorporation into the BNS list of PBTs.",1
"Despite the ban on DDT 30 years earlier and years of various efforts to clean up Puget Sound from DDT and PCBs, there is still a significant presence of both compounds which pose a constant threat to human health and the environment. Harbor seals (Phoca vitulina), a common marine species in the Puget Sound area, have been the focus of a few studies to monitor and examine the effects of DDT accumulation and magnification in aquatic wildlife. One study tagged and reexamined seal pups every 4 to 5 years to be tested for DDT concentrations.",1
"The trends showed the pups to be highly contaminated; this means their prey are also highly contaminated. Due to DDT's high lipid solubility, it also has the ability to accumulate in the local populace who consume seafood from the area. This also translates to women who are pregnant or breastfeeding, since DDT will be transferred from the mother to child. Both animal and human health risk to DDT will continue to be an issue in Puget Sound especially because of the cultural significance of fish in this region. Persistent organic pollutant",1
"POPs typically are halogenated organic compounds (see lists below) and as such exhibit high lipid solubility. For this reason, they bioaccumulate in fatty tissues. Halogenated compounds also exhibit great stability reflecting the nonreactivity of C-Cl bonds toward hydrolysis and photolytic degradation. The stability and lipophilicity of organic compounds often correlates with their halogen content, thus polyhalogenated organic compounds are of particular concern. They exert their negative effects on the environment through two processes, long range transport, which allows them to travel far from their source, and bioaccumulation, which reconcentrates these chemical compounds to potentially dangerous levels.",1
"Compounds that make up POPs are also classed as PBTs (persistent, bioaccumulative and toxic) or TOMPs (toxic organic micro pollutants).",1
"Bioaccumulation of POPs is typically associated with the compounds high lipid solubility and ability to accumulate in the fatty tissues of living organisms for long periods of time. Persistent chemicals tend to have higher concentrations and are eliminated more slowly. Dietary accumulation or bioaccumulation is another hallmark characteristic of POPs, as POPs move up the food chain, they increase in concentration as they are processed and metabolized in certain tissues of organisms. The natural capacity for animals gastrointestinal tract to concentrate ingested chemicals, along with poorly metabolized and hydrophobic nature of POPs, makes such compounds highly susceptible to bioaccumulation.",1
"Thus POPs not only persist in the environment, but also as they are taken in by animals they bioaccumulate, increasing their concentration and toxicity in the environment. This increase in concentration is called biomagnification, which is where organisms higher up in the food chain have a greater accumulation of POPs. Bioaccumulation and long-range transport are the reason why POPs can accumulate in organisms like whales, even in remote areas like Antarctica. The Stockholm Convention was adopted and put into practice by the United Nations Environment Programme (UNEP) on May 22, 2001.",1
"The convention seeks to study and then judge whether or not a number of chemicals that have been developed with advances in technology and science can be categorized as POPs or not. The initial meeting in 2001 made a preliminary list, termed the ""dirty dozen"", of chemicals that are classified as POPs. As of 2022, the United States has signed the Stockholm Convention but has not ratified it. There are a handful of other countries that have not ratified the convention but most countries in the world have ratified the convention.",1
"In laboratory tests have shown high-dose heptachlor as lethal, with adverse behavioral changes and reduced reproductive success at low-doses, and is classified as a possible human carcinogen. Human exposure primarily results from food. Hexachlorobenzene (HCB) was first introduced in 1945–59 to treat seeds because it can kill fungi on food crops. HCB-treated seed grain consumption is associated with photosensitive skin lesions, colic, debilitation, and a metabolic disorder called porphyria turcica, which can be lethal. Mothers who pass HCB to their infants through the placenta and breast milk had limited reproductive success including infant death. Human exposure is primarily from food.",1
"PCBs are toxic to fish at high doses, and associated with spawning failure at low doses. Human exposure occurs through food, and is associated with reproductive failure and immune suppression. Immediate effects of PCB exposure include pigmentation of nails and mucous membranes and swelling of the eyelids, along with fatigue, nausea, and vomiting. Effects are transgenerational, as the chemical can persist in a mother's body for up to 7 years, resulting in developmental delays and behavioral problems in her children. Food contamination has led to large scale PCB exposure. Dichlorodiphenyltrichloroethane (DDT) is probably the most infamous POP.",1
"DDT is toxic to many organisms including birds where it is detrimental to reproduction due to eggshell thinning. DDT can be detected in foods from all over the world and food-borne DDT remains the greatest source of human exposure. Short-term acute effects of DDT on humans are limited, however long-term exposure has been associated with chronic health effects including increased risk of cancer and diabetes, reduced reproductive success, and neurological disease. Dioxins are unintentional by-products of high-temperature processes, such as incomplete combustion and pesticide production.",1
"Dioxins are typically emitted from the burning of hospital waste, municipal waste, and hazardous waste, along with automobile emissions, peat, coal, and wood. Dioxins have been associated with several adverse effects in humans, including immune and enzyme disorders, chloracne, and are classified as a possible human carcinogen. In laboratory studies of dioxin effects an increase in birth defects and stillbirths, and lethal exposure have been associated with the substances. Food, particularly from animals, is the principal source of human exposure to dioxins.",1
"POP exposure may cause developmental defects, chronic illnesses, and death. Some are carcinogens per IARC, possibly including breast cancer. Many POPs are capable of endocrine disruption within the reproductive system, the central nervous system, or the immune system. People and animals are exposed to POPs mostly through their diet, occupationally, or while growing in the womb. For humans not exposed to POPs through accidental or occupational means, over 90% of exposure comes from animal product foods due to bioaccumulation in fat tissues and bioaccumulate through the food chain.",1
"In general, POP serum levels increase with age and tend to be higher in females than males.Studies have investigated the correlation between low level exposure of POPs and various diseases. In order to assess disease risk due to POPs in a particular location, government agencies may produce a human health risk assessment which takes into account the pollutants' bioavailability and their dose-response relationships.",1
"The majority of POPs are known to disrupt normal functioning of the endocrine system. Low level exposure to POPs during critical developmental periods of fetus, newborn and child can have a lasting effect throughout their lifespan. A 2002 study summarizes data on endocrine disruption and health complications from exposure to POPs during critical developmental stages in an organism's lifespan. The study aimed to answer the question whether or not chronic, low level exposure to POPs can have a health impact on the endocrine system and development of organisms from different species.",1
"The study found that exposure of POPs during a critical developmental time frame can produce a permanent changes in the organisms path of development. Exposure of POPs during non-critical developmental time frames may not lead to detectable diseases and health complications later in their life. In wildlife, the critical development time frames are in utero, in ovo, and during reproductive periods. In humans, the critical development timeframe is during fetal development.",1
"The same study in 2002 with evidence of a link from POPs to endocrine disruption also linked low dose exposure of POPs to reproductive health effects. The study stated that POP exposure can lead to negative health effects especially in the male reproductive system, such as decreased sperm quality and quantity, altered sex ratio and early puberty onset. For females exposed to POPs, altered reproductive tissues and pregnancy outcomes as well as endometriosis have been reported.",1
"A Greek study from 2014 investigated the link between maternal weight gain during pregnancy, their PCB-exposure level and PCB level in their newborn infants, their birth weight, gestational age, and head circumference. The lower the birth weight and head circumference of the infants was, the higher POP levels during prenatal development had been, but only if mothers had either excessive or inadequate weight gain during pregnancy. No correlation between POP exposure and gestational age was found.",1
"A 2013 case-control study conducted 2009 in Indian mothers and their offspring showed prenatal exposure of two types of organochlorine pesticides (HCH, DDT and DDE) impaired the growth of the fetus, reduced the birth weight, length, head circumference and chest circumference.",1
"Evaluation of the effects of POPs on health is very challenging in the laboratory setting. For example, for organisms exposed to a mixture of POPs, the effects are assumed to be additive. Mixtures of POPs can in principle produce synergistic effects. With synergistic effects, the toxicity of each compound is enhanced (or depressed) by the presence of other compounds in the mixture. When put together, the effects can far exceed the approximated additive effects of the POP compound mixture.",1
"A 2021 study tested 231 makeup and personal care products and found organic fluorine, an indicator of PFAS, in more than half of the samples. High levels of fluorine were most commonly identified in waterproof mascara (82% of brands tested), foundations (63%), and liquid lipstick (62%). Since PFAS compounds are highly mobile, they are readily absorbed through human skin and through tear ducts, and such products on lips are often unwittingly ingested. Manufacturers often fail to label their products as containing PFAS, which makes it difficult for cosmetics consumers to avoid products containing PFAS.",1
"Current studies aimed at minimizing POPs in the environment are investigating their behavior in photocatalytic oxidation reactions. POPs that are found in humans and in aquatic environments the most are the main subjects of these experiments. Aromatic and aliphatic degradation products have been identified in these reactions. Photochemical degradation is negligible compared to photocatalytic degradation. A method of removal of POPs from marine environments that has been explored is adsorption. It occurs when an absorbable solute comes into contact with a solid with a porous surface structure. This technique was investigated by Mohamed Nageeb Rashed of Aswan University, Egypt.",1
"This differs from other expressions of apparent visual magnitude observed by the human eye or obtained by photography: that usually appear in older astronomical texts and catalogues. Magnitudes measured by photometers in some commonplace photometric systems (UBV, UBVRI or JHK) are expressed with a capital letter. e.g. 'V"" (mV), ""B"" (mB), etc. Other magnitudes estimated by the human eye are expressed using lower case letters. e.g. ""v"", ""b"" or ""p"", etc. e.g. Visual magnitudes as mv, while photographic magnitudes are mph / mp or photovisual magnitudes mp or mpv. Hence, a 6th magnitude star might be stated as 6.0V, 6.0B, 6.0v",1
"or 6.0p. Because starlight is measured over a different range of wavelengths across the electromagnetic spectrum and are affected by different instrumental photometric sensitivities to light, they are not necessarily equivalent in numerical value. For example, apparent magnitude in the UBV system for the solar-like star 51 Pegasi is 5.46V, 6.16B or 6.39U, corresponding to magnitudes observed through each of the visual 'V', blue 'B' or ultraviolet 'U' filters. Magnitude differences between filters indicate colour differences and are related to temperature. Using B and V filters in the UBV system produces the B–V colour index.",1
"For 51 Pegasi, the B–V = 6.16 – 5.46 = +0.70, suggesting a yellow coloured star that agrees with its G2IV spectral type. Knowing the B–V results determines the star's surface temperature, finding an effective surface temperature of 5768±8 K.Another important application of colour indices is graphically plotting star's apparent magnitude against the B–V colour index. This forms the important relationships found between sets of stars in colour–magnitude diagrams, which for stars is the observed version of the Hertzsprung-Russell diagram.",1
"All three will require the extraction of the raw image magnitude of the target object, and a known comparison object. The observed signal from an object will typically cover many pixels according to the point spread function (PSF) of the system. This broadening is due to both the optics in the telescope and the astronomical seeing. When obtaining photometry from a point source, the flux is measured by summing all the light recorded from the object and subtracting the light due to the sky.",1
"Differential photometry is the measurement of the difference in brightness of two objects. In most cases, differential photometry can be done with the highest precision, while absolute photometry is the most difficult to do with high precision. Also, accurate photometry is usually more difficult when the apparent brightness of the object is fainter.",1
"To perform relative photometry, one compares the instrument magnitude of the object to a known comparison object, and then corrects the measurements for spatial variations in the sensitivity of the instrument and the atmospheric extinction. This is often in addition to correcting for their temporal variations, particularly when the objects being compared are too far apart on the sky to be observed simultaneously.",1
"When doing the calibration from an image that contains both the target and comparison objects in close proximity, and using a photometric filter that matches the catalog magnitude of the comparison object most of the measurement variations decrease to null.",1
"Differential photometry is the simplest of the calibrations and most useful for time series observations. When using CCD photometry, both the target and comparison objects are observed at the same time, with the same filters, using the same instrument, and viewed through the same optical path. Most of the observational variables drop out and the differential magnitude is simply the difference between the instrument magnitude of the target object and the comparison object (∆Mag = C Mag – T Mag).",1
"This is very useful when plotting the change in magnitude over time of a target object, and is usually compiled into a light curve.",1
"For spatially extended objects such as galaxies, it is often of interest to measure the spatial distribution of brightness within the galaxy rather than simply measuring the galaxy's total brightness. An object's surface brightness is its brightness per unit solid angle as seen in projection on the sky, and measurement of surface brightness is known as surface photometry. A common application would be measurement of a galaxy's surface brightness profile, meaning its surface brightness as a function of distance from the galaxy's center.",1
"For small solid angles, a useful unit of solid angle is the square arcsecond, and surface brightness is often expressed in magnitudes per square arcsecond.",1
"In forced photometry, measurements are conducted at a specified location rather than for a specified object. It is ""forced"" in the sense that a measurement can be taken even if there is no object visible (in the spectral band of interest) in the location being observed. Forced photometry allows extracting a magnitude, or an upper limit for the magnitude, at a chosen sky location. A number of free computer programs are available for synthetic aperture photometry and PSF-fitting photometry. SExtractor and Aperture Photometry Tool are popular examples for aperture photometry.",1
"The former is geared towards reduction of large scale galaxy-survey data, and the latter has a graphical user interface (GUI) suitable for studying individual images. DAOPHOT is recognized as the best software for PSF-fitting photometry. There are a number of organizations, from professional to amateur, that gather and share photometric data and make it available on-line. Some sites gather the data primarily as a resource for other researchers (ex. AAVSO) and some solicit contributions of data for their own research (ex. CBA): American Association of Variable Star Observers (AAVSO). Astronomyonline.org Center for Backyard Astrophysics (CBA).",1
"Albedo Aperture Photometry Tool - Software Bidirectional reflectance distribution function Hapke parameters Radiometry Redshift survey Spectroscopy ""Photometry Links"". CSIRO : Australian Telescope National Facility. 2019-05-08.",1
"Usually, as a plume moves away from its source, it widens because of entrainment of the surrounding fluid at its edges. Plume shapes can be influenced by flow in the ambient fluid (for example, if local wind blowing in the same direction as the plume results in a co-flowing jet). This usually causes a plume which has initially been 'buoyancy-dominated' to become 'momentum-dominated' (this transition is usually predicted by a dimensionless number called the Richardson number).",1
"A further phenomenon of importance is whether a plume has laminar flow or turbulent flow. Usually, there is a transition from laminar to turbulent as the plume moves away from its source. This phenomenon can be clearly seen in the rising column of smoke from a cigarette. When high accuracy is required, computational fluid dynamics (CFD) can be employed to simulate plumes, but the results can be sensitive to the turbulence model chosen. CFD is often undertaken for rocket plumes, where condensed phase constituents can be present in addition to gaseous constituents.",1
"These types of simulations can become quite complex, including afterburning and thermal radiation, and (for example) ballistic missile launches are often detected by sensing hot rocket plumes. Spacecraft designers are sometimes concerned with impingement of attitude control system thruster plumes onto sensitive subsystems like solar arrays and star trackers, or with the impingement of rocket engine plumes onto moon or planetary surfaces where they can cause local damage or even mid-term disturbances to planetary atmospheres.",1
"Simple modelling will enable many properties of fully developed, turbulent plumes to be investigated. Many of the classic scaling arguments were developed in a combined analytic and laboratory study described in an influential paper by Bruce Morton, G.I. Taylor and Stewart Turner and this and subsequent work is described in the popular monograph of Stewart Turner. It is usually sufficient to assume that the pressure gradient is set by the gradient far from the plume (this approximation is similar to the usual Boussinesq approximation).",1
"The distribution of density and velocity across the plume are modelled either with simple Gaussian distributions or else are taken as uniform across the plume (the so-called 'top hat' model). The rate of entrainment into the plume is proportional to the local velocity. Though initially thought to be a constant, recent work has shown that the entrainment coefficient varies with the local Richardson number. Typical values for the entrainment coefficient are of about 0.08 for vertical jets and 0.12 for vertical, buoyant plumes whilst for bent-over plumes, the entrainment coefficient is about 0.6.",1
"For calculating the expected concentration of a one dimensional instantaneous point source we consider a mass M {\displaystyle M} released at an instantaneous point in time, in a one dimensional domain along x {\displaystyle x} .",1
"This will give the following equation: C ( x , t ) = M 4 π D t exp ⁡ ( ( x − x 0 ) 2 4 D ( t − t 0 ) ) {\displaystyle C(x,t)={\frac {M}{\sqrt {4\pi Dt}}}\exp \left({\frac {(x-x_{0})^{2}}{4D(t-t_{0})}}\right)} where M {\displaystyle M} is the mass released at time t = t 0 {\displaystyle t=t_{0}} and location x = x 0 {\displaystyle x=x_{0}} , and D {\displaystyle D} is the diffusivity [ m 2 s ] {\displaystyle \left[{\frac {{\text{m}}^{2}}{\text{s}}}\right]} . This equation makes the following four assumptions: The mass M {\displaystyle M} is released instantaneously.",1
The mass M {\displaystyle M} is released in an infinite domain. The mass spreads only through diffusion. Diffusion does not vary in space.,1
"Post-consumer waste consists of: packaging parts that are not needed, such as fruit skins, bones in meat, etc. undesired things received, e.g.: advertising material in the mailbox a flyer received in the street without having the opportunity to refuse dust, weeds, fallen leaves, etc. things one no longer needs, e.g.",1
"Additionally, each of those factors influences each other and affects the amount of food that is wasted per person. Retail hazardous waste",1
"The overarching objectives for PAME were formally outlined in the 2009 meeting held in Oslo, Norway. These objectives are: To improve knowledge and respond to emerging knowledge of the Arctic Marine Environment. To determine the adequacy of applicable international/regional commitments and promote their implementation and compliance. To facilitate partnerships, programme and technical cooperation and support communication, reporting and outreach both within and outside the Arctic Council. PAME's objectives, and strategies to further their realisation, are periodically delineated in the group's Arctic Maritime Strategic Plans.",1
"As of May 2020, the group has published two such documents; one for the years between 2000 and 2015, and the other for those between 2015 and 2025.",1
"The second Arctic Maritime Strategic Plan delineated four distinct goals relating to Protection of the Arctic Marine Environment for the following 10 years. It was approved by the Council in April 2015 at a meeting in Iqaluit, Canada.",1
"The former was intended to provide the Arctic Council with an increasingly structured approach to achieving the Working Group's goals, as well as providing guidelines against which progress could be appraised. The latter aimed to facilitate communication and understanding to ensure the fulfilment of the working group's goals. PAME works in partnership with The Arctic Council's five additional working groups to construct its strategic plans and suggest mechanisms for their implementation.",1
"The five additional working groups of the Arctic Council are: Arctic Monitoring and Assessment Programme (AMAP) Conservation of Arctic Flora & Fauna (CAFF) Emergency Prevention, Preparedness & Response (EPPR) Sustainable Development Working Group (SDWG) Arctic Contaminants Action Program (ACAP)",1
"The expert group of PAME's Marine Protected Areas subdivision is co-lead by Canada, Norway and the United States.PAME adheres to the definition of a 'Marine Protected Area' volunteered by the International Union for Conservation of Nature. The definition focuses the existence of a distinct geographical area managed in such a way that ensures the long-term conservation and protection of its natural ecosystems. There are seven categories to accommodate the various characters of protected areas that exist globally, with the Arctic states each possessing policy tools to designate and manage these.",1
"Between 2006 and 2017, PAME produced a total of 11 ecosystem approaches to management (EA) progress reports, and has developed a framework for application of the approach to its projects. The framework principles involve identifying the character of local ecosystems before considering them adjacent to the group's assessments, objectives and values. Decisions with respect to the management of local human activity are made based on the outcomes of these processes.The",1
"establishment of the expert group on Arctic ecosystem-based management (EBM) occurred in 2011, the centrality to the working of the Council of which was furthered in both 2015 and 2017, with council ministers agreeing on the requirement for distinct guidelines for implementing the Ecosystem Approach in the Arctic region.PAME and the Arctic Council define ecosystem approaches to management as the management of human activities based on contemporary, scientific knowledge of local ecosystems. The purpose of the approach is to facilitate management decisions of human activity which balance the exploitation of marine resources with ecosystem prosperity.",1
"In 2009, PAME released guidelines for the exploitation of Arctic off-shore gas and oil, delineating the Arctic Council's understanding of ""good practice"" for the stages of planning, exploring, developing, producing and decommissioning areas and equipment employed in resource exploitation and development.Since the commissioning of these guidelines, PAME has published eight developing documents detailing further development of local regulation on Arctic oil and Gas drilling activities. PAME convenes on an annual, or biannual basis, and meets with the Ministers of the Arctic Council once every two years. The location of PAME meetings alternates between cities situated in the 8 Arctic states.",1
"Past meetings by month, year and location",1
https://archive.today/20080511222501/http://arctic-council.org/working_group/pame http://www.pame.is,1
"Magnet fishing is typically done with gloves, a strong neodymium magnet secured to a durable rope between 15 and 30 meters (50–100 ft), and sometimes a grappling hook as a supplement to the magnet. Some magnet fishers have retrieved dangerous objects, including loaded guns, unexploded ordnance, and sharp pieces of metal.Neodymium magnets are powerful and can interfere with pacemakers, posing a health risk; they can also damage other electronic devices. Fingers can get crushed between the magnet and a piece of metal, potentially causing serious bodily harm. Tetanus can also be a risk for those without an up-to-date tetanus vaccine.",1
"Depending on the jurisdiction, anything of value may belong to the local government, not the finder.",1
"Magnet fishing is subject to local regulations concerning outdoor waters. The Canal & River Trust, which owns most of the canals in England and Wales, has bylaws prohibiting people from removing material from the canal and rivers it owns, so fishers may be subject to a £25 fine for magnet-fishing or removing any material from canal or inland navigation under the control of the Canal & River Trust in England or Wales, other than the Lee and Stort Navigation, Gloucester and Sharpness Canal, and River Severn Navigation.",1
"The Trust ""expressly prohibit[s]"" the practice, although it refrains from legal action against first-time offenders. In 2018, a child magnet-fished a sawn-off shotgun out of the Titford Canal in Oldbury, West Midlands.",1
"Magnet fishing is allowed in Scotland, as long as the fisher has obtained a Scheduled Monument Consent from Historic Environment Scotland, and permission from Scottish Canals. An official group exists which gives its members permission to magnet fish in a stretch of the Union Canal in Edinburgh, with more locations planned in the future. Archaeological or historical finds must be reported to Treasure Trove Scotland.",1
"In Hamburg, magnet fishing without a permit is punishable by fine.",1
"Amateur magnet-fishers in Belgium helped the police by recovering new evidence, specifically firearms and ammunition, related to the crimes of the Brabant killers.In general, police urge those who find weapons or similar items to contact them.",1
"According to Polish penal code, magnet fishing without a valid government permit is a crime punishable by up to two years imprisonment.",1
"In the US, there are no federal laws restricting metal fishing. Magnet fishing in state waters without a license is prohibited in South Carolina under the Underwater Antiquities Act. In Indiana, magnet fishing is allowed on public waters on Department of Natural Resources properties by permit. The magnet must be able to be carried and retrieved by hand. The hobby has been adopted by celebrities such as English rugby player James Haskell.",1
"“One of the most important aims of the StEP Initiative is to elaborate a set of global guidelines for the treatment of e-waste and the promotion of sustainable material recycling” Press communiqué of the initiative The initiative comprises five cooperating task forces, each addressing specific aspects of e-waste, while covering the entire life-cycle of electric and electronic equipment. In all its activities, the initiative places emphasis on working with policy-making bodies to allow results from its research to impact current practices. StEP is being coordinated by the science and research body of the UN System, the United Nations University (UNU).",1
"The supreme body of the StEP Initiative is its general assembly, which decides its general direction and development. This general assembly is based on a memorandum of understanding, which is signed by all members and states the guiding principles of StEP. A Secretariat, hosted by the UNU in Bonn, is mandated with the accomplishment of the day-to-day managerial work of the initiative. A steering committee, composed of representatives from key stakeholders, monitors the progress of the initiative. The core work is accomplished by the five task forces (TF): “Policy”, “ReDesign”, “ReUse”, “ReCycle” and “Capacity Building”.",1
"These task forces conduct research and analysis in their respective domains and seek to implement innovative projects. TF 1 – Policy: The aim of this task force is to assess and analyse current governmental approaches and regulations related to WEEE. Starting from this analysis, recommendations for future regulating activities shall be formulated. TF2 – ReDesign: This task force works on the design of EEE, focusing on the reduction of negative consequences of electrical and electronic appliances throughout their entire life cycle. The task force especially takes heed of the situation in developing countries.",1
"TF3 – ReUse: The focus of this task force lies in the development of sustainable, transmissible principles and standards for the reuse of EEE. TF4 – ReCycle: The objective of this task force is to improve infrastructures, systems and technologies to realize a sustainable recycling on a global level. TF5 – Capacity Building: The aim of this task force is to draw attention to the problems connected to WEEE. This aim shall be achieved by making the results of the research of the task forces and other stakeholders publicly available.",1
"StEP condemns all illegal activities related to e-waste including illegal shipments and reuse/ recycling practices that are harmful to the environment and human health. 5. StEP seeks to foster safe and eco/energy-efficient reuse and recycling practices around the globe in a socially responsible manner."" - Quote from the website: [1] - Computer recycling Sustainable Electronics Initiative (SEI) StEP Website Article by BBC News Online",1
"(See for example, the Surface Mining Control and Reclamation Act of 1977.)",1
"wider issue of stability had been known about prior to the Aberfan disaster; for example, it was discussed in a paper by Professor George Knox in 1927, but received little serious consideration by professional engineers and geologists — even to those directly concerned with mining. Also Aberfan disaster was not the first landslide with casualties: for example, in 1955 two successive landslides killed 73 people in Sasebo, Nagasaki in Japan.[ja] In February 2013, a spoil tip landslip caused the temporary closure of the Scunthorpe to Doncaster railway line in England.Landslides",1
"Conversely, others are painstakingly preserved on account of their ecological wealth. With the passage of time, they become colonised with a variety of flora and fauna, sometimes foreign to the region. This diversity follows the mining exploitation. In South Wales some spoil tips are protected as Sites of Special Scientific Interest because they provide a unique habitat for 57 species of Lichen, several of which are at risk due to their limited environment being developed and by vegetation development.For example, because the miners threw their apple or pear cores into the wagons, the spoil tips became colonised with fruit trees.",1
"It leads from Bernissart in western Hainaut to Blegny in the province of Liège. In the United States, mining companies have not been allowed to leave behind abandoned piles since the Surface Mining Control and Reclamation Act was passed in 1977. The Virginia City Hybrid Energy Center uses coal gob as a fuel source for energy production. One of the highest, at least in Western Europe, is in Loos-en-Gohelle in the former mining area of Pas-de-Calais, France. It comprises a range of five cones, of which two reach 180 metres (590 ft), surpassing the highest peak in Flanders, Mont Cassel.",1
"One of the regions of Europe most ""littered"" with (mountainous) spoil heaps is the Donbas, in Ukraine, especially around the city of Donetsk, which alone boasts about 130 of them. In Ukrainian, they are called terykony (терикону; singular терикон, terykon, 'soil cone') because of their shape. In Heringen, Hesse, Germany, is the popularly called ""Monte Kali"", made of spoil from potash mining and rising some 200 meters above the surrounding terrain. ""La Muntanya de Sal"" (The Salt Mountain), another potash mine spoil heap, lies in Cardona, Catalonia, at about 120 meters in height.",1
"The local mine's spoil tip, which he calls a slag heap, is the central figure of devastation. Eventually the pile overtakes the entire valley and crushes Huw Morgan's house: The slagheap is moving again. I can hear it whispering to itself, and as it whispers, the walls of this brave little house are girding themselves to withstand the assault. For months, more that I ever thought it would have the courage to withstand, that great mound has borne down upon these walls, this roof.",1
"And for those months the great bully has been beaten, for in my father’s day men built well for they were craftsmen. Stout beams, honest blocks, good work, and love for the job, all that is in this house. But the slag heap moves, pressing on, down and down, over and all round this house which was my father’s and my mother’s and now is mine. Soon, perhaps in an hour, the house will be buried, and the slag heap will stretch from the top of the mountain right down to the river in the Valley.",1
"Poor river, how beautiful you were, how gay your song, how clear your green waters, how you enjoyed your play among the sleepy rocks (102). Tailings Overburden Minestone Coal refuse Video and commentary on the Gateside Colliery bing, Sanquhar, Scotland. Spoil heap 11/19 in Loos-en-Gohelle (in French) chainedesterrils.eu/ (in French) Turning coal waste into light, 8 October 2004 Waste Rock and ARD",1
"utilizing hollow bamboo as a piping and naturally occurring gas vents to create kind of street lamps.At the verge of the Middle Ages, cities like Antioch had their streets lit, a practice which continued across the Arab Empire, long before Europe. In the words of Edwin Heathcote: ""Romans illuminated the streets with oil lamps, and cities from Baghdad to Cordoba were similarly lit when most of Europe was living in what it is now rather unfashionable to call the Dark Ages but which were, from the point of view of street lighting, exactly that.""So-called",1
"""link boys"" escorted people from one place to another through the murky, winding streets of medieval towns. Before incandescent lamps, candle lighting was employed in cities. The earliest lamps required that a lamplighter tour the town at dusk, lighting each of the lamps. According to some sources, illumination was ordered in London in 1417 by Sir Henry Barton, Mayor of London though there is no firm evidence of this.Public",1
"street lighting was first developed in the 16th century, and accelerated following the invention of lanterns with glass windows by Edmund Heming in London and Jan van der Heyden in Amsterdam ,, which greatly improved the quantity of light. In 1588 the Parisian Parliament decreed that a torch be installed and lit at each intersection, and in 1594 the police changed this to lanterns. Still, in the mid 17th century it was a common practice for travelers to hire a lantern-bearer if they had to move at night through the dark, winding streets.",1
"King Louis XIV authorized sweeping reforms in Paris in 1667, which included the installation and maintenance of lights on streets and at intersections, as well as stiff penalties for vandalizing or stealing the fixtures. Paris had more than 2,700 streetlights by the end of the 17th century, and twice as many by 1730. Under this system, streets were lit with lanterns suspended 20 yards (18 m) apart on a cord over the middle of the street at a height of 20 feet (6.1",1
"m); as an English visitor enthused in 1698, 'The streets are lit all winter and even during the full moon!' In London, public street lighting was implemented around the end of the 17th century; a diarist wrote in 1712 that 'All the way, quite through Hyde Park to the Queen's Palace at Kensington, lanterns were placed for illuminating the roads on dark nights.'A much-improved oil lantern, called a réverbère, was introduced in 1745 and improved in subsequent years. The light shed from these réverbères was considerably brighter, enough that some people complained of glare.",1
"These lamps were attached to the top of lampposts; by 1817, there were 4,694 lamps on the Paris streets. During the French Revolution (1789–1799), the revolutionaries found that the lampposts were a convenient place to hang aristocrats and other opponents.",1
"The remains of the works, including a chimney and gas plant, have been put on the National Heritage List for England. Clegg's installation saved the building's owners the cost of up to 1,500 candles every night. It also lit the mill owner's house and the street of millworkers' houses in Dolphinholme. In 1812, Parliament granted a charter to the London and Westminster Gas Light and Coke Company, and the first gas company in the world came into being. Less than two years later, on 31 December 1813, the Westminster Bridge was lit by gas.Following",1
"this success, gas lighting spread outside London, both within Britain and abroad. The first place outside London in England to have gas lighting, was Preston, Lancashire in 1816, where Joseph Dunn's Preston Gaslight Company introduced a new, brighter gas lighting. Another early adopter was the city of Baltimore, where the gaslights were first demonstrated at Rembrandt Peale's Museum in 1816, and Peale's Gas Light Company of Baltimore provided the first gas streetlights in the United States. In the 1860s, streetlights were started in the Southern Hemisphere in New Zealand.",1
"The first gas lamps on the main streets of Paris appeared in January 1829 on the place du Carrousel and the Rue de Rivoli, then on the Rue de la Paix, place Vendôme, and rue de Castiglione. By 1857, the Grands Boulevards were all lit with gas; a Parisian writer enthused in August 1857: ""That which most enchants the Parisians is the new lighting by gas of the boulevards...From the church of the Madeleine all the way to rue Montmartre, these two rows of lamps, shining with a clarity white and pure, have a marvelous effect.""",1
"The gaslights installed on the boulevards and city monuments in the 19th century gave the city the nickname ""The City of Light."" Oil-gas appeared in the field as a rival of coal-gas. In 1815, John Taylor patented an apparatus for the decomposition of ""oil"" and other animal substances. Public attention was attracted to ""oil-gas"" by the display of the patent apparatus at Apothecary's Hall, by Taylor & Martineau.",1
"Farola fernandina is a traditional design of gas streetlight which remains popular in Spain. Essentially it is a neoclassical French style of gas lamp dating from the late 18th century. It may be either a wall-bracket or standard lamp. The standard base is cast metal with an escutcheon bearing two intertwined letters 'F', the Royal cypher of King Ferdinand VII of Spain and commemorates the date of the birth of his daughter, the Infanta Luisa Fernanda, Duchess of Montpensier.",1
"The first electric street lighting employed arc lamps, initially the 'Electric candle', 'Jablotchkoff candle', or 'Yablochkov candle' developed by a Russian, Pavel Yablochkov, in 1875. This was a carbon arc lamp employing alternating current, which ensured that both electrodes were consumed at equal rates. In 1876, the common council of the City of Los Angeles ordered four arc lights installed in various places in the fledgling town for street lighting.On",1
"30 May 1878, the first electric streetlights in Paris were installed on the avenue de l'Opera and the Place de l'Étoile, around the Arc de Triomphe, to celebrate the opening of the Paris Universal Exposition. In 1881, to coincide with the Paris International Exposition of Electricity, streetlights were installed on the major boulevards. The first streets in London lit with the electrical arc lamp were by the Holborn Viaduct and the Thames Embankment in 1878.",1
"The first street to be lit by an incandescent lightbulb was Mosley Street, in Newcastle. The street was lit for one night by Joseph Swan's incandescent lamp on 3 February 1879. Consequently, Newcastle has the first city street in the world to be lit by electric lighting. The first city in the United States to successfully demonstrate electric lighting was Cleveland, Ohio with 12 electric lights around the Public Square road system on 29 April 1879.",1
"Wabash, Indiana lit 4 Brush arc lamps with 3,000 candlepower each, suspended over their courthouse on 2 February 1880, making the town square ""as light as midday"".Kimberley, Cape Colony (modern South Africa), was the first city in the Southern Hemisphere and in Africa to have electric streetlights – with 16 first lit on 2 September 1882. The system was only the second in the world, after that of Philadelphia, to be powered municipally. In Central America, San Jose, Costa Rica lit 25 lamps powered by a hydroelectric plant on 9 August 1884.Nuremberg",1
"was the first city in Germany to have electric public lighting on 7 June 1882, followed by Berlin on 20 September 1882 (Potsdamer Platz only). Temesvár (Timișoara in present-day Romania) was the first city in the Austrian-Hungarian Monarchy to have electric public lighting on 12 November 1884; 731 lamps were used.On 9 December 1882, Brisbane, Queensland, Australia was introduced to electricity by having a demonstration of 8 arc lights, erected along Queen Street Mall.",1
"The power to supply these arc lights was taken from a 10 hp Crompton DC generator driven by a Robey steam engine in a small foundry in Adelaide Street and occupied by J. W. Sutton and Co. In 1884 Walhalla, Victoria, Victoria, had two lamps installed on the main street by the Long Tunnel (Gold) Mining Company. In 1886, the isolated mining town of Waratah in Tasmania was the first to have an extensive system of electrically powered street lighting installed.",1
"that would allow current to pass across the transformer whether the bulb worked or not. Later, the film cutout was invented. This was a small disk of insulating film that separated two contacts connected to the two wires leading to the lamp. If the lamp failed (an open circuit), the current through the string became zero, causing the voltage of the circuit (thousands of volts) to be imposed across the insulating film, penetrating it (see Ohm's law). In this way, the failed lamp was bypassed and power restored to the rest of the district.",1
"The streetlight circuit contained an automatic current regulator, preventing the current from increasing as lamps burned out, preserving the life of the remaining lamps. When the failed lamp was replaced, a new piece of film was installed, once again separating the contacts in the cutout. This system was recognizable by the large porcelain insulator separating the lamp and reflector from the mounting arm. This was necessary because the two contacts in the lamp's base may have operated at several thousand volts above ground. Today, street lighting commonly uses high-intensity discharge lamps.",1
"Low-pressure sodium (LPS) lamps became commonplace after World War II for their low power consumption and long life. Late in the 20th century high-pressure sodium (HPS) lamps were preferred, taking further the same virtues. Such lamps provide the greatest amount of photopic illumination for the least consumption of electricity. However, white light sources have been shown to double driver peripheral vision and improve driver brake reaction time by at least 25%; to enable pedestrians to better detect pavement trip hazards and to facilitate visual appraisals of other people associated with interpersonal judgements.",1
"Studies comparing metal halide and high-pressure sodium lamps have shown that at equal photopic light levels, a street scene illuminated at night by a metal halide lighting system was reliably seen as brighter and safer than the same scene illuminated by a high-pressure sodium system.Two national standards now allow for variation in illuminance when using lamps of different spectra. In Australia, HPS lamp performance needs to be reduced by a minimum value of 75%. In the UK, illuminances are reduced with higher values S/P ratio.New",1
"street lighting technologies, such as LED or induction lights, emit a white light that provides high levels of scotopic lumens, allowing streetlights with lower wattages and lower photopic lumens to replace existing streetlights. However, there have been no formal specifications written around Photopic/Scotopic adjustments for different types of light sources, causing many municipalities and street departments to hold back on implementation of these new technologies until the standards are updated. Eastbourne in East Sussex, UK is currently undergoing a project to see 6000 of its streetlights converted to LED and will be closely followed by Hastings in early 2014.",1
"There are two optical phenomena that need to be recognized in streetlight installations. The loss of night vision because of the accommodation reflex of drivers' eyes is the greatest danger. As drivers emerge from an unlighted area into a pool of light from a streetlight their pupils quickly constrict to adjust to the brighter light, but as they leave the pool of light the dilation of their pupils to adjust to the dimmer light is much slower, so they are driving with impaired vision.",1
"As a person gets older, the eye's recovery speed gets slower, so driving time and distance under impaired vision increases. Oncoming headlights are more visible against a black background than a grey one. The contrast creates greater awareness of the oncoming vehicle. Stray voltage is also a concern in many cities. Stray voltage can accidentally electrify lampposts and has the potential to injure or kill anyone who comes into contact with the post.There are also physical dangers to the posts of streetlamps, other than children climbing them for recreational purposes.",1
"Streetlight stanchions (lampposts) pose a collision risk to motorists and pedestrians, particularly those affected by poor eyesight or under the influence of alcohol. This can be reduced by designing them to break away when hit (known as frangible, collapsible, or passively safe supports), protecting them by guardrails, or marking the lower portions to increase their visibility. High winds or accumulated metal fatigue also occasionally topple streetlights.",1
"Bats can be negatively impacted by streetlights, with evidence showing that red light can be least harmful. As a result, some areas have installed red LED streetlights to minimise disruption to bats. A study published in Science Advances reported that streetlights in southern England had detrimental impacts on local insect populations. Streetlights can also impact plant growth and the number of insects that depend on plants for food.",1
"Typical collector road lighting in New York State costs $6,400/mile/year for high pressure sodium at 8.5 kW/mile or $4,000 for light-emitting diode luminaires at 5.4 kW/mile. Improvements can be made by optimising directionality and shape, however. Transitioning to wide angle lights enabled the doubling of distance between streetlights in Flanders from 45 m to 90 m, cutting annual street lighting electricity expenditures to €9 million for the 2,150 km long network that was retrofitted, corresponding to ca. €4,186/km. A number of street light control systems have been developed to control and reduce energy consumption of a town's public lighting system.",1
Many street light controllers come with an astronomical clock for a particular location or a Global Positioning System (GPS) connection to give the best ON-OFF time and energy saving.,1
"Some intelligent street light controllers also come with Global System for Mobile Communications (GSM), Radio frequency (RF) or General Packet Radio Service (GPRS) communication, user adjusted according to latitude and longitude (low cost type), for better street light management and maintenance. Many street light controllers also come with traffic sensors to manage the lux level of the lamp according to the traffic and to save energy by decreasing lux when there is no traffic.",1
"The United States, Canada, India, and many other countries have started introducing street light controllers to their road lighting for energy conservation, street light management and maintenance purpose.",1
"Street light controllers can be expensive in comparison with normal timers, and can cost between $100 and $2,500, but most of them return the investment between 6 months and 2 years. As the equipment's lifetime is 7 to 10 years, it saves energy and cost after the initial investment has been recouped.",1
"A number of companies are now manufacturing intelligent street lighting that adjust light output based on usage and occupancy, i.e. automating classification of pedestrian versus cyclist, versus automobile, sensing also velocity of movement and illuminating a certain number of streetlights ahead and fewer behind, depending on velocity of movement. Also, the lights adjust depending on road conditions, for example, snow produces more reflectance therefore reduced light is required. There are three distinct main uses of street lights, each requiring different types of lights and placement. Using the wrong types of lights can make the situation worse by compromising visibility or safety.",1
"A modest steady light at the intersection of two roads is an aid to navigation because it helps a driver see the location of a side road as they come closer to it, so that they can adjust their braking and know exactly where to turn if they intend to leave the main road or see vehicles or pedestrians. A beacon light's function is to say ""here I am"" and even a dim light provides enough contrast against the dark night to serve the purpose.",1
"To prevent the dangers caused by a car driving through a pool of light, a beacon light must never shine onto the main road, and not brightly onto the side road. In residential areas, this is usually the only appropriate lighting, and it has the bonus side effect of providing spill lighting onto any sidewalk there for the benefit of pedestrians. On Interstate highways, this purpose is commonly served by placing reflectors at the sides of the road.",1
"The main stretches of highways remain unlighted to preserve the driver's night vision and increase the visibility of oncoming headlights. If there is a sharp curve where headlights will not illuminate the road, a light on the outside of the curve is often justified. If it is desired to light a roadway (perhaps due to heavy and fast multi-lane traffic), to avoid the dangers of casual placement of street lights, it should not be lit intermittently since this requires repeated eye readjustment, which causes eyestrain and temporary blindness when entering and leaving light pools.",1
"In this case, the system is designed to eliminate the need for headlights. This is usually achieved with bright lights placed on high poles at close, regular intervals so that there is consistent light along the route. The lighting goes from curb to curb.",1
"A train station light must never shine directly onto the tracks, and has the bonus side effect of providing spill lighting onto any platform for the benefit of passengers waiting there. Street lighting systems require ongoing maintenance, which can be classified as either reactive or preventative. Reactive maintenance is a direct response to a lighting failure, such as replacing a discharge lamp after it has failed, or replacing an entire lighting unit after it has been hit by a vehicle.",1
"Preventative maintenance is scheduled replacement of lighting components, for example, replacing all the discharge lamps in an area of the city when they have reached 85% of their expected life. In the United Kingdom, the Roads Liaison Group has issued a Code of Practice recommending specific reactive and preventative maintenance procedures.Some street lights in New York City have an orange or red light on top of the luminaire (light fixture) or a red light attached to the lamppost. This indicates that near to this lighting pole or in the same intersection, there is a fire alarm pull box.",1
"Other street lights have a small red light next to the street light bulb; when the small light flashes, it indicates an issue with the electric current. Street lights are the basic example of public goods, which are nonexcludable and nonrival. This means that the producer cannot prevent those who do not pay from consuming, and the consumption of one person cannot prevent the consumption of another person. This becomes a problem for governments, because no private company would have the incentive to produce street lights, which is why most governments are in charge of placing and maintaining street lights.",1
"For example, in Armenia, building and maintaining infrastructure is the duty of local self-governance. Fierro, Alfred (1996). Histoire et dictionnaire de Paris. Robert Laffont. ISBN 978-2-221-07862-4. Lobsey, Ian (1988). City of light. Peel-Cunningham County Council. ISBN 978-0731657780. van Bommel, Wout (2015). Road Lighting Fundamentals, Technology and Application. Springer. doi:10.1007/978-3-319-11466-8. ISBN 9783319114651. An enthusiast's guide to street lighting - including many close-up photographs of UK street lighting equipment, as well as information on installations through the ages.",1
"(UK) Example Installation of Integrated Renewable Power in Street Lighting, an example of a street lighting system with integrated solar and wind generator from Panasonic/Matsushita Transportation Lighting at the Lighting Research Center Lighting Research at the University of Sheffield",1
"Tailings are also called mine dumps, culm dumps, slimes, refuse, leach residue, slickens, or terra-cone (terrikon).",1
"Between 100 million and 280 million tons of phosphogypsum waste are estimated to be produced annually as a consequence of the processing of phosphate rock for the production of phosphate fertilizers. In addition to being useless and abundant, phosphogypsum is radioactive due to the presence of naturally occurring uranium and thorium, and their daughter isotopes. Depending on the price achievable on the uranium market, extraction of the uranium content may be economically lucrative even absent other incentives, such as reducing the harm the radioactive heavy metals do to the environment.",1
Bauxite tailings is a waste product generated in the industrial production of aluminium. Making provision for the approximately 77 million tons that is produced annually is one of the most significant problems for the aluminium mining industry.,1
However although there are potential merits to dry stacked tailings these systems are often cost prohibitive due to increased capital cost to purchase and install the filter systems and the increase in operating costs (generally associated electricity consumption and consumables such as filter cloth) of such systems.,1
"The program was convened by United Nations Environment Programme (UNEP), International Council on Mining and Metals (ICMM) and the Principles for Responsible Investment. Coal slurry impoundment Landfarming Mine closure planning Mine reclamation Spoil tip Oil sands tailings ponds Tailings Info site Extox.net Submarine Tailings Disposal at the Mineral Policy Institute Carbon sequestration in mine tailings",1
"for milligrams per cubic meter. A lake is usually classified as being in one of three possible classes: oligotrophic, mesotrophic or eutrophic. Lakes with extreme trophic indices may also be considered hyperoligotrophic or hypereutrophic (also ""hypertrophic""). The table below demonstrates how the index values translate into trophic classes. Oligotrophic lakes generally host very little or no aquatic vegetation and are relatively clear, while eutrophic lakes tend to host large quantities of organisms, including algal blooms. Each trophic class supports different types of fish and other organisms, as well.",1
"Lakes that have intermixing of their layers are classified into the category of holomictic, whereas lakes that do not have interlayer mixing are permanently stratified and thus are termed meromictic. Generally, in a holomictic lake, during the fall, the cooling of the epilimnion reduces lake stratification, thereby allowing for mixing to occur. Winds aid in this process. Thus it is the deep mixing of lakes (which occurs most often during the fall and early winter, in holomictic lakes of the monomictic subtype) that allows oxygen to be transported from the epilimnion to the hypolimnion.In",1
"this way, oligotrophic lakes can have significant oxygen down to the depth to which the aforementioned seasonal mixing occurs, but they will be oxygen deficient below this depth. Therefore, oligotrophic lakes often support fish species such as lake trout, which require cold, well-oxygenated waters. The oxygen content of these lakes is a function of their seasonally mixed hypolimnetic volume. Hypolimnetic volumes that are anoxic will result in fish congregating in areas where oxygen is sufficient for their needs.Anoxia is more common in the hypolimnion during the summer when mixing does not occur.",1
"In the absence of oxygen from the epilimnion, decomposition can cause hypoxia in the hypolimnion.",1
"Occasionally, an excessive algal bloom will occur and can ultimately result in fish death, due to respiration by algae and bottom-living bacteria. The process of eutrophication can occur naturally and by human impact on the environment. Eutrophic comes from the Greek eutrophos meaning ""well-nourished"", from eu meaning good and trephein meaning ""to nourish"".",1
"Hypertrophic or hypereutrophic lakes are very nutrient-rich lakes characterized by frequent and severe nuisance algal blooms and low transparency. Hypereutrophic lakes have a visibility depth of less than 3 feet (90 cm), they have greater than 40 micrograms/litre total chlorophyll and greater than 100 micrograms/litre phosphorus. The excessive algal blooms can also significantly reduce oxygen levels and prevent life from functioning at lower depths creating dead zones beneath the surface. Likewise, large algal blooms can cause biodilution to occur, which is a decrease in the concentration of a pollutant with an increase in trophic level.",1
"Although there is no absolute consensus as to which nutrients contribute the most to increasing primary productivity, phosphorus concentration is thought to be the main limiting factor in freshwater lakes. This is likely due to the prevalence of nitrogen fixing microorganisms in these systems, which can compensate for a lack of readily available fixed nitrogen.",1
"In some coastal marine ecosystems, research has found nitrogen to be the key limiting nutrient, driving primary production independently of phosphorus. Nitrogen fixation cannot adequately supply these marine ecosystems, because the nitrogen fixing microbes are themselves limited by the availability of various abiotic factors like sunlight and dissolved oxygen. However, marine ecosystems are too broad a range of environments for one nutrient to limit all marine primary productivity. The limiting nutrient may vary in different marine environments according to a variety of factors like depth, distance from shore, or availability of organic matter. Often, the desired trophic index differs between stakeholders.",1
Asian swamp eel Lepisosteidae (gar) Northern snakehead Pygmy gourami Spotted barb Walking catfish,1
"Another mechanically aided scrubber, the induced-spray, consists of a whirling rotor submerged in a pool of liquid. The whirling rotor produces a fine droplet spray. By moving the process gas through the spray, particles and gaseous pollutants can subsequently be collected. Figure 2 shows an induced-spray scrubber that uses a vertical-spray rotor. Mechanically aided scrubbers are capable of high collection efficiencies for particles with diameters of 1 μm or greater. Achieving these usually requires a greater energy input than those of other scrubbers operating at similar efficiencies.",1
"The increasing amount of bacterial genomic data provides new opportunities for understanding the genetic and molecular bases of the degradation of organic pollutants. Aromatic compounds are among the most persistent of these pollutants and lessons can be learned from the recent genomic studies of Burkholderia xenovorans LB400 and Rhodococcus sp. strain RHA1, two of the largest bacterial genomes completely sequenced to date. These studies have helped expand our understanding of bacterial catabolism, non-catabolic physiological adaptation to organic compounds, and the evolution of large bacterial genomes. First, the metabolic pathways from phylogenetically diverse isolates are very similar with respect to overall organization.",1
"Thus, as originally noted in pseudomonads, a large number of ""peripheral aromatic"" pathways funnel a range of natural and xenobiotic compounds into a restricted number of ""central aromatic"" pathways. Nevertheless, these pathways are genetically organized in genus-specific fashions, as exemplified by the b-ketoadipate and Paa pathways. Comparative genomic studies further reveal that some pathways are more widespread than initially thought. Thus, the Box and Paa pathways illustrate the prevalence of non-oxygenolytic ring-cleavage strategies in aerobic aromatic degradation processes.",1
"Functional genomic studies have been useful in establishing that even organisms harboring high numbers of homologous enzymes seem to contain few examples of true redundancy. For example, the multiplicity of ring-cleaving dioxygenases in certain rhodococcal isolates may be attributed to the cryptic aromatic catabolism of different terpenoids and steroids. Finally, analyses have indicated that recent genetic flux appears to have played a more significant role in the evolution of some large genomes, such as LB400's, than others.",1
"In particular, hydrocarbons and halogenated compounds have long been doubted to be degradable in the absence of oxygen, but the isolation of hitherto unknown anaerobic hydrocarbon-degrading and reductively dehalogenating bacteria during the last decades provided ultimate proof for these processes in nature. While such research involved mostly chlorinated compounds initially, recent studies have revealed reductive dehalogenation of bromine and iodine moieties in aromatic pesticides. Other reactions, such as biologically induced abiotic reduction by soil minerals, has been shown to deactivate relatively persistent aniline-based herbicides far more rapidly than observed in aerobic environments.",1
Mb genome of the facultative denitrifying Aromatoleum aromaticum strain EbN1 was the first to be determined for an anaerobic hydrocarbon degrader (using toluene or ethylbenzene as substrates). The genome sequence revealed about two dozen gene clusters (including several paralogs) coding for a complex catabolic network for anaerobic and aerobic degradation of aromatic compounds. The genome sequence forms the basis for current detailed studies on regulation of pathways and enzyme structures. Further genomes of anaerobic hydrocarbon degrading bacteria were recently completed for the iron-reducing species Geobacter metallireducens (accession nr. NC_007517) and the perchlorate-reducing Dechloromonas aromatica (accession nr.,1
"NC_007298), but these are not yet evaluated in formal publications. Complete genomes were also determined for bacteria capable of anaerobic degradation of halogenated hydrocarbons by halorespiration: the ~1.4 Mb genomes of Dehalococcoides ethenogenes strain 195 and Dehalococcoides sp. strain CBDB1 and the ~5.7 Mb genome of Desulfitobacterium hafniense strain Y51. Characteristic for all these bacteria is the presence of multiple paralogous genes for reductive dehalogenases, implicating a wider dehalogenating spectrum of the organisms than previously known. Moreover, genome sequences provided unprecedented insights into the evolution of reductive dehalogenation and differing strategies for niche adaptation.Recently,",1
"(2000) showed that, with the exception of kaolinite clay, most soil clays and cation exchange resins attenuated biodegradation of 2-picoline by Arthrobacter sp. strain R1, as a result of adsorption of the substrate to the clays. Chemotaxis, or the directed movement of motile organisms towards or away from chemicals in the environment is an important physiological response that may contribute to effective catabolism of molecules in the environment. In addition, mechanisms for the intracellular accumulation of aromatic molecules via various transport mechanisms are also important. Petroleum oil contains aromatic compounds that are toxic to most life forms.",1
"The interest of these studies lies on the biotechnological applications of sterol transforming enzymes for the industrial synthesis of sexual hormones and corticoids. Very recently, the catabolism of cholesterol has acquired a high relevance because it is involved in the infectivity of the pathogen Mycobacterium tuberculosis (Mtb). Mtb causes tuberculosis disease, and it has been demonstrated that novel enzyme architectures have evolved to bind and modify steroid compounds like cholesterol in this organism and other steroid-utilizing bacteria as well. These new enzymes might be of interest for their potential in the chemical modification of steroid substrates.",1
"To perform a correct assessment, it is necessary to consider various microorganisms having a variety of genomes and expressed transcripts and proteins. A great number of analyses are often required. Using traditional genomic techniques, such assessments are limited and time-consuming. However, several high-throughput techniques originally developed for medical studies can be applied to assess biotreatment in confined environments.",1
"The study of the fate of persistent organic chemicals in the environment has revealed a large reservoir of enzymatic reactions with a large potential in preparative organic synthesis, which has already been exploited for a number of oxygenases on pilot and even on industrial scale. Novel catalysts can be obtained from metagenomic libraries and DNA sequence based approaches. Our increasing capabilities in adapting the catalysts to specific reactions and process requirements by rational and random mutagenesis broadens the scope for application in the fine chemical industry, but also in the field of biodegradation.",1
"In many cases, these catalysts need to be exploited in whole cell bioconversions or in fermentations, calling for system-wide approaches to understanding strain physiology and metabolism and rational approaches to the engineering of whole cells as they are increasingly put forward in the area of systems biotechnology and synthetic biology. In the ecosystem, different substrates are attacked at different rates by consortia of organisms from different kingdoms. Aspergillus and other moulds play an important role in these consortia because they are adept at recycling starches, hemicelluloses, celluloses, pectins and other sugar polymers.",1
"Some aspergilli are capable of degrading more refractory compounds such as fats, oils, chitin, and keratin. Maximum decomposition occurs when there is sufficient nitrogen, phosphorus and other essential inorganic nutrients. Fungi also provide food for many soil organisms.For Aspergillus the process of degradation is the means of obtaining nutrients. When these moulds degrade human-made substrates, the process usually is called biodeterioration. Both paper and textiles (cotton, jute, and linen) are particularly vulnerable to Aspergillus degradation. Our artistic heritage is also subject to Aspergillus assault.",1
"In order to ""reduce"" the amount of electricity consumer's products consume, it advises that consumers look for the Energy Star logo on the products that they buy. A comprehensive list of advice and recommendations are available in the ""Reduce"" section of the site. Thus, it encourages consumers to ""rethink"" ways in which they can make smarter, environmentally friendlier choices when purchasing electronics products. There are some entities in the United States and abroad that raise serious concerns about electronics recycling.",1
Some groups are concerned that the workers who do the actual recycling are exposed to toxins that can be harmful to their health. MyGreenElectronics represents a consumer-driven voluntary approach to recycling. Some people believe that the government should do more to compel consumers to pay for an advance fee for the future recycling cost of their product. Others believe that manufacturers of electronics should take full responsibility for the recycling or disposal of their products.,1
"Going Green With Your Computer - March 5, 2007 WCCO.com CBS News Some Consumers Opting for Eco-Friendly Computers February 21, 2007 ABC News Electronic waste Similar Homepage with a different name",1
"Originally, fourteen states and the European Communities signed the Convention adopted in 1976. It came into effect on 12 February 1978. The amendments adopted in 1995 have yet to be ratified by Bosnia and Herzegovina. Parties are all countries with a Mediterranean shoreline as well as the European Union. NGOs with a stated interest and third-party governments are allowed observer status. The convention is applicable to the 'Zone of the Mediterranean Sea'.",1
"This is defined as 'the maritime waters of the Mediterranean as such, with all its gulfs and tributary seas, bounded to the west by the Strait of Gibraltar and to the east by the Dardanelle Strait'. Parties are allowed to extend the application of the convention to the coastal areas within their own territory.",1
"Mediterranean Sea Law of the Sea Specially Protected Areas of Mediterranean Importance Protected areas London Convention UNEP Regional Seas Programme – Barcelona Convention UNEP Mediterranean Action Plan for the Barcelona Convention UNEP – Governing Instruments of the Mediterranean EU – Barcelona Convention for the Protection of the Mediterranean, acts and protocols, at EUR-Lex: Access to European Union Law",1
"Since all TOC analyzers only actually measure total carbon, TOC analysis always requires some accounting for the inorganic carbon that is always present. One analysis technique involves a two-stage process commonly referred to as TC-IC. It measures the amount of inorganic carbon (IC) evolved from an acidified aliquot of a sample and also the amount of total carbon (TC) present in the sample. TOC is calculated by subtraction of the IC value from the TC of the sample.",1
"Addition of acid and inert-gas sparging allows all bicarbonate and carbonate ions to be converted to carbon dioxide, and this IC product vented along with any purgeable organic carbon (POC) that was present.",1
The second stage is the oxidation of the carbon in the remaining sample in the form of carbon dioxide (CO2) and other gases. Modern TOC analyzers perform this oxidation step by several processes: High temperature combustion High temperature catalytic oxidation (HTCO) Photo-oxidation alone Thermo-chemical oxidation Photo-chemical oxidation Electrolytic oxidation,1
"These substances can interfere with the detection of the CO2 gas. The HTCO method may be useful in those applications where difficult to oxidize compounds, or high molecular weight organics, are present as it provides almost complete oxidation of organics including solids and particulates small enough to be injected into the furnace. The major drawback of HTCO analysis is its unstable baseline resulting from the gradual accumulation of non-volatile residues within the combustion tube. These residues continuously change TOC background levels requiring continuous background correction.",1
"Because aqueous samples are injected directly into a very hot, usually quartz, furnace only small aliquots (less than 2 milliliters and usually less than 50 - 100 microliter, with a maximum of approximately 300 - 400 micro-liters under special conditions; such as repetitive injections) of sample can be handled making the methods less sensitive than chemical oxidation methods capable of digesting as much as 10 times more sample.",1
"Also, the salt content of the samples do not combust, and so therefore, gradually build a residue inside the combustion tube eventually clogging the catalyst resulting in poor peak shapes, and degraded accuracy or precision, unless appropriate maintenance procedures are followed. The catalyst should be regenerated or replaced as needed. To avoid this problem the manufacturing industry has developed several concepts, such as matrix separation, ceramic reactors, better process control or methods without catalysts.",1
"In this oxidation scheme, ultraviolet light alone oxidizes the carbon within the sample to produce CO2. The UV oxidation method offers the most reliable, low maintenance method of analyzing TOC in ultra-pure waters.",1
"Like the photo-oxidation method, UV light is the oxidizer but the oxidation power of the reaction is magnified by the addition of a chemical oxidizer, which is usually a persulfate compound.",1
The mechanisms of the reactions are as follows: Free radical oxidants formed: S 2 O 8 2 − ⟶ h v 2 S O 4 − ∙ {\displaystyle \mathrm {S} _{2}\mathrm {O} _{8}^{2-}{\underset {hv}{\longrightarrow }}2\ \mathrm {SO} _{4}^{-\bullet }} H 2 O ⟶ h v H + + O H ∙ {\displaystyle \mathrm {H} _{2}\mathrm {O} {\underset {hv}{\longrightarrow }}\mathrm {H} ^{+}+\mathrm {OH} ^{\bullet }} S O 4 − ∙ + H 2 O ⟶ S O 4 2 − + O H ∙ + H + {\displaystyle \mathrm {SO} _{4}^{-\bullet }+\mathrm {H} _{2}\mathrm {O} \longrightarrow \mathrm {SO} _{4}^{2-}+\mathrm {OH} ^{\bullet }+\mathrm,1
"{H} ^{+}} Excitation of organics: R ⟶ h v R ∗ {\displaystyle \mathrm {R} {\underset {hv}{\longrightarrow }}\mathrm {R} ^{*}} Oxidation of organics: R ∗ + S O 4 − ∙ + O H ∙ ⟶ n C O 2 + … {\displaystyle \mathrm {R} ^{*}+\mathrm {SO} _{4}^{-\bullet }+\mathrm {OH} ^{\bullet }\longrightarrow n\mathrm {CO} _{2}+\dots } The UV–chemical oxidation method offers a relatively low maintenance, high sensitivity method for a wide range of applications. However, there are oxidation limitations of this method.",1
"Limitations include the inaccuracies associated with the addition of any foreign substance into the analyte and samples with high amounts of particulates. Performing ""system blank"" analysis, which is to analyze then subtract the amount of carbon contributed by the chemical additive, inaccuracies are lowered. However, analyses of levels below 200 ppb TOC are still difficult.",1
"Also known as heated persulfate, the method utilizes the same free radical formation as UV persulfate oxidation except uses heat to magnify the oxidizing power of persulfate. Chemical oxidation of carbon with a strong oxidizer, such as persulfate, is highly efficient, and unlike UV, is not susceptible to lower recoveries caused by turbidity in samples. The analysis of system blanks, necessary in all chemical procedures, is especially necessary with heated persulfate TOC methods because the method is so sensitive that reagents cannot be prepared with carbon contents low enough to not be detected.",1
"There are two types of conductivity detectors, direct and membrane. Direct conductivity provides an all-encompassing approach of measuring CO2. This detection method uses no carrier gas, is good at the parts per billion (ppb) ranges, but has a very limited analytical range. Membrane conductivity relies upon the filtering of the CO2 prior to measuring it with a conductivity cell. Both methods analyze sample conductivity before and after oxidization, attributing this differential measurement to the TOC of the sample. During the sample oxidization phase, CO2 (directly related to the TOC in the sample) and other gases are formed.",1
"The dissolved CO2 forms a weak acid, thereby changing the conductivity of the original sample proportionately to the TOC in the sample. Conductivity analyses assume that only CO2 is present within the solution. As long as this holds true, then the TOC calculation by this differential measurement is valid. However, depending on the chemical species present in the sample and their individual products of oxidation, they may present either a positive or a negative interference to the actual TOC value, resulting in analytical error. Some of the interfering chemical species include Cl−, HCO3−, SO32−, SO2−, ClO2−, and H+.",1
"µm (2350 cm−1), is measured over time as the gas flows through the detector. A second reference measurement that is non-specific to CO2 is also taken and the differential result correlates to the CO2 concentration in the detector at that moment. As the gas continues to flow into and out of the detector cell the sum of the measurements results in a peak that is integrated and correlated to the total CO2 concentration in the sample aliquot. A new advance of NDIR technology is static pressurized concentration (SPC).",1
"The exit valve of the NDIR is closed to allow the detector to become pressurized. Once the gases in the detector have reached equilibrium, the concentration of the CO2 is analyzed. This pressurization of the sample gas stream in the NDIR, a patented technique, allows for increased sensitivity and precision by measuring the entirety of the oxidation products of the sample in one reading, compared to flow-through cell technology. The output signal is proportional to the concentration of CO2 in the carrier gas, from the oxidation of the sample aliquot.",1
"A non-profit research and testing organization, the Instrumentation Testing Association (ITA) can provide results of field testing online TOC analysers in an industrial wastewater application. Gulf Coast Waste Disposal Authority (GCWDA), Bayport Industrial Wastewater Treatment Plant in Pasadena, Texas sponsored and conducted this test in 2011. The GCWDA Bayport facility treats approximately 30 mgd of industrial waste received from approximately 65 customers (primarily petrochemical). Field tests consisted of operating online TOC analysers at the influent of the Bayport facility in which TOC concentrations can range from 490 to 1020 mg/L with an average of 870 mg/L.",1
"In a combustion analyser, half of the sample is injected into a chamber where it is acidified, usually with phosphoric acid, to turn all of the inorganic carbon into carbon dioxide as per the following reaction: CO2 + H2O ⇌ H2CO3 ⇌H+ + HCO3− ⇌ 2H+ + CO32−This is then sent to a detector for measurement. The other half of the sample is injected into a combustion chamber which is raised to between 600–700 °C, some even up to 1200 °C. Here, all the carbon reacts with oxygen, forming carbon dioxide.",1
Chemical oxidation analysers inject the sample into a chamber with phosphoric acid followed by persulfate. The analysis is separated into two steps. One removes inorganic carbon by acidification and purging. After removal of inorganic carbon persulfate is added and the sample is either heated or bombarded with UV light from a mercury vapor lamp. Free radicals form persulfate and react with any carbon available to form carbon dioxide.,1
"Marine mammals are exposed to a variety of chemicals throughout their life, mostly through their diet. Once the chemicals are accumulated in the body tissues of the mammals, a portion of these chemicals in the female mammals are transferred to their offspring during gestation and lactation. The degree of maternal-fetal transfer of chemical pollutants is affected by chemical and physical properties of those compounds. Lipophilicity, protein binding, and active transport mechanisms all influence the absorption and distribution of such chemicals in maternal tissues.",1
"Lipophilic chemicals, such as many POPs, can be transferred through the fatty portion of milk, while hydrophilic components can be transferred along with the liquid portion of the milk. The placenta provides a barrier to some contaminants, but is partially permeable to others, including many organics and certain heavy metals such as lead, mercury and cadmium, particularly when combined with organic molecules.",1
"The transfer of contaminants from mother to pup through lactation is most likely the largest mass transfer of contaminants, greater than that of in-utero transfers. When the mother begins lactation, blubber lipids are converted into milk lipids to feed her offspring. During this process, toxicants that were stored in blubber lipids are moved into the milk and subsequently are transferred to the nursing pup. The transfer of toxicants through lactation is driven by the log Kow of the toxicants.",1
"Chemical compounds with a high affinity for lipids (a higher log Kow) will more readily be transferred through lactation due to the high lipid content of milk. The transfer of toxicants from blubber to milk is not fully understood, and selective transfer of contaminants has been observed. Mass balance of toxicants is difficult during lactation due to milk lipids originating from blubber lipids as well as being synthesized locally in mammary tissue.",1
"The change in toxicant solubility between blubber and circulatory fluid as well as the breakdown and resynthesis of blubber lipids and circulatory lipids also contributes to the difficulties of mass balance of toxicants between blubber, circulatory, and milk lipids.However, even with difficulties of mass balancing, it has generally been observed in grey seals and harbor porpoises that residues in pup blubber lipids are generally similar or slightly higher than in maternal milk lipids, and are approximately half of the residues in maternal blubber lipids.",1
"Some lipophilic chemicals can be metabolized by the fetus using mostly CYP enzymes, but others are quickly incorporated into developing fetal adipose tissue. The storage and release of these chemicals within the fetus can lead to endocrine disruption, immunosuppression, thyroid disruption, and neurotoxicity in seals and orcas.",1
"In mammals, maternal factors can be transferred via the placenta, in the colostrum, and in normal milk during lactation. Marine mammal offspring are especially vulnerable during the time when their own immune systems have not yet matured. When females provide milk to their young, they can have a dramatic impact on offspring fitness during ontogeny, as well as when the offspring matures into an adult. Female marine mammals pass on most of their POP burden to their first-born offspring, while the calf is in utero and afterwards during lactation.",1
"The large amount of POPs transferred to the offspring as well as the fast rate of transfer, can sometimes prove fatal.",1
"The POP burden carried by male and female marine mammals tends to increase with time until they reach the age of sexual maturity. After that point, the burden in males continues to grow, as they continue to absorb POPs from their food. However, with female marine mammals, the POP burden carried decreases after birth but can then increase until the next reproductive cycle.",1
"Most aquatic ecosystems involving mixed fish fauna can tolerate TDS levels of 1000 mg/L. The fathead minnow (Pimephales promelas), for example, realizes an LD50 concentration of 5600 ppm based upon a 96-hour exposure. LD50 is the concentration required to produce a lethal effect on 50 percent of the exposed population. Daphnia magna, a good example of a primary member of the food chain, is a small planktonic crustacean, about 0.5 mm in length, having an LD50 of about 10,000 ppm TDS for a 96-hour exposure.Spawning fishes and juveniles appear to be more sensitive to high TDS levels.",1
"The term ""microplastics"" was introduced in 2004 by Professor Richard Thompson, a marine biologist at the University of Plymouth in the United Kingdom.Microplastics are common in our world today. In 2014, it was estimated that there are between 15 and 51 trillion individual pieces of microplastic in the world's oceans, which was estimated to weigh between 93,000 and 236,000 metric tons.",1
"Secondary plastics are small pieces of plastic derived from the breakdown of larger plastic debris, both at sea and on land. Over time, a culmination of physical, biological, and chemphotodegradation, including photo-oxidation caused by sunlight exposure, can reduce the structural integrity of plastic debris to a size that is eventually undetectable to the naked eye. This process of breaking down large plastic material into much smaller pieces is known as fragmentation. It is considered that microplastics might further degrade to be smaller in size, although the smallest microplastic reportedly detected in the oceans at present is 1.6 micrometres (6.3×10−5",1
"Due to their small size, nanoplastics can cross cellular membranes and affect the functioning of cells. Nanoplastics are lipophilic and models show that polyethylene nanoplastics can be incorporated into the hydrophobic core of lipid bilayers. Nanoplastics are also shown to cross the epithelial membrane of fish accumulating in various organs including the gallbladder, pancreas, and the brain. Little is known on adverse health effects of nanoplastics in organisms including humans. In zebrafish, polystyrene nanoplastics can induce a stress response pathway altering glucose and cortisol levels, which is potentially tied to behavioral changes in stress phases.",1
"Wear and tear from tires significantly contributes to the flow of (micro-)plastics into the environment. Estimates of emissions of microplastics to the environment in Denmark are between 5,500 and 14,000 tonnes (6,100 and 15,400 tons) per year. Secondary microplastics (e.g. from car and truck tires or footwear) are more important than primary microplastics by two orders of magnitude. The formation of microplastics from the degradation of larger plastics in the environment is not accounted for in the study.The estimated per capita emission ranges from 0.23 to 4.7 kg/year, with a global average of 0.81 kg/year.",1
"The emissions from car tires (wear reaching 100%) are substantially higher than those of other sources of microplastics, e.g., airplane tires (2%), artificial turf (wear 12–50%), brakes (wear 8%), and road markings (wear 5%). In the case of road markings, recent field study indicated that they were protected by a layer of glass beads and their contribution was only between 0.1 and 4.3 g/person/year, which would constitute approximately 0.7% of all of the secondary microplastics emissions; this value agrees with some emissions estimates. Emissions and pathways depend on local factors like road type or sewage systems.",1
"Studies have shown that many synthetic fibers, such as polyester, nylon, acrylics, and spandex, can be shed from clothing and persist in the environment. Each garment in a load of laundry can shed more than 1,900 fibers of microplastics, with fleeces releasing the highest percentage of fibers, over 170% more than other garments. For an average wash load of 6 kilograms (13 lb), over 700,000 fibers could be released per wash.Washing machine manufacturers have also reviewed research into whether washing machine filters can reduce the amount of microfiber fibers that need to be treated by sewage treatment facilities.These",1
"The occurrence of these types of fibers in households has been shown to represent 33% of all fibers in indoor environments.Textile fibers have been studied in both indoor and outdoor environments to determine the average human exposure. The indoor concentration was found to be 1.0–60.0 fibers/m3, whereas the outdoor concentration was much lower at 0.3–1.5 fibers/m3. The deposition rate indoors was 1586–11,130 fibers per day/m3 which accumulates to around 190-670 fibers/mg of dust. The largest concern with these concentrations is that it increases exposure to children and the elderly, which can cause adverse health effects.",1
"Recreational and commercial fishing, marine vessels, and marine industries are all sources of plastic that can directly enter the marine environment, posing a risk to biota both as macroplastics, and as secondary microplastics following long-term degradation. Marine debris observed on beaches also arises from beaching of materials carried on inshore and ocean currents. Fishing gear is a form of plastic debris with a marine source. Discarded or lost fishing gear, including plastic monofilament line and nylon netting (sometimes called ghost nets), is typically neutrally buoyant and can, therefore, drift at variable depths within the oceans.",1
"Various countries have reported that microplastics from the industry and other sources have been accumulating in different types of seafood. In Indonesia, 55% of all fish species had evidence of manufactured debris similar to America which reported 67%. However, the majority of debris in Indonesia was plastic, while in North America the majority was synthetic fibers found in clothing and some types of nets. The implication from the fact that fish are being contaminated with microplastic is that those plastics and their chemicals will bioaccumulate in the food chain.",1
"One study analyzed the plastic-derived chemical called polybrominated diphenyl ethers (PBDEs) in the stomachs of short-tailed shearwaters. It found that one-fourth of the birds had higher-brominated congeners that are not naturally found in their prey. However, the PBDE got into the birds' systems through plastic that was found in the stomachs of the birds. It is therefore not just the plastics that are being transferred through the food chain but the chemicals from the plastics as well.",1
"In 2020 researchers reported that polypropylene infant feeding bottles with contemporary preparation procedures were found to cause microplastics exposure to infants ranging from 14,600 to 4,550,000 particles per capita per day in 48 regions. Microplastics release is higher with warmer liquids and similar with other polypropylene products such as lunchboxes. Unexpectedly, silicone rubber baby bottle nipples degrade over time from repeated steam sterilization, shedding micro- and nano-sized particles of silicone rubber, researchers found in 2021. They estimated that, using such heat-degraded nipples for a year, a baby will ingest more than 660,000 particles.",1
"Sewage treatment plants, also known as wastewater treatment plants (WWTPs), remove contaminants from wastewater, primarily from household sewage, using various physical, chemical, and biological processes. Most plants in developed countries have both primary and secondary treatment stages. In the primary stage of treatment, physical processes are employed to remove oils, sand, and other large solids using conventional filters, clarifiers, and settling tanks. Secondary treatment uses biological processes involving bacteria and protozoa to break down organic matter. Common secondary technologies are activated sludge systems, trickling filters, and constructed wetlands.",1
"In addition, some studies show that microplastics do pass through filtration processes at some WWTPs. According to a study from the UK, samples taken from sewage sludge disposal sites on the coasts of six continents contained an average one particle of microplastic per liter. A significant amount of these particles was of clothing fibers from washing machine effluent. According to a comprehensive review of scientific evidence published by the European Union's Scientific Advice Mechanism in 2019, microplastics are now present in every part of the environment.",1
"at the 2008 International Research Workshop on the Occurrence, Effects and Fate of Microplastic Marine Debris at the University of Washington at Tacoma concluded that microplastics are a problem in the marine environment, based on: the documented occurrence of microplastics in the marine environment, the long residence times of these particles (and, therefore, their likely buildup in the future), and their demonstrated ingestion by marine organisms.So far, research has mainly focused on larger plastic items. Widely recognized problems facing marine life are entanglement, ingestion, suffocation and general debilitation often leading to death and/or strandings. This causes serious public concern.",1
"have been detected not just in marine but also in freshwater systems including marshes, streams, ponds, lakes, and rivers in (Europe, North America, South America, Asia and Australia). Samples collected across 29 Great Lakes tributaries from six states in the United States were found to contain plastic particles, 98% of which were microplastics ranging in size from 0.355mm to 4.75mm.",1
"Microplastics can become embedded in animals' tissue through ingestion or respiration. Various annelid species, such as deposit-feeding lugworms (Arenicola marina), have been shown to have microplastics embedded in their gastrointestinal tracts. Many crustaceans, like the shore crab Carcinus maenas, have been seen to integrate microplastics into both their respiratory and digestive tracts. Plastic particles are often mistaken by fish for food which can block their digestive tracts sending incorrect feeding signals to the brains of the animals. New research revealed, however, that fish ingest microplastics inadvertently rather than intentionally.",1
"Some coral such as Pocillopora verrucosa have also been found to ingest microplastics. It can take up to 14 days for microplastics to pass through an animal (as compared to a normal digestion period of 2 days), but enmeshment of the particles in animals' gills can prevent elimination entirely. When microplastic-laden animals are consumed by predators, the microplastics are then incorporated into the bodies of higher trophic-level feeders. For example, scientists have reported plastic accumulation in the stomachs of lantern fish which are small filter feeders and are the main prey for commercial fish like tuna and swordfish.",1
"Microplastics also absorb chemical pollutants that can be transferred into the organism's tissues. Small animals are at risk of reduced food intake due to false satiation and resulting starvation or other physical harm from the microplastics. A study done at the Argentinean coastline of the Rio de la Plata estuary, found the presence of microplastics in the guts of 11 species of coastal freshwater fish. These 11 species of fish represented four different feeding habits: detritivore, planktivore, omnivore and ichthyophagous. This study is one of the few so far to show the ingestion of microplastics by freshwater organisms.",1
"Bottom feeders, such as benthic sea cucumbers, who are non-selective scavengers that feed on debris on the ocean floor, ingest large amounts of sediment. It has been shown that four species of sea cucumber (Thyonella gemmate, Holothuria floridana, H. grisea and Cucumaria frondosa) ingested between 2- and 20-fold more PVC fragments and between 2- and 138-fold more nylon line fragments (as much as 517 fibers per organism) based on plastic-to-sand grain ratios from each sediment treatment. These results suggest that individuals may be selectively ingesting plastic particles.",1
"This contradicts the accepted indiscriminate feeding strategy of sea cucumbers, and may occur in all presumed non-selective feeders when presented with microplastics.Bivalves, important aquatic filter feeders, have also been shown to ingest microplastics and nanoplastics. Upon exposure to microplastics, bivalve filtration ability decreases. Multiple cascading effects occur as a result, such as immunotoxicity and neurotoxicity. Decreased immune function occurs due to reduced phagocytosis and NF-κB gene activity. Impaired neurological function is a result of the inhibition of ChE and suppression of neurotransmitter regulatory enzymes.",1
"When exposed to microplastics, bivalves also experience oxidative stress, indicating an impaired ability to detoxify compounds within the body, which can ultimately damage DNA. Bivalve gametes and larvae are also impaired when exposed to microplastics. Rates of developmental arrest, and developmental malformities increase, while rates of fertilization decrease. When bivalves have been exposed to microplastics as well as other pollutants such as POPs, mercury or hydrocarbons in lab settings, toxic effects were shown to be aggravated.Not only fish and free-living organisms can ingest microplastics. Scleractinian corals, which are primary reef-builders, have been shown to ingest microplastics under laboratory conditions.",1
"While the effects of ingestion on these corals has not been studied, corals can easily become stressed and bleach. Microplastics have been shown to stick to the exterior of the corals after exposure in the laboratory. The adherence to the outside of corals can potentially be harmful, because corals cannot handle sediment or any particulate matter on their exterior and slough it off by secreting mucus, expending energy in the process, increasing the likelihood of mortality.Marine",1
"published in 2023 demonstrated that microplastic exposure impaired the cognitive performance of hermit crabs, which could potentially impact their survivability.It is not just aquatic animals which may be harmed. Microplastics can stunt the growth of terrestrial plants due to the increased uptake of toxic metals such as cadmium.In 2019, the first European records of microplastic items in amphibians' stomach content was reported in specimens of the common European newt (Triturus carnifex). This also represented the first evidence for Caudata worldwide, highlighting that the emerging issue of plastics is a threat even in remote high-altitude environments.",1
"The microplastic has also been found in Common Blackbirds (Turdus merula) and Song Thrushes (Turdus philomelos) which shows a ubiquity of microplastics in terrestrial environments.Zooplankton ingest microplastics beads (1.7–30.6 μm) and excrete fecal matter contaminated with microplastics. Along with ingestion, the microplastics stick to the appendages and exoskeleton of the zooplankton. Zooplankton, among other marine organisms, consume microplastics because they emit similar infochemicals, notably dimethyl sulfide, just as phytoplankton do. Plastics such as high-density polyethylene (HDPE), low-density polyethylene (LDPE), and polypropylene (PP) produce dimethyl sulfide odors.",1
"These types of plastics are commonly found in plastic bags, food storage containers, and bottle caps. Green and red filaments of plastics are found in the planktonic organisms and in seaweeds.Not only do animals and plants ingest microplastics, some microbes also live on the surface of microplastics. This community of microbes form a slimy biofilm which, according to a 2019 study, has a unique structure and possesses a special risk, because microplastic biofilms have been proven to provide a novel habitat for colonization that increases overlap between different species, thus spreading pathogens and antibiotic resistant genes through horizontal gene transfer.",1
"Then, due to rapid movement through waterways, these pathogens can be moved very quickly from their origin to another location where a specific pathogen may not be naturally present, spreading the potential disease.",1
"According to a comprehensive review of scientific evidence published by the European Union's Scientific Advice Mechanism in 2019, ""little is known with respect to the human health risks of nano- and microplastics, and what is known is surrounded by considerable uncertainty"". The authors of the review identify the main limitations as the quality or methodology of the research to date. Since ""the poison is in the dose"", the review concludes that ""there is a need to understand the potential modes of toxicity for different size-shape-type NMP [nano- (< 0.1",1
"mm) and microplastic] combinations in carefully selected human models, before robust conclusions about 'real' human risks can be made"".Mean/median intake of microplastics in humans are at levels considered to be safe in humans; however, some individuals may sometimes exceed these limits; the effects, if any, of this is unknown. It is unknown whether and to what degree microplastics bioaccumulate in humans. Research reported in 2022 identified, for the first time, the presence of polymers in human blood in 17 of 22 healthy volunteers. The mean of the sum quantifiable concentration of plastic particles was 1.6 mg/L.",1
"However, ingestion of microplastics via food may be relatively minor; for example, while mussels are known to accumulate microplastics, humans are predicted to be exposed to more microplastics in household dust than by consuming mussels.There are three main areas of potential concern with microplastics: the plastics themselves may have some effect on human physiology, microplastics might complex with heavy metals or other chemical compounds in the environment and act as a vector for bringing them into the body, and it is possible that microplastics might serve as vectors for pathogens.",1
"It is as yet unknown if exposure to microplastics at the levels found in the environment represent a ""real"" risk to humans; research into the subject is ongoing.",1
"In 2023, plasticosis, a new disease caused solely by plastics, was discovered in seabirds. The birds identified as having the disease have scarred digestive tracts from ingesting plastic waste. ""When birds ingest small pieces of plastic, they found, it inflames the digestive tract. Over time, the persistent inflammation causes tissues to become scarred and disfigured, affecting digestion, growth and survival.""",1
"Airborne microplastics have been detected in the atmosphere, as well as indoors and outdoors. In 2019 a study found microplastic to be atmospherically transported to remote areas on the wind. A 2017 study found indoor airborne microfiber concentrations between 1.0 and 60.0 microfibers per cubic meter (33% of which were found to be microplastics). Another study looked at microplastic in the street dust of Tehran and found 2,649 particles of microplastic within 10 samples of street dust, with ranging samples concentrations from 83 particle – 605 particles (±10) per 30.0 g of street dust.",1
"Microplastics have been widely detected in the world's aquatic environments. The first study on microplastics in freshwater ecosystems was published in 2011 that found an average of 37.8 fragments per square meter of Lake Huron sediment samples. Additionally, studies have found MP (microplastic) to be present in all of the Great Lakes with an average concentration of 43,000 MP particle km−2. Microplastics have also been detected in freshwater ecosystems outside of the United States, for example in 2019 study conducted in Poland showed that microplastic was present in all 30 studied lakes of the Masurian Lakeland with density from 0.27",1
"to 1.57 particles per liter. In Canada, a three-year study found a mean microplastic concentration of 193,420 particles km−2 in Lake Winnipeg. None of the microplastics detected were micro-pellets or beads and most were fibers resulting from the breakdown of larger particles, synthetic textiles, or atmospheric fallout. The highest concentration of microplastic ever discovered in a studied freshwater ecosystem was recorded in the Rhine river at 4000 MP particles kg−1.",1
"In December 2020, microplastic particles were found in the placentas of unborn babies for the first time. In June 2022, microplastic particles were found in breastmilk for the first time. In July 2022, scientists found microplastic particles in the lungs of 11 of 13 samples, supporting the hypothesis that we can inhale microplastics as well as swallow them.According to a research conducted by the Medical University of Vienna, five grams of plastic particles enter each person's gastrointestinal stream on average per week. This is approximately the weight of a credit card.",1
"Computer modelling done by The Ocean Cleanup, a Dutch foundation, has suggested that collection devices placed nearer to the coasts could remove about 31% of the microplastics in the area. On September 9, 2018, The Ocean Cleanup launched the world's first ocean cleanup system, 001 aka ""Wilson"", which is being deployed to the Great Pacific Garbage Patch. System 001 is 600 meters long that acts as a U-shaped skiff that uses natural oceanic currents to concentrate plastic and other debris on the ocean's surface into a confined area for extraction by vessels.",1
Some advocate for improving recycling technology to be able to recycle smaller plastics to reduce the need for production of new plastics.,1
"Cassa Depositi e Prestiti (CDP), the Italian national promotional institution and financial institution for development cooperation, and the Instituto de Crédito Oficial (ICO), the Spanish promotional bank, became new partners in October 2020.In February 2022, the initiative stated that it would increase its financing aim to €4 billion by the end of 2025. At the same time, the European Bank for Reconstruction and Development (EBRD) became the Clean Oceans Initiative's sixth member. By February 2023, the program had met 65% of its goal, with €2.6",1
"In 2018, China banned the import of recyclables from other countries, forcing those other countries to re-examine their recycling schemes. The Yangtze River in China contributes 55% of all plastic waste going to the seas. Including microplastics, the Yangtze bears an average of 500,000 pieces of plastic per square kilometer. Scientific American reported that China dumps 30% of all plastics in the ocean.",1
"The Environment Ministry has also proposed a number of recommendations for methods to monitor microplastic quantities in the ocean (Recommendations, 2018). However, the legislation does not specify any penalties for those who continue manufacturing products with microplastics.",1
"January 2019, the European Chemicals Agency (ECHA) proposed to restrict intentionally added microplastics.The European Union participates with 10% of the global total, around 150 000 tonnes of microplastics each year. This is 200 grams per person per year, with significant regional variance in per-capita microplastic creation. The European Commission's Circular Economy Action Plan sets out mandatory requirements for the recycling and waste reduction of key products e.g. plastic packaging. The plan starts the process to restrict addition of microplastics in products. It mandates measures for capturing more microplastics at all stages of the lifecycle of a product. E.g.",1
"Archived 2007-08-15 at the Wayback Machine DMOZ Open Directory Project - Heat Generating Equipment Archived 2017-03-16 at the Wayback Machine NORA, An Association of Responsible Recyclers, formerly the National Oil Recyclers Association {http://www.dep.state.fl.us/waste/categories/used_oil/}",1
Both solid phase (soils and sediment) and aqueous acute toxicity testing (described below) can be conducted using this technology.,1
"If a greater salinity is required, this can be accomplished by dissolving solid sodium chloride in the sample to achieve a final salinity of 2% for the protection of Allivibrio fischeri. Highly turbid samples that contain particulate matter will be required to settle before the test can be conducted. Particulate matter in the sample can interfere with bioluminescence by absorbing light and give misleading test results. Interference of luminescence can also occur with samples which are highly colored (particularly red, brown or black). It may be necessary to centrifuge samples to obtain an acceptable clarity for the test.",1
"As a result, it is difficult to obtain representative samples from such matrices. Toxic substances are likely to bind to particulate matter, and the extent to which toxic materials bind depends on the composition of the particles. For example, smaller particles such as clay tend to tightly bind to chemicals, acting like ion exchange resins. Microtox tests for sediment and soil differ in the way the matrix is prepared for contact with Allivibrio fischeri. To obtain a representative soil or sediment sample, it is necessary to conduct an elutriate test.",1
"The light output of the bacteria is measured using a photometer after five and 15 minutes from exposing the bacteria to the samples. The light measured directly correlates to the toxicity of the sample, producing data that allows for the calculation of EC50 or IC50s, or other ECxx and ICxx values.Acute Toxicity Basic Test is a procedure that measures the relative acute toxicity of a sample. This test is the best protocol for testing samples of unknown toxicity, a high level of toxicity, or when the test results are required to provide the highest confidence and precision.",1
This program calculates the most efficient way of setting up the desired test on the Model 500 Analyser. A test tutor is also included with Microsoft Omni that gives listed instructions on how to set up and run the test of interest. This software allows users to load files from previous versions of the Microtox DOS Software and also gives users the ability to save new data in that original format.,1
This could lead to an over or under estimation of contaminants and their biological effects.,1
"Developed countries such as the United States, Canada, most Western European nations (e.g. Italy and France), Australia, Singapore, South Korea and Japan are struggling with public health problems of SSO prevention. The magnitude of the problem is much greater in most developing countries.",1
"percent of all treated sewage in the United States, the total volume amounts to several billion gallons per annum and accounts for thousands of cases of gastrointestinal illness each year.: Ch. 6",1
"Developed European countries and Japan have similar or somewhat larger percentages of SSO events compared to the U.S.In developing countries, most wastewater is still not treated when discharged into the environment. The People's Republic of China discharged about 55 percent of all sewage without treatment of any type, as of 2001. In a relatively developed Middle Eastern country such as Iran, the majority of Tehran's population has totally untreated sewage injected to the city’s groundwater. In Venezuela, a below-average country in South America with respect to wastewater treatment, 97 percent of the country’s sewage is discharged untreated into the environment.In",1
"many countries there are obligations to measure and report SSO occurrence using real-time telemetry to warn the public, bathers and shellfishery operators.",1
"Sewers that were built in the early stages of urbanization were usually built before sewage treatment was implemented. Early sewers were simple drainage systems to remove surface runoff with any waste material it might contain. These drainage systems became combined sewers when sewage from kitchens, baths, and toilets was added; and the discharge became offensive. Early sewage treatment plants were built to treat the sewage during dry weather; but it was infeasible to treat the larger volume of mixed sewage and precipitation runoff from combined sewers during wet weather.",1
"These fats congeal as solid deposits in the cooler sewer. Solid debris includes soiled clothing, diapers, and sanitary napkins flushed down the toilet rather than being put in a waste bin.: p. 4–28 One of the main problems of a decentralized line failure is the difficulty of defining the location of overflow, since a typical urban system contains thousands of miles of collection pipes, and the central treatment plant has no way of communicating with all the lines, unless expensive monitoring equipment has been installed.",1
"Approximately one-quarter of United States SSOs occur during heavy rainfall events, which can cause inflow of stormwater into sanitary sewers through damage, improper connections, or flooding buildings and lift stations in low-lying areas of the collection system. The combined flow of sewage and stormwater exceeds the capacity of the sanitary sewer system and sewage is released into homes, businesses and streets.: p. 4–26 This circumstance is most prevalent in older cities whose subsurface infrastructure is quite old; Paris, London, Stockholm, New York City, Washington, DC, and Oakland, California are typical examples of such locations.",1
Inflow into the sanitary lines can be caused by tree root rupture of subsurface lines or by mechanical fracture due to age and overpressure from trucks and buildings.,1
"4–27 Power failure, human error, or mechanical failure may cause similar discharge of untreated or partially treated sewage from a sewage treatment plant; but this is typically regarded as a sewage treatment plant malfunction rather than a sanitary sewer overflow. Sewage treatment plants may be designed to capture overflow from malfunctioning units and discharge it to alternative treatment facilities. Flooding of private or public property is typically avoided by discharging the overflow to an outfall designed for discharge of treated sewage.: p.",1
"ES–3 Human health impacts include significant numbers of gastrointestinal illness each year, although death from one overflow event is uncommon. Additional human impacts include beach closures, swimming restrictions and prohibition of the consumption of certain aquatic animals (particularly certain molluscs) after overflow events. Ecological consequences include fish kills, harm to plankton and other aquatic microflora and microfauna. Turbidity increase and dissolved oxygen decrease in receiving waters can lead to accentuated effects beyond the obvious pathogenic induced damage to aquatic ecosystems.",1
"It is possible that higher life forms such as marine mammals can be affected since certain seals and sea lions are known to experience peaks in pathogenic harm. The concept of SSO containment valves has been pioneered in the UK and they are installed to mitigate dry spills, by correlating rainfall data with SSO spill activity. Since medieval times rulers have been aware of the impact of raw sewage improperly discharged to the environment.",1
"He was so effective in keeping his neighbourhood clean that the local authority named a waste vehicle in his honour. The Lord Lieutenant of West Sussex, Susan Pyper, said ""The sign on this truck is a very fitting way to say a huge 'thank you' to David for his tireless efforts ... he is a real local hero.""The Keep America Beautiful organisation is now promoting plogging to its affiliates and has found that some already combined exercise with clean up, such as the Trashercize program in Tennessee.",1
"In New York, a Meetup group, Plogging NYC, had about 100 members in 2018, with events in four boroughs. In Indianapolis in 2018, a Summer of Plogging was organised by the November Project and the local affiliate of Keep America Beautiful.National Cleanup Day advocates plogging as a way to clean up and keep the outdoors clean and maintains the website Plogging.org in support of organizations holding plogging events. There is a group in Oakland, California, called Fit4Good that aims to pick up trash around Lake Merritt each week.",1
"Ripu Daman Bevli, introduced the concept of plogging in India and he is known as the Plogman of India. He commenced Litter Free India movement, which combines Swachh Bharat and FIT India missions. Till March 2021, Bevli has organized more than 500 cleanups across 80 cities under the Litter Free India movement, which has seen a participation of close to 1 crore (10 million) people. The Indian Prime Minister, Narendra Modi, has plogged to lead by example for his Swachh Bharat Mission to clean up India.Pune",1
"Ploggers founded by Vivek Gurav is the largest community of ploggers in a single city with more than 500 routine ploggers throughout Pune, and has collected more than 40,000 kilograms of plastic. In December 2019 the organization coordinated the largest plogging drive, with 105,000 people involved who collected 19,000 kilograms of trash in one hour.A non-profit initiative called Go Plog! has collected 16 tonnes of dry waste in Kolar through plogging. They organise an event every month. Students to high-ranking officials of the local administration participate.",1
"A scientific study from 2022 found that plogging and jogging are comparable in terms of energy expenditure, but that the proportion of energy coming from fat is significantly higher in plogging. Earth Day Clean-up (environment) SpoGomi Plogging Official website",1
"5 Gyres was founded by Anna Cummins and Marcus Eriksen. Eriksen and Cummins have been featured speakers at universities and in news stories. Anna Cummins has also been awarded the Golden Goody Award, during a meeting of the Los Angeles chapter of the USNC for UN WOMEN First Annual Special Assembly. Before founding 5 Gyres, Cummins and Eriksen had worked at the Algalita Marine Research Foundation, with founder Charles J. Moore, who is currently a scientific advisor for 5 Gyres.5 Gyres was one of two organizations that sent Expeditions to research the Great Pacific Garbage Patch.",1
"more than 100 communities in California recently enacting polystyrene bans, and a statewide ban on the ballot for 2018, 5 Gyres sees polystyrene as a natural extension of the momentum that began with microbeads. 5 Gyres",1
"liquid-phase oxidation of heavy naphtha and the Fischer–Tropsch reaction produce mixed oxygenate streams, from which 2-butanone is extracted by fractionation.",1
"Butanone is the precursor to methyl ethyl ketone peroxide, which is a catalyst for some polymerization reactions such as crosslinking of unsaturated polyester resins. Dimethylglyoxime can be prepared from butanone first by reaction with ethyl nitrite to give diacetyl monoxime followed by conversion to the dioxime: In the peroxide process on producing hydrazine, the starting chemical ammonia is bonded to butanone, oxidized by hydrogen peroxide, bonded to another ammonia molecule. In the final step of the process, hydrolysis produces the desired product, hydrazine, and regenerates the butanone. Me(Et)C=NN=C(Et)Me + 2 H2O → 2 Me(Et)C=O + N2H4",1
"There are reports of neuropsychological effects. It is rapidly absorbed through undamaged skin and lungs. It contributes to the formation of ground-level ozone, which is toxic in low concentrations.Butanone is listed as a Table II precursor under the United Nations Convention Against Illicit Traffic in Narcotic Drugs and Psychotropic Substances.",1
"Generally, ingested insoluble actinide compounds, such as high-fired uranium dioxide and mixed oxide (MOX) fuel, will pass through the digestive system with little effect since they cannot dissolve and be absorbed by the body. Inhaled actinide compounds, however, will be more damaging as they remain in the lungs and irradiate the lung tissue. Ingested low-fired oxides and soluble salts such as nitrate can be absorbed into the blood stream. If they are inhaled then it is possible for the solid to dissolve and leave the lungs. Hence, the dose to the lungs will be lower for the soluble form.",1
"Actinium can be naturally found in traces in uranium ore as 227Ac, an α and β emitter with half-life 21.773 years. Uranium ore contains about 0.2 mg of actinium per ton of uranium. It is more commonly made in milligram amounts by neutron irradiation of 226Ra in a nuclear reactor. Natural actinium almost exclusively consists of one isotope, 227Ac, with only minute traces of other shorter-lived isotopes (225Ac and 228Ac) occurring in other decay chains.",1
"In India, a large amount of thorium ore can be found in the form of monazite in placer deposits of the Western and Eastern coastal dune sands, particularly in the Tamil Nadu coastal areas. The residents of this area are exposed to a naturally occurring radiation dose ten times higher than the worldwide average.",1
"Thorium is found at low levels in most rocks and soils, where it is about three times more abundant than uranium and about as abundant as lead. On average, soil commonly contains approximately 6 parts per million (ppm) thorium. Thorium occurs in several minerals; the most common is the rare earth-thorium-phosphate mineral monazite, which contains up to 12% thorium oxide. Several countries have substantial deposits. 232Th decays very slowly (its half-life is about three times the age of the Earth). Other isotopes of thorium occur in the thorium and uranium decay chains.",1
"These are shorter-lived and hence much more radioactive than 232Th, though on a mass basis they are negligible.",1
"It is present in almost all soils and it is more plentiful than antimony, beryllium, cadmium, gold, mercury, silver, or tungsten, and is about as abundant as arsenic or molybdenum. Significant concentrations of uranium occur in some substances such as phosphate rock deposits, and minerals such as lignite, and monazite sands in uranium-rich ores (it is recovered commercially from these sources). Seawater contains about 3.3 parts per billion of uranium by weight as uranium (VI) forms soluble carbonate complexes. Extraction of uranium from seawater has been considered as a means of obtaining the element.",1
Plutonium in the environment has several sources. These include: Atomic batteries In space In pacemakers Bomb detonations Bomb safety trials Nuclear crime Nuclear fuel cycle Nuclear power plants,1
"Plutonium, like other actinides, readily forms a plutonium dioxide (plutonyl) core (PuO2). In the environment, this plutonyl core readily complexes with carbonate as well as other oxygen moieties (OH−, NO2−, NO3−, and SO42−) to form charged complexes which can be readily mobile with low affinities to soil. PuO2CO32− PuO2(CO3)24− PuO2(CO3)36−PuO2 formed from neutralizing highly acidic nitric acid solutions tends to form polymeric PuO2 which is resistant to complexation. Plutonium also readily shifts valences between the +3, +4, +5 and +6 states. It is common for some fraction of plutonium in solution to exist in all of these states in equilibrium.",1
"Americium often enters landfills from discarded smoke detectors. The rules associated with the disposal of smoke detectors are very relaxed in most municipalities. For instance, in the UK it is permissible to dispose of an americium containing smoke detector by placing it in the dustbin with normal household rubbish, but each dustbin worth of rubbish is limited to only containing one smoke detector. The manufacture of products containing americium (such as smoke detectors) as well as nuclear reactors and explosions may also release the americium into the environment.",1
"In 1999, a truck transporting 900 smoke detectors in France had been reported to have caught fire; it is claimed that this led to a release of americium into the environment. In the U.S., the ""Radioactive Boy Scout"" David Hahn was able to buy thousands of smoke detectors at remainder prices and concentrate the americium from them. There have been cases of humans being exposed to americium. The worst case was that of Harold McCluskey, who was exposed to an extremely high dose of americium-241 after an accident involving a glove box. He was subsequently treated with chelation therapy.",1
"It is likely that the medical care which he was given saved his life; despite similar biodistribution and toxicity to plutonium, the two radioactive elements have different solution-state chemistries. Americium is stable in the +3 oxidation state, while the +4 oxidation state of plutonium can form in the human body.The most common isotope americium-241 decays (half-life 432 years) to neptunium-237 which has a much longer half-life, so in the long term, the issues discussed above for neptunium apply.Americium",1
"Noise-induced hearing loss is an irreversible condition that is 100% preventable, and over 30 million US workers are exposed to hazardous noise on the job, which makes them susceptible to noise-induced hearing loss and tinnitus. Noise-induced hearing loss is also the most common occupational illness in the United States. The National Institute for Occupational Safety and Health recommends that workers be exposed to no more than 85 dB per eight hours per day.",1
"This market-based, incentive-driven approach enabled federal, state, and local governments to purchase quieter products and equipment at competitive prices, by awarding procurements to the lowest ""effective bid price”. The effective bid price adjusted the monetary bid price by the sound level of the bidder's equipment in comparison to the average level of all bidders' proposals.Products purchased under this program included construction equipment, lawn and garden equipment, trash trucks/compactors, chain saws, and similar noise generating equipment. The program was part of an initiative to help localities create ""quiet communities"".",1
"States and localities that participated were encouraged also to promote similar Buy Quiet procurements by private sector organizations in their jurisdictions as a way of ""spreading"" the market.The EPA/NIGP/NLC Buy Quiet program extended the concepts of ""social marketing"" to include the creation of markets for socially and environmentally responsible products. It did this by combining incentivized procurements with the development of a national database of buy quiet purchases available to all interested parties. This database demonstrated that incentivized procurements could achieve quiet products at competitive prices.The",1
"In 2006, the National Aeronautics and Space Administration (NASA) codified a Buy Quiet program. In 2009 NASA implemented an online tool called the NASA Buy-Quiet Roadmap.",1
"National Institute for Occupational Safety and Health (NIOSH) researchers developed a Buy Quiet prevention initiative intended to facilitate the implementation of Buy Quiet programs for the construction and manufacturing sectors. As a part of this, NIOSH created a searchable database describing noise emission levels of powered hand tools. The database is called the NIOSH Power Tools Database. In 2014, NIOSH officially launched a Buy Quiet website and blog to promote the purchase of quieter tools and equipment. The initiative also aims to encourage manufacturers to design quieter equipment.The",1
"The quieter piece of equipment may be the least expensive when all life cycle costs of the machinery, possible workers’ compensation claims, costs associated with a company’s hearing conservation program, costs of healthcare (such as hearing aids), and lost productivity are counted. NIOSH estimates a savings of $100 per decibel reduced when purchasing a quieter machine.",1
"(November–December 1989), ""Noise wars: citizens are losing their hearing because the federal government's efforts to dampen neighborhood and workplace noise are dwindling"", Technology Review: 42+ – via General OneFile (subscription required) NIOSH Power Tools Sound Pressure and Vibrations Database NIOSH Noise and Hearing Loss Prevention Topic Page NYC DEP Approved Vendor List NYC DEP Noise Homepage Laborers' Health and Safety Fund – Noise NASA Buy Quiet Roadmap NASA Procedures Requirements (NPR) Document, NPR 1800.1, Chapter 4 NIOSH Buy Quiet Topic Page NIOSH Prevention through Design(PtD) NIOSH Science Blog Buy Quiet Update",1
"Classically, ARS is divided into three main presentations: hematopoietic, gastrointestinal, and neuro vascular. These syndromes may be preceded by a prodrome. The speed of symptom onset is related to radiation exposure, with greater doses resulting in a shorter delay in symptom onset. These presentations presume whole-body exposure, and many of them are markers that are invalid if the entire body has not been exposed. Each syndrome requires that the tissue showing the syndrome itself be exposed (e.g., gastrointestinal syndrome is not seen if the stomach and intestines are not exposed to radiation). Some areas affected are: Hematopoietic.",1
"This syndrome is marked by a drop in the number of blood cells, called aplastic anemia. This may result in infections, due to a low number of white blood cells, bleeding, due to a lack of platelets, and anemia, due to too few red blood cells in circulation. These changes can be detected by blood tests after receiving a whole-body acute dose as low as 0.25 grays (25 rad), though they might never be felt by the patient if the dose is below 1 gray (100 rad).",1
"Conventional trauma and burns resulting from a bomb blast are complicated by the poor wound healing caused by hematopoietic syndrome, increasing mortality. Gastrointestinal. This syndrome often follows absorbed doses of 6–30 grays (600–3,000 rad). The signs and symptoms of this form of radiation injury include nausea, vomiting, loss of appetite, and abdominal pain. Vomiting in this time-frame is a marker for whole body exposures that are in the fatal range above 4 grays (400 rad). Without exotic treatment such as bone marrow transplant, death with this dose is common, due generally more to infection than gastrointestinal dysfunction. Neurovascular.",1
"This syndrome typically occurs at absorbed doses greater than 30 grays (3,000 rad), though it may occur at doses as low as 10 grays (1,000 rad). It presents with neurological symptoms such as dizziness, headache, or decreased level of consciousness, occurring within minutes to a few hours, with an absence of vomiting, and is almost always fatal, even with aggressive intensive care.Early symptoms of ARS typically include nausea, vomiting, headaches, fatigue, fever, and a short period of skin reddening. These symptoms may occur at radiation doses as low as 0.35 grays (35 rad).",1
"These symptoms are common to many illnesses, and may not, by themselves, indicate acute radiation sickness.",1
"A similar table and description of symptoms (given in rems, where 100 rem = 1 Sv), derived from data from the effects on humans subjected to the atomic bombings of Hiroshima and Nagasaki, the indigenous peoples of the Marshall Islands subjected to the Castle Bravo thermonuclear bomb, animal studies and lab experiment accidents, have been compiled by the U.S. Department of Defense.A person who was less than 1 mile (1.6 km) from the atomic bomb Little Boy's hypocenter at Hiroshima, Japan, was found to absorb about 9.46 grays (Gy) of ionizing radiation.The",1
"doses at the hypocenters of the Hiroshima and Nagasaki atomic bombings were 240 and 290 Gy, respectively.",1
"Cutaneous radiation syndrome (CRS) refers to the skin symptoms of radiation exposure. Within a few hours after irradiation, a transient and inconsistent redness (associated with itching) can occur. Then, a latent phase may occur and last from a few days up to several weeks, when intense reddening, blistering, and ulceration of the irradiated site is visible. In most cases, healing occurs by regenerative means; however, very large skin doses can cause permanent hair loss, damaged sebaceous and sweat glands, atrophy, fibrosis (mostly keloids), decreased or increased skin pigmentation, and ulceration or necrosis of the exposed tissue.",1
"As seen at Chernobyl, when skin is irradiated with high energy beta particles, moist desquamation (peeling of skin) and similar early effects can heal, only to be followed by the collapse of the dermal vascular system after two months, resulting in the loss of the full thickness of the exposed skin. Another example of skin loss caused by high-level exposure of radiation is during the 1999 Tokaimura nuclear accident, where technician Hisashi Ouchi had lost a majority of his skin due to the high amounts of radiation he absorbed during the irradiation.",1
"This effect had been demonstrated previously with pig skin using high energy beta sources at the Churchill Hospital Research Institute, in Oxford. ARS is caused by exposure to a large dose of ionizing radiation (> ~0.1 Gy) over a short period of time (> ~0.1 Gy/h). Alpha and beta radiation have low penetrating power and are unlikely to affect vital internal organs from outside the body. Any type of ionizing radiation can cause burns, but alpha and beta radiation can only do so if radioactive contamination or nuclear fallout is deposited on the individual's skin or clothing.",1
"Gamma and neutron radiation can travel much greater distances and penetrate the body easily, so whole-body irradiation generally causes ARS before skin effects are evident. Local gamma irradiation can cause skin effects without any sickness. In the early twentieth century, radiographers would commonly calibrate their machines by irradiating their own hands and measuring the time to onset of erythema.",1
"Other events have to do with orphan sources, in which radioactive material is unknowingly kept, sold, or stolen. The Goiânia accident is an example, where a forgotten radioactive source was taken from a hospital, resulting in the deaths of 4 people from ARS. Theft and attempted theft of radioactive material by clueless thieves has also led to lethal exposure in at least one incident.Exposure may also come from routine spaceflight and solar flares that result in radiation effects on earth in the form of solar storms.",1
"During spaceflight, astronauts are exposed to both galactic cosmic radiation (GCR) and solar particle event (SPE) radiation. The exposure particularly occurs during flights beyond low Earth orbit (LEO). Evidence indicates past SPE radiation levels that would have been lethal for unprotected astronauts. GCR levels that might lead to acute radiation poisoning are less well understood. The latter cause is rarer, with an event possibly occurring during the solar storm of 1859.",1
"Death is highly likely, and radiation poisoning is almost certain if one is caught in the open with no terrain or building masking-effects within a radius of 0–3 km from a 1 megaton airburst. The 50% chance of death from the blast extends out to ~8 km from a 1 megaton atmospheric explosion.Scientific testing on humans within the United States occurred extensively throughout the atomic age. Experiments took place on a range of subjects including, but not limited to; the disabled, children, soldiers, and incarcerated persons, with the level of understanding and consent given by subjects varying from complete to none.",1
"most of the acute exposure scenarios that lead to radiation sickness, the bulk of the radiation is external whole-body gamma, in which case the absorbed, equivalent, and effective doses are all equal. There are exceptions, such as the Therac-25 accidents and the 1958 Cecil Kelley criticality accident, where the absorbed doses in Gy or rad are the only useful quantities, because of the targeted nature of the exposure to the body. Radiotherapy treatments are typically prescribed in terms of the local absorbed dose, which might be 60 Gy or higher.",1
"The dose is fractionated to about 2 Gy per day for ""curative"" treatment, which allows normal tissues to undergo repair, allowing them to tolerate a higher dose than would otherwise be expected. The dose to the targeted tissue mass must be averaged over the entire body mass, most of which receives negligible radiation, to arrive at a whole-body absorbed dose that can be compared to the table above.",1
"Exposure to high doses of radiation causes DNA damage, later creating serious and even lethal chromosomal aberrations if left unrepaired. Ionizing radiation can produce reactive oxygen species, and does directly damage cells by causing localized ionization events. The former is very damaging to DNA, while the latter events create clusters of DNA damage. This damage includes loss of nucleobases and breakage of the sugar-phosphate backbone that binds to the nucleobases. The DNA organization at the level of histones, nucleosomes, and chromatin also affects its susceptibility to radiation damage.",1
"Clustered damage, defined as at least two lesions within a helical turn, is especially harmful. While DNA damage happens frequently and naturally in the cell from endogenous sources, clustered damage is a unique effect of radiation exposure. Clustered damage takes longer to repair than isolated breakages, and is less likely to be repaired at all. Larger radiation doses are more prone to cause tighter clustering of damage, and closely localized damage is increasingly less likely to be repaired.Somatic mutations cannot be passed down from parent to offspring, but these mutations can propagate in cell lines within an organism.",1
"Radiation damage can also cause chromosome and chromatid aberrations, and their effects depend on in which stage of the mitotic cycle the cell is when the irradiation occurs. If the cell is in interphase, while it is still a single strand of chromatin, the damage will be replicated during the S1 phase of cell cycle, and there will be a break on both chromosome arms; the damage then will be apparent in both daughter cells. If the irradiation occurs after replication, only one arm will bear the damage; this damage will be apparent in only one daughter cell.",1
"A damaged chromosome may cyclize, binding to another chromosome, or to itself. Diagnosis is typically made based on a history of significant radiation exposure and suitable clinical findings. An absolute lymphocyte count can give a rough estimate of radiation exposure. Time from exposure to vomiting can also give estimates of exposure levels if they are less than 10 Gray (1000 rad). A guiding principle of radiation safety is as low as reasonably achievable (ALARA). This means try to avoid exposure as much as possible and includes the three components of time, distance, and shielding.",1
"The longer that humans are subjected to radiation the larger the dose will be. The advice in the nuclear war manual entitled Nuclear War Survival Skills published by Cresson Kearny in the U.S. was that if one needed to leave the shelter then this should be done as rapidly as possible to minimize exposure.In chapter 12, he states that ""[q]uickly putting or dumping wastes outside is not hazardous once fallout is no longer being deposited.",1
"For example, assume the shelter is in an area of heavy fallout and the dose rate outside is 400 roentgen (R) per hour, enough to give a potentially fatal dose in about an hour to a person exposed in the open. If a person needs to be exposed for only 10 seconds to dump a bucket, in this 1/360 of an hour he will receive a dose of only about 1 R. Under war conditions, an additional 1-R dose is of little concern.""",1
"In peacetime, radiation workers are taught to work as quickly as possible when performing a task that exposes them to radiation. For instance, the recovery of a radioactive source should be done as quickly as possible.",1
"While these protective measures do provide a barrier from radioactive material deposition, they do not shield from externally penetrating gamma radiation. This leaves anyone exposed to penetrating gamma rays at high risk of ARS. Naturally, shielding the entire body from high energy gamma radiation is optimal, but the required mass to provide adequate attenuation makes functional movement nearly impossible. In the event of a radiation catastrophe, medical and security personnel need mobile protection equipment in order to safely assist in containment, evacuation, and many other necessary public safety objectives.",1
"Research has been done exploring the feasibility of partial body shielding, a radiation protection strategy that provides adequate attenuation to only the most radio-sensitive organs and tissues inside the body. Irreversible stem cell damage in the bone marrow is the first life-threatening effect of intense radiation exposure and therefore one of the most important bodily elements to protect. Due to the regenerative property of hematopoietic stem cells, it is only necessary to protect enough bone marrow to repopulate the exposed areas of the body with the shielded supply.",1
"This concept allows for the development of lightweight mobile radiation protection equipment, which provides adequate protection, deferring the onset of ARS to much higher exposure doses. One example of such equipment is the 360 gamma, a radiation protection belt that applies selective shielding to protect the bone marrow stored in the pelvic area as well as other radio sensitive organs in the abdominal region without hindering functional mobility. More information on bone marrow shielding can be found in the ""Health Physics Radiation Safety Journal"". article Waterman, Gideon; Kase, Kenneth; Orion, Itzhak; Broisman, Andrey; Milstein, Oren (September 2017).",1
"""Selective Shielding of Bone Marrow: An Approach to Protecting Humans from External Gamma Radiation"". Health Physics. 113 (3): 195–208. doi:10.1097/HP.0000000000000688. PMID 28749810. S2CID 3300412., or in the Organisation for Economic Co-operation and Development (OECD) and the Nuclear Energy Agency (NEA)'s 2015 report: ""Occupational Radiation Protection in Severe Accident Management"" (PDF).",1
"Individuals that develop neutropenia after exposure to radiation are also susceptible to irradiation damage in other tissues, such as the gastrointestinal tract, lungs and central nervous system. These patients may require therapeutic interventions not needed in other types of neutropenic patients. The response of irradiated animals to antimicrobial therapy can be unpredictable, as was evident in experimental studies where metronidazole and pefloxacin therapies were detrimental. Antimicrobials that reduce the number of the strict anaerobic component of the gut flora (i.e.,",1
"metronidazole) generally should not be given because they may enhance systemic infection by aerobic or facultative bacteria, thus facilitating mortality after irradiation.An empirical regimen of antimicrobials should be chosen based on the pattern of bacterial susceptibility and nosocomial infections in the affected area and medical center and the degree of neutropenia. Broad-spectrum empirical therapy (see below for choices) with high doses of one or more antibiotics should be initiated at the onset of fever. These antimicrobials should be directed at the eradication of Gram-negative aerobic bacilli (i.e., Enterobacteriace, Pseudomonas) that account for more than three quarters of the isolates causing sepsis.",1
"Because aerobic and facultative Gram-positive bacteria (mostly alpha-hemolytic streptococci) cause sepsis in about a quarter of the victims, coverage for these organisms may also be needed.A standardized management plan for people with neutropenia and fever should be devised. Empirical regimens contain antibiotics broadly active against Gram-negative aerobic bacteria (quinolones: i.e., ciprofloxacin, levofloxacin, a third- or fourth-generation cephalosporin with pseudomonal coverage: e.g., cefepime, ceftazidime, or an aminoglycoside: i.e. gentamicin, amikacin). The prognosis for ARS is dependent on the exposure dose, with anything above 8 Gy being almost always lethal, even with medical care.",1
"Radiation burns from lower-level exposures usually manifest after 2 months, while reactions from the burns occur months to years after radiation treatment. Complications from ARS include an increased risk of developing radiation-induced cancer later in life. According to the controversial but commonly applied linear no-threshold model, any exposure to ionizing radiation, even at doses too low to produce any symptoms of radiation sickness, can induce cancer due to cellular and genetic damage. The probability of developing cancer is a linear function with respect to the effective radiation dose.",1
"of radioactive materials caused many radiation-induced cancers in the 1930s, but no one was exposed to high enough doses at high enough rates to bring on ARS. The atomic bombings of Hiroshima and Nagasaki resulted in high acute doses of radiation to a large number of Japanese people, allowing for greater insight into its symptoms and dangers. Red Cross Hospital Surgeon Terufumi Sasaki led intensive research into the syndrome in the weeks and months following the Hiroshima and Nagasaki bombings.",1
"Sasaki and his team were able to monitor the effects of radiation in patients of varying proximities to the blast itself, leading to the establishment of three recorded stages of the syndrome. Within 25–30 days of the explosion, Sasaki noticed a sharp drop in white blood cell count and established this drop, along with symptoms of fever, as prognostic standards for ARS. Actress Midori Naka, who was present during the atomic bombing of Hiroshima, was the first incident of radiation poisoning to be extensively studied.",1
"Her death on 24 August 1945 was the first death ever to be officially certified as a result of ARS (or ""Atomic bomb disease""). There are two major databases that track radiation accidents: The American ORISE REAC/TS and the European IRSN ACCIRAD. REAC/TS shows 417 accidents occurring between 1944 and 2000, causing about 3000 cases of ARS, of which 127 were fatal. ACCIRAD lists 580 accidents with 180 ARS fatalities for an almost identical period. The two deliberate bombings are not included in either database, nor are any possible radiation-induced cancers from low doses.",1
"The detailed accounting is difficult because of confounding factors. ARS may be accompanied by conventional injuries such as steam burns, or may occur in someone with a pre-existing condition undergoing radiotherapy. There may be multiple causes for death, and the contribution from radiation may be unclear. Some documents may incorrectly refer to radiation-induced cancers as radiation poisoning, or may count all overexposed individuals as survivors without mentioning if they had any symptoms of ARS.",1
"The following table includes only those known for their attempted survival with ARS. These cases exclude chronic radiation syndrome such as Albert Stevens, in which radiation is exposed to a given subject over a long duration. The ""result"" column represents the time of exposure to the time of death attributed to the short and long term effects attributed to initial exposure. As ARS is measured by a whole-body absorbed dose, the ""exposure"" column only includes units of Gray (Gy). Thousands of scientific experiments have been performed to study ARS in animals.",1
"There is a simple guide for predicting survival and death in mammals, including humans, following the acute effects of inhaling radioactive particles. This article incorporates public domain material from websites or documents of the U.S. Armed Forces Radiobiology Research Institute and the U.S. Centers for Disease Control and Prevention ""Emergency preparedness and subject matter expertise on the medical management of radiation incidents"". U.S. Radiation Emergency Assistance Center Training Site REACts. Archived from the original on 2023-05-05. ""Fact sheet on Acute Radiation Syndrome"". U.S. Centers for Disease Control and Prevention. Archived from the original on 16 July 2006. Retrieved 22 July 2006.",1
"""The criticality accident in Sarov"" (PDF). International Atomic Energy Agency. 2001. – A well documented account of the biological effects of a criticality accident. ""Armed Forces Radiobiology Research Institute"". Archived from the original on 2015-03-03. Retrieved 2011-07-01.",1
"The world’s first large-scale thermal desorption for treatment of mercury containing wastes was erected in Wölsau, for the remediation of the Chemical Factory Marktredwitz (founded in 1788) was considered to be the oldest in Germany. Operation commenced in October 1993 including the first optimising phase. 50,000 tons of mercury-contaminated solid wastes were treated successfully between August 1993 and June 1996. 25 metric tons of mercury had been recovered from soil and rubble. Unfortunately the Marktredwitz plant is often misunderstood in the literature as a pilot-scale plant only. Numerous desorber types are available today.",1
"The cylinder for full-scale transportable systems is typically five to eight feet in diameter with heated lengths ranging from twenty to fifty feet. With a carbon steel shell, the maximum solids temperature is around 1,000 °F, while temperatures of 1,800 °F with special alloy cylinders are attainable. Total residence time in this type of desorber normally ranges from 30 to 120 minutes. Treatment capacities can range from 2 to 30 tons per hour for transportable units.",1
A few of these systems also have a quench and scrubber after the oxidizer which allows them to treat soils containing chlorinated organics such as solvents and pesticides. The desorbing cylinder for full-scale transportable systems is typically four to ten feet in diameter with heated lengths ranging from twenty to fifty feet. The maximum practical solids temperature for these systems is around 750 to 900 °F depending on the material of construction of the cylinder. Total residence time in this type of desorber normally ranges from 3 to 15 minutes.,1
"Pesticides and herbicides are applied to agricultural land to control pests that disrupt crop production. Soil contamination can occur when pesticides persist and accumulate in soils, which can alter microbial processes, increase plant uptake of the chemical, and are toxic to soil organisms. The extent to which the pesticides and herbicides persist depends on the compound's unique chemistry, which affects sorption dynamics and resulting fate and transport in the soil environment. Pesticides can also accumulate in animals that eat contaminated pests and soil organisms.",1
"In addition, pesticides can be more harmful to beneficial insects, such as pollinators, and to natural enemies of pests (i.e. insects that prey on or parasitize pests) than they are to the target pests themselves.",1
"Nitrogen fertilizers supply plants with forms of nitrogen that are biologically available for plant uptake; namely NO3− (nitrate) and NH4+ (ammonium). This increases crop yield and agricultural productivity, but it can also negatively affect groundwater and surface waters, pollute the atmosphere, and degrade soil health. Not all nutrient applied through fertilizer are taken up by the crops, and the remainder accumulates in the soil or is lost as runoff. Nitrate fertilizers are much more likely to be lost to the soil profile through runoff because of its high solubility and like charges between the molecule and negatively charged clay particles.",1
"Nitrogen fixation, which converts atmospheric nitrogen (N2) to more biologically available forms, and denitrification, which converts biologically available nitrogen compounds to N2 and N2O, are two of the most important metabolic processes involved in the nitrogen cycle because they are the largest inputs and outputs of nitrogen to ecosystems. They allow nitrogen to flow between the atmosphere, which is around 78% nitrogen) and the biosphere. Other significant processes in the nitrogen cycle are nitrification and ammonification which convert ammonium to nitrate or nitrite and organic matter to ammonia respectively.",1
"Because these processes keep nitrogen concentrations relatively stable in most ecosystems, a large influx of nitrogen from agricultural runoff can cause serious disruption. A common result of this in aquatic ecosystems is eutrophication which in turn creates hypoxic and anoxic conditions – both of which are deadly and/or damaging to many species. Nitrogen fertilization can also release NH3 gases into the atmosphere which can then be converted into NOx compounds. A greater amount of NOx compounds in the atmosphere can result in the acidification of aquatic ecosystems and cause various respiratory issues in humans.",1
"Fertilization can also release N2O which is a greenhouse gas and can facilitate the destruction of ozone (O3) in the stratosphere. Soils that receive nitrogen fertilizers can also be damaged. An increase in plant available nitrogen will increase a crop's net primary production, and eventually, soil microbial activity will increase as a result of the larger inputs of nitrogen from fertilizers and carbon compounds through decomposed biomass. Because of the increase in decomposition in the soil, its organic matter content will be depleted which results in lower overall soil health.",1
"Microbial populations in soils are able to convert organic forms of phosphorus to soluble plant available forms such as phosphate. This step is generally bypassed with inorganic fertilizers because it is applied as phosphate or other plant available forms. Any phosphorus that is not taken up by plants is adsorbed to soil particles which helps it remain in place. Because of this, it typically enters surface waters when the soil particles it is attached to are eroded as a result of precipitation or stormwater runoff.",1
"The amount that enters surface waters is relatively low in comparison to the amount that is applied as fertilizer, but because it acts as a limiting nutrient in most environments, even a small amount can disrupt an ecosystem's natural phosphorus biogeochemical cycles. Although nitrogen plays a role in harmful algae and cyanobacteria blooms that cause eutrophication, excess phosphorus is considered the largest contributing factor due to the fact that phosphorus is often the most limiting nutrient, especially in freshwaters.",1
"Manures and biosolids contain many nutrients consumed by animals and humans in the form of food. The practice of returning such waste products to agricultural land presents an opportunity to recycle soil nutrients. The challenge is that manures and biosolids contain not only nutrients such as carbon, nitrogen, and phosphorus, but they may also contain contaminants, including pharmaceuticals and personal care products (PPCPs). There is a wide variety and vast quantity of PPCPs consumed by both humans and animals, and each has unique chemistry in terrestrial and aquatic environments.",1
"This process is known as the ""Kesterson Effect"", eponymously named after the Kesterson Reservoir in the San Joaquin Valley (California, US), which was declared a toxic waste dump in 1987. Heavy metals present in the environment can be taken up by plants, which can pose health risks to humans in the event of consuming affected plants. Some metals are essential to plant growth, however an abundance can have adverse effects on plant health.",1
"Sedimentation also affects the transport and accumulation of pollutants, including phosphorus and various pesticides.",1
"Natural soil biogeochemical processes result in the emission of various greenhouse gases, including nitrous oxide. Agricultural management practices can affect emission levels. For example, tillage levels have also been shown to affect nitrous oxide emissions.",1
"Many biopesticides are permitted under the National Organic Program, United States Department of Agriculture, standards for organic crop production.",1
"Agriculturally introduced species can also hybridize with native species resulting in a decline in genetic biodiversity and threaten agricultural production.Habitat disturbance associated with farming practices themselves can also facilitate the establishment of these introduced organisms. Contaminated machinery, livestock and fodder, and contaminated crop or pasture seed can also lead to the spread of weeds.Quarantines (see biosecurity) are one way in which prevention of the spread of invasive species can be regulated at the policy level.",1
"A quarantine is a legal instrument that restricts the movement of infested material from areas where an invasive species is present to areas in which it is absent. The World Trade Organization has international regulations concerning the quarantine of pests and diseases under the Agreement on the Application of Sanitary and Phytosanitary Measures. Individual countries often have their own quarantine regulations. In the United States, for example, the United States Department of Agriculture/Animal and Plant Health Inspection Service (USDA/APHIS) administers domestic (within the United States) and foreign (importations from outside the United States) quarantines.",1
These quarantines are enforced by inspectors at state borders and ports of entry.,1
"One example of a biocontrol program that resulted in ecological damage occurred in North America, where a parasitoid of butterflies was introduced to control gypsy moth and browntail moth. This parasitoid is capable of utilizing many butterfly host species, and likely resulted in the decline and extirpation of several native silk moth species.International exploration for potential biocontrol agents is aided by agencies such as the European Biological Control Laboratory, the United States Department of Agriculture/Agricultural Research Service (USDA/ARS), the Commonwealth Institute of Biological Control, and the International Organization for Biological Control of Noxious Plants and Animals.",1
"GMO crops can, however, result in genetic contamination of native plant species through hybridization. This could lead to increased weediness of the plant or the extinction of the native species. In addition, the transgenic plant itself may become a weed if the modification improves its fitness in a given environment.There are also concerns that non-target organisms, such as pollinators and natural enemies, could be poisoned by accidental ingestion of Bt-producing plants.",1
"Grains, such as corn and wheat, have phosphorus that is bound in a naturally indigestible form known as phytic acid. Phosphorus, an essential nutrient for pigs, is then added to the diet, since it can not be broken down in the pigs digestive tract. As a result, nearly all of the phosphorus naturally found in the grain is wasted in the feces, and can contribute to elevated levels in the soil. Phytase is an enzyme that is able to break down the otherwise indigestible phytic acid, making it available to the pig.",1
"The ability of the Enviropig to digest the phosphorus from the grains eliminates the waste of that natural phosphorus (20-60% reduction), while also eliminating the need to supplement the nutrient in feed.",1
"The advantages of manure treatment are a reduction in the amount of manure that needs to be transported and applied to crops, as well as reduced soil compaction. Nutrients are reduced as well, meaning that less cropland is needed for manure to be spread upon. Manure treatment can also reduce the risk of human health and biosecurity risks by reducing the amount of pathogens present in manure. Undiluted animal manure or slurry is one hundred times more concentrated than domestic sewage, and can carry an intestinal parasite, Cryptosporidium, which is difficult to detect but can be passed to humans.",1
"Silage liquor (from fermented wet grass) is even stronger than slurry, with a low pH and very high biological oxygen demand. With a low pH, silage liquor can be highly corrosive; it can attack synthetic materials, causing damage to storage equipment, and leading to accidental spillage. All of these advantages can be optimized by using the right manure management system on the right farm based on the resources that are available.",1
"Composting is a solid manure management system that relies on solid manure from bedded pack pens, or the solids from a liquid manure separator. There are two methods of composting, active and passive. Manure is churned periodically during active composting, whereas in passive composting it is not. Passive composting has been found to have lower green house gas emissions due to incomplete decomposition and lower gas diffusion rates.",1
"Lagoons also offer the benefit of reduced odor and biogas is made available for heat and electric power.Studies have demonstrated that GHG emissions are reduced using aerobic digestion systems. GHG emission reductions and credits can help compensate for the higher installation cost of cleaner aerobic technologies and facilitate producer adoption of environmentally superior technologies to replace current anaerobic lagoons. This article incorporates public domain material from Jasper Womach. Report for Congress: Agriculture: A Glossary of Terms, Programs, and Laws, 2005 Edition (PDF). Congressional Research Service.",1
"The Tijuana River drains an area along the U.S.–Mexico border, flowing through Mexico for most its course then crossing the border into Southern California for its lower 5 mi (8 km) to empty into the ocean in an estuary on the southern edge of San Diego. The region straddles the Mediterranean climate and semi-arid climate zones, so the Tijuana River and its tributaries often go dry in times of drought. The Tijuana River has two main tributaries. One, the Arroyo de Alamar or Rio Alamar, runs in its upper reaches in the United States as Cottonwood Creek.",1
"The lower 2 mi (3 km) of the river form the broad mud flat estuary, and the Tijuana River Estuary is a rich habitat for wildlife, including over 370 species of birds; one of these species is the Ridgway's rail. It is Southern California's largest coastal wetland. It is naturally prone to flooding during heavy rains. The Tijuana River enters the Pacific 10 mi (15 km) south of downtown San Diego at the southern city limits of Imperial Beach. The river is an intermittent river, flowing naturally only during rains.",1
"majority of its watershed is within Mexico, between Mesa de Otay to the east, and hills to the west.",1
"The Tijuana River National Estuarine Research Reserve protects 2,293 acres (928 ha) and studies the Tijuana River Estuary. It was established as part of the National Estuarine Research Reserve system in the United States. The reserve is managed in part as a Biological Field Station by the San Diego State University (SDSU) College of Sciences, which also protects part of the estuary near the ocean within the United States.The Tijuana Slough National Wildlife Refuge is part of the San Diego National Wildlife Refuge Complex, and is also within the Estuarine Research Reserve.",1
"The Tijuana Slough Refuge protects one of southern California's largest remaining salt marshes without a road or railroad trestle running through it. Designated as a Globally Important Bird Area by the American Bird Conservancy, over 370 species of birds have been sighted on the refuge. Salmon have been recorded in the past in the river during runs.",1
"The first attempt to deal with sewage flowing into the Tijuana River was the creation of the International Outfall, a marine outfall, which was completed in 1939, but was proven to be inadequate as early as the late 1940s. By the 1950s, there were over 4 million gallons of sewage flowing into the river each day. Following a threat by the San Diego County's health officer, Mexico began to treat its sewage with chlorine.",1
"According to a 1993 report by the city of San Diego, the city had collected an average of 13 million gallons (50 million liters) per day of raw sewage, that then was treated by the Point Loma wastewater treatment plant; this is down from 20 million gallons per day in 1997 being treated by the city of San Diego, which it had received from Tijuana. Since 1998 the U.S. EPA has funded $42 million on sewage projects in Tijuana.",1
"While Tijuana's sewage capture rate of 90% exceeds the Mexican national average of 50%, Roberto Espinosa of CILA is quoted as saying ""Tijuana is a complex city, and it has a sanitary system that has never kept pace with the increase in population,"". Due to the sewage in the river, it has been called ""one of the most polluted waterways in the country"". This has led to a multitude of beach closures in Imperial Beach. Each year the beach at Border Field State Park is closed for 233 days.In",1
"The construction of the Mexico–United States barrier in the area around and crossing the Tijuana River, began with construction of a fence made of Marston Mat in 1989, followed by construction of a secondary fence beginning in 1996. Due to the fences, the amount of illegal entry into the United States along the border south of the Tijuana River has been significantly reduced.Areas of the Tijuana River canal are home to individuals described as ""ñongo"".",1
"In March 2015, a homeless encampment was removed from the Tijuana River canal, some of whom had previously been deported from the United States; a year later, some of those who had been removed from the Tijuana River canal had returned and began to live in tunnels which drain into the canal. Tijuana is a major resettling location for Mexicans deported from the United States, with some living on the Tijuana River canal. A 2016 study found that the Tijuana River Canal was a known site for where people inject drugs.",1
"In 2018, more than 20 bodies were found in or near the Tijuana River, on the Mexico side.The Tijuana River has not been off limits to the impact of the Mexican Drug War; in one instance in June 2006 the severed heads of three Rosarito Beach police officers were found in the Tijuana River. Over 30 federal, local, state, private and other interested groups want to develop binational long-term goals to address wastewater treatment and debris-related improvements.",1
"One major initiative introduced in the United States on March 16, 2015, was Resolution R902015-0035, a Five-Year Action Plan that aimed to implement restorative projects over the span of five-years. The resolution was initially introduced by the Tijuana River Valley Recovery Team (TRVRT) whose ultimate goal is to progress and implement strategies originally introduced in January 2012, under the Tijuana River Valley Recovery Strategy regulatory measures. Other restorative measures across the U.S. include grants like the Community-based Marine Debris Removal Grant that brings organizations together in conjunction with community-based cleanups to remove trash and debris from the Tijuana River Valley.",1
"The Tijuana River Valley Regional Park is located in the Tijuana River Valley district of San Diego. It protects over 1,800 acres (730 ha), including dense riparian forests along the Tijuana River. It has an extensive system of trails for walking and equestrian access. In early 2019, construction of a campground within the regional park, was approved, and is expected to be complete in Spring of 2020 at the cost of $8.3 million. As of April 2021, the campground is active and offers sites for tent campers, RVers, and yurts.",1
"The mouth of the Tijuana River is the location of the Tijuana Sloughs big-wave surfing break, which is a mile off shore. Winter waves can be as high as 12 feet or greater; 20 foot high waves are not unknown to occur. Surfing has been occurring at the slough since at least 1937, when Allen Holder began to surf there. It has been described as the ""gold standard"" in Southern California; with surfers using it as a training ground for surf found in Hawaii.Surfing at the sloughs has impacted the evolution of surfing culture, as well as regional culture.",1
"ISBN 0-925613-44-4. Muñoz Meléndez, Gabriela (22 March 2018). The case of the Tijuana River binational watershed (PDF). Sixth Annual Eccles Family Rural West Conference. Yakima, Washington: Stanford University. San Diego State University (SDSU) Tijuana River Watershed webpage SDSU Biological Field Station San Diego Earth Times: Tijuana River Controversy NOAA: Tijuana River Reserve San Diego National Wildlife Refuge Complex SCCOOS Tijuana River Stormwater Plume Tracking",1
Some animal slurries are treated by mixing with straws and composted at high temperature to produce a bacteriologically sterile and friable manure for soil improvement.,1
"Piggery waste is comparable to other animal wastes and is processed as for general animal waste, except that many piggery wastes contain elevated levels of copper that can be toxic in the natural environment. The liquid fraction of the waste is frequently separated off and re-used in the piggery to avoid the prohibitively expensive costs of disposing of copper-rich liquid. Ascarid worms and their eggs are also common in piggery waste and can infect humans if wastewater treatment is ineffective.",1
Land spreading is also a treatment option.,1
Wastewater from slaughtering activities is similar to milking parlour waste (see above) although considerably stronger in its organic composition and therefore potentially much more polluting. TreatmentAs for milking parlour waste (see above).,1
"Prior to the early 1970s, most trichloroethylene was produced in a two-step process from acetylene. First, acetylene was treated with chlorine using a ferric chloride catalyst at 90 °C to produce 1,1,2,2-tetrachloroethane according to the chemical equation HC≡CH + 2 Cl2 → Cl2CHCHCl2The 1,1,2,2-tetrachloroethane is then dehydrochlorinated to give trichloroethylene.",1
"This can be accomplished either with an aqueous solution of calcium hydroxide 2 Cl2CHCHCl2 + Ca(OH)2 → 2 ClCH=CCl2 + CaCl2 + 2 H2Oor in the vapor phase by heating it to 300–500 °C on a barium chloride or calcium chloride catalyst Cl2CHCHCl2 → ClCH=CCl2 + HClToday, however, most trichloroethylene is produced from ethylene. First, ethylene is chlorinated over a ferric chloride catalyst to produce 1,2-dichloroethane.",1
Other chemical stabilizers include ketones such as methyl ethyl ketone.,1
"When inhaled, trichloroethylene produces central nervous system depression resulting in general anesthesia. These effects may be mediated by trichloroethylene acting as a positive allosteric modulator of inhibitory GABAA and glycine receptors. Its high blood solubility results in a less desirable slower induction of anesthesia. At low concentrations it is relatively non-irritating to the respiratory tract. Higher concentrations result in tachypnea. Many types of cardiac arrhythmias can occur and are exacerbated by epinephrine (adrenaline). It was noted in the 1940s that TCE reacted with carbon dioxide (CO2) absorbing systems (soda lime) to produce dichloroacetylene and phosgene.",1
"Cranial nerve dysfunction (especially the fifth cranial nerve) was common when TCE anesthesia was given using CO2 absorbing systems. Muscle relaxation with TCE anesthesia sufficient for surgery was poor. For these reasons as well as problems with hepatotoxicity, TCE lost popularity in North America and Europe to more potent anesthetics such as halothane by the 1960s.The symptoms of acute non-medical exposure are similar to those of alcohol intoxication, beginning with headache, dizziness, and confusion and progressing with increasing exposure to unconsciousness.Much of what is known about the human health effects of trichloroethylene is based on occupational exposures.",1
"Beyond the effects to the central nervous system, workplace exposure to trichloroethylene has been associated with toxic effects in the liver and kidney.",1
"TCE levels in the low parts per billion range have been measured in food; however, levels as high as 140 ppb were measured in a few samples of food.",1
"Until recent years, the US Agency for Toxic Substances and Disease Registry (ATSDR) contended that trichloroethylene had little-to-no carcinogenic potential, and was probably a co-carcinogen—that is, it acted in concert with other substances to promote the formation of tumors.State, federal, and international agencies classify trichloroethylene as a known or probable carcinogen. In 2014, the International Agency for Research on Cancer updated its classification of trichloroethylene to Group 1, indicating that sufficient evidence exists that it causes cancer of the kidney in humans as well as some evidence of cancer of the liver and non-Hodgkin's lymphoma.In",1
"The Trump White House rewrote their assessment."" by Elizabeth Shogren, Reveal, February 28, 2020",1
"The International Dark-Sky Association certifies fixtures as dark sky friendly, and these will have the IDA Fixture Seal of Approval. Opinions vary on what color the light should be, but most agree on the description of ""warm"", which is considered more yellow or orange/amber than white. Skyglow is the illumination of the night sky or parts of it, resembling an orange ""smog"". It occurs from both natural and human-made sources. Artificial skyglow is caused by the over-illumination of the sky from large city centres, shopping centres, or stadiums.",1
"It consists of light that is either emitted directly upward or reflected from the ground that is then scattered by dust and gas molecules in the atmosphere, producing a luminous background or light dome. These artificial skyglows cause the sky to be 5–10 times brighter in urban areas than a naturally dark sky that is unaffected by artificial light. Natural skyglow can come from natural light sources, such as the Sun, the Moon, the stars, or auroras. Some communities are becoming aware of this problem and are putting forth efforts to minimize the hazy, orange skyglow.",1
"A current list of designated parks is maintained by the Dark Skies Advisory Group of the International Union for Conservation of Nature (IUCN). The parks are put in place by the Dark Sky Places program with the intention to remind us that the night sky serves just as much importance to our culture and history as our day-time sky. The International Dark-Sky Association (IDA) began in 1988. A non-profit, it manages the Fixture Seal of Approval program, which offers a third-party rating system judging the ""sky-friendliness"" of lighting fixtures.",1
"The maximum wattage for most commercial applications should be 250 watts of high intensity discharge lighting, but less is usually sufficient. Incorporate curfews (i.e., turn lights off automatically after a certain hour when businesses close or traffic is minimal). International Dark-Sky Association MyDarkSky – dark sky survey maps Outdoor Lighting Regulations and Ordinances on Google Earth Archived 2007-09-30 at the Wayback Machine Interactive map comparing U.S.",1
dark sky laws The dark sky movement – yahoo Jasper National Park Archived 2012-05-12 at the Wayback Machine Dark-sky parks of the world Flagstaff Dark Skies Coalition Globe at Night Cities at Night Dark Skies Awareness Archived 2011-04-10 at the Wayback Machine The Consortium for Dark Sky Studies,1
"WT1190F was first discovered by the Mount Lemmon Survey, a participant in the Catalina Sky Survey Near-Earth Object surveying program. The object was identified with an apparent magnitude 19.5 on 18 February 2013, and given the temporary designation UDA34A3, but was lost soon after, with an observation arc of only 5 hours. However, it was again seen by the same survey on 29 November 2013 and given the designation UW8551D and lost again, only being observed for 1 hour 35 minutes.Most recently, it was recovered on 3 October 2015 and given the designation WT1190F.",1
"Its orbit was soon calculated and found to be orbiting Earth, but not with the orbit of any known artificial satellite. The object's orbit was soon connected, allowing more observations to be made, and several precovery observations have been found of the object, dating back to June 2009.The type of orbit that WT1190F had was not stable long-term. An object in this type of orbit was likely to impact into Earth or the Moon, or acquire enough orbital speed to be ejected into orbit around the Sun. It was not likely that it had been orbiting Earth for decades.",1
"In 2011 the orbit had an eccentricity of 0.33 and perigee (closest approach to Earth) of 248,000 km (154,000 mi). It passed about 22,000 km (14,000 mi) from the Moon on 24 May 2012. By 2013 the eccentricity had increased to 0.70 and the perigee decreased to 105,000 km (65,000 mi). During WT1190F's orbit, it changed significantly in brightness, from an apparent magnitude 16 at perigee, to magnitude 23 at apogee. It spent most of its time dimmer than magnitude 20.",1
"This, combined with solar pressure acceleration, the Yarkovsky effect, and frequent orbital perturbations by the Moon, made it difficult to precisely predict its orbit and location. About one hour before atmospheric entry, the object had a R magnitude of 13.6, roughly the brightness of Pluto.",1
"WT1190F made atmospheric entry at 11 kilometers per second (25,000 miles per hour). Whatever was left from the re-entry was calculated to have fallen into the ocean about 100 kilometres (62 mi) from Galle, Sri Lanka. The closest approach to Galle occurred during atmospheric flight when the object had an altitude of 45 km and a distance of 51 km. For observers in Colombo, Sri Lanka, the object started out 30 degrees above the horizon coming in from slightly south of due west.",1
"Its mass was not sufficient to cause any risk to the area, but the event still produced a bright fireball. Scientists wanted to study WT1190F to better understand the trajectory and atmospheric entry of satellites, debris, and small asteroids from translunar orbit. The International Astronomical Center (IAC) and the United Arab Emirates Space Agency utilized a Gulfstream 450 jet to study the re-entry from above the clouds and haze. The airborne observation team successfully captured the re-entry on video.",1
"The International Astronomical Center (IAC) and the United Arab Emirates Space Agency observed WT1190F as it fell towards the Earth. The IAC chartered a Gulfstream 450 jet to bring researchers such as Peter Jenniskens to the area of WT1190F's impact, at a high altitude, to view the event over clouds or haze. The Next TC3 Consortium Asteroid Detection and Early Warning team narrowed the atmospheric entry time to ± 1.3 seconds.Observers on the ground could not see the fireball because of rain, but the plane was able to find an opening in the clouds.",1
"The fireball was a bright naked eye object. Spectroscopic data was acquired to determine what the object was made of, and the results published.: 9 List of reentering space debris",1
2008 TC3 2014 AA 2018 LA 2019 MO,1
2006 RH120 6Q0B44E J002E3 A Piece of Cosmic Debris Will Hit Earth on Nov. 13 – Phil Plait Ephemeris – JPL Horizons On-Line Ephemeris System WT1190F FAQs – Bill Gray MP4 video of approximately how the fireball would have looked to the naked eye – Peter Jenniskens WT1190F – Collection of articles from docslib.org,1
"According to the Basel Convention on the Control of Transboundary Movements of Hazardous Wastes and Their Disposal of 1989, Art. 2(1), ""'Wastes' are substance or objects, which are disposed of or are intended to be disposed of or are required to be disposed of by the provisions of national law"".",1
"Under the Waste Framework Directive 2008/98/EC, Art. 3(1), the European Union defines waste as ""an object the holder discards, intends to discard or is required to discard."" For a more structural description of the Waste Directive, see the European Commission's summary.",1
"Household waste more commonly known as trash or garbage are items that are typically thrown away daily from ordinary households. Items often included in this category include product packaging, yard waste, clothing, food scraps, appliance, paints, and batteries. Most of the items that are collected by municipalities end up in landfills across the world. In the United States, it is estimated that 11.3 million tons of textile waste is generated. On an individual level, it is estimated that the average American throws away 81.5 pounds of clothes each year.",1
"As online shopping becomes more prevalent, items such as cardboard, bubble wrap, shipping envelopes are ending up in landfills across the United States. The EPA has estimated that approximately 10.1 million tons of plastic containers and packaging ended up landfills in 2018. The EPA noted that only 30.5% of plastic containers and packaging was recycled or combusted as an energy source. Additionally, approximately 940,000 pounds of cardboard ends up in the landfill each year.Commercial waste is very similar to household waste. To be considered as commercial waste, it must come from a business or commercial occupancy.",1
"This can be restaurants, retail occupants, manufacturing occupants or similar businesses. Typically, commercial waste contains similar items such as food scraps, cardboard, paper, and shipping materials. Generally speaking, commercial waste creates more waste than household waste on a per location basis.",1
"The EPA defines this type of waste as ""Construction and Demolition (C&D) debris is a type of waste that is not included in municipal solid waste (MSW)."" Items typically found in C&D include but are not limited to steel, wood products, drywall and plaster, brick and clay tile, asphalt shingles, concrete, and asphalt. Generally speaking, construction and demolition waste can be categorized as any components needed to build infrastructures. In 2018, the EPA estimated that the US generated approximately 600 million tons of C&D waste.",1
"The EPA defines hazardous waste as ""a waste with properties that make it dangerous or capable of having a harmful effect on human health or the environment."" Hazardous Waste falls under the Resource Conservation and Recovery Act (RCRA). Under the RCRA, the EPA has the authority to control hazardous waste during its entire lifecycle. This means from the point of creation to the point where it has been properly disposed of. The life cycle of hazardous waste includes generation, transportation, treatment, and storage and disposal. All of which are included in the RCRA.",1
"Some forms of hazardous waste include radioactive waste, explosive waste, and electronic waste.",1
"US currently defines five types of radioactive waste, as shown below. High-level Waste: This type of radioactive waste is generated from nuclear reactors or reprocessing spent nuclear fuel.Transuranic Waste: This type of radioactive waste is man-made and has an atomic number of 92 or higher.Uranium or thorium mill tailings: This type of radioactive waste is a result after the mining or milling or uranium or thorium ore.Low-level waste: This type of radioactive waste is radioactively contaminated waste. It is typically generated from industrial processes or research. Examples of these items include paper, protective clothing, bags, and cardboard.Technologically",1
"The EPA defines energetic hazardous waste as ""wastes that have the potential to detonate and bulk military propellants which cannot safely be disposed of through other modes of treatments."" The items which typically fall under this category include munitions, fireworks, flares, hobby rockets, and automobile propellants.",1
"Munitions were added to hazardous waste in 1997 when the EPA finalized RCRA. A special rule was added to address munitions in waste. This new rule is commonly referred to as the Military Munitions Rule. The EPA defines military munitions as ""all types of both conventional and chemical ammunition products and their components, produced by or for the military for national defense and security (including munitions produced by other parties under contract to or acting as an agent for DOD—in the case of Government Owned/Contractor Operated [GOCO] operations)."" The entire rule can be found here.",1
"While a large percentage of munitions waste is generated by the government or governmental contractors, residents also throw away expired or faulty ammunition inside their household waste.",1
"Every year, the US generates this type of waste from both the commercial and consumer aspects. This waste is often generated from fireworks, signal flares and hobby rockets which have been damaged, failed to operate or for other reasons. Due to their chemical properties, these types of devices are extremely dangerous.",1
"While automobile airbag propellants are not as common as munitions and fireworks, they share similar properties which makes them extremely hazardous. Airbag propellants characteristics of reactivity and ignitability are the characteristics which qualify for hazardous waste. When disposed undeployed, leaves these two hazardous characteristics intact. To properly dispose of these items, they must be safely deployed which removes these hazardous characteristics.The EPA includes the waste of automobile airbag propellants under the RCRA. In 2018, the EPA issued a final rule on handling of automobile airbag propellants. The ""interim final rule""provides an exemption of entities which install and remove airbags.",1
"This includes automobile dealerships, salvage yards, automobile repair facilities and collision centers. The handler and transporter are exempt from RCRA, but the airbag waste collection facility is not exempt. Once the airbags have met the collection center, it will then be classified as RCRA hazardous waste and must be disposed or recycled at a RCRA disposal facility.",1
"Electronic waste, often referred to as ""E-Waste"" or ""E-Scrap,"" are often thrown away or sent to a recycler. E-Waste continues to end up in landfills across the world. The EPA estimates that in 2009, 2.37 million tons of televisions, computers, cell phones, printers, scanners, and fax machines were discarded by US consumers. Only 25% of these devices were recycled; the remainder ended up in landfills across the US. E-Waste contains many elements that can be recycled or re-used. Typically speaking, electronics are encased in a plastic or light metal enclosure.",1
"Mixed waste is a term that has different definitions based its context. Most commonly, Mixed Waste refers to hazardous waste which contains radioactive material. In this context, the management of mixed waste is regulated by the EPA and RCRA and Atomic Energy Act. The Hazardous materials content is regulated by RCRA while the radiological component is regulated by the Department of Energy (DOE) and Nuclear Regulatory Commission (NRC). Mixed waste can also be defined as a type of waste which includes recyclable materials and organic materials.",1
"Some examples of mixed waste in this context include a combination of broken glassware, floor sweepings, non-repairable household goods, non-recyclable plastic and metal, and clothing and furnishings. Additionally, ashes and soot, residential renovation waste materials are also included under this definition.",1
"This type of waste is typically generated from hospitals, physicians' offices, dental practices, blood banks, veterinary offices, and research facilities. This waste has often been contaminated with bodily fluids from humans or animals. Examples of this type of contamination can include blood, vomit, urine, and other bodily fluids. Concerns started to generate when medical waste was appearing on east coast beaches in the 1980's. This forced congress to pass the Medical Waste Tracking Act.",1
"It is most commonly measured by size or weight, and there is a stark difference between the two. For example, organic waste is much heavier when it is wet, and plastic or glass bottles can have different weights but be the same size. On a global scale it is difficult to report waste because countries have different definitions of waste and what falls into waste categories, as well as different ways of reporting. Based on incomplete reports from its parties, the Basel Convention estimated 338 million tonnes of waste was generated in 2001.",1
"For the same year, OECD estimated 4 billion tonnes from its member countries. Despite these inconsistencies, waste reporting is still useful on a small and large scale to determine key causes and locations, and to find ways of preventing, minimizing, recovering, treating, and disposing of waste.",1
"As global warming and CO2 emissions increase, soil begins to become a larger carbon sink and will become increasingly valuable for plant life.",1
"There is now a growing market in the transboundary movement of waste, and although most waste that flows between countries goes between developed nations, a significant amount of waste is moved from developed to developing nations.",1
"Energy recovery from waste is using non-recyclable waste materials and extracting from it heat, electricity, or energy through a variety of processes, including combustion, gasification, pyrolyzation, and anaerobic digestion. This process is referred to as waste-to-energy. There are several ways to recover energy from waste. Anaerobic digestion is a naturally occurring process of decomposition where organic matter is reduced to a simpler chemical component in the absence of oxygen. Incineration or direct controlled burning of municipal solid waste reduces waste and makes energy.",1
"Secondary recovered fuel is the energy recovery from waste that cannot be reused or recycled from mechanical and biological treatment activities. Pyrolysis involves heating of waste, with the absence of oxygen, to high temperatures to break down any carbon content into a mixture of gaseous and liquid fuels and solid residue. Gasification is the conversion of carbon rich material through high temperature with partial oxidation into a gas stream. Plasma arc heating is the very high heating of municipal solid waste to temperatures ranging from 3,000 to 10,000°C, where energy is released by an electrical discharge in an inert atmosphere.Using",1
"Waste House has its origins in an earlier project by Duncan Baker-Brown, a senior lecturer at the university and a director of architecture firm BBM Sustainable Design based at Cooksbridge railway station in East Sussex. On Channel 4 television programme Grand Designs, he and designer and television presenter Kevin McCloud assembled a ""low-energy ... ecologically friendly"" prefabricated house made of organic materials. It was the first such building to be constructed in the United Kingdom. Baker-Brown was responsible for the design of this building, which was in turn referred to as ""The House that Kevin Built"".",1
"Work was planned to begin in 2012 in time for an end-of-year completion date and a public opening in February 2013. These dates were not achieved, but preparation started on 26 November 2012 and by May 2013 construction was underway. Work finished in April 2014, the building was featured as part of the Brighton Festival the following month, the public were able to view the interior during June 2014, and by August 2014 Waste House was complete. Construction cost £140,000 and the total value of the contract was £200,000.",1
"Waste House is the first permanent public building in Europe made from waste material.Over 300 students from the University of Brighton, City College Brighton & Hove (CCB) and apprentices from housing provider Mears Group were involved in the project. The construction work was mainly undertaken by CCB students, the Mears apprentices and some volunteers, led by a project manager from Mears Group. Students learning carpentry at CCB designed the timber-framed structure and the ""fine timber staircase, finished with a decorative flourish of offcuts"". Many of the structural elements were created in the college's own workshops.",1
"University of Brighton Faculty of Arts students worked with Baker-Brown on the design, the selection of materials and on interior features such as furniture. Overall, 97.5% of the time taken to build Waste House—2,507 person-days—was provided by students and volunteers, and about 700 people worked on the project. A major aim of the project was to introduce students and apprentices to sustainable building techniques and to allow them to continue testing their ideas by retrofitting new fixtures.",1
"Structurally, the building is timber-framed and uses a mixture of reclaimed wood and plywood from various sources around Brighton. It has been constructed on foundations of ground granulated blast-furnace slag. The ""rather unusual"" walls consist of a mixture of waste chalk and clay left over or reclaimed from building sites. These are compressed into rammed earth-style walls using pneumatic equipment—a technique which improves the building's energy conservation, because such walls store solar energy for a long time. On the outside the walls are covered with ""a scaly surface of rubbery black shingles""—2,000 carpet tiles from an old office building in Brighton.",1
"Throughout the building, the space between the boarding and the exterior clay and chalk blocks has been filled with household rubbish which will act as insulation. Sensors have been installed to monitor how well heat is kept in, which will form part of a PhD project for a University of Brighton student.",1
"The insulation materials are revealed in various places by ""little peephole windows"" (transparent panels in the walls): as well as some secondhand conventional (polyurethane) insulation material, there are floppy disks, 4,000 VHS cassettes, 4,000 DVD and video cases, two tonnes of denim offcuts from pairs of jeans and denim jackets, cycle inner tubes to insulate windows, and 20,000 toothbrushes.",1
"This Royal Institute of British Architects (RIBA) award, named after the aspiring architect who was murdered in 1993, is for projects with a budget of up to £1 million. In its shortlisting for the award, which was judged in mid-October 2015, judges from the RIBA stated that the house ""has sufficient scientific integrity to be taken seriously by the construction industry"" and the potential to alter political attitudes to recycling. Waste House was one of seven buildings nominated for the prize, which was won by a fishing hut designed by Niall McLaughlin Architects.Waste",1
"House was one of several buildings in Sussex, along with the Chichester Festival Theatre and St Botolph's Church at Botolphs, to win an award at the RIBA South East Regional Awards in April 2015. It was described as ""a project with an interesting agenda"" and ""a collective of experiments in which students learn by application"". Duncan Baker-Brown also won an Argus Achievement Award from local newspaper The Argus.RIBA awarded Waste House a Sustainability Award in 2014.",1
"When work started, Baker-Brown stated the aim of making it one of the United Kingdom's first A*-rated buildings. Buildings and architecture of Brighton and Hove Sustainable architecture Media related to Waste House, Brighton at Wikimedia Commons",1
"EPA issued final regulations for new facilities in 2001 (amended 2003), and for existing facilities in 2014.",1
"The tube n acts as a mini-reservoir and allows air-bubbles to travel into it as they are caught into the ""tee"" connector, and ultimately travel out of the system (bleeding). The capped line may be capped with a fill-port fitting to allow release of trapped gas and addition of liquid.Water coolers for desktop computers were, until the end of the 1990s, homemade.",1
"The West Lake Landfill site originated in 1939 as a limestone quarry operated by the Westlake Quarry Company. Landfilling at the site began in the 1950s.In 1973, after having changed hands (and responsible oversight) several times, B&K Construction Co., a company contracted by Cotter Corporation, dumped a portion of the original stored radioactive material at a nearby storage facility. 8,700 short tons (7,900 tonnes) of leached barium sulfate, the material with the lowest relative radioactivity, was combined with 39,000 short tons (35,000 t) of topsoil to dilute the contaminated material at the landfill.",1
"The leached barium sulfate was a byproduct of Mallinckrodt Chemical Works’ uranium enrichment program as a part of the Manhattan Project and later nuclear weapons production, and dumping it there was illegal. Due to the discovery of the radioactive and other contaminants at the site, West Lake was proposed as a Superfund site in October 1989, and was officially listed as such a site in August 1990.The Nuclear Regulatory Commission discovered the disposal and investigated the site, publishing a report in 1977.West",1
"Lake was proposed to be a Superfund site on October 28, 1989, and the EPA placed the landfill on the National Priorities List, designating it as a Superfund site on August 30, 1990. The EPA has listed four potentially responsible parties: the US Department of Energy; the Cotter Corporation; and Republic Services subsidiaries Bridgeton Landfill and Rock Road Industries. EPA directed those parties to undertake investigations and evaluations consistent with CERCLA (Superfund) guidance.After decades of investigation, including multiple studies, public meetings, and public comment periods, the EPA selected a final site cleanup plan.",1
"After conducting an aerial survey of the site and surrounding areas in 2013, the EPA reported that the radioactive waste remained contained within OU-1 and posed no safety risk to outlying areas.The West Lake landfill has drawn further scrutiny because of a nearby subsurface smoldering fire (in OU-2), an event located only 1,000 feet (300 m) away from OU-1. If the fire were to reach the OU-1 area of radioactive waste, the radiation risks are low.In February 2018 EPA head Scott Pruitt announced a proposed plan to remediate the West Lake Landfill.",1
"Known as “Excavation Plus” or “Alternative 4,” the plan involved removing radioactively impacted material with a concentration greater than 52.9 picocuries per gram (pCi/g), to a maximum depth of 16 feet. The proposal would remove approximately 67 percent of the radioactivity from the landfill and take 5 years to implement at an estimated cost of $236 million. Potentially responsible parties, including Bridgeton Landfill LLC, Rock Road Industries Inc., Cotter Corporation, and the Department of Energy are liable for the costs of the clean-up.",1
"Included in the plan is a proposal to build a cover system which will protect the community of Bridgeton for the long term. The landfill is divided into multiple sectors, within which are two operable units (OU), OU-1 and OU-2. OU-1 contains radioactive material; OU-2 has been shown to as well. OU-1 covers 940 cubic yards (720 m3) on the surface (based on soil depth of 6 inches or 150 millimeters) and 24,000 cubic yards (18,000 m3) subsurface, while OU-2 covers 8,700 cubic yards (6,700 m3) on the surface and 109,000 cubic yards (83,000 m3) subsurface.The U.S.",1
"Late summer 2015, initiation of pyrolysis testing, to determine how radioactively impacted material is effected by elevated temperatures . 2016, suspense for site characterization and conceptual site model update completion, to inform the planned further Supplemental Feasibility Study (SFS), and suspense for SFS completion . 2017, public commenting period regarding the long term remedies proposed for West Lake, and EPA finalization of changes to the 2008 ROD.",1
"In December 2010, those overseeing the adjoining OU-2 landfill area, the Bridgeton Sanitary Landfill ""reported... experiencing elevated temperatures on some gas extraction wells"" and concluded that a subsurface smoldering event (SSE) had begun. SSEs are a form of chemical combustion that occur deep within a landfill and produces no visible flame or quantity of smoke, unless they reach the surface, where oxygen is abundant. They usually last for several years.In March 2013, high subsurface temperatures were measured at depths of over 150 feet covering an area of over 15 football fields.",1
"Trying to excavate such a large area to put out the reaction would be difficult, if not impossible, and would most likely increase toxic fumes and the risk of the reaction breaking through to the surface.",1
"Since the discovery of the smoldering fire, Republic Services ordered an isolation barrier be built (September 2013), which will prevent smoldering sanitary waste from reaching the radioactive waste stored in OU-1.The EPA, working in conjunction with the Missouri Department of Natural Resources, the US Army Corps of Engineers and others, announced a decision in December, 2015, to install a physical isolation barrier for the West Lake Landfill Superfund Site.",1
"FUSRAP was established in 1974 to clean up radioactive wastes resulting from early nuclear activity of the US Atomic Energy Commission. FUSRAP uses independent government scientists to conduct site studies and evaluations. After thorough evaluations are conducted, the US Army Corps of Engineers (USACE) determines how to manage the radioactive waste. Fiscally responsible parties are not able to legally challenge this decision. FUSRAP currently controls two on-going remediation projects within the greater St. Louis metropolitan area, the St.",1
"Louis Airport Site (SLAPS) and the Hazelwood Interim Storage Site (HISS), both of which contain the same composition of radioactive waste as the West Lake Landfill.According to Steven Stockton, the corps' director of civil works, adding West Lake to the FUSRAP would not speed up remediation. In addition, key US congressional energy committee members, along with the US Army Corps of Engineers oppose a proposal by Missouri's delegation to move the landfill's oversight from the EPA Superfund to FUSRAP. EPA Region 7 Midwest (2015). ""West Lake Update: The Path Ahead,"" June 15, 2015, see, accessed 27 October 2015.",1
"EPA Region 7 Midwest (2015). ""West Lake Update: EPA Oversight, A Vital Part of the Remedial Process at West Lake,"" July 6, 2015,"" see, accessed 27 October 2015. Hanford site Radioactive contamination Official Website EPA Region 7 Cleanup - West Lake Landfill",1
"In 2014, a 72-year-old man from Falmouth died at the site after what was initially thought to be a cycling accident. It was later found that the man had been murdered. A 34-year-old was found guilty and sentenced to life and to serve at least 28 years.",1
"In Idrija, Slovenia, where the world’s second largest mercury (Hg) mine operated has a significant amount of Hg emissions into the atmosphere by a surface process of adsorption of Hg from and to soil particles surfaces, which results in a diffusion of Hg through the pores of soil. To calculate the emission flux for Hg, a Hg emission model was developed: in which the FHg is the flux of Hg emission, Ea is the activation energy, R is the gas constant, Ts is the soil temperature, n and m are constants, [Hg]s is the Hg concentration, and 0.003*",1
"Using GIS, a map was developed for the seven counties (Hillsborough, Polk, Manatee, Hardee, Sarasota, DeSoto, and Charlotte) in Florida, which shows the DRASTIC summary index score for the Floridan Aquifer System, Surficial Aquifer System, and Other Rocks aquifer. The developed map is a combination of multiple layers that are stacked on top of each other as shown in Figure 1. http://www.usgs.gov/ http://www.fgdl.org/",1
"A company called Photo-Pac produced a cardboard camera beginning in 1949 which shot eight exposures and which was mailed-in for processing. Cameras were expensive, and would often have been left safely at home when photo opportunities presented themselves. Frustrated with missing photo opportunities, H. M. Stiles had invented a way to enclose 35mm film in an inexpensive enclosure without the expensive precision film transport mechanism. It cost US$1.29 (equivalent to $15.87 in 2022). Though incredibly similar to the familiar single-use cameras today, Photo-Pac failed to make a permanent impression on the market.In",1
"They often have cheap plastic lenses, questionable film quality, fixed focal lengths but quick and 'point and shoot' ease make the disposable camera popular with many photographers who enjoy the 'less than perfect' style these cameras provide, in a move away from digital imagery, which can also be seen in the rise in popularity of 'lomography'. This has also led to a number of 'lost art' type projects where disposable cameras are left in public spaces with a message for anyone finding the camera to take some images and then post the camera back, or pass it on to another person.",1
"In the 1880s, material to be disposed of was divided into four general categories: ashes (derived from the burning of coal or wood), garbage, rubbish, and street-sweepings. This scheme of categorization reduced some of these terms to more specific concepts: Garbage, the technical term for putrescent organic matter such as kitchen or food scraps, was fed to pigs and other livestock or boiled down in a process known as “rendering,” to extract fats, oils, and greases for manufacturing lubricants, or allowed to dry to become commercial fertilizer.",1
"In urban areas, garbage of all kinds is collected and treated as municipal solid waste; garbage that is discarded in ways that cause it to end up in the environment, rather than in containers or facilities designed to receive garbage, is considered litter. Litter is a form of garbage that has been improperly disposed of, and which therefore enters the environment. Notably, however, only a small fraction of garbage that is generated becomes litter, with the vast majority being disposed of in ways intended to secure it from entering the environment.",1
"Humans have been creating garbage throughout history, beginning with bone fragments left over from using animal parts and stone fragments discarded from toolmaking. The degree to which groups of early humans began engaging in agriculture can be estimated by examining the type and quality of animal bones in their garbage. Garbage from prehistoric or pre-civilization humans was often collected into mounds called middens, which might contain things such as ""a mix of discarded food, charcoal, shell tools, and broken pottery"". Garbology (study of modern refuse and trash) Landfill",1
"There are strong links between weed invasion of natural areas and the proximity and density of housing. The size and duration of the community have a direct relation to the density of weed infestation. Of the various means in which migration of exotic species from gardens take place, such as vegetative dispersal of runners, wind born and fallen seed, garden waste dumping can play a significant role. The results of one North German study found that of the problematic population of Fallopia, app. 29% originated from garden waste.",1
"People dump garden waste to avoid disposal fees at landfill sites or because they do not want to spend the time or effort disposing of or recycling their waste properly. This activity is carried out by people in all parts of the community, from householders to businesses, such as professional landscapers and gardeners. The spread of exotic vegetation can out-compete locally endemic vegetation, altering the composition and structure of an ecosystem.Dumping of garden waste in particular facilitates the spread of exotic vegetation into forest remnants via the introduction of seeds and propagules contained within the garden waste.",1
"dumping of garden waste in nature reserves surrounding and near urban areas increases the risk of fires. The dumped garden waste will eventually dry out creating fuel adding to already fallen debris fuel load on which a fire can thrive and spread on. Garden waste can spread weeds and these weeds build fuel for fires. Dumped garden waste can facilitate higher rates of erosion by smothering natural vegetation cover. With no root systems for stabilisation the top soil is vulnerable to erosion (Ritter, J. 2015), This can add higher levels of sediments, contributing to the siltation of creeks and waterways.If",1
Green and garden waste has a direct impact to the visual aesthetics of land and can often attract further illegal dumping.,1
"Dumping garden waste in nature reserves and parks surrounding and near urban areas can directly and indirectly affect the existing flora and fauna, as well as human life through the increased risk of fires. The dumped garden waste will eventually dry, creating additional fuel, adding to already fallen debris on which a fire can thrive and spread. Garden waste can spread weeds and these weeds also build fuel for fires.",1
"Fires may also spread to the suburban areas where humans can also be impacted by losing their homes from fire, incur injury or death from smoke or burns, and suffer economic loses such as income loss and clean-up costs. Fires can lead to an overall loss of habitat and biodiversity.",1
"The invasion of exotic plant species into remnant native forests is a threat to biodiversity. Some impacts of habitat degradation include; when native animals, insects and birds become vulnerable and put at risk; loss of food source for native wildlife; disruption of native plant-animal relationships ie pollination and seed dispersal and disconnection of plant-host relationships. Highly adaptive plants chosen for their ease of cultivation out compete more specialised species.",1
"Weed invasion of a forest system can change the processes of plant succession (the system of one species replacing another due to disturbance factors), the composition of the plant community and the composition and availability of nutrients. The change in forest composition can lead to loss of unique plant species. When a habitat is destroyed, the plants, animals, and other organisms that occupied the habitat have a reduced carrying capacity so that populations decline and extinction becomes a threat. Many endemic organisms have very specific requirements for their survival that can only be found within a certain ecosystem.",1
"Although increased bio diversity in subregions created by newly introduced species may occur, the displacement of the existing plant species may lead to reduced biodiversity on a global scale.When population-level properties that indicate superior competitive ability of the invading species are examined, 13–24 (42–77%) of the species are included, with the majority of species showing traits capable of modifying natural systems at both ecosystem and community/population scales.",1
"Addressing these motivations will enable strategies to be developed that deal with the root causes, rather than the results, of illegal dumping.Some of the main reasons for this careless disregard for waste can be put down to sheer convenience, lack of care for the environment and also a reluctance to pay for the correct collection or disposal of the waste. The monitoring of illegally dumped garden waste by the community and industries will drive effectual tactics to battle illegal depositing.",1
"People dump waste illegally to avoid disposal fees at landfill sites or because they do not want to spend the time or effort disposing of or recycling their waste properly. Alligator weed (Alternanthera philoxeroides (Mart.) Griseb.) is an introduced weed originating from Sri Lanka and is creating major issues throughout the Australia since its introduction into the country. Alligator weed has the potential to affect aquatic and terrestrial biodiversity severely and to cause considerable social and economic costs, particularly in aquatic situations.",1
"Education on the value of biodiversity and the negative effects of weed invasion have been identified as key items in changing current trends. Specific education campaigns on the risks of dumping garden waste could be targeted at high-risk societal groups such as residents of housing in close proximity to reserves as well as members of gardening communities and plant sellers. Restricting the selection of garden species in new housing developments adjacent to reserves may reduce the effects of illegal dumping, thereby reducing requirement and associated cost of weed management.",1
"The addition of facilities for waste disposal could also improve the issue (DECC. 2008). Mitigation may involve governments holding campaigns that show people disposing legally and reporting the consequences for disposing illegally. A way Australian governments are addressing the problem is through the increase of fines in conjunction with better law enforcement. In Australia, fines can be up to $1,000,000 and can also incur imprisonment. The Protection of the Environment Operations Act imposes penalties for offences including polluting waters with waste, polluting land, illegally dumping waste or using land as an illegal waste facility.",1
"The new section of the POEO Act (The Protection of the Environment Operations Act 1997) now imposes further penalties for offences including polluting waters with waste, polluting land, illegally dumping waste or using land as an illegal waste facility (Parrino, Maysaa, Kaoutarani & Salam, 2014). Communities are encouraged to report illegal dumping. In accordance with NSW Illegal Dumping Strategy 2014–16, hefty fines and a maximum jail sentence of 2 years can be handed down to repeat offenders.",1
"Local and national governments normally respond to droughts once they happen and are in crisis mode, whereas a robust policy would include early drought monitoring systems, preparedness plans, energy response programs, and impact assessment and management procedures to help mitigate the effects of drought on the economy and the environment. Different nations have different policies regarding national droughts.",1
"In 2013, the High-level Meeting on National Drought Policy (HMNDP) was organized by the World Meteorological Organization, the Secretariat of the United Nations Convention to Combat Desertification (UNCCD) and the Food and Agriculture Organization of the United Nations (FAO) to help nations develop drought preparedness policies and plans for international emergency relief efforts in the event of droughts. There were 414 participants from 87 countries that unanimously adopted the HMNDP declaration at the end of the meeting rallying national governments to implement drought management policies.",1
"Ecosystem-based fishery management (EBFM) is an attempt to correct some RFMO mismanagement by limiting biomass that is allowed to be removed by fisheries, and by making sure fishing is more targeted for the desired species. One problem EBFM tries to eliminate is bycatch, or unintentional catching of the wrong fish species. For example, white marlin, an endangered billfish, is mostly accidentally caught and killed by swordfish and tuna longline fisheries.Desalination",1
"Policies are implemented by organizational entities created by government exercise of state power. However, all such entities are subject to constraints upon their autonomy.",1
ISBN 978-1-84980-324-3.,1
"Whitechapel Mount was on the south side of the Whitechapel Road, on the ancient route from the City of London to Mile End, Stratford, Colchester and Harwich. In the 18th century and later the surroundings were mostly fields: grazing for cows or market gardens.Leaving London, a traveller would pass the church of St Mary Matfelon (origin of the name ""white chapel"") on the right, then a windmill, before arriving at the Mount. Across the Whitechapel Road was a burying ground and the Ducking Pond.",1
"Further east, at the turnpike, the name changed to Mile End Road, with Dog Row (today Cambridge Heath Road) branching off to Bethnal Green. According to John Strype (1720) the neighbourhood was a busy one, with good inns for travellers in Whitechapel and good houses for sea captains in Mile End. Even so, said Strype, the Whitechapel Road was ""pestered"" by illegally built, poor quality dwellings.Another source said it was infested by highwaymen, footpads and riff-raff of all kinds who preyed on travellers to and from London. News and court reports speak of murders and robberies.",1
"In two Old Bailey cases stolen property was buried in, and recovered from, Whitechapel Mount. It was a place of resort for pugilists and dog-fighters.From the summit of Whitechapel Mount an extensive view of the hamlets of Limehouse, Shadwell, and Ratcliff could be obtained.",1
"Whitechapel Mount's position is first depicted in a 1673 building plan by Sir Christopher Wren, where he refers to it as ""the mud wall called the Fort"". In Joel Gascoyne's survey of the parish of Stepney (1703) it is called The Dunghill: it is at least 400 yards long, and is crossed not only by a path, but a road. In John Rocque's map of London (1746) it has been horizontally truncated, but is shown with substantial elevation, with at least one dwelling-house – if not a terrace of houses – on its western end.",1
"In Richard Blome's map of 1755 it has a large dwelling-house with front drive and appears alongside the newly built London Hospital. In John Cary's 1795 map its western portion has been truncated by the newly built New Road, but appears to have a substantial building in its northwest corner.",1
"In 1643 London was hastily fortified against the Royalist armies, for ""there is terrible news that [Prince] Rupert will sack it and so a complete and sufficient dike and earthern wall and bulwarks must be made"".Twenty-three or 24 earthen forts were built at intervals around the city and its main suburbs; neighbouring forts were in sight of one another. These forts were manned by volunteers e.g. men too old to be in the regular militia; local innkeepers were ordered to provide them with food.",1
"The forts were interconnected by an earth bank and trench, dug by ""great numbers of men, women and young children"". All social classes joined in the labour: The completed ring was 18 miles in circumference. A visiting Scotsman walked it; it took him 12 hours.Fort No.2, officially a hornwork with two flanks, commanded the Whitechapel Road.",1
"The Scottish traveller, who inspected it, said it was a ""nine angled fort only pallosaded and single ditched and planted with seven pieces of brazen ordnance [brass cannon], and a court du guard [guardhouse] composed of timber and thatched with tyle stone as all the rest are"". There was a trench around its base.Daniel Lysons said the earthwork at Whitechapel was 329 foot long, 182 foot broad and more than 25 foot above ground level.After the civil war these fortifications were swiftly removed because they spoiled productive agricultural land. However traces remained and one of these was Whitechapel Mount.",1
"Wrote Lysons (1811): ""The east end was till of late years very perfect; on the west side some houses had been built. The surface on the top, except where it had been dug away, was perfectly level. Mount Street, Mayfair, is another relict name of one of these civil war forts.",1
"In the bubonic epidemic of 1665 an estimated 70,000-100,000 Londoners died of the plague. Aldgate, Whitechapel and Stepney were badly affected. This placed a strain on the burial facilities and some were buried in mass graves.Official mass graves were made by opening a deep pit and leaving it open for as long as it took to fill with cadavers, which was done downwind. The number of lost plague pits in London is commonly exaggerated — most mass graves were actually in pre-existing churchyards . However there were some gaps in the records and ""undoubtedly some temporary and irregular plague burial sites"".",1
"In one version, Whitechapel Mount's origin was that rubble from the Fire of London was thrown over a plague pit to cover it up. These rumours were denied by the authorities when they proposed to remove Whitechapel Mount; they had it ""pierced"" in an effort to refute them.",1
"The clearest reputable source is the author Joseph Moser, who wrote In the course of last summer [1802], when part of the rubbish of [Whitechapel Mount] had just been removed, I had the curiosity to inspect the place, and observed in the different strata a great number of human bones, together with those, apparently, of different animals, oxen, or cows, and sheep’s horns, bricks, tiles, &c.",1
"The Great Fire of London occurred the year after the plague. The nearest burnt environment was a mile away. Even so, respectable sources asserted that Whitechapel Mount was formed or augmented from rubble from the Fire of London, including Dr Markham the rector of Whitechapel Church, who took pains to investigate the subject. This origin theory was widely believed, though some denied it. When the Mount was dismantled in the 19th century the belief attracted flocks of antique hunters; see below.",1
"The above theories about the origin of Whitechapel Mount, by themselves, may not account for its sheer size as shown in the maps and illustrations cited. A laystall was an open rubbish tip; towns relied on them for disposing of garbage, and did so until the sanitary landfills of the 20th century. By legislation of October 1671 seven laystalls were appointed for the City of London. All street sweepings and household rubbish was to be collected in carts and had to be tipped in one of these, and nowhere else.",1
"One of them was Whitechapel Mount: it was to receive the rubbish from the wards of Portsoken, Tower, Duke's Place and Lime Street. However, a laystall was more than a passive tip: it was a business. Its proprietor employed gangs of men, women and boys to sort the rubbish and recycle it. Without him, nothing prevented indiscriminate fly-tipping and random lateral spread onto adjoining properties.",1
"William Guy who investigated the laystalls of mid-19th century London reported In most of the laystalls or dustmen's yards, every species of refuse matter is collected and deposited:– nightsoil, the decomposing refuse of markets, the sweepings of narrow streets and courts, the sour-smelling grains from breweries, the surface soil of the leading thoroughfares, and the ashes from the houses. The proportion in which these several matters are collected, vary...",1
"At the close of the 18th century there was a tremendous demand for bricks to build the rapidly expanding London; ""At night, a 'ring of fire' and pungent smoke encircled the City""; there were numerous local brickfields e.g. at Mile End. An Old Bailey case of 1809 records that bricks were being delivered from the diminishing Whitechapel Mount. The construction of the East and West India Docks early in the nineteenth century caused roads to be made through the low marshy fields extending from Shadwell and Ratcliff to Whitechapel.",1
"New Street/Cannon Street Road, leading from Whitechapel Mount to St George in the East so increased the value of the land on each side of it, that the Corporation of London decided to take down the Mount. This occurred in 1807–8, and Mount Place, Mount Terrace, and Mount Street were then built on that site, thus marking the spot where the Mount stood.The process took several years, efforts at first being desultory. There was even a proposal – a prefiguring of the Regent's Canal – to bring a canal from Paddington to the docks at Wapping by passing through Whitechapel Mount.The",1
"Believing it to contain detritus from the Fire of London, flocks of cockney enthusiasts examined the Mount's soil. Various antiques were found in it – or alleged to be found in it, since it gave them provenance – including a silver tankard and a Roman coin.The most spectacular find was a carved boar's head with silver tusks; it was, said reputable antiquarians, an authentic memento of the Boar's Head Inn, Eastcheap: a setting for Shakespeare plays, Falstaff, Mistress Quickly and so forth, and genuinely burnt down in the Fire of London.",1
"For lack of access, there has been no systematic archaeological investigation of the site. However, redevelopment of the Royal London Hospital has allowed occasional glimpses. Mackinder (1994), London Hospital Medical College, Newark Building, Grid Reference TQ3456815: Evaluation produced evidence of a deep cut feature on the alignment of the English Civil War defences. A subsequent excavation found the feature to be a ditch, 5.5m wide and 1.4m deep, filled with waterlain silts (the earliest dating to the 17th century), which was backfilled in the late 18th century. Other activity consisted of an undated drainage channel.",1
"Later, there were two post holes possibly forming a fence-line and possibly associated with a rutted gravel surface that post-dated the infilling of the ditch. A large quantity of post-medieval red ware sugar cone moulds and collecting jars were recovered from the infilling of the ditch and later levelling of the site. Aitken (2005), The Front Green, Royal London Hospital, Grid Reference TQ347816: Post-medieval deposits, ashy fill deposits were recorded below the cellars of former terrace houses facing Whitechapel Road.",1
"Extensive fill deposits may indicate quarrying, which took place after a successful petition to flatten the Mount fort by the hospital authorities at the end of the 18th century. There is no trace of a former burial ground on the site prior to that date and no disturbed graves or disarticulated human bone was recovered. A rise in the ground level to a metre above that of the surrounding Whitechapel and New Roads indicates a topographic replacement of the Mount as an elevated feature and the same rise is reflected along the 19th century Mount Terrace.",1
"No significant archaeological deposits were observed. The Skeleton Witness: or, The Murder at the Mound by William Leman Rede was a play performed on the English and American stage. The villain does a murder and conceals the body in Whitechapel Mount. The crime is done in such a way that, should the remains be discovered, the impoverished hero will get the blame, though innocent. The hero goes abroad for seven years and makes his fortune.",1
"On his return to London, about to marry the heroine, he learns, to his horror, that the Mount is to be cleared away, digging to start on the morrow. To stop this, he hurries off to the Mount's owner and buys it at an extravagant price. The vendor, suspicious, wonders if the Mount contains a buried treasure and sends some men to poke around. They discover the skeleton. By a complicated plot twist the hero proves his innocence and gets the girl, both living happily ever after.The",1
"Transactions of the London and Middlesex Archaeological Society. J. H. & J. Parker. 5: 516–519. Retrieved 9 September 2020. Brett-James, Norman G. (1928). ""The Fortification of London in 1642/3"". London Topographical Record. London Topographical Society. 14: 1–35. Retrieved 12 September 2020. Bull, G. B. G. (1956). ""Thomas Milne's Land Utilization Map of the London Area in 1800"". The Geographical Journal. The Royal Geographical Society. 122 (1): 25–30. JSTOR 1791472. Clunn, Harold P. (1937). The Face of London: The Record of a Century's Changes and Development. New York; London: E.P. Dutton; Simpkin Marshall. Retrieved 9 September 2020. Cooke, G. A. (1832).",1
"Walks Through London; or, a Picture of the British Metropolis. London: Sherwood, Gilbert and Piper. Retrieved 9 September 2020. Crosby, B. (1799). Modern Songster. London: Crosby. Retrieved 5 September 2020. ""Domestic Events"". The Monthly Mirror: Reflecting Men and Manners. Vol. 20. London: Vernon and Hood. July 1805. Retrieved 28 August 2020. Emerson, George Rose (1862). London: How the Great City Grew. London: Routledge, Warne & Routledge. Retrieved 9 September 2020. Entick, John (1766). A New and Accurate Survey of London, Westminster, Southwark and Places Adjacent. Vol. 2. Edward and Charles Dilly. Retrieved 9 September 2020. Flintham, David (1999).",1
"""Whitechapel Mount and the London Hospital"". THHOL. Mernick. Retrieved 30 August 2020. Guy, William Augustus (1848). ""On the Health of Nightmen, Scavengers, and Dustmen"". Journal of the Statistical Society of London. Wiley. 11 (1): 72–81. JSTOR 2337767. Harding, Vanessa (1993). ""Burial of the plague dead in early modern London"" (PDF). In Champion, J. A. I. (ed.). Epidemic Disease in London. Centre for Metropolitan History. pp. 53–64. Retrieved 5 September 2020. Hobler, Francis (1860). Roman History from Cnæus Pompeius to Tiberius Constantinus as Exhibited on the Roman Coins Collected by Francis Hobler. Vol. 1. Westminster: John Bowyer Nichols and Sons.",1
"Retrieved 9 September 2020. Holmes, Mrs Basil (Isabella M.) (1896). The London Burial Grounds. Notes on their History from the Earliest Times to the Present Day. New York: Macmillan. Retrieved 4 September 2020. Juninus (1813). ""Conversations on the Arts"". Repository of Arts, Literature, Commerce, Manufactures, Fashion and Politics. Vol. 9, no. 51. R. Ackermann. Retrieved 8 September 2020. Lambert, R. (1806). The History and Survey of London and its Environs from the Earliest Period to the Present Time. Vol. 4. London: T. Hughes, M. Jones. Retrieved 9 September 2020. Lysons, Daniel (1811).",1
"The Environs of London: Being An Historical Account of the Towns, Villages and Hamlets Within Twelve Miles of the Capital. Vol. 2(2) (2nd ed.). London: Cadell and Davies. Retrieved 3 September 2020. Mackinder, A. (1994). ""London Hospital Medical College, Newark Building, New Road, London E1, London Borough of Tower Hamlets"". MOLA (Museum of London Archaeology). Retrieved 11 September 2020. Malcolm, James Pelham (1807). Londinium Redivivum, or an Ancient History and Modern Description of London. Vol. 4. London: Longman Rees Hurst & Orme. Retrieved 9 September 2020. Mayhew, Henry (1861).",1
"London Labour and the London Poor: Cyclopædia of the Conditions and Earnings of Those that Will Work, Those that Cannot Work, and Those that Will Not Work. Vol. 2. London: Griffin, Bohn. Retrieved 9 September 2020. MOLAS (2004). ""The Front Garden, Royal London Hospital, Whitechape Road, E1: an archaeological watching brief report"". Retrieved 30 August 2020. Morris, E. W. (1910). A History of the London Hospital. London: Edward Arnold. Retrieved 29 August 2020. Moser, Joseph (1803). ""Vestiges, Collected and Recollected"". The European Magazine and Monthly Review. Vol. 43. Philological Society of London. Retrieved 8 September 2020. Norman, Philip (1897).",1
"London Signs and Inscriptions. Elliot Stock. Retrieved 9 September 2020. Porter, Stephen (2012). The Great Plague (Kindle ed.). Stroud: Amberley. ISBN 978-1-4456-1219-5. R v. Hall (1809). The Proceedings of the Old Bailey. Retrieved 9 September 2020. R v. Patrick (1747). The Proceedings of the Old Bailey. Retrieved 8 September 2020. R v. Travis (1734). The Proceedings of the Old Bailey. Retrieved 8 September 2020. Rede, William Leman (1868). The Skeleton Witness: or, The Murder at the Mound. A Domestic Drama in Three Act, as Performed at the Principal English and American Theatres. New York: Samuel French. Retrieved 7 September 2020.",1
"Roberts, William (1836). Memories of the Life of Mrs Hannah More. Vol. 1. London: Senley and Burnside. Retrieved 29 August 2020. Strype (1720). A Survey of the Cities of London and Westminster (online ed.). ISBN 0-9542608-9-9. Retrieved 8 September 2020. Timbs, John (1855). Curiosities of London. London: David Bogue. Retrieved 9 September 2020. ""To my Esteem'd Fellow-labourers"". The Scots Magazine. 22 December 1739. Wallis, John (1810). London: being a Complete Guide to the British Capital (3rd ed.). Sherwood, Neeley and Jones. Retrieved 9 September 2020. Watson, Isobel (1995).",1
"""From West Heath to Stepney Green: building development in Mile End Old Town, 1660–1820"". London Topographical Record. London Topographical Society. 27: 231–256. Retrieved 9 September 2020. ""Whitechapel Mount"". The Times. London. 30 July 1805. Mount Terrace in the Survey of London",1
"Haze is no longer just a confined as a domestic problem. It has become one of the causes of international disputes among neighboring countries. Haze can migrate to adjacent countries in the path of wind and thereby pollutes other countries as well, even if haze does not first manifest there. One of the most recent problems occur in Southeast Asia which largely affects the nations of Indonesia, Malaysia and Singapore.",1
"This results in the visual effect of a loss of contrast in the subject, due to the effect of light scattering and reflection through the haze particles. For these reasons, sunrise and sunset colors and possibly the sun itself appear subdued on hazy days, and stars may be obscured by haze at night. In some cases, attenuation by haze is so great that, toward sunset, the sun disappears altogether before even reaching the horizon.Haze",1
"natural DNA, each nucleotide is composed of one of four nucleobases (cytosine [C], guanine [G], adenine [A] or thymine [T]), a sugar called deoxyribose, and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. The nitrogenous bases of the two separate polynucleotide strands are bound to each other with hydrogen bonds, according to base pairing rules (A with T and C with G), to make double-stranded DNA.",1
"DNA and RNA are naturally composed of four nucleotide bases that form hydrogen bonds in order to pair. Hachimoji DNA uses an additional four synthetic nucleotides to form four types of base pairs, two of which are unnatural: P binds with Z and B binds with S (dS in DNA, rS in RNA).",1
"Creating new life forms may be possible, at least theoretically, with the new DNA system. For now, however, the hachimoji DNA system is not self-sustaining; the system needs a steady supply of unique building blocks and proteins found only in the laboratory. As a result, ""Hachimoji DNA can go nowhere if it escapes the laboratory."" NASA funded this research to ""expand[s] the scope of the structures that we might encounter as we search for life in the cosmos"".",1
"According to Lori Glaze of the Planetary Science Division of NASA, ""Life detection is an increasingly important goal of NASA's planetary science missions, and this new work [with hachimoji DNA] will help us to develop effective instruments and experiments that will expand the scope of what we look for."" Research team leader Steven Benner notes, ""By carefully analyzing the roles of shape, size and structure in hachimoji DNA, this work expands our understanding of the types of molecules that might store information in extraterrestrial life on alien worlds.""According",1
Astronomy FAQ - Why do we assume that other beings must be based on carbon? Why couldn't organisms be based on other substances? Film clip encoded into DNA using CRISPR: video (01:39) on YouTube,1
"the overlap between synthetic biology and the do-it-yourself biology movement, concerns have been raised that its practitioners may not abide by risk assessment and biosafety practices required of professionals,: 39 although it has been suggested that an informal code of ethics exists that recognizes health risks and other adverse outcomes.: 15",1
"The rise of synthetic biology has also spurred biosecurity concerns that synthetic or redesigned organisms could be engineered for bioterrorism. This is considered possible but unlikely given the resources needed to perform this kind of research. However, synthetic biology could expand the group of people with relevant capabilities, and reduce the amount of time needed to develop them.: 2–7 A 2018 National Academies of Sciences, Engineering, and Medicine (NASEM) report identified three capabilities as being of greatest concern.",1
"The first is the recreation of known pathogens from scratch, for example using genome synthesis to recreate historical viruses such as the Spanish Flu virus or polio virus.: 12, 14 : 2–7 Current technology allows genome synthesis for almost any mammalian virus, the sequences of known human viruses are publicly available, and the procedure has relatively low cost and requires access to basic laboratory equipment. However, the pathogens would have known properties and could be mitigated by standard public health measures, and could be partially prevented by screening of commercially produced DNA molecules.",1
"In contrast to viruses, creating existing bacteria or completely novel pathogens from scratch was not yet possible as of 2018, and was considered a low risk.: 39–43, 54–56 Another capability of concern cited by NASEM is engineering existing pathogens to be more dangerous. This includes altering the targeted host or tissue, as well as enhancing the pathogen's replication, virulence, transmissibility, or stability; or its ability to produce toxins, reactivate from a dormant state, evade natural or vaccine-induced immunity, or evade detection.",1
"59–65 There is also the possibility of novel threats that were considered lower risks by NASEM due to their technical challenges. Delivery of an engineered organism into the human microbiome has the challenges of delivery and persistence in the microbiome, though an attack would be difficult to detect and mitigate. Pathogens engineered to alter the human immune system by causing immunodeficiency, hyperreactivity, or autoimmunity, or to directly alter the human genome, were also considered lower-risk due to extreme technical challenges.: 65–83",1
"It could also cause products to be produced by non-agricultural means or through large-scale commercial farming, which could economically outcompete small-scale farmers. Finally, there is a risk that conservation methods based on synthetic biology, such as de-extinction, may reduce support for traditional conservation efforts.",1
"agriculture, extrinsic biocontainment methods include maintaining isolation distances and physical pollen barriers to prevent modified organisms from fertilizing wild-type plants, as well as sowing modified and wild-type seed at different times so that their flowering periods do not overlap.",1
"However, they may be useful in combination with other hazard controls, and may provide enhanced protections relative to GMOs.: 6, 40–43 Many approaches fall under the umbrella of intrinsic biocontainment. Auxotrophy is the inability of an organism to synthesize a particular compound required for its growth, meaning that the organism cannot survive unless the compound is provided to it. A kill switch is a pathway that initiates cell death that is triggered by a signal from humans.: 40–43 Inability of the organisms to replicate is another such method.:",1
"18 Some researchers have suggested that traditional life-cycle assessment methods may be insufficient because unlike with traditional industries, the boundary between industry the environment is blurred, and materials have an information-rich description that cannot be described only by their chemical formula.",1
"Several treaties contain provisions which apply to synthetic biology. These include the Convention on Biological Diversity, Cartagena Protocol on Biosafety, Nagoya–Kuala Lumpur Supplementary Protocol on Liability, Biological Weapons Convention, and Australia Group Guidelines.",1
"In general, the United States relies on the regulatory frameworks established for chemicals and pharmaceuticals to regulate synthetic biology, mainly the Toxic Substances Control Act of 1976 as updated by the Frank R. Lautenberg Chemical Safety for the 21st Century Act, as well as the Federal Food, Drug, and Cosmetic Act.The biosafety concerns about synthetic biology and its gene-editing tools are similar to the concerns lodged about recombinant DNA technology when it emerged in the mid-1970s. The recommendations of the 1975 Asilomar Conference on Recombinant DNA formed the basis for the U.S.",1
"In addition, the 2010 NIH Screening Framework Guidance for Providers of Synthetic Double-Stranded DNA provides voluntary guidelines for vendors of synthetic DNA to verify the identity and affiliation of buyers, and screen for sequences of concern.The Occupational Safety and Health Administration (OSHA) regulates the health and safety of workers, including those involved in synthetic biology. In the mid-1980s, OSHA maintained that the general duty clause and existing regulatory standards were sufficient to protect biotechnology workers.The",1
"Singapore relies on its Biosafety Guidelines for GMOs, Biological Agents and Toxins Act, and the Workplace Safety and Health Act. Biosafety level Regulation of genetic engineering Biocontainment of genetically modified organisms",1
"Noise-induced hearing loss is a permanent shift in pure-tone thresholds, resulting in sensorineural hearing loss. The severity of a threshold shift is dependent on duration and severity of noise exposure. Noise-induced threshold shifts are seen as a notch on an audiogram from 3000 to 6000 Hz, but most often at 4000 Hz.Exposure to loud noises, either in a single traumatic experience or over time, can damage the auditory system and result in hearing loss and sometimes tinnitus as well. Traumatic noise exposure can happen at work (e.g., loud machinery), at play (e.g.,",1
"loud sporting events, concerts, recreational activities), and/or by accident (e.g., a backfiring engine.) Noise induced hearing loss is sometimes unilateral and typically causes patients to lose hearing around the frequency of the triggering sound trauma. Tinnitus is an auditory disorder characterized by the perception of a sound (ringing, chirping, buzzing, etc.) in the ear in the absence of an external sound source. There are two types of tinnitus: subjective and objective. Subjective is the most common and can only be heard ""in the head"" by the person affected.",1
"Objective tinnitus can be heard from those around the affected person and the audiologist can hear it using a stethoscope. Tinnitus can also be categorized by the way it sounds in one's ear, pulsatile tinnitus which is caused by the vascular nature of Glomus tumors and non-pulsatile tinnitus which usually sounds like crickets, the sea and bees. Though the pathophysiology of tinnitus is not known, noise exposure can be a contributing factor, therefore tinnitus can be associated with hearing loss, generated by the cochlea and central nervous system (CNS).",1
"High frequency hearing loss causes a high pitched tinnitus and low frequency hearing loss causes a roaring tinnitus. Noise-induced tinnitus can be temporary or permanent depending on the type and amount of noise a person was exposed to. Noise has been associated with important cardiovascular health problems, particularly hypertension, as it causes an increase in levels of stress hormones and vascular oxidative stress. Noise levels of 50 dB(A) or greater at night may increase the risk of myocardial infarction by chronically elevating cortisol production.Traffic",1
"noise has several negative effects, including increased risk for coronary artery disease, with night-time exposure to noise possibly more harmful than day-time exposure. It has also been shown to increase blood pressure in individuals within the surrounding residential areas, with railways causing the greatest cardiovascular effects. Roadway noise levels are sufficient to constrict arterial blood flow and lead to elevated blood pressure. Vasoconstriction can result from elevated adrenaline levels or through medical stress reactions. Long-term exposure to noise is correlated to increase in cortisol and angiotensin-II levels which are respectively associated with oxidative stress and vascular inflammation.",1
"Individuals subject to great than 80 dB(A) in the workplace are at increased risk of having increased blood pressure.A 2021 systematic review on the effect of occupational exposure to noise on ischemic heart disease (IHD), stroke and hypertension, coordinated by the World Health Organization (WHO) and the International Labour Organization (ILO) located 17 studies that met the inclusion criteria, comprising a total of 534,688 participants (7.47% females) in 11 countries and in three WHO regions (the Americas, Europe, and the Western Pacific).",1
"Causal relationships have been discovered between noise and psychological effects such as annoyance, psychiatric disorders, and effects on psychosocial well-being. Exposure to intense levels of noise can cause personality changes and violent reactions. Noise has also been shown to be a factor attributed to violent reactions. The psychological impacts of noise also include an addiction to loud music. This was researched in a study where non-professional musicians were found to have loudness addictions more often than non-musician control subjects.Psychological health effects from noise also include depression and anxiety.",1
"Research commissioned by Rockwool, a multi-national insulation manufacturer headquartered in Denmark, reveals that in the UK one third (33%) of victims of domestic disturbances claim that loud parties have left them unable to sleep or made them stressed in the last two years. Around one in eleven (9%) of those affected by domestic disturbances claims it has left them continually disturbed and stressed. More than 1.8 million people claim noisy neighbours have made their life a misery and they cannot enjoy their own homes.",1
"Annoyance effects of noise are minimally affected by demographics, but fear of the noise source and sensitivity to noise both strongly affect the 'annoyance' of a noise. Sound levels as low as 40 dB(A) can generate noise complaints and the lower threshold for noise producing sleep disturbance is 45 dB(A) or lower.Other factors that affect the annoyance level of sound include beliefs about noise prevention and the importance of the noise source, and annoyance at the cause (i.e., non-noise related factors) of the noise.",1
"Many of the interpretations of the level of annoyance and the relationship between noise levels and resulting health symptoms could be influenced by the quality of interpersonal relationships at the workplace, as well as the stress level generated by the work itself. Evidence for impact on annoyance of long-term noise versus recent changes is uncertain.Approximately 35% to 40% of office workers find noise levels from 55 to 60 dB(A) extremely irritating.",1
"Specific birth abnormalities included harelip, cleft palate, and defects in the spine.According to Lester W. Sontag of The Fels Research Institute (as presented in the same EPA study): ""There is ample evidence that environment has a role in shaping the physique, behavior, and function of animals, including man, from conception and not merely from birth. The fetus is capable of perceiving sounds and responding to them by motor activity and cardiac rate change.""",1
"The effects of noise exposure are highest when it occurs between 15 and 60 days after conception, a period in which major internal organs and the central nervous system are formed.Later developmental effects occur as vasoconstriction in the mother reduces blood flow and therefore oxygen and nutrition to the fetus. Low birth weights and noise were also associated with lower levels of certain hormones in the mother. These hormones are thought to affect fetal growth and to be good indicators of protein production. The difference between the hormone levels of pregnant mothers in noisy versus quiet areas increased as birth approached.In",1
"a 2000 publication, a review of studies on birthweight and noise exposure note that while some older studies suggest that when women are exposed to >65 dB aircraft noise, a small decrease in birthweight occurs, in a more recent study of 200 Taiwanese women including noise dosimetry measurements of individual noise exposure, the authors found no significant association between noise exposure and birth weight after adjusting for relevant confounders, e.g. social class, maternal weight gain during pregnancy, etc.",1
"When young children are regularly exposed to levels of noise that interfere with speech, they may develop speech or reading difficulties, because auditory processing functions are compromised. Children continue to develop their speech perception abilities until they reach their teens. Evidence has shown that when children learn in noisier classrooms, they have more difficulties understanding speech than those who learn in quieter settings.In a study conducted by Cornell University in 1993, children exposed to noise in learning environments experienced trouble with word discrimination, as well as various cognitive developmental delays.",1
"While people are often educated on the effects of noise exposure in humans, there are also different noise exposure effects in animals as well. An example of this would be in dogs, and the noise exposure levels occurring within kennels. Dogs experience this noise exposure whether it be a long stay at an animal shelter, or a weekend stay at a boarding facility. Organizations like NIOSH and OSHA have different regulations when it comes to the noise exposure levels in industrial workers.",1
"All of these behavioral patterns are characteristics that result in a longer stay at the kennels before being adopted. A longer stay at the shelter results in a longer duration of noise exposure and therefore more likely to show either a temporary or permanent threshold shift in the canine's hearing.These excessive noise levels are not only harming the dogs physical and psychological state, but the workers' and potential adoptive families' physical and psychological state as well. The workers' psychological state could affect the care provided to the dogs.",1
"These loud noise exposures also have the potential to reduce the amount of time that potential adoptive families spend in the facility. This can result in less dogs being adopted and more time being exposed to excessive sound levels.To reduce the level of noise exposure poses a little more difficulty because the majority of the noise is coming from the dogs (barking), but structural changes can be made to the facilities in order to reduce the noise.",1
Acoustical Society of America Noise and Health International Journal devoted to research on all aspects of noise and its effects on human health World Health Organization: Guidelines for Community Noise Archived 2018-07-12 at the Wayback Machine ICBEN International Commission on Biological Effects of Noise How Sound Affects Us (8:18)—TED talk by Julian Treasure NIOSH Buy Quiet Topic Page Occupational Hearing Loss Prevention,1
The levels of 210Pb can be measured. The rate of deposition of this radioisotope is dependent on the weather.,1
"In an oil processing plant, the area of the plant where propane is processed is often one of the more contaminated areas, because radon has a similar boiling point to propane.",1
"Typical domestic exposures are of around 100 Bq/m3 indoors, but specifics of construction and ventilation strongly affect levels of accumulation; a further complication for risk assessment is that concentrations in a single location may differ by a factor of two over an hour, and concentrations can vary greatly even between two adjoining rooms in the same structure.The distribution of radon concentrations is highly skewed: the larger concentrations have a disproportionately greater weight. Indoor radon concentration is usually assumed to follow a lognormal distribution on a given territory.",1
"nuclear power plant, who triggered radiation monitors while leaving work over several days—even though the plant had not yet been fueled, and despite Watras being decontaminated and sent home ""clean"" each evening. This pointed to a source of contamination outside the power plant, which turned out to be radon levels of 100,000 Bq/m3 (2.7 nCi/L) in the basement of his home. He was told that living in the home was the equivalent of smoking 135 packs of cigarettes a day, and he and his family had increased their risk of developing lung cancer by 13 or 14 percent.",1
"The incident dramatized the fact that radon levels in particular dwellings can occasionally be orders of magnitude higher than typical. Radon soon became a standard homeowner concern, though typical domestic exposures are two to three orders of magnitude lower (100 Bq/m3, or 2.5 pCi/L), making individual testing essential to assessment of radon risk in any particular dwelling. Radon exists in every U.S. state, and about 6% of American houses have elevated levels. The highest average radon concentrations in the United States are found in Iowa and in the Appalachian Mountain areas in southeastern Pennsylvania.",1
"The health effects of high exposure to radon in mines, where exposures reaching 1,000,000 Bq/m3 can be found, can be recognized in Paracelsus' 1530 description of a wasting disease of miners, the mala metallorum. Though at the time radon itself was not understood to be the cause—indeed, neither it nor radiation had even been discovered—mineralogist Georg Agricola recommended ventilation of mines to avoid this mountain sickness (Bergsucht). In 1879, the ""wasting"" was identified as lung cancer by Herting and Hesse in their investigation of miners from Schneeberg, Saxony, Germany.",1
"Given that the type locality of the important uranium ore pitchblende is in the Ore Mountains and that region was the most important German speaking mining area at the time, it is likely the radon induced lung cancers were associated with uranium. Beyond mining in general, radon is a particular problem in the mining of uranium; significant excess lung cancer deaths have been identified in epidemiological studies of uranium miners and other hard-rock miners employed in the 1940s and 1950s. Residues from processing of uranium ore can also be a source of radon.",1
"Radon resulting from the high radium content in uncovered dumps and tailing ponds can be easily released into the atmosphere. Modern mining techniques, including better ventilation for underground mines, routine radiation monitoring as well as technologies like in-situ leaching have helped decrease the incidence of radon exposure among miners in subsequent decades. The first major studies with radon and health occurred in the context of uranium mining, first in the Joachimsthal region of Bohemia and then in the Southwestern United States during the early Cold War.",1
"Because radon is a product of the radioactive decay of uranium, underground uranium mines may have high concentrations of radon. Many uranium miners in the Four Corners region contracted lung cancer and other pathologies as a result of high levels of exposure to radon in the mid-1950s. The increased incidence of lung cancer was particularly pronounced among Native American and Mormon miners, because those groups normally have low rates of lung cancer. Safety standards requiring expensive ventilation were not widely implemented or policed during this period.In",1
"are possibly due to systematic errors in exposure ascertainment, unaccounted for differences in the study populations (genetic, lifestyle, etc.), or confounding mine exposures. There are a number of confounding factors to consider, including exposure to other agents, ethnicity, smoking history, and work experience. The cases reported in these miners cannot be attributed solely to radon or radon daughters but may be due to exposure to silica, to other mine pollutants, to smoking, or to other causes. The majority of miners in the studies are smokers and all inhale dust and other pollutants in mines.",1
"This has reduced the risk of occupationally induced cancer from radon, although it still remains an issue both for those who are currently employed in affected mines and for those who have been employed in the past. The power to detect any excess risks in miners nowadays is likely to be small, exposures being much smaller than in the early years of mining.A confounding factor with mines is that both radon concentration and carcinogenic dust (such as quartz dust) depend on the amount of ventilation.",1
This makes it very difficult to state that radon causes cancer in miners; the lung cancers could be partially or wholly caused by high dust concentrations from poor ventilation.,1
"Radon-222 has been classified by International Agency for Research on Cancer as being carcinogenic to humans. In September 2009, the World Health Organization released a comprehensive global initiative on radon that recommended a reference level of 100 Bq/m3 for radon, urging establishment or strengthening of radon measurement and mitigation programs as well as development building codes requiring radon prevention measures in homes under construction.",1
Elevated lung cancer rates have been reported from a number of cohort and case-control studies of underground miners exposed to radon and its decay products but the main confounding factor in all miners' studies is smoking and dust. Up to the most of regulatory bodies there is sufficient evidence for the carcinogenicity of radon and its decay products in humans for such exposures.,1
"However, the discussion about the opposite results is still going on, especially a recent retrospective case-control study of lung cancer risk showed substantial cancer rate reduction between 50 and 123 Bq per cubic meter relative to a group at zero to 25 Bq per cubic meter. Additionally, the meta-analysis of many radon studies, which independently show radon risk increase, gives no confirmation of that conclusion: the joined data show log-normal distribution with the maximal value in zero risk of lung cancer below 800 Bq per cubic meter.The primary route of exposure to radon and its progeny is inhalation.",1
"Radiation exposure from radon is indirect. The health hazard from radon does not come primarily from radon itself, but rather from the radioactive products formed in the decay of radon. The general effects of radon to the human body are caused by its radioactivity and consequent risk of radiation-induced cancer. Lung cancer is the only observed consequence of high concentration radon exposures; both human and animal studies indicate that the lung and respiratory system are the primary targets of radon daughter-induced toxicity.Radon has a short half-life (3.8 days) and decays into other solid particulate radium-series radioactive nuclides.",1
"Two of these decay products, polonium-218 and 214, present a significant radiologic hazard. If the gas is inhaled, the radon atoms decay in the airways or the lungs, resulting in radioactive polonium and ultimately lead atoms attaching to the nearest tissue. If dust or aerosol is inhaled that already carries radon decay products, the deposition pattern of the decay products in the respiratory tract depends on the behaviour of the particles in the lungs.",1
"Smaller diameter particles diffuse further into the respiratory system, whereas the larger—tens to hundreds of micron-sized—particles often deposit higher in the airways and are cleared by the body's mucociliary staircase. Deposited radioactive atoms or dust or aerosol particles continue to decay, causing continued exposure by emitting energetic alpha radiation with some associated gamma radiation too, that can damage vital molecules in lung cells, by either creating free radicals or causing DNA breaks or damage, perhaps causing mutations that sometimes turn cancerous.",1
"In addition, through ingestion and blood transport, following crossing of the lung membrane by radon, radioactive progeny may also be transported to other parts of the body. The risk of lung cancer caused by smoking is much higher than the risk of lung cancer caused by indoor radon. Radiation from radon has been attributed to increase of lung cancer among smokers too. It is generally believed that exposure to radon and cigarette smoking are synergistic; that is, that the combined effect exceeds the sum of their independent effects.",1
"More than 90% of the absorbed radon is eliminated by exhalation within 100 minutes, By 600 minutes, only 1% of the absorbed amount remains in the body.",1
"While radon presents the aforementioned risks in adults, exposure in children leads to a unique set of health hazards that are still being researched. The physical composition of children leads to faster rates of exposure through inhalation given that their respiratory rate is higher than that of adults, resulting in more gas exchange and more potential opportunities for radon to be inhaled.The resulting health effects in children are similar to those of adults, predominantly including lung cancer and respiratory illnesses such as asthma, bronchitis, and pneumonia.",1
"While there have been numerous studies assessing the link between radon exposure and childhood leukemia, the results are largely varied. Many ecological studies show a positive association between radon exposure and childhood leukemia; however, most case control studies have produced a weak correlation. Genotoxicity has been noted in children exposed to high levels of radon, specifically a significant increase of frequency of aberrant cells was noted, as well as an “increase in the frequencies of single and double fragments, chromosome interchanges, [and] number of aberrations chromatid and chromosome type”.",1
"Because radon is generally associated with diseases that are not detected until many years after elevated exposure, the public may not consider the amount of radon that children are currently being exposed to. Aside from the exposure in the home, one of the major contributors to radon exposure in children are the schools in which they attend almost every day. A survey was conducted in schools across the United States to detect radon levels, and it was estimated that about one in five schools has at least one room (more than 70,000 schoolrooms) with short-term levels above 4pCi/L.Many",1
"states have active radon testing and mitigation programs in place, which require testing in buildings such as public schools. However, these are not standardized nationwide, and the rules and regulations on reducing high radon levels are even less common. The School Health Policies and Practices Study (SHPPS), conducted by the CDC in 2012, found that of schools located in counties with high predicted indoor radon levels, only 42.4% had radon testing policies, and a mere 37.5% had policy for radon-resistant new construction practices.",1
"Only about 20% of all schools nationwide have done testing, even though the EPA recommends that every school be tested. These numbers are arguably not high enough to ensure protection of the majority of children from elevated radon exposures. For exposure standards to be effective, they should be set for those most susceptible.",1
"UNSCEAR recommends a reference value of 9 nSv (Bq·h/m3)−1. For example, a person living (7000 h/year) in a concentration of 40 Bq/m3 receives an effective dose of 1 mSv/year. Studies of miners exposed to radon and its decay products provide a direct basis for assessing their lung cancer risk. The BEIR VI report, entitled Health Effects of Exposure to Radon, reported an excess relative risk from exposure to radon that was equivalent to 1.8% per megabecquerel hours per cubic meter (MBq·h/m3) (95% confidence interval: 0.3, 35) for miners with cumulative exposures below 30 MBq·h/m3.",1
"Estimates of risk per unit exposure are 5.38×10−4 per WLM; 9.68×10−4/WLM for ever smokers; and 1.67×10−4 per WLM for never smokers.According to the UNSCEAR modeling, based on these miner's studies, the excess relative risk from long-term residential exposure to radon at 100 Bq/m3 is considered to be about 0.16 (after correction for uncertainties in exposure assessment), with about a threefold factor of uncertainty higher or lower than that value. In other words, the absence of ill effects (or even positive hormesis effects) at 100 Bq/m3 are compatible with the known data.",1
"The ICPR 65 model follows the same approach, and estimates the relative lifelong risk probability of radon-induced cancer death to 1.23 × 10−6 per Bq/(m3·year). This relative risk is a global indicator; the risk estimation is independent of sex, age, or smoking habit. Thus, if a smoker's chances of dying of lung cancer are 10 times that of a nonsmoker's, the relative risks for a given radon exposure will be the same according to that model, meaning that the absolute risk of a radon-generated cancer for a smoker is (implicitly) tenfold that of a nonsmoker.",1
"The risk estimates correspond to a unit risk of approximately 3–6 × 10−5 per Bq/m3, assuming a lifetime risk of lung cancer of 3%. This means that a person living in an average European dwelling with 50 Bq/m3 has a lifetime excess lung cancer risk of 1.5–3 × 10−3. Similarly, a person living in a dwelling with a high radon concentration of 1000 Bq/m3 has a lifetime excess lung cancer risk of 3–6%, implying a doubling of background lung cancer risk.The BEIR VI model proposed by the National Academy of Sciences of the USA is more complex.",1
"It is a multiplicative model that estimates an excess risk per exposure unit. It takes into account age, elapsed time since exposure, and duration and length of exposure, and its parameters allow for taking smoking habits into account. In the absence of other causes of death, the absolute risks of lung cancer by age 75 at usual radon concentrations of 0, 100, and 400 Bq/m3 would be about 0.4%, 0.5%, and 0.7%, respectively, for lifelong nonsmokers, and about 25 times greater (10%, 12%, and 16%) for cigarette smokers.There",1
"is great uncertainty in applying risk estimates derived from studies in miners to the effects of residential radon, and direct estimates of the risks of residential radon are needed.As with the miner data, the same confounding factor of other carcinogens such as dust applies. The largest natural contributor to public radiation dose is radon, a naturally occurring, radioactive gas found in soil and rock, which comprises approximately 55% of the annual background dose. Radon gas levels vary by locality and the composition of the underlying soil and rocks.",1
"Radon (at concentrations encountered in mines) was recognized as carcinogenic in the 1980s, in view of the lung cancer statistics for miners' cohorts. Although radon may present significant risks, thousands of persons annually go to radon-contaminated mines for deliberate exposure to help with the symptoms of arthritis without any serious health effects.Radon as a terrestrial source of background radiation is of particular concern because, although overall very rare, where it does occur it often does so in high concentrations.",1
"Some of these areas, including parts of Cornwall and Aberdeenshire have high enough natural radiation levels that nuclear licensed sites cannot be built there—the sites would already exceed legal limits before they opened, and the natural topsoil and rock would all have to be disposed of as low-level nuclear waste. People in affected localities can receive up to 10 mSv per year background radiation.This led to a health policy problem: what is the health impact of exposure to radon concentrations (100 Bq/m3) typically found in some buildings?",1
"When exposure to a carcinogenic substance is suspected, the cause/effect relationship on any given case can never be ascertained. Lung cancer occurs spontaneously, and there is no difference between a ""natural"" cancer and another one caused by radon (or smoking). Furthermore, it takes years for a cancer to develop, so that determining the past exposure of a case is usually very approximative. The health effect of radon can only be demonstrated through theory and statistical observation.",1
"Even when a statistical link between factor and effect appears significant, it must be backed by a theoretical explanation; and a theory is not accepted as factual unless confirmed by observations.",1
"most direct way to assess the risks posed by radon in homes is through case-control studies. The studies have not produced a definitive answer, primarily because the risk is likely to be very small at the low exposure encountered from most homes and because it is difficult to estimate radon exposures that people have received over their lifetimes. In addition, it is clear that far more lung cancers are caused by smoking than are caused by radon.Epidemiologic",1
"radon studies have found trends to increased lung cancer risk from radon with a no evidence of a threshold, and evidence against a threshold above high as 150 Bq/m3 (almost exactly the EPA's action level of 4 pCi/L). Another study similarly found that there is no evidence of a threshold but lacked the statistical power to clearly identify the threshold at this low level.",1
"Notably, the latter deviance from zero at low level convinced the World Health Organization that, ""The dose-response relation seems to be linear without evidence of a threshold, meaning that the lung cancer risk increases proportionally with increasing radon exposure.""The most elaborate case-control epidemiologic radon study performed by R. William Field and colleagues identified a 50% increased lung cancer risk with prolonged radon exposure at the EPA's action level of 4 pCi/L. Iowa has the highest average radon concentrations in the United States and a very stable population which added to the strength of the study.",1
"For that study, the odds ratio was found to be increased slightly above the confidence interval (95% CI) for cumulative radon exposures above 17 WLM (6.2 pC/L=230 Bq/m3 and above). The results of a methodical ten-year-long, case-controlled study of residential radon exposure in Worcester County, Massachusetts, found an apparent 60% reduction in lung cancer risk amongst people exposed to low levels (0–150 Bq/m3) of radon gas; levels typically encountered in 90% of American homes—an apparent support for the idea of radiation hormesis. In that study, a significant result (95% CI) was obtained for the 75–150 Bq/m3 category.",1
"Nevertheless, epidemiological evidence shows a clear link between breathing high concentrations of radon and incidence of lung cancer.",1
"This study also assumes 60 patients represents all patients. This study also did not record if any patients taken any NSAIDS. The study also claims that the therapeutic benefit comes form the ""integration of radon into the skin"".",1
"The activities might range from 2 to 200 MBq/seed. The gamma rays are produced by radon and the first short-lived elements of its decay chain (218Po, 214Pb, 214Bi, 214Po). Radon and its first decay products being very short-lived, the seed is left in place. After 11 half-lives (42 days), radon radioactivity is at 1/2 000 of its original level. At this stage, the predominant residual activity is due to the radon decay product 210Pb, whose half-life (22.3 years) is 2 000 times that of radon, and its descendants 210Bi and 210Po, totalling 0.03% of the initial seed activity.",1
"They identified the barriers to change as limited public knowledge of the dangers of radon exposure, the perceived high costs of mitigation, and the availability of radon testing. As a result, they also identified major ways to create change: demonstrate the importance of testing and the ease of mitigation, provide incentives for testing and mitigation, and build the radon services industry. To complete these goals, representatives from each organization and department established specific commitments and timelines to complete tasks and continued to meet periodically. However, FRAP was concluded in 2016 as The National Radon Action Plan took over.",1
"In the final report on commitments, it was found that FRAP completed 88% of their commitments. They reported achieving the highest rates of radon mitigation and new construction mitigation in the United States as of 2014. FRAP concluded that because of their efforts, at least 1.6 million homes, schools, and childcare facilities received direct and immediate positive effects.",1
"The goals of NRAP are to continue efforts set forth by FRAP to eliminate radon induced cancer that can be prevented by expanding radon testing, mitigating high levels of radon exposure, and developing radon resistant construction. NRAP also aims to reduce radon risk in 5 million homes, and save 3,200 lives by 2020.",1
"The only dose-effect relationship available are those of miners cohorts (for much higher exposures), exposed to radon. Studies of Hiroshima and Nagasaki survivors are less informative (the exposure to radon is chronic, localized, and the ionizing radiations are alpha rays). Although low-exposed miners experienced exposures comparable to long-term residence in high-radon dwellings, the mean cumulative exposure among miners is approximately 30-fold higher than that associated with long-term residency in a typical home. Moreover, the smoking is a significant confounding factor in all miners' studies.",1
"It can be concluded from miner studies that when the radon exposure in dwellings compares to that in mines (above 1000 Bq/m3), radon is a proven health hazard; but in the 1980s very little was known on the dose-effect relationship, both theoretically and statistical. Studies have been made since the 1980s, both on epidemiological studies and in the radiobiology field. In the radiobiology and carcinogenesis studies, progress has been made in understanding the first steps of cancer development, but not to the point of validating a reference dose-effect model.",1
"The only certainty gained is that the process is very complex, the resulting dose-effect response being complex, and most probably not a linear one. Biologically based models have also been proposed that could project substantially reduced carcinogenicity at low doses. In the epidemiological field, no definite conclusion has been reached. However, from the evidence now available, a threshold exposure, that is, a level of exposure below which there is no effect of radon, cannot be excluded.Given",1
"the radon distribution observed in dwellings, and the dose-effect relationship proposed by a given model, a theoretical number of victims can be calculated, and serve as a basis for public health policies. With the BEIR VI model, the main health effect (nearly 75% of the death toll) is to be found at low radon concentration exposures, because most of the population (about 90%) lives in the 0–200 Bq/m3 range.",1
"Under this modeling, the best policy is obviously to reduce the radon levels of all homes where the radon level is above average, because this leads to a significant decrease of radon exposure on a significant fraction of the population; but this effect is predicted in the 0–200 Bq/m3 range, where the linear model has its maximum uncertainty. From the statistical evidence available, a threshold exposure cannot be excluded; if such a threshold exists, the real radon health effect would in fact be limited to those homes where the radon concentrations reaches that observed in mines—at most a few percent.",1
"If a radiation hormesis effect exists after all, the situation would be even worse: under that hypothesis, suppressing the natural low exposure to radon (in the 0–200 Bq/m3 range) would actually lead to an increase of cancer incidence, due to the suppression of this (hypothetical) protecting effect. As the low-dose response is unclear, the choice of a model is very controversial.",1
"No conclusive statistics being available for the levels of exposure usually found in homes, the risks posed by domestic exposures is usually estimated on the basis of observed lung-cancer deaths caused by higher exposures in mines, under the assumption that the risk of developing lung-cancer increases linearly as the exposure increases. This was the basis for the model proposed by BEIR IV in the 1980s. The linear no-threshold model has since been kept in a conservative approach by the UNSCEAR report and the BEIR VI and BEIR VII publications, essentially for lack of a better choice:Until the [...]",1
"uncertainties on low-dose response are resolved, the Committee believes that [the linear no-threshold model] is consistent with developing knowledge and that it remains, accordingly, the most scientifically defensible approximation of low-dose response. However, a strictly linear dose response should not be expected in all circumstances. The BEIR VI committee adopted the linear no-threshold assumption based on its understanding of the mechanisms of radon-induced lung cancer, but recognized that this understanding is incomplete and that therefore the evidence for this assumption is not conclusive.",1
"In discussing these figures, it should be kept in mind that both the radon distribution in dwelling and its effect at low exposures are not precisely known, and the radon health effect has to be computed (deaths caused by radon domestic exposure cannot be observed as such). These estimations are strongly dependent on the model retained. According to these models, radon exposure is thought to be the second major cause of lung cancer after smoking.Iowa",1
"to radon only, and 5.5% to a combination of radon and smoking.The World Health Organization has recommended a radon reference concentration of 100 Bq/m3 (2.7 pCi/L). The European Union recommends that action should be taken starting from concentrations of 400 Bq/m3 (11 pCi/L) for older dwellings and 200 Bq/m3 (5 pCi/L) for newer ones. After publication of the North American and European Pooling Studies, Health Canada proposed a new guideline that lowers their action level from 800 to 200 Bq/m3 (22 to 5 pCi/L).",1
"The EPA estimates that nationally, 8% to 12% of all dwellings are above their maximum ""safe levels"" (four picocuries per liter—the equivalent to roughly 200 chest x-rays). The United States Surgeon General and the EPA both recommend that all homes be tested for radon. The limits retained do not correspond to a known threshold in the biological effect, but are determined by a cost-efficiency analysis. EPA believes that a 150 Bq/m3 level (4 pCi/L) is achievable in the majority of homes for a reasonable cost, the average cost per life saved by using this action level is about $700,000.For",1
"Long-term kits, taking collections for 3 months up to one year, are also available. An open-land test kit can test radon emissions from the land before construction begins. A Lucas cell is one type of long-term device. A Lucas cell is also an active device, or one that requires power to function. Active devices provide continuous monitoring, and some can report on the variation of radon and interference within the testing period. These tests usually require operation by trained testers and are often more expensive than passive testing. The National Radon Proficiency Program (NRPP) provides a list of radon measurement professionals.Radon",1
"levels fluctuate naturally. An initial test might not be an accurate assessment of a home's average radon level. Transient weather can affect short term measurements.[95] Therefore, a high result (over 4 pCi/L) justifies repeating the test before undertaking more expensive abatement projects. Measurements between 4 and 10 pCi/L warrant a long-term radon test. Measurements over 10 pCi/L warrant only another short-term test so that abatement measures are not unduly delayed. Purchasers of real estate are advised to delay or decline a purchase if the seller has not successfully abated radon to 4 pCi/L or less.[95]Since",1
"radon concentrations vary substantially from day to day, single grab-type measurements are generally not very useful, except as a means of identifying a potential problem area, and indicating a need for more sophisticated testing. The EPA recommends that an initial short-term test be performed in a closed building. An initial short-term test of 2 to 90 days allows residents to be informed quickly in case a home contains high levels of radon. Long-term tests provide a better estimate of the average annual radon level.",1
"The high cost of radon remediation in the 1980s led to detractors arguing that the issue is a financial boondoggle reminiscent of the swine flu scare of 1976. They further argued that the results of mitigation are inconsistent with lowered cancer risk, especially when indoor radon levels are in the lower range of the actionable exposure level. International Radon Project Lucas cell Radon mitigation Radon removal Radiation Exposure Compensation Act Radiohalo",1
"Toxicological Profile for Radon, Draft for Public Comment, Agency for Toxic Substances and Disease Registry, September 2008 Health Effects of Exposure to Radon: BEIR VI. Committee on Health Risks of Exposure to Radon (BEIR VI), National Research Council available on-line UNSCEAR 2000 Report to the General Assembly, with scientific annexes: Annex B: Exposures from natural radiation sources. Should you measure the radon concentration in your home?, Phillip N. Price, Andrew Gelman, in Statistics: A Guide to the Unknown, January 2004.",1
"There are certain levels of harmfulness in which the different types of trash have; therefore, there are different types of liner systems which are required for these different types of disposal sites. The first type is single liner-systems. These systems usually are put within landfills which mostly hold construction rubble. These landfills are not meant to hold the disposal of harmful liquid wastes such as paint, tar, or any other type of liquid garbage that can easily seep through a single liner system. The second type is double-liner systems.",1
"The leachate system is surrounded in a by a type of solid drainage layer such as gravel which is enclosed by a geomembrane and compressed clay, also known as a geosynthetic clay liner. This geosynthetic clay liner is usually made of sodium bentonite which is compacted in between two thick pieces of geotextile. The next material surrounding the composite liner would be a leak detection system composed of another material like gravel with an additional geomembrane or complex liner.",1
"The geosynthetic clay liners are manufactured by factories and the purpose for it being made of sodium bentonite is that they regulate the movement of liquids in gases within the waste. The geocomposites which are a combination of the geomembranes and geosynthetic liner material also include a layer of bentonite between the middle of the layers of geotextile; however, airspace is allowed to be implemented. It is then topped off with a final cover.",1
The main role a composite liner performs in a municipal solid waste system for landfills is reducing the amount of leakage through small seep holes that sometimes form in the geomembrane part of the composite liner. The protection layer part serves as a preventer from these holes from forming inside the geomembrane which would allow the waste to leak through the entire liner. It also takes away the pressure and stress which can cause cracking and holes from forming in the membrane as well.,1
"The ideal method of assessing the amount of liner degradation would be by examining field samples over their service life. Due to the lengths of time required for field sampling tests, various laboratory-accelerated ageing tests have been developed to measure the important mechanical properties.",1
"Tensile strength represents the ability for a geomembrane to resist tensile stress. Geomembranes are most commonly tested for tensile strength using one of three methods; the uniaxial tensile test described in ASTM D639-94, the wide-strip tensile test described in ASTM D4885-88, and the multiaxial tension test described in ASTM D5617-94. The difference in these three methods lies in the boundaries imposed into the test specimens. Uniaxial tests do not provide lateral restraint during testing and thus tests the sample under uniaxial stress conditions. During the wide-strip test the sample is restrained laterally while the middle portion is unrestrained.",1
The multiaxial tensile test provides a plane stress boundary condition at the edges of the sample. A typical range of tensile strengths in the machine direction are from 225 to 245 lb/in for 60-mil HDPE to 280 to 325 lb/in for 80-mil HDPE.,1
"Tear resistance of a geomembrane becomes important when it is exposed to high winds or handling stress during installation. There are various ASTM methods for measuring tear resistance of geomembranes, with most common reports using ASTM D1004. Typical tear resistances show a value of 40 to 45 lb for 60-mil HDPE and 50 to 60 lb for 80-mil HDPE.",1
"Impact resistance provides an assessment of the effects of impacts from falling objects which can either tear or weaken the geomembrane. As with the previous mechanical properties, there are various ASTM methods for assessment. Significantly higher impact resistances are realized when geotextiles are placed above or below the geomembrane. Thicker geomembranes also display higher impact resistances.",1
"Puncture resistance of a geomembrane is important due to the heterogeneous material above and below a typical liner. Rough surfaces, such as stones or other sharp objects, may puncture a membrane if it does not have sufficient puncture resistance. Various methods beyond standard ASTM tests are available; one such method, the critical cone height test, measures the maximum height of a cone on which a compressed geomembrane, which is subjected to increasing pressure, does not fail. HDPE samples typically have a critical cone height of around 1 cm.",1
Geomembrane / Pond Liner Bioclogging Biogas Daily cover Landfill mining Landfills in the United States Waste compaction,1
"The laser would operate in a pulsed fashion to avoid the target from self-shielding via its ablated plasma. The power levels of lasers in this concept are well below the power levels in concepts for more rapidly effective anti-satellite weapons. Research into this field reveal the precise physical constraints required, noting the significant relevance to the space debris's orientation and resultant trajectory of the ablated object. Using a laser guide star and adaptive optics, a sufficiently large ground-based laser (1 megajoule pulsed HF laser) can offset the orbits of dozens of debris daily at a reasonable cost.",1
"The Space Shuttle routinely showed evidence of ""tiny"" impacts upon post-flight inspection.Orion was a proposed ground-based laser broom project in the 1990s, estimated to cost $500 million.A space-based laser also called ""Project Orion"" was planned to be installed on the International Space Station in 2003. In 2015, Japanese researchers proposed adding laser broom capabilities to the Extreme Universe Space Observatory telescope, to be launched to the ISS in 2017.In 2014, the European CLEANSPACE project published a report studying a global architecture of debris tracking and removal laser stations.",1
"2000 Earth Orbital Debris - NASA Research on Satellite and Spacecraft Effects by World Spaceflight News, CD-ROM: 862 pages ISBN 1-893472-28-0 BBC News report on Laser broom Space Station gets high tech broom ABC NASA Hopes Laser Broom Will Help Clean Up Space Debris Agence France-Presse story via SpaceDaily Orbiting Junk Continues to Threaten International Space Station Space.com",1
Shuttle to test space junk broom New Scientist SpaceViews July 1997: Articles ORION: A Solution to the Orbital Debris Problem by Claude Phipps Wired October 2011: Space Junk Crisis: Time to Bring in the Lasers story on Wired Removing Orbital Debris with Pulsed Lasers,1
"As of 2023, the United States has 2,538 industrial laundry facilities which may discharge an average of 400 m3 of wastewater every day. Annually, about 5.11 km3 laundry wastewater is produced, which can fill 1,460 Superdomes in New Orleans.",1
"There are several parameters in the evaluation of laundry wastewater: temperature, pH-value, suspended substances, Cl2, sediment substances, total nitrogen, total phosphorus, nitrogen ammonia, chemical oxygen demand(COD), biochemical oxygen demand(BOD5), anionic surfactants.",1
"Nonionic surfactants are able to bind to both proteins and phospholipid membrane, leading to leakage of low molecular mass compounds by increasing the permeability of membranes and vesicles. This may result in serious damage in cells or even cell death.",1
"Researchers also prove that biodegradation process is restricted in 20–40 mg/L and even inhibited at a higher concentration, which leads to the incomplete biodegradation of LAS in sewage treatment plants.",1
"Excessive phosphorus can make for excessive production of autotrophs, like algae and cyanobacteria, leading to eutrophication in an inorganic nutrient pathway. Nutrient enrichment in lakes and reservoirs results in the microscopic floating plants, algae and formation of dense mats of larger floating plants that can produce oxygen by photosynthesis. When they die and sink to the bottom, they consume oxygen in decomposition. Bacteria thriving in this process consume oxygen. With the depletion of oxygen, fishes die and anaerobic bacteria produce methane, hydrogen sulfide and ammonia, which can destroy the ecosystem.",1
"+ NO−3 + 5H2O → 2Fe(OH)3 + NO−2 + 4H+ (∆G°=-103.5 kJ/mol) The microbial oxidation of ferrous iron coupled to denitrification (with nitrite or dinitrogen gas being the final product) can be autotrophic using inorganic carbon or organic co-substrates (acetate, butyrate, pyruvate, ethanol) performing heterotrophic growth in the absence of inorganic carbon. It has been suggested that the heterotrophic nitrate-dependent ferrous iron oxidation using organic carbon might be the most favorable process. This metabolism might be very important for carrying out an important step in the biogeochemical cycle within the OMZ.",1
"Despite being phylogenetically diverse, the microbial ferrous iron oxidation metabolic strategy (found in Archaea and Bacteria) is present in 7 phyla, being highly pronounced in the phylum Pseudomonadota (formerly Proteobacteria), particularly the Alpha, Beta, Gamma, and Zetaproteobacteria classes, and among the Archaea domain in the ""Euryarchaeota"" and Thermoproteota phyla, as well as in Actinomycetota, Bacillota, Chlorobiota, and Nitrospirota phyla.There are very well-studied iron-oxidizing bacterial species such as Thiobacillus ferrooxidans, and Leptospirillum ferrooxidans, and some like Gallionella ferruginea and Mariprofundis ferrooxydans are able to produce a particular extracellular stalk-ribbon structure rich in iron, known as a typical biosignature of microbial iron oxidation.",1
"At neutrophilic pHs (hydrothermal vents, deep ocean basalts, groundwater iron seeps) the oxidation of iron by microorganisms is highly competitive with the rapid abiotic reaction occurring in <1 min. Therefore, the microbial community has to inhabit microaerophilic regions where the low oxygen concentration allows the cell to oxidize Fe(II) and produce energy to grow. However, under acidic conditions, where ferrous iron is more soluble and stable even in the presence of oxygen, only biological processes are responsible for the oxidation of iron, thus making ferrous iron oxidation the major metabolic strategy in iron-rich acidic environments.In",1
"It was first isolated from the Kamaʻehuakanaloa Seamount (formerly Loihi) vent field, near Hawaii at a depth between 1100 and 1325 meters, on the summit of this shield volcano. Vents can be found ranging from slightly above ambient (10 °C) to high temperature (167 °C). The vent waters are rich in CO2, Fe(II) and Mn. Large, heavily encrusted mats with a gelatinous texture are created by iron-oxidizing bacteria as a by-product (iron-oxyhydroxide precipitation), and can be present around the vent orifices. The vents present at Kamaʻehuakanaloa seamount can be categorized into two types based on concentration and temperature of flow.",1
"Those with a focused and high-temperature flow (above 50 °C) can be expected to show higher flow rates as well. These vents are characterized by flocculent mats aggregated around the vent orifices. Mat depth at focused, high-temperature vents averages in the tens of centimeters, but can vary. In contrast, vents with cooler (10-30 °C) and diffuse flow can create mats up to one meter thick. These mats may cover hundreds of square meters of sea floor. Either type of mat can be colonized by other bacterial communities, which can change the chemical composition and the flow of the local waters.",1
"Unlike most lithotrophic metabolisms, the oxidation of Fe2+ to Fe3+ yields very little energy to the cell (∆G° = 29 kJ/mol and ∆G° = -90 kJ/mol in acidic and neutral environments, respectively) compared to other chemolithotrophic metabolisms. Therefore, the cell must oxidize large amounts of Fe2+ to fulfill its metabolic requirements while contributing to the mineralization process (through the excretion of twisted stalks). The aerobic iron-oxidizing bacterial metabolism is thought to have made a remarkable contribution to the formation of the largest iron deposit (banded iron formation (BIF)) due to the advent of oxygen in the atmosphere 2.7",1
"billion years ago (produced by cyanobacteria).However, with the discovery of Fe(II) oxidation carried out under anoxic conditions in the late 1990s using light as an energy source or chemolithotrophically, using a different terminal electron acceptor (mostly NO3−), the suggestion arose that anoxic Fe2+ metabolism may pre-date aerobic Fe2+ oxidation and that the age of the BIF pre-dates oxygenic photosynthesis. This suggests that microbial anoxic phototrophic and anaerobic chemolithotrophic metabolism may have been present on the ancient earth, and together with Fe(III) reducers, they may have been responsible for the BIF in the Precambrian eon.",1
"Currently the concentration of carbon dioxide in the atmosphere is around 420 ppm (120 ppm more than 20 million years ago), and about a quarter of the total CO2 emission enters the oceans (2.2 pg C year−1). Reacting with seawater it produces bicarbonate ion (HCO3−) and thus the ocean acidity increases. Furthermore, the temperature of the ocean has increased by almost one degree (0.74 °C) causing the melting of big quantities of glaciers contributing to the sea-level rise. This lowers the O2 solubility by inhibiting the oxygen exchange between surface waters, where O2 is very abundant, and anoxic deep waters.All",1
"More serious problems occur when bacteria build up in well systems. Iron bacteria in wells do not cause health problems, but they can reduce well yields by clogging screens and pipes. Treatment techniques that may successfully remove or reduce iron bacteria include physical removal, pasteurization, and chemical treatment. Treatment of heavily infected wells may be difficult, expensive, and only partially successful. Recent application of ultrasonic devices that destroy and prevent the formation of biofilm in wells has been proven to prevent iron bacteria infection and the associated clogging very successfully.Physical removal is typically done as a first step.",1
"There are various lead abatement techniques to remove residential lead-based paint and lead in household dusts. Encapsulation and enclosure makes the hazard of lead-based paint inaccessible, while chemical stripping, removal of abrasives, scraping with the hand, and component replacement are effective in permanently removing lead-based paints from households. Encapsulation refers to the technique that coats all lead-contaminated surfaces with a special liquid coating, which provides a long-lasting and effective barrier and prevents lead dust particles from being released.",1
"Enclosure refers to covering all lead-contaminated surfaces and objects with a solid, dust-tight barrier, which is effective in not exposing children to harmful lead paint but is not a permanent solution. Removal is the act of scraping, stripping, vacuuming, and blasting lead-based paint from contaminated surfaces. Replacement is the simple removal and substitution of only objects contaminated with lead, such as lead-painted doors and windows. However, residential lead abatement practices are relatively expensive, and some practices are ineffective and could even worsen the current situation.",1
"For risk assessment, it is recommended by the US EPA that more than two dust and soil samples are taken. Remediation technologies and methods for lead contaminated soils include excavation and off-site disposal to permanently remove the contaminated soils from the site, containment technologies (such as asphalt capping) to reduce human health exposure and hazards, and traditional techniques (such as washing and stabilizing soil). In addition, it is important that there is a comprehensive nationwide understanding by the people of the hazards and proper removal of lead contaminated soils.",1
"Specific, official guidelines for removal or covering of lead-contaminated soil can be found in the US EPA guidance issues in 1994, also known as the Section 403 Guidance. Lead abatement and RRP (Renovation, Repair, and Painting) activities are similar in that they are both performed in target housing and child-occupied facilities. In the United States, they are both protected under OSHA 29 CFR 1926.62 and required to post signage in lead-related work areas.However, even though the activities performed look similar, lead abatement and RRP activities are also very different.",1
"Lead abatement is a specialized activity that is performed to permanently eliminate lead-based paint hazards and is usually done based on orders from state or local governments after a serious lead-related incident. Meanwhile, RRP activities are only performed at the discretion and desire of the home or facility owner to temporarily minimize lead-related hazards for aesthetic or lead-unrelated purposes.",1
"Laws and policies involving lead abatement activities are enforced and kept in check by the EPA, local government, and state government. All lead-based paint activities intended by state governments and facility owners must receive proper authorization from the EPA before being carried out. Because working with lead poses health risks and even permanent damage to health, it is important that lead abatement workers, supervisors, inspectors, and other individuals dealing with lead-based paint strictly comply to the following regulations.",1
"Individuals performing lead abatement activities in the home environment or child-occupied facilities must be properly trained, take classes, and get certified; training programs providing instruction in such activities must be accredited and approved by the EPA; and these activities must be carried out in accordance to reliable, effective, and safe work practice standards, as defined by OSHA. Improper lead abatement or removal by the incorrect method or by an unlicensed individual can result in severe consequences. If lead abatement is improperly managed or carried out, chips and dust can pose additional health hazards. Furthermore, the current situation can worsen as well.",1
"Many paints contain much more lead content than regulatory standards allow. It is important to note that the regulatory standards can be misleading as well. For example, in China, the safe lead content criteria is based on soluble lead levels, not total lead levels; this can lead to paints being labeled as safe even when they contain harmful concentrations of lead. It was also found in a study that colored paints have more lead concentrations than pure white paints, most likely due to lead being added for additional color enhancement.",1
"As such, even with regulatory standards for lead content in paints, there are still paints with lead being produced around the world. It has been observed that paints produced in third world, developing countries contain higher lead content than those produced in first world, developed countries. The production and consumption of lead-based paints is actually growing in developing countries. In these developing countries, many of which do not have the proper resources, personnel, technology, and tools to remove lead from their paints. Thus, many lead-related illnesses and defects, especially in children, are arising in these countries.",1
"In order to prevent the detrimental effects of the production and consumption of lead-based paints, the United Nations Environment Program (UNEP) has initiated the Global Alliance to Eliminate Lead Paint to prevent exposure to lead through advocating the phase-out of paints containing lead. Through these kinds of programs, it is important that all countries worldwide understand what lead-based paints are, what the effects and risks of lead-based paints are, what alternatives to lead-based paints there are, and what the proper removal methods and strategies are.",1
"The intensity of roadway noise is governed by the following variables: traffic operations (speed, truck mix, age of vehicle fleet), roadway surface type, tire types, roadway geometrics, terrain, micrometeorology and the geometry of area structures. Due to the complexity of the variables, a line source acoustic model must be a computer model that can analyze sound levels in the vicinity of roadways. The first meaningful models arose in the late 1960s and early 1970s. Two of the leading research teams were BBN in Boston and ESL Inc. of Sunnyvale, California.",1
"The Lodge Fume Deposit Company Limited was founded in Birmingham, England in 1913 by Sir Oliver Lodge who pioneered the electrostatic precipitation technique for removing dust. In 1922, the Lodge Fume Company changed its name to Lodge-Cottrell Ltd. in honor of Frederick Gardner Cottrell's additional contributions to the development electrostatic precipitation. Lodge Cottrell Ltd website",1
Listeners hear a speech recorded with background noise better than they hear a speech which has been recorded in quiet with masking noise applied afterwards.,1
"people can learn control with feedback.The Lombard effect also occurs following laryngectomy when people following speech therapy talk with esophageal speech. The intelligibility of an individual's own vocalization can be adjusted with audio-vocal reflexes using their own hearing (private loop), or it can be adjusted indirectly in terms of how well listeners can hear the vocalization (public loop). Both processes are involved in the Lombard effect.",1
"A speaker can regulate their vocalizations, particularly their amplitude relative to background noise, with reflexive auditory feedback. Such auditory feedback is known to maintain the production of vocalization since deafness affects the vocal acoustics of both humans and songbirds Changing the auditory feedback also changes vocalization in human speech or bird song. Neural circuits have been found in the brainstem that enable such reflex adjustment.",1
"A speaker can regulate their vocalizations at higher cognitive level in terms of observing its consequences on their audience's ability to hear it. In this auditory self-monitoring adjusts vocalizations in terms of learnt associations of what features of their vocalization, when made in noise, create effective and efficient communication. The Lombard effect has been found to be greatest upon those words that are important to the listener to understand a speaker suggesting such cognitive effects are important.",1
Both private and public loop processes exist in children. There is a development shift however from the Lombard effect being linked to acoustic self-monitoring in young children to the adjustment of vocalizations to aid its intelligibility for others in adults.,1
The Lombard effect depends upon audio-vocal neurons in the periolivary region of the superior olivary complex and the adjacent pontine reticular formation. It has been suggested that the Lombard effect might also involve the higher cortical areas that control these lower brainstem areas. Choral singers experience reduced feedback due to the sound of other singers upon their own voice. This results in a tendency for people in choruses to sing at a louder level if it is not controlled by a conductor.,1
"Mixed metal catalysts, such a Ce/Mn, Co/Ce, Ag/Ce, have also been effective in improving the treatment achieved in a WAO system.A special type of wet oxidation process was the so-called ""VerTech process"" system. A system of this type operated in Apeldoorn, Netherlands between 1994 and 2004. The system was installed in a below-ground pressure vessel (also called a gravity pressure vessel or GPV). The pressure was supplied by feeding the material to a reactor with a depth of 1,200 metres (3,900 ft). The deep shaft reactor also served as a heat exchanger, so no pre-heating was required.",1
"The operating temperature was about 270 °C with a pressure of about 100 bars (1,500 psi). The installation was eventually shut down due to operational problems.",1
"The convention was called for by the United Nations Conference on the Human Environment (June 1972, Stockholm), the treaty was drafted at the Intergovernmental Conference on the Convention on the Dumping of Wastes at Sea (13 November 1972, London) and it was opened for signature on 29 December 1972. It entered into force on 30 August 1975 when 15 nations ratified. As of 1 October 2001, there were 78 Contracting Parties to the convention. International Administration of the Convention functions through Consultative Meetings held at International Maritime Organization (IMO) headquarters in London.",1
"The London Convention consists of 22 Articles and three Annexes. It follows a ""black list/grey list"" approach to regulating ocean dumping; Annex I materials (black list) generally may not be ocean dumped (though for certain Annex I materials dumping may be permissible if present only as ""trace contaminants"" or ""rapidly rendered harmless"" and Annex II materials (grey list) require ""special care"". Annex III lays out general technical factors to be considered in establishing criteria for issuance of ocean dumping permits.",1
"The main objective of the London Convention is to prevent indiscriminate disposal at sea of wastes that could be liable for creating hazards to human health; harming living resources and marine life; damaging amenities; or interfering with other legitimate uses of the sea. The 1972 Convention extends its scope over ""all marine waters other than the internal waters"" of the States and prohibits the dumping of certain hazardous materials. It further requires a prior special permit for the dumping of a number of other identified materials and a prior general permit for other wastes or matter.",1
"The convention is implemented in the United States through Title I of the Marine Protection, Research, and Sanctuaries Act (MPRSA) which directs that implementing regulations are to apply binding requirements of LC to the extent that this would not relax the MPRSA.",1
"the most important innovations brought by the 1996 protocol is the codification of the ""precautionary approach"" and the ""polluter pays principle."" Reflecting these principles, the protocol embodies a major structural revision of the convention the so-called ""reverse list"" approach. Now, instead of prohibiting the dumping of certain (listed) hazardous materials, the parties are obligated to prohibit the dumping of any waste or other matter that is not listed in Annex 1 (""the reverse list"") of the 1996 protocol. Dumping of wastes or other matter on this reverse list requires a permit.",1
Parties to the protocol are further obligated to adopt measures to ensure that the issuance of permits and permit conditions for the dumping of reverse list substances comply with Annex 2 (the Waste Assessment Annex) of the protocol.,1
"The substances on the reverse list include dredged material; sewage sludge; industrial fish processing waste; vessels and offshore platforms or other man-made structures at sea; inert, inorganic geological material; organic material of natural origin; and bulky items including iron, steel, concrete and similar materials for which the concern is physical impact, and limited to those circumstances where such wastes are generated at locations with no land-disposal alternatives.",1
"In addition, the 1996 protocol prohibits altogether the practice of incineration at sea, except for emergencies, and prohibits the exports of wastes or other matter to non-Parties for the purpose of dumping or incineration at sea. The 1996 protocol has effectively moved the scope of the original London convention landwards, relating it to the policy and management issues of land as well as sea wastes disposal.",1
"Relaying on its vast ICM technical expertise, the National Ocean Service (NOS) is to contribute to the creation of the necessary foundation for the US accession to the 1996 Protocol and, further on, to the protocol's implementation. Through its International Program Office, NOS would also contribute to the international co-operation efforts towards meeting the objectives of the 1996 Protocol. The legal interpretation about carbon capture and storage (CCS) is uncertain. The sub-seabed wastes fall within the scope of the treaty, which can prohibit CCS projects like the injection of CO2 into offshore platforms built into sub-seabed geological formations.",1
"State parties - (87 as of 2013) Afghanistan, Angola, Antigua and Barbuda, Argentina, Australia, Azerbaijan, Barbados, Belarus (ratified as Byelorussian SSR), Belgium, Benin, Bolivia, Brazil, Bulgaria, Canada, Cape Verde, Chile, People's Republic of China, Democratic Republic of the Congo, Costa Rica, Côte d'Ivoire, Croatia, Cuba, Cyprus, Denmark, Dominican Republic, Egypt, Equatorial Guinea, Finland, France, Gabon, Germany, Greece, Guatemala, Haiti, Honduras, Hungary, Iceland, Iran, Ireland, Italy, Jamaica, Japan (ratified but w/ exclusion), Jordan, Kenya, Kiribati, South Korea, Libya, Luxembourg, Malta, Mexico, Monaco, Montenegro, Morocco, Nauru, Netherlands, New Zealand, Nigeria, Norway, Oman, Pakistan, Panama, Papua New Guinea, Peru, Philippines, Poland, Portugal, Russia (ratified",1
"EPA summary of convention NOAA summary of convention CIA World Factbook, as of 2003 edition",1
"and during the day restricts it to a higher sound level; however, enforcement is uneven. Many municipalities do not follow up on complaints. Even where a municipality has an enforcement office, it may only be willing to issue warnings, since taking offenders to court is expensive. A notable exception to this rule is the City of Portland, Oregon, which has instituted an aggressive protection for its citizens with fines reaching as high at $5000 per infraction, with the ability to cite a responsible noise violator multiple times in a single day.Under",1
"the Occupational Safety and Health Act of 1970, employers are responsible for providing safe and healthful workplaces for their employees. OSHA's role is to ensure these conditions for America's working men and women by setting and enforcing standards, and providing training, education and assistance. The same Act charges the National Institute for Occupational Safety and Health (NIOSH) with recommending occupational safety and health standards.",1
NIOSH communicates these recommended standards to regulatory agencies (including OSHA) and to others in the occupational safety and health community through the publication and dissemination of Criteria Documents such as the Criteria for A Recommended Standard - Occupational Noise Exposure.,1
"with about half of the states and hundreds of cities passing substantive noise control laws. The EPA coordinated all federal noise control activities through its Office of Noise Abatement and Control. The EPA phased out the office's funding in 1982 as part of a shift in federal noise control policy to transfer the primary responsibility of regulating noise to state and local governments. However, the Noise Control Act of 1972 and the Quiet Communities Act of 1978 were never rescinded by Congress and remain in effect today, although essentially unfunded.The",1
"Federal Aviation Administration (FAA) regulates aircraft noise by specifying the maximum noise level that individual civil aircraft can emit through requiring aircraft to meet certain noise certification standards. These standards designate changes in maximum noise level requirements by ""stage"" designation. The U.S. noise standards are defined in the Code of Federal Regulations (CFR) Title 14 Part 36 – Noise Standards: Aircraft Type and Airworthiness Certification (14 CFR Part 36). The FAA also pursues a program of aircraft noise control in cooperation with the aviation community.The",1
"also have noise ordinances, which specifies the allowable sound level that can cross property lines. These ordinances can be enforced with local police powers.",1
"Japan actually passed the first national noise control act, but its scope was much more limited than the U.S. law, addressing mainly workplace and construction noise.",1
"cities have prepared noise ordinances that give noise control officers and police the power to investigate noise complaints and enforcement power to abate the offending noise source, through shutdowns and fines. In the 1970s and early 1980s there was even a professional association for noise enforcement officers called NANCO, ""National Association of Noise Control Officials."" Today only a handful of properly trained Noise Control Officers remain in the United States.",1
"A typical noise ordinance sets forth clear definitions of acoustic nomenclature and defines categories of noise generation; then numerical standards are established, so that enforcement personnel can take the necessary steps of warnings, fines or other municipal police power to rectify unacceptable noise generation. Ordinances have achieved certain successes but they can be thorny to implement. Many European cities are still treating noise as the U.S. did in the 1960s, as a nuisance and not as a numerical standard to be achieved.",1
"The third type is psychological that adversely effects a person's welfare; examples are distraction, annoyance, and complaint. The only feasible legal basis for a community's right to control noise is based on these adverse health and welfare effects. It is clearly easier to uphold the constitutionality of a noise ordinance in a court of law if it can be shown that it is based on health and welfare concerns. The following is a short list of recognized effects of noise that can be addressed as a reason for a noise ordinance.",1
"Excess non-Occupational noise exposure, hearing loss on both public and private property, speech interference on both public and private property, audio interference on both public and private property, and sleep interference on mostly private property.",1
"There are several fundamental issues that shape the legality, effectiveness and enforceability of any community noise regulation.",1
Any restriction on interstate motor carriers or railroads may NOT be for the purpose of noise control. States have police powers granted by the Constitution. They may also enact regulations that are no more strict than federal regulations. They may also preempt local ordinances. California and New Jersey have comprehensive noise codes that communities must meet. Many states required that local ordinances be no more strict than the state code whether such code exists or not.,1
One relatively common preemption is protection of shooting ranges from noise regulation or litigation and right to farm laws that protect agricultural areas from nuisance litigation by encroaching residential areas.,1
"In one state court case, the court declared that numerical sound levels were constitutional as not void for vagueness, as the term plainly audible provided it was associated with a reasonable distance. Two requirements for a noise ordinance provision is that: provide fair warning avoid the possibility of arbitrary enforcement",1
"In one Supreme Court case the court ruled that the specificity of the city ordinance regulating school verbal protests was not constitutionally vague, gave fair warning, and was not an invitation to arbitrary enforcement and so was not overbroad, despite the implied limitation on free speech.",1
Nuisance law applies to both community noise regulation as well as private suits brought to court to reduce noise impact.,1
"Care must be taken in writing a subjective noise provision so that it overcomes the objections listed above. Care must be taken when writing an objective noise provision to make sure that the sound levels are physically realizable. For example, requiring the maximum sound level of an automobile to be 40 dB(A) or the maximum sound level in a residential zone to be 30 dB(A) opens the provision to an enforceability challenge.",1
"Fixed sound sources must be treated differently than moving sources. In the former case, the listener is normally defined while for moving sources it is not. Historically, regulations were enforced by the subjective judgment of an enforcing officer. With the advent of sound measuring equipment, the judgment can be based on measured sound levels. Most comprehensive noise ordinances contain four types of provisions.Subjective Emission These regulations allow an official to decide if the output of a sound source is acceptable without recourse to sound measurements and without regard to the presence of a specific listener.",1
Regulations with plainly audible terms on public property as a criterion are examples. Subjective Immission These regulations allow an official to decide if the sound received by a listener is acceptable without recourse to sound measurements and without regard for the specific sound power generated by the source. Regulations with plainly audible or noise disturbance terms on private property as a criterion are examples. Objective Emission These regulations require an official to measure the output of a sound source to determine whether it is acceptable without regard to the presence of a specific listener.,1
Regulations with specific maximum sound output levels for motor vehicles are examples. Objective Immission These regulations require an official to measure the sound received by a listener to determine whether it is acceptable without regard to the specific sound power generated by the source. Regulations with maximum allowable sound levels on property lines are examples Independence Day,1
"Many communities have definitions that are local to them, such as those defining motor vehicles and sound levels and sound level measurements. Some that have been added to make noise enforcement more specific are listed here.",1
"Any device for the abatement of sound emission while permitting the transfer of gas. A muffler is considered to be in good working order if the sound reduction is equal to, or greater than, that of the original equipment.",1
"Any sound or vibration which: may disturb or annoy reasonable persons of normal sensitivities or; causes, or tends to cause, an adverse effect on the public health and welfare or; endangers or injures people or; endangers or injures personal or real property.This can also be defined as noise nuisance.",1
"Any location, exterior, or interior, to a building that regularly permits public entrance for entertainment purposes. For this purpose, “public” means citizens of all types, including but not limited to, children, and private or public employees.",1
"Any sound for which the information content is unambiguously communicated to the listener, such as, but not limited to, understandable speech, comprehension of whether a voice is raised or normal, repetitive bass sounds, or comprehension of musical rhythms, without the aid of any listening device.",1
"Any self-propelled airborne, water-borne, or land-borne, plane, vessel, or vehicle, which is not designed to carry persons, including, but not limited to, any model airplane, boat, car, or rocket.",1
"An imaginary line along the ground surface, and its vertical extension, which separates the real property owned by one person from that owned by another person, but not including intra-building real property divisions.",1
"Any device, instrument, mechanism, equipment or apparatus for the amplification of any sounds from any radio, phonograph, stereo, tape player, musical instrument, television, loudspeaker or other sound-making or sound-producing device or any device or apparatus for the reproduction or amplification of the human voice or other sound.",1
"The minimum ground or structure borne vibrational motion necessary to cause a person of normal sensitivity to be aware of the motion through contact, hearing, or through visual observation of moving things.",1
there are three levels of regulation for stationary sound sources. The most basic is the general one associated with noise disturbance. (See Noise Disturbance below.) It is a very broad subjective immission control that has evolved from earlier disturbance of the peace provisions. Subjectivity can lead to arbitrary enforcement. The next level of regulation is less broad; it is an objective immission control that uses specific levels of sound considered to be a noise disturbance. Arbitrary enforcement is reduced. (See Maximum Permissible Sound Levels below.),1
"In both cases, however, the person creating the sound may not be aware that his actions are in violation. The concept that a potential violator should have fair warning that his actions are in violation has led to provisions that address specific noise problems. The sections below list those that are found in community noise ordinances.",1
"This provision is a subjective immission control. An evaluation of the noise disturbance is made at the listener without a sound level meter. This provision is mostly applied in residential zones such as homes, apartments and condominiums. Albuquerque, NM (Article 9-9) requires that such units the maximum permissible sound levels (Se section below) and recommend that those units be placed away from other residential units or on roof tops to diminish impact.",1
"This provision is a subjective immission control. Most relate to barking dogs and put an upper time limit for continuous sound from them. New Jersey (Chapter 13:1G) considers a violation if the sound is continuous for more than 5 minutes or intermittent for more than 20 minutes. They also consider it a defense to violation if the animal is provoked to bark. Connecticut (Chapter 442)exempts animal sounds while Anchorage, AK (Chapter 15.70) requires that continual violations permit the animal to be taken and put out for adoption.",1
This provision contains only a curfew since most states protect shooting ranges from liability for noise disturbance. It can include a curfew requirement and a requirement for a public hearing if expansion of the range is desired. The provision may prohibit other weapons such as rocket propelled projectiles but may exempt unpowered weapons such as arrows. South Carolina (title 31 Chapter 18) requires that a sign stating SHOOTING RANGE-NOISE AREA be placed on all primary roads. Arizona (ARS 17-602) places a curfew from 10pm to 7 am.,1
"It also allows a tradeoff between the number of events and the maximum permitted sound level. New York (Chapter 150) also trades off overall levels with the duration of the sounds. Colorado (Article 25-12-109) declared that noise restrictions on shooting ranges is a detriment to public health, welfare, and morale.",1
"Boston, MA(Section 16–26.4) permits construction on weekdays between 7am and 6 pm. Madison, WI (Chapter 24.08) limits sound levels to 88 dB(A) at 50 Feet. Miami, FL (Section 36-6) considers the noise a noise disturbance if it occurs between 6pm and 8am during the week and any time on Sunday. Dallas, TX (Section 30-2 (9)) permits construction in residential zones from 7am to 7pm on weekdays, from 9am to 7pm on Saturdays and Holidays, and prohibits construction on Sundays. Albuquerque, New Mexico (Section 9-9-8) has a more complex control.",1
"Green Bay, WI (Subchapter II – 27.201) exempts snow removal tools.",1
"Hydraulic Fracturing operations generate site sound as well as vehicle sound and several different provisions are required to control it. Federal law regulates the levels of certain site machinery. A subjective immission control or an objective immission control can be applied to surrounding neighborhoods. See maximum Permissible Sound Levels. Motor vehicle sound is mostly off-site so vehicle noise regulations are applicable. See Motor Vehicles on a Public Right-of-way. The State of New York has announced a statewide ban on such operations. Buffalo, NY and Pittsburgh, PA have announced a ban. Colorado has numerous activities to stop fracking.",1
Utah(Section 76-9-108) restricts disruptive activity to beyond 200 feet.,1
"This provision is a subjective immission control with a curfew. Operations in commercial facilities can impact adjacent residential zones. Los Angeles, CA (Section 114.03) places a curfew on such operations between 10pm and 7am but only if the source is within 200 feet of a residence. Chicago, IL (Section 11-4-2830) permits night operations unless they create a noise disturbance. Hammond, IN (Section 6.2.6) prohibits noise disturbance between 7pm and 7am.",1
"This provision is an objective immission control. It requires the measurement of sound levels at or beyond a property line and its vertical extension. There are several methods for implementing such a provision: It may not permit any exceedence or may permit exceedence only for a percentage of the measurement period. It may require the measurement method to be instantaneous, such as dB(A) or time-averaged, such as Energy Equivalent Level (Leq). It may be a fixed level limit, such as 55 dB(A), or it may be a level relative to the ambient sound, such as 5 dB(A) above the ambient.",1
"It may require measurement of the frequency spectrum, such as one octave bands, or A-weighting, such as dB(A). It may define different maximum levels based on zoning criteria, such as residential, commercial, or industrial. It may define different maximum levels based on time-of-day or day-of-week, such as reduced maxima during night hours or on weekends. It may require reduction of maximum levels based on the character of the sound, such as intermittent or impulsive. It may exempt certain classes of sound sources, such as shooting ranges, farm equipment, emergency equipment, railroads, or licensed activities.Most",1
"Atlanta, GA () limits impulsive sound to 100 dB(C) at property lines, while most reduce the maximum level by 5 dB for pure tones and impulsive sounds.",1
"The third is exceeding the presumed ambient by 5 dB. Hammond, IN (Section 6.2.7) prohibits this activity as a noise disturbance at any time.",1
"This provision is an objective immission control. It regulates the site of the sound source while the Sound Reproduction Devices section regulates the devices that create the sound. It can regulate the sound levels received by involuntary listeners in the surrounding community as well as the sound levels received by voluntary listeners. If the latter aspect is incorporated, limiting internal sound levels often resolves community noise impact. Los Angeles (Article 2, Section 112.06)requires warning signs and limits noise exposure to 95 dB(A) at any position normally occupied. Seattle, WA {Section 25.08.501}",1
"considers the sound emitted to be in violation if the sound is plainly audible within a dwelling from 10 pm to 7am; the need for a sound level meter is avoided. Chicago, IL {Section 11-4-2805} limits received sound levels to 55 dB(A) inside a residential dwelling unit but if the ambient is greater, the limit is 65 dB(A). If outdoors, the limit is conversational level at 100 feet from the property line. If the building is set back 20 feet from the property line, the allowable level is 84 dB(A)! Both of Chicago's limits apply from 10 pm to 8 am.",1
"Salt Lake health Department, UT {Section 4.5.11.(vii)} sets the limit at 95 dB(A) at a position that would normally be occupied by a patron and 100 dB(A) at other positions. They also require a sign stating WARNING: SOUND LEVELS ON THIS PREMISE [sic] MAY CAUSE PERMANENT HEARING DAMAGE. HEARING PROTECTION IS AVAILABLE. Anchorage, AK (Section 15.70.060.B.12) sets maximum levels for any patron at 90 dB(A).",1
"exempts bells, carillons, and chimes from religious facilities.",1
"This provision is an emission control with a list of devices that are exempt. It can have a term that limits the time periods in which emergency alarms may be tested. It can have a term that limits the activation time of burglar or fire alarms. Chicago, IL (Section 11-4-2815) limits the time for tests to 4 minutes between 9am and 5pm. Oregon (Chapter 467) prohibits sound when an emergency vehicle is stationary.",1
"This provision is an emission control that limits the activation period of alarms and restricts activation to a specific time-of-day or day-of-week. Los Angeles, CA () prohibits the sounding if the signal can be heard at 200 feet or more. Chicago, IL (Section 11-4-2820) considers the sound to be a noise disturbance in residential areas if the sound exceeds 5 minutes in any hour; steam whistles are exempt. Albuquerque, NM (Section 9-9-12) restricts levels to 5 dB over the ambient at a property line and applies maximum permissible residential level as well as plainly audible restrictions at night.",1
"This provision is a subjective immission control with a curfew. Boston, MA (Section 16–2.2) prohibits street sales near schools or churches if there is a “disturbance of the peace”. Hammond, IN (Section 6.2.4) places a curfew between 6 pm and 9 am.",1
"The sound created by wind turbines is caused by the blade rotation similar to aircraft propellers. Because the rotation rate is low, the frequency is also low, but the large size of many can result in disturbing sound levels, particularly in high wind areas. Most local control is done by advantageous site planning. New Hampshire (Title LXIV, Section 674:63) sets a sound level limit of 55 dB when measured at the site property line, allowing for exceptional events, such as storms. Studies have declared that wind noise can have a negative effect on health.",1
"Stationary sources have fixed positions, so it is possible to define the listeners and therefore immission controls are appropriate. Motor vehicles are moving sources so it is not possible to define any specific listeners so emission controls are appropriate. There are exceptions to this distinction. Construction equipment, and some recreation vehicles, move within a bounded area and can be considered to be time varying fixed sources. Standing motor vehicles can radiate sufficient sound to create noise disturbance. These must be treated by specific provisions.",1
"This provision is an objective emission control. Unlike the Tampering provision, this is specific to motor vehicles. It requires that a vehicle muffler not create more sound than the original equipment which has been measured. It prohibits any modification or replacement that increases the sound emission beyond that of the original equipment. It prohibits the sale of mufflers that do not meet original equipment standards. Many states have requirements that a muffler shall be in good working order which is not specific enough. California (Section 27150.1))",1
requires that a retail seller that sells a product in violation of the muffler regulation must install a replacement muffler that meets the regulation and must reimburse the purchaser for the expense of replacement.,1
"This provision is both an objective emission control and a subjective immission control. Because they are moving sources, objective controls are appropriate for measurements on open waterways. Many motorboats operate in bounding areas, such as small lakes or canals, with adjacent residential areas. In this case, immission controls are appropriate. California (Section 654.05), Portland OR (Section 18.10.040), and Seattle, WA (Section 25.08.485) require immission measurements to be made at the shoreline. Many states require emission measurements to be made at 50 feet.",1
"This provision is a subjective emission control with only an operational time limit. Los Angeles, CA () requires silencing in 5 minutes. New York City, NY (Section 24.221(d)) requires automatic shut-off after 10 minutes and a prominent display of the local precinct number and telephone number. Boston, MA (Section 16–26.2) considers it a violation if the alarm is plainly audible at 200 feet and is on more than 5 minutes. Other states and communities have automatic shutoff times from 10 to 15 minutes. Some communities have banned such alarms.",1
"This provision is a subjective immission control. It is based on the noise disturbance from drag racing and tire squealing on public rights-of-way. Illinois (625 ILCS 5/11-505) prohibits such activities. Hammond, IN (Section 6.2.14) prohibits such activity if it creates a noise disturbance.",1
"This provision is both an objective emission control and a subjective immission control with a curfew. It can apply to both public and private properties. Since these vehicles can move in large open areas, an objective control, limiting maximum sound levels at a fixed distance, is appropriate. Since they also can move in bounded areas near residences, a subjective control is appropriate. Numerous states and cities have emission controls measured at 50 feet; the most common level is 82 dB(A), which is similar to that for motor vehicles on public rights-of-way. Colorado Springs, CO (Section 9.8.204.C)",1
"This provision is both an objective emission control and a subjective immission control with a curfew. It can apply to both public and private properties. Since these vehicles can move in large open areas, an objective control, limiting maximum sound levels at a fixed distance is appropriate. Since they also can move in bounded areas near residences, a subjective control is appropriate. Numerous states and communities have objective controls; the most common maximum level is 78 dB(A). Federal law (36 CFR 2.18)",1
"regulates snowmobiles on federal property at 78 dB(A), so states and communities are free to regulate snowmobile sound levels on their property. Lincoln NE (Section 8.24.110) limits levels to 78 dB(A). Maine (Section 13112, Chapter 937) exempts snowmobiles at sanctioned racing events. Illinois (625 ILCS 40 Sec. 4-4)does also.",1
"This provision is an objective emission control and a subjective control. It can place a maximum sound level at a specific distance for the loudest operation. It can set a curfew, or it can be based on noise disturbance in residential zones. Los Angeles, CA (Section 113.01) has a time limit that applies only within 200 feet of any residential building. Chicago, IL (Section 11-4-2900) considers any noise it a noise disturbance if the activity occurs between 8pm to 8am. Salt Lake City, UT (Section 4.5.6)",1
"This provision is a subjective immission control. It sets a time limit on engine activity. It can also place a curfew on any engine activity. e. In Salt Lake City, UT (Section 4.5.10(xi)) it is considered a noise disturbance if the operation lasts more than 15 minutes. Dallas, TX (Section 30–3.1) applies the code to vehicles over 14,000 GVWR; they must be more than 300 feet from a residential zone and there is a 10-minute maximum. They also provide a list of idling vehicles that are exempt from prosecution such as buses or active concrete trucks. Hammond, IN (Section 6.2.10)",1
"limits operation to 3 minutes in an hour for vehicles over 14,000 GVWR in either public or private property. It exempts buses and taxis. Massachusetts allows idling no more than 5 minutes. In the case of construction of new (or remodeled) apartments, condominiums, hospitals and hotels, many U.S. states and cities have stringent building codes with requirements of acoustical analysis, in order to protect building occupants from exterior noise sources and sound generated within the building itself.",1
"Since many of these sounds are inherently loud, the principle of regulation is to require the wall or ceiling assembly to meet certain performance standards (typically Sound Transmission Class of 50), which allows considerable attenuation of the sound level reaching occupants. The second type of interior sound is called Impact Insulation Class (IIC) transmission. This effect arises not from airborne transmission, but rather from transmission of sound through the building itself. The most common perception of IIC noise is from footfall of occupants in living spaces above.",1
"This type of noise is somewhat more difficult to abate, but consideration must be given to isolating the floor assembly above or hanging the lower ceiling on resilient channel. Commonly a performance standard of IIC equal to 50 is specified in building codes. California has generally led the U.S. in widespread application of building code requirements for sound transmission; accordingly, the level of protection for building occupants has increased markedly in the last several decades. The U.S. Occupational Safety and Health Administration has established maximum noise levels for occupational exposure, beyond which mitigation measures or personal protective equipment is required.",1
"The onset of puberty is characterized by increased levels of hypothalamic gonadotropin releasing hormone (GnRH). GnRH triggers the secretion of luteinizing hormone (LH) and follicle-stimulating hormone (FSH) from the anterior pituitary gland, which in turn causes the ovaries to respond and secrete estradiol. Increases in gonadal estrogen promote breast development, female fat distribution and skeletal growth. Adrenal androgen and gonadal androgen result in pubic and axillary hair. Peripheral precocious puberty caused by exogenous estrogens is evaluated by assessing decreased levels of gonadotrophins.Xenoestrogens",1
"The overall mechanism of action is binding of the exogenous compounds that mimic estrogen to the estrogen binding receptors and cause the determined action in the target organs. Xenoestrogens have been implicated in a variety of medical problems, and during the last 10 years many scientific studies have found hard evidence of adverse effects on human and animal health.There is a concern that xenoestrogens may act as false messengers and disrupt the process of reproduction. Xenoestrogens, like all estrogens, can increase growth of the endometrium, so treatments for endometriosis include avoidance of products which contain them.",1
"comparing fish from above a wastewater treatment plant and below a wastewater treatment plant, studies found disrupted ovarian and testicular histopathology, gonadal intersex, reduced gonad size, vitellogenin induction, and altered sex ratios.The sex ratios are female biased because xenoestrogens interrupt gonadal configuration causing complete or partial sex reversal. When comparing adjacent populations of white sucker fish, the exposed female fish can have up to five oocyte stages and asynchronously developing ovaries versus the unexposed female fish who usually have two oocyte stages and group-synchronously developing ovaries. Previously, this type of difference has only been found between tropical and temperate species.Sperm",1
"Furthermore, xenoestrogens expose fish to CYP1A inducers through inhibiting a putative labile protein and enhancing the Ah receptor, which has been linked to epizootics of cancer and the initiation of tumors.The induction of CYP1A has been established to be a good bioindicator for xenoestrogen exposure. In addition, xenoestrogens stimulate vitellogenin (Vtg), which acts as a nutrient reserve, and Zona readiata proteins (Zrp), which forms eggshells. Therefore, Vtg and Zrp are biomarkers to exposure for fish.Another potential effect of xenoestrogens is on oncogenes, specifically in relation to breast cancer.",1
"Some scientists doubt that xenoestrogens have any significant biological effect, in the concentrations found in the environment. However, there is substantial evidence in a variety of recent studies to indicate that xenoestrogens can increase breast cancer growth in tissue culture.It has been suggested that very low levels of a xenoestrogen, Bisphenol A, could affect fetal neural signalling more than higher levels, indicating that classical models where dose equals response may not be applicable in susceptible tissue.",1
"has been speculation that falling sperm counts in males may be due to increased estrogen exposure in utero. Sharpe in a 2005 review indicated that external estrogenic substances are too weak in their cumulative effects to alter male reproductive functioning, but indicates that the situation appears to be more complex as external chemicals may affect the internal testosterone-estrogen balance.",1
"Puberty is a complex developmental process defined as the transition from childhood to adolescence and adult reproductive function. The first sign of female puberty is an acceleration of growth followed by the development of a palpable breast bud (thelarche). The median age of thelarche is 9.8 years. Although the sequence may be reversed, androgen dependent changes such as growth of axillary and pubic hair, body odor and acne (adrenarche) usually appears 2 years later. Onset of menstruation (menarche) is a late event (median 12.8 years), occurring after the peak of growth has passed.Puberty",1
"is considered precocious (precocious puberty) if secondary sex characteristics occur before the age of 8 in girls and 9 years in boys. Increased growth is often the first change in precocious puberty, followed by breast development and growth of pubic hair. However, thelarche, adrenarche, and linear growth can occur simultaneously and although uncommon, menarche can be the first sign. Precocious puberty can be classified into central (gonadotropin-dependent) precocious puberty or peripheral (gonadotropin-independent) puberty. Peripheral precocious puberty has been linked to exposure to exogenous estrogenic compounds.",1
"Since 1979, pediatric endocrinologists in Puerto Rico recognized an increase in number of patients with premature thelarche. The presence of phthalates were measured in the blood of 41 girls experiencing early onset breast development and matched set of controls. The average age of girls with premature thelarche was 31 months. They found high phthalate levels in the girls suffering from premature thelarche compared to the controls.",1
"Not all cases of premature thelarche in the study sample contained elevated levels of phthalate esters and there was concern whether artificial contamination from vinyl lab equipment and tubing invalidated the results, hence weakening the link between exposure and causation.",1
Animal feed was contaminated with several thousand pounds of polybrominated biphenyl in Michigan in 1973 resulting in high exposures of PBB in the population via milk and other products from contaminated cows. Perinatal exposure of children was estimated by measuring PBB in serum of mothers some years after exposure. Girls that had been exposed to high PBB levels through lactation had an earlier age of menarche and pubic hair development than girls who had less perinatal exposure. The study noted there no differences found in the timing of breast development among the cases and controls.,1
"The Great Lakes have been polluted with industrial wastes (mainly PCBs and DDT) since the beginning of the 20th century. These compounds have accumulated in birds and sports fish. A study was designed to assess the impact of consumption of contaminated fish on pregnant women and their children. Concentrations of maternal serum PCB and DDE and their daughters' age at menarche were reviewed. In multivariate analysis, DDE but not PCB was linked with a lowered age of menarche. Limitations of the study included indirect measurement of the exposure and self reporting of menarche.",1
"Precocious puberty has numerous significant physical, psychological and social implications for a young girl. Unfortunately, premature pubertal growth spurt and accelerated bone maturation will result in premature closure of distal epiphysis which causes reduced adult height and short stature. In 1999, US Food and Drug Administration has recommended to not take estrogen in food of more than 3.24 ng per day for females. Precocious puberty has also been implicated in pediatric and adult obesity. Some studies have suggested precocious puberty places girls at a higher risk of breast cancer later in life.",1
"Other compounds, such as bisphenol Z, have been shown to have stronger estrogenic effects in rats.It has been suggested that biphenol A and other xenoestrogens might cause disease to humans and animals. BPA exposure is linked to dysfunctions in human systems including the immune, neuroendocrine, and excretory systems. The damage that results in these dysfunctions is via the mechanisms of enzyme interference, cellular oxidation, epigenetic changes, and the breaking of DNA strands.Bisphenol S (BPS), an analog of BPA, has also been shown to alter estrogenic activity.",1
"One study demonstrated that when cultured rat pituitary cells were exposed to low levels of BPS, it altered the estrogen-estradiol signaling pathway and led to the inappropriate release of prolactin.",1
"In vertebrates, DDT is unable to be broken down and remains within the organism. There is little risk of DDT causing an increase in health risk upon exposure in adulthood, but in key developmental periods prenatally and in adolescence, there has been evidence to suggest an increased risk of breast cancer.",1
"Dioxin, a group of highly toxic chemicals are released during combustion processes, pesticide manufacturing and chlorine bleaching of wood pulp. Dioxin is discharged into waterways from pulp and paper mills. Consumption of animals fats is thought to be the primary pathway for human exposure. The connection between dioxin and dioxin-like compound (DLC) exposure and human disease is one not well established. Bioassays performed in animals does not show a strong connection between the two.",1
"PBDEs are not chemically bound to the items they are attached to, and thus can leech into the environment.",1
"In children, exposure to phthalates has a marked difference when compared to adults, having been associated with disrupted reproductive hormone levels and thyroid function.",1
"""Our Stolen Future"" book about endocrine disruption How to avoid xenoestrogens S. Safe on lack of evidence for any effect",1
"In the UK, the public announcement of the pollen count was popularised by Dr. William Frankland, an immunologist. The National Pollen and Aerobiology Research Unit became the world's first pollen forecasting service in 1983. According to a study by Leonard Bielory, M.D. that was presented to the American College of Allergy, Asthma & Immunology in 2012, climate changes are expected to cause pollen counts to more than double by 2040.",1
"Aerobiology Palynology European Pollen Database, a freely available database of pollen frequencies in Europe Daily pollen reports in the US Daily pollen reports in the UK Daily and historical pollen counts US",1
"The integration of shallow oxidisation ponds of microalgae was demonstrated by Golueke & Oswald in the 1960s. The widespread global implementation of these systems can be largely credited to Prof George Lai Chan-Yu-Thim (02 March 1924 Mauritius-08 October 2016 Mauritius) from ZERI. Zero waste agriculture is now practiced in China (ecological farming), Columbia (integrated food & waste management systems) & Fiji (integrated farming systems), India (integrated biogas farming), South Africa (BEAT Coop & African Agroecological Biotechnology Initiative) and Mauritius.",1
"Agricultural technology a/k/a Agritech Integrated Multi-Trophic Aquaculture Miniwaste Ashok Pandey; Jonathan Wong; Kim Bolton; Mohammad Taherzadeh, eds. (July 18, 2019). Sustainable Resource Recovery and Zero Waste Approaches (Ebook). St. Louis, Missouri, USA: Elsevier Science. ISBN 978-0-444-64283-7. Gowhar Hamid Dar; Humaira Qadri; Khursheed Ahmad Wani; Mohammad Aneesul Mehmood; Rouf Ahmad Bhat, eds. (August 30, 2019). Innovative waste management technologies for sustainable development (Ebook). Practice, Progress and Proficiency in Sustainability (PPPS) Book Series. Hershey, Pennsylvania USA: IGI Global. ISBN 978-1-7998-0033-0.",1
"2022 UQ1 came to perihelion (closest approach to the Sun) on 27 July 2022 at a distance of 0.84 AU, between the orbits of Venus and Earth. The Earth encounter in October reduced the period of its heliocentric orbit from 1 year to about 241 days and reduced its perihelion to 0.52 AU, placing it in between the orbits of Mercury and Venus. 2010 KQ 2020 SO Lucy rocket booster trajectory (Tony Dunn) Closest Asteroid Flyby in 2022 Was Really Space Junk From NASA Mission cnet.com,",1
"Oct 20, 2022 Asteroid (NEO) 2022 UQ1 2022 UQ1 at NeoDyS-2, Near Earth Objects—Dynamic Site Ephemerides · Observation prediction · Orbital info · MOID · Proper elements · Observational info · Close approaches · Physical info · Orbit animation 2022 UQ1 at the JPL Small-Body Database",1
"6PPD is prepared by reductive amination of methyl isobutyl ketone (which has six carbon atoms, hence the '6' in the name) with phenyl phenylenediamine (PPD). This produces a racemic mixture. 6PPD is a common rubber antiozonant, with major application in vehicle tires. It is mobile within the rubber and slowly migrates to the surface via blooming. Here it forms a ""scavenger-protective film"", reacting with the ozone more quickly than the ozone can react with the rubber.",1
"2022 study also identified the toxic impact on species like brook trout and rainbow trout. The published lethal concentrations are: coho salmon: LC50 = 95 ng/L brook trout: LC50 = 0.59 μg/L rainbow trout: LC50 = 1.0 μg/LIt is not known why the ozone-oxidised 6PPD is toxic to coho salmon. The Nisqually and nonprofit Long Live the Kings are trying out a mobile stormwater filter at a bridge in the Ohop Valley. The Washington Department of Ecology, Washington State University and the US Tire Manufacturer's Association are working on regulation and education.6PPD",1
"The show is organised by the Hong Kong Tourism Board and is displayed every night with good weather at 8 pm Hong Kong Time (UTC+8). An orchestration of music, decoration lights, laser light displays, and pyrotechnic fireworks, the multimedia light and sound show lasts for around 10 minutes and was conceptualised, created, and installed by LaserVision.The best vantage points include the ""Avenue of Stars"" on the Tsim Sha Tsui waterfront, on the waterfront promenade outside the Golden Bauhinia Square in Wan Chai and on sightseeing ferries (i.e. Star Ferry) running across the Victoria Harbour.",1
"or above or a Red or Black Rainstorm Warning Signal is issued by the Hong Kong Observatory at or after 3 pm on any given day, the show is suspended for that evening, even if the warning is subsequently rescinded prior to the 8 pm start time. The show may also be suspended in emergencies without prior notice. The show is also suspended during days of mourning and the night of Earth Hour.",1
"A new version was revealed on 1 December 2017 with 40 locations involved. A central feature of the new show was ""coloured searchlights, lasers, and all-new beam lights"" sent out as a fan-shaped lighting effect from the sent out like a special fan-shaped lighting effect from the Central Government Offices and the Revenue Tower. Music continued to be broadcast nightly from the Tsim Sha Tsui waterfront, and the Golden Bauhinia Square.After",1
"six months of protests heightened security concerns, in December 2019, the Hong Kong Tourism Board said the New Year's Eve fireworks would be cancelled for the first time in a decade, to be replaced by a Symphony of Lights multimedia show at the stroke of midnight instead. Small-scale pyrotechnics were still to be released from nearby buildings. On December 31, 2019, an ""enhanced"" A Symphony of Lights occurred, with the Hong Kong Convention and Exhibition Centre's facade turning into a count-down clock for the new year. The light show commenced at exactly midnight, with lighting effects synchronised with pyrotechnics.The",1
"As of 2022, there are 39 participating buildings in the show, and two attractions. The show comprises five major themes, taking spectators on a unique journey celebrating the energy, spirit and diversity of Hong Kong: The first scene ""Awakening"" begins with flashes of laser lights that give life to a nucleus of light-energy which gradually illuminates participating buildings using an array of dancing lights and rainbow colour. This scene symbolises the genesis and powerful growth of Hong Kong.",1
"The second scene ""Energy"" is represented by the display of rising colour patterns and the sweeping of the lasers and searchlights energetically across the night sky, signifying the vibrant energy of Hong Kong. In the third scene ""Heritage"", traditional lucky red and gold colours are displayed across buildings on both sides of the Harbour, complemented by the introduction of music using Chinese musical instruments, symbolising Hong Kong's colourful heritage and rich cultural traditions. The fourth scene ""Partnership"" features a display of laser beams and sweeping searchlights scanning across the Harbour, representing an illuminated connection with the opposite side.",1
"Beams reach out to symbolically connect the two sides of the Harbour into one greater and unified partnership. The finale ""Celebration"" brings out a powerful rhythmic display of swirling, kaleidoscopic patterns of lights and beams dancing lively across the Harbour. The exciting final scene signifies the celebration of the close partnership between the two sides of the Harbour and represents an even brighter future for Asia's world city – Hong Kong. The show has been further expanded with the total number of participating buildings increased to 47 on both sides of Victoria Harbour in 2007.",1
"As of 2017, it has been reduced to 42. There are different types of lighting effects included in the show, such as laser, searchlights, LED lights, simple lighting and projection lighting, indicated with brackets below.",1
"Since 17 January 2004, by the Symphony of Lights in Hong Kong Island North Shore (including Wan Chai, Admiralty and Central ) walls of 18 buildings as a performance venue, after gradually extended to 20.",1
lights] Queensway Government Offices^ (from 17 January 2004) [searchlights] The Chinese People's Liberation Army Forces Hong Kong Building (from 17 January 2004) [searchlights/projection lighting] Bank of China Tower (from 17 January 2004) [LED lights/searchlights] Cheung Kong Center^ (from 17 January 2004) [Optical Fiber] HSBC Main Building^ (from 17 January 2004) [LED lights/searchlights] Hong Kong City Hall (from 17 January 2004) [LED lights] Jardine House^ (from 17 January 2004) [searchlights/projection lighting] One Exchange Square (from 17 January 2004) [searchlights/projection lighting] Two Exchange Square (from 17 January 2004) [searchlights/projection lighting] Two International Finance Centre^ (from 17 January 2004) [laser] One International Finance Centre,1
(from 17 January 2004) [laser] The Center (from 17 January 2004) [LED lights],1
"Since 23 December 2005, Symphony of Lights extended to the Kowloon peninsula (including the Tsim Sha Tsui and Hung Hom).",1
"There was a building added in Hong Kong Island: AIA Central (from 23 December 2005) [LED lights]There were 12 buildings added in Kowloon Peninsula in 2005, from west to east including: Star House (from 23 December 2005) [projection lighting] Hong Kong Cultural Centre^ (from 23 December 2005) [searchlights/projection lighting] One Peking^ (from 23 December 2005) [searchlights] Hong Kong Museum of Art^ (from 23 December 2005) [LED lights/searchlights/projection lighting] The Peninsula Hong Kong (from 23 December 2005) [simple lighting ] Avenue of Stars (from 23 December 2005) [searchlights/LED lights] Hotel Panorama^ (from 23 December 2005) [projection lighting] New World Centre^ (from 23",1
December 2005) [searchlights](Under redevelopment) Tsim Sha Tsui Centre (from 23 December 2005) [LED lights/searchlights] Empire Centre^ (from 23 December 2005) [LED lights/searchlights] InterContinental Grand Stanford Hong Kong (from 23 December 2005) [simple lighting] Hong Kong Coliseum (from 23 December 2005) [LED lights/searchlights/projection],1
"There are two building added in Hong Kong Island, from east to west include: Bank of America Tower (from 1 May 2007) [LED lights] Standard Chartered Bank Building (from 1 May 2007) [LED lights]There are nine (official will Gateway Tower 5 building combined) building was added in Kowloon Peninsula, from west to east include: The Gateway – Harbour City (from 1 May 2007) [LED lights/searchlights] Ocean Terminal – Harbour City (from 26 June 2007) [projection lighting] Langham Place (from 26 June 2007)[LED lights/searchlights] 26 Nathan Road^ (from 1 May 2007) [LED lights] K11 (from 26 June 2007)[laser] Harbourview Horizon All-Suite Hotel",1
(from 26 June 2007)[LED lights] Harbourfront Horizon All-Suite Hotel (from 26 June 2007)[LED lights] EMax (from 26 June 2007) [searchlights] Megabox (from 1 October 2007) [LED lights/searchlights],1
There was a building added in Kowloon in 2012: International Commerce Centre (from 1 May 2012) [LED lights/laser]There was a building added in Hong Kong Island in 2014: CCB Tower (from first 2014) [LED lights/laser]There was a building added in Kowloon in 2014: Kai Tak Cruise Terminal (from late 2014) [Searchlights],1
"To celebrate the arrival of the year 2008, on New Year's Eve of 2007, pyrotechnics were added to the show on the rooftops of participating buildings on both sides of the harbour.Moreover, for the last 20 seconds before entering the year of 2008 (23:59:40), Two International Finance Centre started firing pyrotechnic fireworks from the outer walls, which face the Victoria Harbour, and counting down.",1
"For the first 2 minutes of the year 2008, (24:00:00), 18 of the participating buildings of both sides of the harbour had a themed pyrotechnic show, along with Two International Finance Centre, to celebrate the arrival of the new year. Reuters Earth TV broadcast the show live to the whole world on that night.",1
"Thousands of spectators gathered along both sides of Victoria Harbour for Hong Kong's 2009 New Year Countdown celebrations. Before entering the new year, there was a 60-second countdown by LED lights with pyrotechnic effects launched on facades of the two International Finance Centre towers.",1
"Hong Kong welcomed 2009 with a 4-minute pyrotechnical show on 10 landmark buildings on Hong Kong island. The show was orchestrated with a special theme song written and produced by Hong Kong musician Peter Kam to illuminate Victoria Harbour, to signify a bright and hopeful New Year for Hong Kong and the world.A similar display was also launched before entering the year 2010 (23:59:00), followed by fireworks with an installation set on the facade of Two International Finance Centre.",1
"In a reply to the request made to delay the light show, Donald Tsang said that the campaign could ""give adverse publicity to Hong Kong as an international metropolis and a major tourist attraction."" List of tallest buildings in Hong Kong spectra (installation) Official website Discover Hong Kong introduction page Concept design introduction page",1
"Later work, first by Zwicker and then by Schomer, attempted to overcome the difficulty posed by different levels, and work by the BBC resulted in the CCIR-468 weighting, currently maintained as ITU-R 468 noise weighting, which gives more representative readings on noise as opposed to pure tones. A-weighting is valid to represent the sensitivity of the human ear as a function of the frequency of pure tones. The A-weighting was based on the 40-phon Fletcher–Munson curves, which represented an early determination of the equal-loudness contour for human hearing.",1
"However, because decades of field experience have shown a very good correlation between the A scale and occupational deafness in the frequency range of human speech, this scale is employed in many jurisdictions to evaluate the risks of occupational deafness and other auditory problems related to signals or speech intelligibility in noisy environments. Because of perceived discrepancies between early and more recent determinations, the International Organization for Standardization (ISO) revised its standard curves as defined in ISO 226, in response to the recommendations of a study coordinated by the Research Institute of Electrical Communication, Tohoku University, Japan.",1
"The study produced new curves by combining the results of several studies, by researchers in Japan, Germany, Denmark, UK, and USA. (Japan was the greatest contributor with about 40% of the data.) This has resulted in the recent acceptance of a new set of curves standardized as ISO 226:2003. The report comments on the surprisingly large differences, and the fact that the original Fletcher–Munson contours are in better agreement with recent results than the Robinson-Dadson, which appear to differ by as much as 10–15 dB especially in the low-frequency region, for reasons that are not explained.",1
"The report also shows that the 40-phon Fletcher-Munson contour is in better agreement with the updated 60-phon contour incorporated into ISO 226:2003, which challenges the common assertion that A-weighting represents loudness only for quiet sounds.Nevertheless, A-weighting would be a better match to the loudness curve if it fell much more steeply above 10 kHz, and it is likely that this compromise came about because steep filters were difficult to construct in the early days of electronics. Nowadays, no such limitation need exist, as demonstrated by the ITU-R 468 curve.",1
"For this reason, today A-frequency-weighting is now mandated for light civilian aircraft measurements, while a more accurate loudness-corrected weighting EPNdB is required for certification of large transport aircraft. D-weighting is the basis for the measurement underlying EPNdB. Z- or ZERO frequency-weighting was introduced in the International Standard IEC 61672 in 2003 and was intended to replace the ""Flat"" or ""Linear"" frequency weighting often fitted by manufacturers. This change was needed as each sound level meter manufacturer could choose their own low and high frequency cut-offs (–3 dB) points, resulting in different readings, especially when peak sound level was being measured.",1
"However, when more than one critical band is stimulated, the outputs of the various bands are summed by the brain to produce an impression of loudness. For these reasons equal-loudness curves derived using noise bands show an upwards tilt above 1 kHz and a downward tilt below 1 kHz when compared to the curves derived using pure tones. This enhanced sensitivity to noise in the region of 6 kHz became particularly apparent in the late 1960s with the introduction of compact cassette recorders and Dolby-B noise reduction.",1
"A-weighted noise measurements were found to give misleading results because they did not give sufficient prominence to the 6 kHz region where the noise reduction was having greatest effect, and did not sufficiently attenuate noise around 10 kHz and above (a particular example is with the 19 kHz pilot tone on FM radio systems which, though usually inaudible is not sufficiently attenuated by A-weighting, so that sometimes one piece of equipment would even measure worse than another and yet sound better, because of differing spectral content.",1
The weighting function R X ( f ) {\displaystyle R_{X}(f)} is applied to the amplitude spectrum (not the intensity spectrum) of the unweighted sound level. The offsets ensure the normalisation to 0 dB at 1000 Hz. Appropriate weighting functions are:,1
"R A ( f ) = 12194 2 f 4 ( f 2 + 20.6 2 ) ( f 2 + 107.7 2 ) ( f 2 + 737.9 2 ) ( f 2 + 12194 2 ) , A ( f ) = 20 log 10 ⁡ ( R A ( f ) ) − 20 log 10 ⁡ ( R A ( 1000 ) ) ≈ 20 log 10 ⁡ ( R A ( f ) ) + 2.00 {\displaystyle {\begin{aligned}R_{A}(f)&={12194^{2}f^{4} \over \left(f^{2}+20.6^{2}\right)\ {\sqrt {\left(f^{2}+107.7^{2}\right)\left(f^{2}+737.9^{2}\right)}}\ \left(f^{2}+12194^{2}\right)}\ ,\\[3pt]A(f)&=20\log _{10}\left(R_{A}(f)\right)-20\log _{10}\left(R_{A}(1000)\right)\\&\approx 20\log _{10}\left(R_{A}(f)\right)+2.00\end{aligned}}}",1
"R B ( f ) = 12194 2 f 3 ( f 2 + 20.6 2 ) ( f 2 + 158.5 2 ) ( f 2 + 12194 2 ) , B ( f ) = 20 log 10 ⁡ ( R B ( f ) ) − 20 log 10 ⁡ ( R B ( 1000 ) ) ≈ 20 log 10 ⁡ ( R B ( f ) ) + 0.17 {\displaystyle {\begin{aligned}R_{B}(f)&={12194^{2}f^{3} \over \left(f^{2}+20.6^{2}\right)\ {\sqrt {\left(f^{2}+158.5^{2}\right)}}\ \left(f^{2}+12194^{2}\right)}\ ,\\[3pt]B(f)&=20\log _{10}\left(R_{B}(f)\right)-20\log _{10}\left(R_{B}(1000)\right)\\&\approx 20\log _{10}\left(R_{B}(f)\right)+0.17\end{aligned}}}",1
"R C ( f ) = 12194 2 f 2 ( f 2 + 20.6 2 ) ( f 2 + 12194 2 ) , C ( f ) = 20 log 10 ⁡ ( R C ( f ) ) − 20 log 10 ⁡ ( R C ( 1000 ) ) ≈ 20 log 10 ⁡ ( R C ( f ) ) + 0.06 {\displaystyle {\begin{aligned}R_{C}(f)&={12194^{2}f^{2} \over \left(f^{2}+20.6^{2}\right)\ \left(f^{2}+12194^{2}\right)}\ ,\\[3pt]C(f)&=20\log _{10}\left(R_{C}(f)\right)-20\log _{10}\left(R_{C}(1000)\right)\\[3pt]&\approx 20\log _{10}\left(R_{C}(f)\right)+0.06\end{aligned}}}",1
"h ( f ) = ( 1037918.48 − f 2 ) 2 + 1080768.16 f 2 ( 9837328 − f 2 ) 2 + 11723776 f 2 R D ( f ) = f 6.8966888496476 ⋅ 10 − 5 h ( f ) ( f 2 + 79919.29 ) ( f 2 + 1345600 ) D ( f ) = 20 log 10 ⁡ ( R D ( f ) ) . {\displaystyle {\begin{aligned}h(f)&={\frac {\left(1037918.48-f^{2}\right)^{2}+1080768.16\,f^{2}}{\left(9837328-f^{2}\right)^{2}+11723776\,f^{2}}}\\[3pt]R_{D}(f)&={\frac {f}{6.8966888496476\cdot 10^{-5}}}{\sqrt {\frac {h(f)}{\left(f^{2}+79919.29\right)\left(f^{2}+1345600\right)}}}\\D(f)&=20\log _{10}\left(R_{D}(f)\right).\end{aligned}}} The gain curves can be realised by the following s-domain transfer functions.",1
"They are not defined in this way though, being defined by tables of values with tolerances in the standards documents, thus allowing different realisations:",1
H A ( s ) ≈ k A ⋅ s 4 ( s + 129.4 ) 2 ( s + 676.7 ) ( s + 4636 ) ( s + 76617 ) 2 {\displaystyle H_{\text{A}}(s)\approx {k_{\text{A}}\cdot s^{4} \over (s+129.4)^{2}\quad (s+676.7)\quad (s+4636)\quad (s+76617)^{2}}} kA ≈ 7.39705 × 109,1
H B ( s ) ≈ k B ⋅ s 3 ( s + 129.4 ) 2 ( s + 995.9 ) ( s + 76617 ) 2 {\displaystyle H_{\text{B}}(s)\approx {k_{\text{B}}\cdot s^{3} \over (s+129.4)^{2}\quad (s+995.9)\quad (s+76617)^{2}}} kB ≈ 5.99185 × 109,1
H C ( s ) ≈ k C ⋅ s 2 ( s + 129.4 ) 2 ( s + 76617 ) 2 {\displaystyle H_{\text{C}}(s)\approx {k_{\text{C}}\cdot s^{2} \over (s+129.4)^{2}\quad (s+76617)^{2}}} kC ≈ 5.91797 × 109,1
"A-weighting filter circuit for audio measurements Archived 2016-12-31 at the Wayback Machine Weighting Filter Set Circuit diagrams AES pro audio reference definition of ""weighting filters"" Frequency Weighting Equations A-weighting in detail A-Weighting Equation and online calculation Researches in loudness measurement by CBS using noise bands, 1966 IEEE Article Comparison of some loudness measures for loudspeaker listening tests (Aarts, JAES, 1992) PDF containing algorithm for ABCD filters",1
"6Q0B44E was first observed by Catalina Sky Survey researchers at the Lunar and Planetary Laboratory of the University of Arizona on 28 August 2006. The sighting was confirmed the next day by observations at the Siding Spring Survey and Table Mountain Observatory. 6Q0B44E was spotted at what was later calculated to be the brightest part of its orbit, at 19th magnitude. As the object moved away from Earth, its brightness dropped on an approximately six-month cycle down to 28th magnitude, severely limiting study.The object was observed 56 times in the seven months after its discovery, but was lost in March 2007.",1
"Another unidentified satellite of Earth, XL8D89E, was discovered in June 2016 on a similar - but not identical - orbit. It is likely, though unproven, that both 6Q0B44E and XL8D89E are the same object, with the orbit shifted in the intervening decade by non-gravitational accelerations (such as slow escape of gas). The object is just a few metres across and was classified as probably artificial. 6Q0B44E (and XL8D89E) orbits Earth between 585,000 and 983,000 km, which is 2 to 3 times the distance of the Moon's orbit, over a period of 80 days.",1
"Its density was estimated at around 15 kg/m3, too low for natural rock but similar to an empty fuel tank.Ephemerides calculated from the observations suggest that 6Q0B44E probably entered the Earth–Moon system between 2001 and 2003, although it may have arrived up to a decade earlier. Similarities between the discoveries of 6Q0B44E and J002E3, now believed to be part of the Apollo 12 rocket, led some astronomers to speculate that 6Q0B44E may be another relic of human space exploration which has returned to Earth orbit. However, no space mission has been identified as the source of 6Q0B44E.",1
"2006 RH120 3753 Cruithne – An asteroid in an Earth horseshoe orbit 2002 AA29 – Another asteroid in an Earth horseshoe orbit Natural satellite The Distant Artificial Satellites Observation Page, accessed 2011-01-08 Discovery of 6Q0B44E, by Richard Kowalski 30 August 2006",1
"Among the many reasons that something had to be done was the importance of reducing the greenhouse gases that contribute to global warming. Before the industrial revolution era of the late 1700s, carbon dioxide could be measured in the atmosphere at around 280 parts per million (ppm), whereas in 2005 it was found to be 379 ppm. Methane, similarly in the same period, was 715 ppm reaching up to 1774 ppm. This is significant because methane has a potential for global warming 70% more than CO2 (Birnie et al., 2009, Bodansky et al., 2007).",1
"The national AQHI is based on three-hour average concentrations of ground-level ozone (O3), nitrogen dioxide (NO2), and fine particulate matter (PM2.5). O3 and NO2 are measured in parts per billion (ppb) while PM2.5 is measured in micrograms per cubic metre (µg/m3). The AQHI is calculated on a community basis (each community may have one or more monitoring stations). First, the average concentration of the three substances (O3, NO2, PM2.5) is calculated at each station within a community for the 3 preceding hours. This is considered valid only if at least 2 out of 3 hours are available at the station.",1
"If more than 1 of the preceding 3 hours is missing the station average is set to ""Not Available"". This part of the process results in three ""station parameter averages"" for each station. Second, the 3 hour ""community average"" for each parameter is calculated from the 3 hour substance averages at the available stations. If no stations are available for a parameter, that parameter is set to ""Not Available"". This part of the process results in three community parameter averages. Third, if all three community parameter averages are available, a community AQHI is calculated.",1
The formula is: A Q H I = ( 10 10.4 ) × 100 × [ ( e 0.000537 × O 3 − 1 ) + ( e 0.000871 × N O 2 − 1 ) + ( e 0.000487 × P M 2.5 − 1 ) ] {\displaystyle AQHI=({\frac {10}{10.4}})\times 100\times [(e^{0.000537\times O_{3}}-1)+(e^{0.000871\times NO_{2}}-1)+(e^{0.000487\times PM_{2.5}}-1)]} The result is then rounded to the nearest whole number. Alberta has modified AQHI reporting to better suit the needs of the Province. Because of Alberta's energy based economy other pollutants are also considered when reporting the AQHI.,1
"Dust from natural sources, usually large areas of land with little vegetation or no vegetation Methane, emitted by the digestion of food by animals, for example cattle Radon gas from radioactive decay within the Earth's crust. Radon is a colorless, odorless, naturally occurring, radioactive noble gas that is formed from the decay of radium. It is considered to be a health hazard. Radon gas from natural sources can accumulate in buildings, especially in confined areas such as the basement and it is the second most frequent cause of lung cancer, after cigarette smoking. Smoke and carbon monoxide from wildfires.",1
"Volcanic activity, which produces sulfur, chlorine, and ash particulates",1
"CO2 currently forms about 410 parts per million (ppm) of earth's atmosphere, compared to about 280 ppm in pre-industrial times, and billions of metric tons of CO2 are emitted annually by burning of fossil fuels. CO2 increase in earth's atmosphere has been accelerating. CO2 is an asphyxiant gas and not classified as toxic or harmful in general. Workplace exposure limits exist in places like UK (5,000 ppm for long-term exposure and 15,000 ppm for short-term exposure). Natural disasters like the limnic eruption at Lake Nyos can result in a sudden release of huge amount of CO2 as well.",1
"CFCs reach the stratosphere after being released into the atmosphere. They interact with other gases here, causing harm to the ozone layer. UV rays are able to reach the earth's surface as a result of this. This can result in skin cancer, eye problems, and even plant damage. Nitrogen oxides (NOx): Nitrogen oxides, particularly nitrogen dioxide, are expelled from high temperature combustion, and are also produced during thunderstorms by electric discharge. They can be seen as a brown haze dome above or a plume downwind of cities. Nitrogen dioxide is a chemical compound with the formula NO2.",1
"Secondary pollutants include: Ground level ozone (O3): Ozone is created when NOx and VOCs mix. It is a significant part of the troposphere. It's also an important part of the ozone layer, which can be found in different sections of the stratosphere. Photochemical and chemical reactions involving it fuel many of the chemical activities that occur in the atmosphere during the day and night. It is a pollutant and a component of smog that is produced in large quantities as a result of human activities (mostly the combustion of fossil fuels). Peroxyacetyl nitrate (C2H3NO5): similarly formed from NOx and VOCs.",1
"Associations are believed to be causal and effects may be mediated by vasoconstriction, low-grade inflammation and atherosclerosis. Other mechanisms such as autonomic nervous system imbalance have also been suggested.",1
"study conducted in 1960–1961 in the wake of the Great Smog of 1952 compared 293 London residents with 477 residents of Gloucester, Peterborough, and Norwich, three towns with low reported death rates from chronic bronchitis. All subjects were male postal truck drivers aged 40 to 59. Compared to the subjects from the outlying towns, the London subjects exhibited more severe respiratory symptoms (including cough, phlegm, and dyspnea), reduced lung function (FEV1 and peak flow rate), and increased sputum production and purulence. The differences were more pronounced for subjects aged 50 to 59.",1
"review further noted that living close to busy traffic appears to be associated with elevated risks of these three outcomes – increase in lung cancer deaths, cardiovascular deaths, and overall non-accidental deaths. The reviewers also found suggestive evidence that exposure to PM2.5 is positively associated with mortality from coronary heart diseases and exposure to SO2 increases mortality from lung cancer, but the data was insufficient to provide solid conclusions. Another investigation showed that higher activity level increases deposition fraction of aerosol particles in human lung and recommended avoiding heavy activities like running in outdoor space at polluted areas.In",1
"In 2021, a study of 163,197 Taiwanese residents over the period of 2001–2016 estimated that every 5 μg/m3 decrease in the ambient concentration of PM2.5 was associated with a 25% reduced risk of chronic kidney disease development. According to a chord study involving 10,997 atherosclerosis patients, higher PM 2.5 exposure is associate with increased albuminuria.",1
"In women undergoing IVF treatment, increases in NO2 both at the patient's address and by the IVF lab were significantly associated with a lower live birth rate.In the general population, there is a significant increase in miscarriage rate in women exposed to NO2 compared to the non-exposed group.",1
CO exposure is significantly associated with stillbirth in the second and third trimester.,1
Polycyclic aromatic hydrocarbons (PAHs) have been associated with reduced fertility. Benzo(a)pyrene (BaP) is a well-known PAH and carcinogen which is often found in exhaust fumes and cigarette smoke. PAHs have been reported to administer their toxic effects through oxidative stress by increasing the production of Reactive Oxygen Species (ROS) which can result in inflammation and cell death. More long-term exposure to PAHs can result in DNA damage and reduced repair.Exposure to BaP has been reported to reduce sperm motility and increasing the exposure worsens this effect.,1
Research has demonstrated that more BaPs were found in men with reported fertility issues compared to men without.Studies have shown that BaPs can affect folliculogenesis and ovarian development by reducing the number of ovarian germ cells via triggering cell death pathways and inducing inflammation which can lead to ovarian damage.,1
"However, findings on the effect of ozone exposure on male fertility are somewhat discordant, highlighting the need for further research.",1
Women living less than 50 meters away from an expressway or highway were 26% more likely to give birth to a SGA infant.,1
"Ultraviolet light will release free electrons from material, thereby creating free radicals, which break up VOCs and NOx gases. One form is superhydrophilic.Pollution-eating nanoparticles placed near a busy road were shown to absorb toxic emission from around 20 cars each day.",1
"The conversion equations depend on the temperature at which the conversion is wanted (usually about 20 to 25 °C). At an ambient sea level atmospheric pressure of 1 atm (101.325 kPa or 1.01325 bar), the general equation is: p p m v = m g / m 3 ⋅ ( 0.082057338 ⋅ T ) M {\displaystyle \mathrm {ppmv} =\mathrm {mg} /\mathrm {m} ^{3}\cdot {\frac {(0.082057338\cdot T)}{M}}} and for the reverse conversion: m g / m 3 = p p m v ⋅ M ( 0.082057338 ⋅ T ) {\displaystyle \mathrm {mg} /\mathrm {m} ^{3}=\mathrm {ppmv} \cdot {\frac {M}{(0.082057338\cdot",1
"For example, such a regulation might limit the concentration of NOx to 55 ppmv in a dry combustion exhaust gas (at a specified reference temperature and pressure) corrected to 3 volume percent O2 in the dry gas. As another example, a regulation might limit the concentration of total particulate matter to 200 mg/m3 of an emitted gas (at a specified reference temperature and pressure) corrected to a dry basis and further corrected to 12 volume percent CO2 in the dry gas.",1
"{measured\,volume\,\%\,O_{2}} )}}} As an example, a measured NOx concentration of 45 ppmv in a dry gas having 5 volume % O2 is: 45 × ( 20.9 - 3 ) ÷ ( 20.9 - 5 ) = 50.7 ppmv of NOxwhen corrected to a dry gas having a specified reference O2 content of 3 volume %. Note: The measured gas concentration Cm must first be corrected to a dry basis before using the above equation.",1
"Volcanic aerosol forms in the stratosphere after an eruption as droplets of sulfuric acid that can prevail for up to two years, and reflect sunlight, lowering temperature. Desert dust, mineral particles blown to high altitudes, absorb heat and may be responsible for inhibiting storm cloud formation. Human-made sulfate aerosols, primarily from burning oil and coal, affect the behavior of clouds.Although all hydrometeors, solid and liquid, can be described as aerosols, a distinction is commonly made between such dispersions (i.e. clouds) containing activated drops and crystals, and aerosol particles.",1
"Volcanic eruptions release large amounts of sulphuric acid, hydrogen sulfide and hydrochloric acid into the atmosphere. These gases represent aerosols and eventually return to earth as acid rain, having a number of adverse effects on the environment and human life. Aerosols interact with the Earth's energy budget in two ways, directly and indirectly.E.g., a direct effect is that aerosols scatter and absorb incoming solar radiation. This will mainly lead to a cooling of the surface (solar radiation is scattered back to space) but may also contribute to a warming of the surface (caused by the absorption of incoming solar energy).",1
"This will be an additional element to the greenhouse effect and therefore contributing to the global climate change.The indirect effects refer to the aerosol interfering with formations that interact directly with radiation. For example, they are able to modify the size of the cloud particles in the lower atmosphere, thereby changing the way clouds reflect and absorb light and therefore modifying the Earth's energy budget.",1
"Another approach splits the size range into intervals and finds the number (or proportion) of particles in each interval. These data can be presented in a histogram with the area of each bar representing the proportion of particles in that size bin, usually normalised by dividing the number of particles in a bin by the width of the interval so that the area of each bar is proportionate to the number of particles in the size range that it represents.",1
"If the width of the bins tends to zero, the frequency function is: d f = f ( d p ) d d p {\displaystyle \mathrm {d} f=f(d_{p})\,\mathrm {d} d_{p}} where d p {\displaystyle d_{p}} is the diameter of the particles d f {\displaystyle \,\mathrm {d} f} is the fraction of particles having diameters between d p {\displaystyle d_{p}} and d p {\displaystyle d_{p}} + d d p {\displaystyle \mathrm {d} d_{p}} f ( d p ) {\displaystyle f(d_{p})} is the frequency functionTherefore, the area under the frequency curve between two sizes a and b represents the total fraction of the",1
"particles in that size range: f a b = ∫ a b f ( d p ) d d p {\displaystyle f_{ab}=\int _{a}^{b}f(d_{p})\,\mathrm {d} d_{p}} It can also be formulated in terms of the total number density N: d N = N ( d p ) d d p {\displaystyle dN=N(d_{p})\,\mathrm {d} d_{p}} Assuming spherical aerosol particles, the aerosol surface area per unit volume (S) is given by the second moment: S = π / 2 ∫ 0 ∞ N ( d p ) d p 2 d d p {\displaystyle S=\pi /2\int _{0}^{\infty }N(d_{p})d_{p}^{2}\,\mathrm {d} d_{p}} And the third moment",1
"gives the total volume concentration (V) of the particles: V = π / 6 ∫ 0 ∞ N ( d p ) d p 3 d d p {\displaystyle V=\pi /6\int _{0}^{\infty }N(d_{p})d_{p}^{3}\,\mathrm {d} d_{p}} The particle size distribution can be approximated. The normal distribution usually does not suitably describe particle size distributions in aerosols because of the skewness associated with a long tail of larger particles. Also for a quantity that varies over a large range, as many aerosol sizes do, the width of the distribution implies negative particles sizes, which is not physically realistic.",1
"However, the normal distribution can be suitable for some aerosols, such as test aerosols, certain pollen grains and spores.A more widely chosen log-normal distribution gives the number frequency as: d f = 1 d p σ 2 π e − ( l n ( d p ) − d p ¯ ) 2 2 σ 2 d d p {\displaystyle \mathrm {d} f={\frac {1}{d_{p}\sigma {\sqrt {2\pi }}}}e^{-{\frac {(ln(d_{p})-{\bar {d_{p}}})^{2}}{2\sigma ^{2}}}}\mathrm {d} d_{p}} where: σ {\displaystyle \sigma } is the standard deviation of the size distribution and d p ¯ {\displaystyle {\bar {d_{p}}}} is the arithmetic mean diameter.The",1
"For low values of the Reynolds number (<1), true for most aerosol motion, Stokes' law describes the force of resistance on a solid spherical particle in a fluid. However, Stokes' law is only valid when the velocity of the gas at the surface of the particle is zero. For small particles (< 1 μm) that characterize aerosols, however, this assumption fails. To account for this failure, one can introduce the Cunningham correction factor, always greater than 1.",1
"Neglecting buoyancy effects, we find: V T S = ρ p d 2 g C c 18 η {\displaystyle V_{TS}={\frac {\rho _{p}d^{2}gC_{c}}{18\eta }}} where V T S {\displaystyle V_{TS}} is the terminal settling velocity of the particle.The terminal velocity can also be derived for other kinds of forces. If Stokes' law holds, then the resistance to motion is directly proportional to speed.",1
The constant of proportionality is the mechanical mobility (B) of a particle: B = V F D = C c 3 π η d {\displaystyle B={\frac {V}{F_{D}}}={\frac {C_{c}}{3\pi \eta d}}} A particle traveling at any reasonable initial velocity approaches its terminal velocity exponentially with an e-folding time equal to the relaxation time: V ( t ) = V f − ( V f − V 0 ) e − t τ {\displaystyle V(t)=V_{f}-(V_{f}-V_{0})e^{-{\frac {t}{\tau }}}} where: V ( t ) {\displaystyle V(t)} is the particle speed at time t V f {\displaystyle V_{f}} is the final particle speed V 0 {\displaystyle,1
"V_{0}} is the initial particle speedTo account for the effect of the shape of non-spherical particles, a correction factor known as the dynamic shape factor is applied to Stokes' law. It is defined as the ratio of the resistive force of the irregular particle to that of a spherical particle with the same volume and velocity: χ = F D 3 π η V d e {\displaystyle \chi ={\frac {F_{D}}{3\pi \eta Vd_{e}}}} where: χ {\displaystyle \chi } is the dynamic shape factor",1
"The aerodynamic diameter of an irregular particle is defined as the diameter of the spherical particle with a density of 1000 kg/m3 and the same settling velocity as the irregular particle.Neglecting the slip correction, the particle settles at the terminal velocity proportional to the square of the aerodynamic diameter, da: V T S = ρ 0 d a 2 g 18 η {\displaystyle V_{TS}={\frac {\rho _{0}d_{a}^{2}g}{18\eta }}} where ρ 0 {\displaystyle \ \rho _{0}} = standard particle density (1000 kg/m3).This",1
"The previous discussion focused on single aerosol particles. In contrast, aerosol dynamics explains the evolution of complete aerosol populations. The concentrations of particles will change over time as a result of many processes. External processes that move particles outside a volume of gas under study include diffusion, gravitational settling, and electric charges and other external forces that cause particle migration. A second set of processes internal to a given volume of gas include particle formation (nucleation), evaporation, chemical reaction, and coagulation.A",1
differential equation called the Aerosol General Dynamic Equation (GDE) characterizes the evolution of the number density of particles in an aerosol due to these processes.,1
∂ n i ∂ t = − ∇ ⋅ n i q + ∇ ⋅ D p ∇ i n i + ( ∂ n i ∂ t ) g r o w t h + ( ∂ n i ∂ t ) c o a g − ∇ ⋅ q F n i {\displaystyle {\frac {\partial {n_{i}}}{\partial {t}}}=-\nabla \cdot n_{i}\mathbf {q} +\nabla \cdot D_{p}\nabla _{i}n_{i}+\left({\frac {\partial {n_{i}}}{\partial {t}}}\right)_{\mathrm {growth} }+\left({\frac {\partial {n_{i}}}{\partial {t}}}\right)_{\mathrm {coag} }-\nabla \cdot \mathbf {q} _{F}n_{i}} Change in time = Convective transport + brownian diffusion + gas-particle interactions + coagulation + migration by external forces Where: n,1
i {\displaystyle n_{i}} is number density of particles of size category i {\displaystyle i} q {\displaystyle \mathbf {q} } is the particle velocity D p {\displaystyle D_{p}} is the particle Stokes-Einstein diffusivity q F {\displaystyle \mathbf {q} _{F}} is the particle velocity associated with an external force,1
"As particles and droplets in an aerosol collide with one another, they may undergo coalescence or aggregation. This process leads to a change in the aerosol particle-size distribution, with the mode increasing in diameter as total number of particles decreases. On occasion, particles may shatter apart into numerous smaller particles; however, this process usually occurs primarily in particles too large for consideration as aerosols.",1
"The Knudsen number of the particle define three different dynamical regimes that govern the behaviour of an aerosol: K n = 2 λ d {\displaystyle K_{n}={\frac {2\lambda }{d}}} where λ {\displaystyle \lambda } is the mean free path of the suspending gas and d {\displaystyle d} is the diameter of the particle. For particles in the free molecular regime, Kn >> 1; particles small compared to the mean free path of the suspending gas. In this regime, particles interact with the suspending gas through a series of ""ballistic"" collisions with gas molecules.",1
"As such, they behave similarly to gas molecules, tending to follow streamlines and diffusing rapidly through Brownian motion.",1
"The mass flux equation in the free molecular regime is: I = π a 2 k b ( P ∞ T ∞ − P A T A ) ⋅ C A α {\displaystyle I={\frac {\pi a^{2}}{k_{b}}}\left({\frac {P_{\infty }}{T_{\infty }}}-{\frac {P_{A}}{T_{A}}}\right)\cdot C_{A}\alpha } where a is the particle radius, P∞ and PA are the pressures far from the droplet and at the surface of the droplet respectively, kb is the Boltzmann constant, T is the temperature, CA is mean thermal velocity and α is mass accommodation coefficient. The derivation of this equation assumes constant pressure and constant diffusion coefficient.",1
"Particles are in the continuum regime when Kn << 1. In this regime, the particles are big compared to the mean free path of the suspending gas, meaning that the suspending gas acts as a continuous fluid flowing round the particle.",1
"The molecular flux in this regime is: I c o n t ∼ 4 π a M A D A B R T ( P A ∞ − P A S ) {\displaystyle I_{cont}\sim {\frac {4\pi aM_{A}D_{AB}}{RT}}\left(P_{A\infty }-P_{AS}\right)} where a is the radius of the particle A, MA is the molecular mass of the particle A, DAB is the diffusion coefficient between particles A and B, R is the ideal gas constant, T is the temperature (in absolute units like kelvin), and PA∞ and PAS are the pressures at infinite and at the surface respectively.The",1
transition regime contains all the particles in between the free molecular and continuum regimes or Kn ≈ 1. The forces experienced by a particle are a complex combination of interactions with individual gas molecules and macroscopic interactions. The semi-empirical equation describing mass flux is: I = I c o n t ⋅ 1 + K n 1 + 1.71 K n + 1.33 K n 2 {\displaystyle I=I_{cont}\cdot {\frac {1+K_{n}}{1+1.71K_{n}+1.33{K_{n}}^{2}}}} where Icont is the mass flux in the continuum regime. This formula is called the Fuchs-Sutugin interpolation formula. These equations do not take into account the heat release effect.,1
"Aerosol partitioning theory governs condensation on and evaporation from an aerosol surface, respectively. Condensation of mass causes the mode of the particle-size distributions of the aerosol to increase; conversely, evaporation causes the mode to decrease. Nucleation is the process of forming aerosol mass from the condensation of a gaseous precursor, specifically a vapor. Net condensation of the vapor requires supersaturation, a partial pressure greater than its vapor pressure. This can happen for three reasons: Lowering the temperature of the system lowers the vapor pressure. Chemical reactions may increase the partial pressure of a gas or lower its vapor pressure.",1
"The addition of additional vapor to the system may lower the equilibrium vapor pressure according to Raoult's law.There are two types of nucleation processes. Gases preferentially condense onto surfaces of pre-existing aerosol particles, known as heterogeneous nucleation. This process causes the diameter at the mode of particle-size distribution to increase with constant number concentration. With sufficiently high supersaturation and no suitable surfaces, particles may condense in the absence of a pre-existing surface, known as homogeneous nucleation. This results in the addition of very small, rapidly growing particles to the particle-size distribution.",1
"The following formula gives relative humidity at equilibrium: R H = p s p 0 × 100 % = S × 100 % {\displaystyle RH={\frac {p_{s}}{p_{0}}}\times 100\%=S\times 100\%} where p s {\displaystyle p_{s}} is the saturation vapor pressure above a particle at equilibrium (around a curved liquid droplet), p0 is the saturation vapor pressure (flat surface of the same liquid) and S is the saturation ratio.",1
"Kelvin equation for saturation vapor pressure above a curved surface is: ln ⁡ p s p 0 = 2 σ M R T ρ ⋅ r p {\displaystyle \ln {p_{s} \over p_{0}}={\frac {2\sigma M}{RT\rho \cdot r_{p}}}} where rp droplet radius, σ surface tension of droplet, ρ density of liquid, M molar mass, T temperature, and R molar gas constant.",1
Some available in situ measurement techniques include: Aerosol mass spectrometer (AMS) Differential mobility analyzer (DMA) Electrical aerosol spectrometer (EAS) Aerodynamic particle sizer (APS) Aerodynamic aerosol classifier (AAC) Wide range particle spectrometer (WPS) Micro-Orifice Uniform Deposit Impactor(MOUDI) Condensation particle counter (CPC) Epiphaniometer Electrical low pressure impactor (ELPI) Aerosol particle mass-analyser (APM) Centrifugal Particle Mass Analyser (CPMA),1
Remote sensing approaches include: Sun photometer Lidar Imaging spectroscopy,1
"Particles can deposit in the nose, mouth, pharynx and larynx (the head airways region), deeper within the respiratory tract (from the trachea to the terminal bronchioles), or in the alveolar region. The location of deposition of aerosol particles within the respiratory system strongly determines the health effects of exposure to such aerosols. This phenomenon led people to invent aerosol samplers that select a subset of the aerosol particles that reach certain parts of the respiratory system.Examples of these subsets of the particle-size distribution of an aerosol, important in occupational health, include the inhalable, thoracic, and respirable fractions.",1
International Aerosol Research Assembly Archived 2020-01-21 at the Wayback Machine American Association for Aerosol Research NIOSH Manual of Analytical Methods (see chapters on aerosol sampling),1
"An input of the forecasted weather during the period of prediction, to predict any pollutant's movement. A model of pollutant emission. This can include traffic, industry, and pollen. The cycles of pollutant emission range from daily to weekly (for human commute) and yearly (for pollen and coal-burning). Non-periodic sources such as wildfire are also considered when known.Pollen forecasting not only matters for forecast of PM concentration, but also for allergies. There are a range of ways to do so, some taking into account the predicted weather.",1
"Recent studies have incorporated machine learning techniques such as neural networks, regressions, and random forests to achieve high accuracy in this part. An input of the local terrain. An understanding of how pollutants act given certain weather and terrain conditions. This is the job done by chemical transport models and atmospheric dispersion modeling. The concentration of pollutants in the atmosphere is determined by their transport, or mean velocity of movement through the atmosphere, their diffusion, chemical transformation, and ground deposition.The",1
"Particulates can also be measured using other kinds of particulate matter sampler, including optical photodetectors, which measure the light reflected from samples of light (bigger particles reflect more light) and gravimetric analysis (collected on filters and weighed). Black carbon is usually measured optically with Aethalometer-type instruments.Ultrafine particles (smaller than PM0.1, so generally less than 100 nanometers in diameter) are hard to detect and measure with some of these techniques. Typically, they are measured (or counted) with condensation particle counters, which effectively enlarge the particles by condensing vapors onto them to make bigger and much more easily detectable droplets.The",1
atomic composition of particulate samples can be measured with techniques such as X-ray spectrometry.,1
"Nitrogen dioxide (NO2) can be measured passively with diffusion tubes, though it takes time to collect samples, analyze them, and produce results. It can be measured manually or automatically through the Griess-Saltzman method, as specified in ISO 6768:1998, or the Jacobs-Hocheiser method.It can also be measured automatically much more quickly, by a chemiluminescence analyzer, which determines nitrogen oxide levels from the light they give off. In the UK, for example, there are over 200 sites where NO2 is continuously monitored by chemiluminescence.",1
Carbon monoxide (CO) and carbon dioxide (CO2) are measured by non-dispersive infrared (NDIR) light absorption based on the Beer-Lambert law. CO can also be measured using electrochemical gel sensors and metal-oxide semiconductor (MOS) detectors.,1
These are measured using gas chromatography and flame ionization (GC-FID).,1
"Hydrocarbons can be measured by gas chromatography and flame ionization detectors. They are sometimes expressed as separate measurements of methane (CH4), NMHC (non-methane hydrocarbons), and THC (total hydrocarbon) emissions (where THC is the sum of CH4 and NMHC emissions).",1
"The AQHIs are grouped into five AQHI health risk categories with health advice provided: Each of the health risk categories has advice associated with it. At the low and moderate levels the public are advised that they can continue normal activities. For the high category, children, the elderly and people with heart or respiratory illnesses are advised to reduce outdoor physical exertion. Above this (very high or serious), the general public are likewise advised to reduce or avoid outdoor physical exertion.",1
"As of 2012, the CAQI had two mandatory components for the roadside index, NO2 and PM10, and three mandatory components for the background index, NO2, PM10 and O3. It also included optional pollutants PM2.5, CO and SO2. A ""sub-index"" is calculated for each of the mandatory (and optional if available) components. The CAQI is defined as the sub-index that represents the worst quality among those components.Some of the key pollutant concentrations in μg/m3 for the hourly background index, the corresponding sub-indices, and five CAQI ranges and verbal descriptions are as follows. Frequently updated CAQI values and maps are shown on www.airqualitynow.eu",1
"The worst sub-index reflects overall AQI. Likely health impacts for different AQI categories and pollutants have also been suggested, with primary inputs from the medical experts in the group. The AQI values and corresponding ambient concentrations (health breakpoints) as well as associated likely health impacts for the identified eight pollutants are as follows:",1
The ozone AQI between 100 and 300 is computed by selecting the larger of the AQI calculated with a 1-hour ozone value and the AQI computed with the 8-hour ozone value. Eight-hour ozone averages do not define AQI values greater than 300; AQI values of 301 or greater are calculated with 1-hour ozone concentrations. 1-hour SO2 values do not define higher AQI values greater than 200. AQI values of 201 or greater are calculated with 24-hour SO2 concentrations. Real-time monitoring data from continuous monitors are typically available as 1-hour averages.,1
This corrected LCS data currently appears alongside regulatory data on EPA's national fire map.,1
"It also aimed to develop an integrated management platform that could become more effective as data was entered. Thus, testing of IAQ in an individual building would be aligned with the monitoring of IAQ across the EU. The problems in IAQ auditing that were to be overcome included: inefficient planning of audits, overdue reports, incompleteness, lack of transparency in reporting audit progress and slow accumulation of results for monitoring.",1
"addition to the central office in Prague-Komořany, the CHMI has a regional offices (branches) in six other Czech cities, not all sections are represented in each branch. Those other offices are in Brno, Ostrava, Plzeň, Ústí nad Labem, Hradec Králové, and České Budějovice.",1
"Such devices include but are not limited to flare stacks, incinerators, catalytic combustion reactors, selective catalytic reduction reactors, electrostatic precipitators, baghouses, wet scrubbers, cyclones, thermal oxidizers, Venturi scrubbers, carbon adsorbers, and biofilters. The selection of emissions control technology may be the subject of complex regulation that may balance multiple conflicting considerations and interests, including economic cost, availability, feasibility, and effectiveness. The various weight given to each factor may ultimately determine the technology selected.",1
"Precise requirements may be very difficult to determine without technical training and may change over time in response to, for example, changes in law, changes in policy, changes in available technology, and changes in industry practice. Such requirements may be developed at a national level and reflect consensus or compromise between government agencies, regulated industry, and public interest groups.",1
"According to the same report, 2010 alone the reduction of ozone and particulate matter in the atmosphere prevented more than 160,000 cases of premature mortality, 130,000 heart attacks, 13 million lost work days and 1.7 million asthma attacks. Criticisms of EPA's methodologies in reaching these and similar numbers are publicly available.",1
"agreement on acid rain), 1986 Vienna Convention for the Protection of the Ozone Layer, Vienna, 1985, including the Montreal Protocol on Substances that Deplete the Ozone Layer, Montreal, 1987",1
"Canadian government has also made efforts to pass legislation related to the country's greenhouse gas emissions. It has passed laws related to fuel economy in passenger vehicles and light trucks, heavy-duty vehicles, renewable fuels, and the energy and transportation sectors.",1
"DRUMS was developed by Japanese company Kawasaki Heavy Industries (KHI), which will also operate the satellite following its launch. DRUMS will be operated from a ground station inside KHI's Gifu Works facility, and an antenna for communicating with the satellite was finished in October 2019. KHI characterizes DRUMS as a demonstration for future missions to remove launch vehicle upper stages from orbit, along with potential applications for on-orbit satellite servicing. DRUMS was launched on 9 November 2021 by an Epsilon launch vehicle. A half size model of DRUMS was displayed at the 2019 G20 Osaka summit.",1
EAS OGS has been credited by the Minor Planet Center with the discovery of 37 minor planets. These are: List of largest optical telescopes in the 20th century List of minor planet discoverers § Discovering dedicated institutions http://www.iac.es/eno.php?op1=3&op2=6&lang=en&id=7 http://sci.esa.int/science-e/www/object/index.cfm?fobjectid=36520 http://vmo.estec.esa.int/totas,1
"A 1,600-kilogram (3,500 lb) spacecraft was to be launched on board a Vega rocket into a polar orbit at an altitude of 800–1,000 kilometres (500–620 mi). Once on orbit, the spacecraft would rendezvous with the derelict satellite Envisat which is in an unknown condition, inoperative, and probably tumbling.Capture would be conducted in one of two ways: either by using mechanical tentacles or nets. The tentacles option included equipping the spacecraft with robotic arms, one of which will first capture a holding point, before the remaining arms embrace the derelict and secure it with a clamping mechanism.",1
"The net option included equipping the spacecraft with a deployable net on a tether, that will envelop the target derelict before the spacecraft will begin changing orbit.: 13, 24, 25 The net option has the advantage of being able to capture objects with a wide range of sizes and spins.After successfully capturing the targeted derelict, the spacecraft would deorbit itself by performing a controlled atmospheric reentry. The mission was developed at ESA's Concurrent Design Facility, with studies for the Clean Space programme on de-orbiting techniques being carried out in 2009. The first symposium about the mission took place in May 2014.",1
"ESA Clean Space website Space debris removal mission ESA illustration Interview with Robin Biesbroek, e.Deorbit study manager",1
"The ECO Funnel was conceptualized by Dr. Ron Najafi in 1996 during his tenure at a facility in the San Francisco Bay Area. This facility encountered issues related to odorous fumes emanating from the laboratory, which prompted an investigation beyond the confines of the chemical waste storage area. As a member of the company's Health and Safety Committee, Dr. Najafi, conducted thorough tests to assess the emission levels from unsealed waste bottles positioned under a fume hood.",1
"Najafi created the ECO Funnel. The current design of the ECO Funnel utilizes a latching lid with gasket and two internal tubes. One larger and longer tube extends into the container from the base of the funnel into the liquid waste to restrict the surface area of the contents and inhibit fume emission. The other tube is designed to sit above the liquid level as a means to warn against overfilling. When the ECO Funnel is secured to a container, this second shorter and smaller tube provides the only ventilation.",1
"When the volume of liquid inside the container reaches the smaller tube opening, it will obstruct the airflow through the smaller tube; the waste fluid backs up into the funnel to signal the user that the container is at capacity. Detaching the ECO Funnel allows the remaining liquid to flow into the container and be safely sealed inside. So long as the ECO Funnel's contents do not exceed the maximum volume indicated, the liquid will drain into the container without overflowing. The ECO was also designed for easier transference.",1
"The ECO Funnel resolves a long-standing incongruity between federally mandated safety protocol and standard laboratory practice. The traditional method for handling fluid waste is to set a standard funnel onto the mouth of an open bottle, which is sometimes stored under a fume hood. This is out of compliance with OSHA 29 CFR 1910.1450 and EPA 40 CFR 264.173. Testing confirms that these methods allow chemicals to evaporate, contaminating the surrounding atmosphere and posing a health risk not only to laboratory workers but to neighboring areas.",1
"Additionally, chemical contaminants in the atmosphere, in combination with normal oxygen levels in the lab, fulfill two of the three components necessary to complete the fire triangle. Further, chemical spills in the laboratory preclude procedures of safe disposal, leading these toxins to end up in landfills, and consequently, soil, rivers, and oceans. As plant and animal life are affected, the consequences escalate exponentially.",1
"Ethyl tert-butyl ether is manufactured industrially by the acidic etherification of isobutylene with ethanol at a temperature of 30–110 °C and a pressure of 0,8–1,3 MPa. The reaction is carried out with an acidic ion-exchange resin as a catalyst. Suitable reactors are fixed-bed reactors such as tube bundle or circulation reactors in which the reflux can be cooled optionally.Ethanol, produced by fermentation and distillation, is more expensive than methanol, which is derived from natural gas. Therefore, MTBE, made from methanol is cheaper than ETBE, made from ethanol.",1
Methyl tert-butyl ether (MTBE) tert-Amyl methyl ether (TAME) Tetraethyllead (TEL) List of gasoline additives EC Joint Research Centre ETBE risk assessment report Directive 98/70/EC of the European Parliament and of the Council of 13 October 1998 relating to the quality of petrol and diesel fuels and amending Council Directive 93/12/EEC An assessment of the impact of ethanol-blended petrol on the total NMVOC emission from road transport in selected countries,1
"It is important for any numerical standard that averaging period, unit, and statistical measure are given (e.g. the 98th percentile of hourly means measured over a calendar year in micrograms per cubic metre (μg/m3)). Without these there is no common ground for a given criterion, making it confusing or even meaningless. Criteria can be set in different units (e.g. μg/m3, parts per billion by volume (ppbv), parts per billion by mass (ppb (mass)), parts per million (ppm)) and it is possible to convert between all of these units if the molecular mass of the pollutant and the temperature are known.",1
Assessment of Ambient Noise Levels Apple Airpods,1
"Fionn Ferreira, whose full name is Fionn Miguel Eckardt Ferreira, was born in Cork to boat-builder and modeller Anne Eckardt, from Germany and West Cork, and boat-builder Rui Ferreira from Portugal, who had met in the UK in 1994 and settled in Ballydehob, County Cork. He was brought up in Ballydehob and attended St James' primary school in Durrus and subsequently Schull Community College in Schull, completing school, at the age of 18, in 2019.Ferreira",1
"Ferreira subsequently exhibited at ISEF 2018 winning the 1st place American Chemical Society award, 2nd place award in Chemistry, 1st place for Drug Chemical and associated technologies, a scholarship to the University of Arizona and a certificate of honourable mention by the American Statistical Association.In 2019, Ferreira exhibited at the 2019 Google Science Fair winning the global grand prize award of $50,000. In autumn 2019, Ferreira started a BSc in Chemistry at the University of Groningen in the Netherlands and graduated in 2022 with Cum Laude. Currently, Ferreira is following a MSc in Chemistry at the University of Groningen.",1
"In 2020, Ferreira founded a business, Fionn & Co., focused on microplastic removal technology. In 2020 and 2021 his work was featured by the global campaign by Hewlett-Packard: For every dream. In 2018 the MIT Lincoln Laboratory named a minor planet after Ferreira, following his being awarded 2nd place at the Intel International Science and Engineering Fair. In 2021 he was named a National Geographic Society Young Explorer; he has since been working on a new platform for youth in the space of invention with the help of the funding from the society.",1
"In 2021, he was named a Forbes 30 Under 30 listee in the Science and Healthcare category. In September 2021 Ferreira was awarded a Premio Internationale Giuseppe Sciacca award for his conservation and ecological efforts.Ferreira",1
Interview and summary of invention concept Interview on invention process with BBC,1
"Fish kills may also occur due to the presence of disease, agricultural runoff, sewage discharges, oil or hazardous waste spills, hydraulic fracturing wastewater, sea-quakes, inappropriate re-stocking of fish, poaching with chemicals, underwater explosions, and other catastrophic events that upset a normally stable aquatic population. Because of the difficulty and lack of standard protocol to investigate fish kills, many fish kill cases are designated as having an unknown cause.",1
"In temperate zones oxygen levels in eutrophic rivers in summertime can exhibit very large diurnal fluctuations with many hours of oxygen supersaturation during daylight followed by oxygen depletion at night. Associated with these photosynthetic rhythms there is a matching pH rhythm as bicarbonate ion is metabolised by plant cells. This can lead to pH stress even when oxygen levels are high. Additional dissolved organic loads are the most common cause of oxygen depletion and such organic loads may come from sewage, farm waste, tip/landfill leachate and many other sources.",1
"In addition to altered behavior, affected fish have swollen gills that are mottled and have the appearance of ground hamburger meat.Some",1
"early warning signs of fish suffering from disease or parasite infections include: Discolouration, open sores, reddening of the skin, bleeding, black or white spots on the skin Abnormal shape, swollen areas, abnormal lumps, or popeyes Abnormal distribution of the fish such as crowding at the surface, inlet, or pond edges (though crowding at the surface during specific times of day, such as early morning, is more likely a sign of low oxygen) Abnormal activity such as flashing, twisting, whirling, convulsions, loss of buoyancy Listlessness, weakness, sluggishness, lack of activity Loss of appetite or refusal to feed.",1
Lime produces similar symptoms but is also often associated with milk eyes.,1
"A fish kill in a lake in Estonia in 2002 was attributed to a combination of algae bloom and high temperatures. When people manage algae blooms in fish ponds, it is recommended that treatments be staggered to avoid too much algae dying at once, which may result in a large drop in oxygen content. Some diseases result in mass die-offs. One of the more bizarre and recently discovered diseases produces huge fish kills in shallow marine waters. It is caused by the ambush predator dinoflagellate Pfiesteria piscicida.",1
"These blooms are natural phenomenon, but the exact cause or combination of factors that result in red tides outbreak not fully understood.",1
"Furthermore, a significant detrimental outcome caused by eutrophication in the Mississippi River is the increased uptake of dissolved oxygen by bacteria, in response to higher concentrations of organic matter. After eutrophication starts and is in progress, the phytoplankton reach their maximum population density and begin to die. As the dead phytoplankton accumulate, detritus, or organic matter waste, forms at the surface along with other bacteria and algae. As more phytoplankton die, the higher the concentration of organic matter becomes; and with a higher concentration of organic matter, more bacteria will reproduce.",1
"Consequently, as more bacteria, phytoplankton, and algae exponentially grow and multiply, the more submerged aquatic vegetation die, because they do not have access to sunlight due to eutrophication. Once this snowball-like course of action is in full motion, a dead zone has been created. As a result of the excess nutrient enrichment in the Mississippi River, dead zones appear in the Gulf of Mexico, created from the process of eutrophication. The dead zones in the gulf are mainly created by the nitrogen and phosphorus enrichment of the Lower Mississippi River.",1
"Some species of fish exhibit mass simultaneous mortality as part of their natural life cycle. Fish kill due to spawning fatalities can occur when fish are exhausted from spawning activities such as courtship, nest building, and the release of eggs or milt (sperm). Fish are generally weaker after spawning and are less resilient than usual to smaller changes in the environment. Examples include the Atlantic salmon and the Sockeye salmon where many of the females routinely die immediately after spawning.",1
"Polluted waters are often very turbid or have low transparency making it difficult or impossible to see fish that have sunk Rivers and streams can move fish downstream out of the investigation area. Small fish and fry can decompose or become buried in sediments very quickly and are lost from the count. Predators and scavengers remove and eat fish. Stressed fish may swim up tributaries and die there Many kills are reported only when dead fish resurface due to decompositional gas formation, often several hours after the kill has occurred.Some",1
"Even when conditions that contribute to fish kill are known to exist, prevention is hard because often conditions cannot be improved and fish cannot be safely removed in time. In small ponds, mechanical aeration and/or removal of decaying matter (such as fallen leaves or dead algae) may be reasonable and effective preventive measures. Many countries in the developed world have specific provisions in place to encourage the public to report fish kills so that a proper investigation can take place.",1
"Aflockalypse Aquatic biomonitoring Bird kill Fish-kill tree Harmful algal bloom Mass mortality event Paramoebiasis Roadkill Sentinel species Herring, and Scott (2002) Fish Kill in the Gulf of Oman: A space-based diagnosis NASA: Earth Observatory, featured article. Oxygen Depletion in Ponds, University of Georgia Cooperative Extension Service, Publication L233, 1993 Fish Kills – Their Causes and Prevention, Virginia Tech, Virginia Cooperative Extension Publication 420-252, 2009",1
"It can be compared to a rubber duck race. Postcards are attached to the balloons which are then released. The flight of the balloons cannot be influenced by the competitors. Instead, success in the contest is dependent on the wind conditions and on the location in which the balloon lands. The contest depends on the goodwill of passers-by to find the balloons and return the postcards. A prize may be awarded to the person whose balloon travels the furthest. Helium balloons are claimed to reach a height of anywhere up to ten kilometres.It",1
"2011: A farmer from Stalisfield Green near Ashford in Kent, England, successfully claimed compensation, after one of his bullocks choked to death on the string of a balloon released by pupils at Lyndhurst Primary School in Camberwell, south-east London, over 50 miles away, as part of a Comic Relief event. 2016: In 2008 Radio City 2—a radio station in Liverpool, England—started annually releasing hundreds of balloons (with messages attached) from the roof of the Radio City 2 ""in memory of loved ones that we miss at Christmas time.""",1
"Despite sustained lobbying by the public in December 2016, DJ Pete Price ignored the pleas and the balloon release went ahead at the end of the programme 'Remember A Loved One At Christmas'. Two leading diving journalists contacted Radio City 2's owner—Bauer Media Group—appealing for this practice to be stopped. Bauer Media confirmed that no company within the Group would conduct a balloon release in the future and a donation would be made to Greenpeace. 2017: A three-year-old thoroughbred horse, 'Espoiro', known as 'Feisty', died as a direct result of a helium party balloon landing in her field.",1
"Her owner Jennifer Birtwhistle (a leading horse breeder) told Horse & Hound magazine ""God isn't sitting in his heaven gathering up all this airborne litter that is sent up with messages attached to it on pieces of string. It doesn't reach anyone, it is entirely self serving."" 2017: In March 2017 Poundbakery headquarters released 500 orange and black balloons. Each balloon contained a voucher for a 'Go Large' free Poundbakery sandwich. Poundbakery subsequently apologised on 11 April 2017 and donated £1,000 to the British Divers Marine Life Rescue.",1
"""Like millions of people watching Blue Planet II, I was shocked to see the avoidable waste and harm created by single-use plastic. We all need to do our bit to tackle this problem, and I want the BBC to lead the way. Tony Hall, BBC Director-General"" 2019: On Friday 1 March 2019 an estimated 700 people released balloons in Sunderland, England following the murder of teenager Connor Brown. This mass balloon release was conducted on the same day that the Independent reported that scientists have stated balloons pose the biggest risk of death for seabirds eating plastic.",1
"A balloon release in 1986 by the charity United Way Services of Cleveland, in Ohio, USA, was a fund-raising attempt to break the world record for the number of balloons in a single release. One-and-a-half million balloons were released, but an approaching weather front caused them to return to earth, covering the city in balloons, causing cars to crash, and hindering a coast guard rescue mission. It contributed to the deaths of two sailors on Lake Erie (the wife of one victim sued the organizers, and settled out-of-court), resulted in injuries to horses, and caused traffic accidents.",1
A runway at Burke Lakefront Airport had to be closed. The Guinness Book of Records no longer accepts balloon release records.,1
"The Balloon Council, an organization of balloon retailers, balloon distributors, and balloon manufacturers, has publicly come out against the practice of releasing balloons. Included in their list of ""Smart Balloon Practices"" is the message that balloons are ""Worth the Weight,"" meaning that all balloons should be tied to a weight and not released outdoors. The campaign to end the release of balloons includes the hashtag #BeBalloonSmart and a cartoon character named Faraday, named after Michael Faraday, the inventor of the rubber balloon.",1
"A number of organisations (for example, in the United Kingdom, these include the Marine Conservation Society, the Royal Society for the Prevention of Cruelty to Animals, the Tidy Britain Group, the National Farmers' Union and the RSPB) oppose balloon releases, because of the visual impact of the fallen, deflated balloons, and the risk of harm to wildlife and domestic animals which they pose. For these reasons, balloon releases are prohibited in some jurisdictions.In May 2018 a peer-reviewed study by Delia M.",1
"Webb was published that revealed 2,223 pieces of balloon litter were found on 39 beaches across Cornwall between July and December 2016. The study entitled ""Just a balloon? A local study of the extent and impacts of balloon litter on beaches"" reported that some of the balloons found on Cornish beaches had travelled from other parts of the UK, Ireland and Europe.",1
"Within many countries written permission is often required from the relevant airspace regulatory authority. In the UK this would be the Civil Aviation Authority, for releases over a certain number of balloons.",1
"On 9 February 2018 rush-hour trains near Billericay, Essex were disrupted for more than two hours because 50 yellow and black balloons were tangled on overhead lines.",1
"As no physical contact is involved this fund-raising method was useful for charities during the lockdown of the 2020 COVID-19 pandemic when many other fund-raising events had to be cancelled. British marketing company Purepages, based in Bolton, has developed ""the world's first 100% eco-friendly virtual balloon race platform"", with software which allows purchasers to adjust the properties of their balloon to influence its prospects. Release dove 21-gun salute Sky lantern (also known as Chinese lantern) The Balloons Blow organisation maintains a list of cancelled balloon releases dating from 2014.",1
"The Food and Agriculture Organization (FAO) of the United Nations defines food loss and waste as the decrease in quantity or quality of food along the food supply chain. Within this framework, UN Agencies distinguish loss and waste at two different stages in the process: Food loss occurs along the food supply chain from harvest/slaughter/catch up to, but not including, the sales level Food waste occurs at the retail and consumption level.Important components of this definition include: Food redirected to nonfood chains (including animal feed, compost, or recovery to bioenergy) is not counted as food loss or waste.",1
"In the European Union (EU), food waste is defined by combining the definitions of food and waste, namely: ""any substance or product, whether processed, partially processed or unprocessed, intended to be, or reasonably expected to be ingested by humans (...)"" (including things such as drinks and chewing gum; excluding things such as feed, medicine, cosmetics, tobacco products, and narcotic or psychotropic substances) ""which the holder discards or intends or is required to discard"".: 2–3 Previously, food waste was defined by directive 75/442/EEC as ""any food substance, raw or cooked, which is discarded, or intended or required to be discarded"" in 1975.",1
"In 2006, 75/442/EEC was repealed by 2006/12/EC, which defined waste as ""any substance or object in the categories set out in Annex I which the holder discards or intends or is required to discard"". Meanwhile, Article 2 of Regulation (EC) No 178/2002 (the General Food Law Regulation), as amended on 1 July 2022, defined food as ""any substance or product, whether processed, partially processed or unprocessed, intended to be, or reasonably expected to be ingested by humans (...)"", including things such as drinks and chewing gum, excluding things such as feed, medicine, cosmetics, tobacco products, and narcotic or psychotropic substances.A",1
"2016 European Court of Auditors special report had criticised the lack of a common definition of food waste as hampering progress, and a May 2017 resolution by the European Parliament supported a legally binding definition of food waste.: 4, 6 Finally, the 2018/851/EU directive of 30 May 2018 (the revised Waste Framework Directive) combined the two (after waste was redefined in 2008 by Article 3.1",1
"of 2008/98/EC as ""any substance or object which the holder discards or intends or is required to discard"") by defining food waste as ""all food as defined in Article 2 of Regulation (EC) No 178/2002 of the European Parliament and of the Council that has become waste."": 2–3",1
"2006, the EPA defined food waste as ""uneaten food and food preparation wastes from residences and commercial establishments such as grocery stores, restaurants, produce stands, institutional cafeterias and kitchens, and industrial sources like employee lunchrooms"".The states remain free to define food waste differently for their purposes, though as of 2009, many had not done so.",1
"It includes cooking loss and natural shrinkage (for example, moisture loss); loss from mould, pests, or inadequate climate control; and food waste.",1
"Food waste is a component of food loss and occurs when an edible item goes unconsumed, as in food discarded by retailers due to color or appearance, and plate waste by consumers""; a FUSIONS (an EU project) 2016 report: ""Food waste is any food, and inedible parts of food, removed from the food supply chain to be recovered or disposed (including composed [sic], crops ploughed in/not harvested, anaerobic digestion, bioenergy production, co-generation, incineration, disposal to sewer, landfill or discarded to sea)""; and an EPA 2016 report: ""The amount of food going to landfills from residences, commercial establishments (e.g.,",1
"also noted that ""the FAO and ERS definitions only apply to edible and safe and nutritious food, whereas the definitions of FUSIONS and the EPA apply to both edible and inedible parts of food. Finally, the ERS and EPA definitions of food waste exclude the food that is not harvested at the farm level."": 4 A 2019 FAO report stated: 'The notion of food being lost or wasted is deceptively simple, but in practice there is no commonly agreed definition of food loss and waste.",1
"FAO has worked towards the harmonization of concepts related to food loss and waste, and the definitions adopted in this report are the result of a consensus reached in consultation with experts in this field. This report understands food loss and waste as the decrease in quantity or quality of food along the food supply chain. Empirically it considers food losses as occurring along the food supply chain from harvest/slaughter/catch up to, but not including, the retail level. Food waste, on the other hand, occurs at the retail and consumption level.",1
"This definition also aligns with the distinction implicit in SDG Target 12.3. This report also asserts that, although there may be an economic loss, food diverted to other economic uses, such as animal feed, is not considered as quantitative food loss or waste. Similarly, inedible parts are not considered as food loss or waste.': 9–10",1
"The 2019 FAO report stated: ""Food loss and waste has typically been measured in physical terms using tonnes as reporting units. This measurement fails to account for the economic value of different commodities and can risk attributing a higher weight to low-value products just because they are heavier. [This] report acknowledges this by adopting a measure that accounts for the economic value of produce."": 10 Hall et al. (2009) calculated food waste in the United States in terms of energy value ""by comparing the US food supply data with the calculated food consumed by the US population.""",1
"The result was that food waste among American consumers increased from ""about 30% of the available food supply in 1974 to almost 40% in recent years"" (the early 2000s), or about 900 kcal per person per day (1974) to about 1400 kcal per person per day (2003). A 2012 Natural Resources Defense Council report interpreted this to mean that Americans threw away up to 40% of food that was safe to eat.",1
"Buzby & Hyman (2012) estimated both the total weight (in kg and lbs) and monetary value (in USD) of food loss in the United States, concluding that 'the annual value of food loss is almost 10% of the average amount spent on food per consumer in 2008'.",1
"In the United States, food loss can occur at most stages of the food industry and in significant amounts. In subsistence agriculture, the amounts of food loss are unknown, but are likely to be insignificant by comparison, due to the limited stages at which loss can occur, and given that food is grown for projected need as opposed to a global marketplace demand. Nevertheless, on-farm losses in storage in developing countries, particularly in African countries, can be high although the exact nature of such losses is much debated.In",1
"the food industry of the United States, the food supply of which is the most diverse and abundant of any country in the world, loss occurs from the beginning of food production chain. From planting, crops can be subjected to pest infestations and severe weather, which cause losses before harvest. Since natural forces (e.g. temperature and precipitation) remain the primary drivers of crop growth, losses from these can be experienced by all forms of outdoor agriculture. On average, farms in the United States lose up to six billion pounds of crops every year because of these unpredictable conditions.",1
"In urban areas, fruit and nut trees often go unharvested because people either do not realize that the fruit is edible or they fear that it is contaminated, despite research which shows that urban fruit is safe to consume.",1
"Food loss continues in the post-harvest stage, but the amounts of post-harvest loss involved are relatively unknown and difficult to estimate.: 1 Regardless, the variety of factors that contribute to food loss, both biological/environmental and socio-economical, would limit the usefulness and reliability of general figures.: 1, 7–8 In storage, considerable quantitative losses can be attributed to pests and micro-organisms. This is a particular problem for countries that experience a combination of heat (around 30 °C) and ambient humidity (between 70 and 90 per cent), as such conditions encourage the reproduction of insect pests and micro-organisms.",1
"Losses in the nutritional value, caloric value and edibility of crops, by extremes of temperature, humidity or the action of micro-organisms, also account for food waste. Further losses are generated in the handling of food and by shrinkage in weight or volume.Some of the food loss produced by processing can be difficult to reduce without affecting the quality of the finished product.: 3 Food safety regulations are able to claim foods that contradict standards before they reach markets.",1
"Although this can conflict with efforts to reuse food loss (such as in animal feed), safety regulations are in place to ensure the health of the consumer; they are vitally important, especially in the processing of foodstuffs of animal origin (e.g. meat and dairy products), as contaminated products from these sources can lead to and are associated with microbiological and chemical hazards.",1
"Joined by Harvard's Food Law and Policy Clinic, the NRDC produced a study called The Dating Game: How Confusing Food Date Labels Leads to Food Waste in America. This United States-based study looked at the intertwining laws which lead labeling to end up unclear and erratic. This uncertainty leads to consumers to toss food, most often because they think the food may be unsafe or misunderstand the labeling on the food completely. Lack of regulation on labeling can result in large quantities of food being removed from the market overall.Retail stores throw away large quantities of food.",1
"Usually, this consists of items that have reached either their best-before, sell-by, or use-by dates. Some stores make an effort to markdown these goods with systems like discount stickers, stores have widely varying policies to handle the excess food. Much of the food discarded by stores is still edible. Some stores put effort into preventing access to poor or homeless people, while others work with charitable organization to distribute food. Retailers also contribute to waste as a result of their contractual arrangements with suppliers. Failure to supply agreed quantities renders farmers or processors liable to have their contracts cancelled.",1
"These guidelines and how they rate are readily available on their website. For example, apples get graded by their size, color, wax residue, firmness, and skin appearance. If apples rank highly in these categories and show close to no superficial defects, they are rated as ""U.S. Extra Fancy"" or ""U.S. Fancy"", these are the typical ratings sought out by grocery stores when purchasing their produce. Any apples with suboptimal levels of appearance are ranked as either ""U.S. Number 1"" or ""Utility"" and are not normally purchased for retail, as recommended by produce marketing sources, despite being safe and edible.",1
"A number of regional programs and organizations have been established by the EPA and USDA in an attempt to reduce such produce waste. Organizations in other countries, such as Good & Fugly in Australia and No Food Waste in India, are making similar efforts worldwide. The popular trend of selling ""imperfect"" produce at retail has been criticized for overlooking existing markets for these foods (eg the food processing industry and bargain grocery stores) and downplaying the household-level wasting of food that is statistically a larger part of the overall problem.The",1
fishing industry wastes substantial amounts of food: about 40–60% of fish caught in Europe is discarded as the wrong size or wrong species. This comes to about 2.3 million tonnes per annum in the North Atlantic and the North Sea.,1
"Addressing food waste requires involving multiple stakeholders throughout the food supply chain, which is a market-driven system. Each stakeholder and their food waste quantification can be dependent on geographical scales. This geographical scale then results in the production of different definitions of food waste, as mentioned earlier, with respect to the complexities of food supply chains and then create a narrative that further shows the needs for specific research on important stakeholders. The food service industry suggests to be a key stakeholder to achieve mitigation.",1
"restaurants in developing countries, the lack of infrastructure and associated technical and managerial skills in food production have been identified as the key drivers in the creation of food waste currently and in the future. Comparatively, the majority of food waste in developed countries tends to be produced post-consumer, which is driven by the low prices of food, greater disposable income, consumers' high expectations of food cosmetic standards, and the increasing disconnect between consumers and how food is being produced (Urbanization). That being said, in United States restaurants alone, an estimated 22 to 33 billion pounds are wasted each year.Serving",1
"plate size reduction has been identified as an intervention effective at reducing restaurant food waste. Under such interventions, restaurants decrease the size of plates for meals provided to diners. Similar interventions which have been found to be effective at reducing restaurant food waste include utilizing reusable rather than disposable plates and decreasing serving size.",1
"Consumers are directly and indirectly responsible for wasting a lot of food, which could for a large part be avoided if they were willing to accept suboptimal food (SOF) that deviates in sensory characteristics (odd shapes, discolorations) or has a best-before date that is approaching or has passed, but is still perfectly fine to eat. In addition to inedible and edible food waste generated by consumers, substantial amounts of food is wasted through food overconsumption, also referred to as metabolic food waste, estimated globally as 10% of foods reaching the consumer.",1
"Efforts are underway by the Food and Agriculture Organization (FAO) and the United Nations Environment Programme (UNEP) to measure progress towards SDG Target 12.3 through two separate indices: the Food Loss Index (FLI) and the Food Waste Index (FWI).According to FAO's The State of Food and Agriculture 2019, globally, in 2016, around 14 percent of the world's food is lost from production before reaching the retail level. Generally, levels of loss are higher for fruits and vegetables than for cereals and pulses.",1
"However, even for the latter, significant levels are found in sub-Saharan Africa and Eastern and South-Eastern Asia, while they are limited in Central and Southern Asia.Estimates from UN Environment's Food Waste Index suggest that about 931 million tonnes of food, or 17 percent of total food available to consumers in 2019, went into the waste bins of households, retailers, restaurants and other food services.According to a report from Feedback EU, the EU wastes 153 million tonnes of food each year, around double previous estimates.",1
"In 2011, an FAO publication based on studies carried out by The Swedish Institute for Food and Biotechnology (SIK) found that the total of global amount of food loss and waste was around one third of the edible parts of food produced for human consumption, amounting to about 1.3 billion tonnes (1.28×109 long tons; 1.43×109 short tons) per year.: 4 As the following table shows, industrialized and developing countries differ substantially. In developing countries, it is estimated that 400–500 calories per day per person are wasted, while in developed countries 1,500 calories per day per person are wasted.",1
"In the former, more than 40% of losses occur at the post-harvest and processing stages, while in the latter, more than 40% of losses occur at the retail and consumer levels. The total food waste by consumers in industrialized countries (222 million tonnes or 218,000,000 long tons or 245,000,000 short tons) is almost equal to the entire food production in sub-Saharan Africa (230 million tonnes or 226,000,000 long tons or 254,000,000 short tons).: 4 A 2013 report from the British Institution of Mechanical Engineers (IME) likewise estimated that 30–50% (or 1.2–2 billion tonnes or 1.18×109–1.97×109 long tons or 1.32×109–2.20×109",1
short tons ) of all food produced remains uneaten.,1
"In March 2019, the Australian ministry of the environment shared the key findings of Australia's National food waste baseline, which will facilitate the tracking of the progress towards their goal to halve Australian food waste by 2030.Many initiatives were taken by the Australian government in order to help achieve this goal. In fact, they financed $1.2 million in organization that invest in renewable energies systems to store and transport food. They also funded more than $10 million for research on food waste reduction.",1
"Local governments have also implemented programs such as information sessions on storing food and composting, diversion of waste from restaurants and cafes from landfills to shared recycling facilities and donation of food to organization that would otherwise be wasted.",1
"In Canada, 58% of all food is wasted, amounting to 35.5 million tonnes of food per annuum. The value of this lost food is equivalent to CA$21 billion. Such quantities of food would be enough to feed all Canadians for five months. It is estimated that about one third of this waste could be spared and sent to those in need. There are many factors that contribute to such large-scale waste. Manufacturing and processing food alone incur costs of CA$21 billion, or 4.82 million tons. Per household, it is estimated that $1,766 is lost in food loss and waste.",1
"specifically is working in the following ways to reduce food waste: Canada pledged to consult on strategies in the Strategy on Short-lived Climate Pollutants to reduce avoidable food waste within the country. This will help to reduce methane emissions from Canadian landfills. The government has implemented a Food Policy for Canada, which is a movement towards a more sustainable food system. In February 2019, the government brought together several experts from different sectors to share ideas and discuss opportunities for measuring and reducing food loss and waste across the food supply chain.During",1
"the 2022 Quebec general election, Québec solidaire party spokesman Gabriel Nadeau-Dubois stated that ending food waste in Quebec would be a priority of the party if in government. The party seeks to cut food waste by 50% by mandating large businesses and institutions to give unsold food to groups that would distribute the food, or to businesses that would process the food.",1
"In 2015 the Chinese Academy of Sciences reported that in big cities there was 17 to 18 million tons of food waste, enough to feed over 30 million people. About 25% of the waste was staple foods and about 18% meat.In August 2020 the Chinese Communist Party general secretary Xi Jinping said the amount of food waste was shocking and distressing. A local authority campaign ""Operation empty plate"" (Chinese: 光盘行动) was started to reduce waste, including encouraging food outlets to limit orders to one fewer main dish than the number of customers.As",1
"of December 2020, a draft law is under consideration to penalise food outlets if they encourage or mislead customers to order excessive meals causing obvious waste, first with a warning and then fines of up to 10,000 yuan. It would allow restaurants to charge customers who leave excessive leftovers. Broadcasters who promote overeating or food waste could also be fined up to 100,000 yuan.",1
"According to Ministry of Environment (Denmark), over 700,000 tonnes per year of food is wasted every year in Denmark in the entire food value chain from farm to fork. Due to the work of activist Selina Juul's Stop Wasting Food movement, Denmark has achieved a national reduction in food waste by 25% in 5 years (2010–2015).",1
"In France, approximately 1.3–1.9 million tonnes of food waste is produced every year, or between 20 and 30 kilograms per person per year. Out of the 10 million tonnes of food that is either lost or wasted in the country, 7.1 million tonnes of food wasted in the country, only 11% comes from supermarkets. Not only does this cost the French €16 billion per year, but also the negative impact on the environment is also shocking. In France, food waste emits 15.3 million tonnes of CO2, which represents 3% of the country's total CO2 emission.",1
"In response to this issue, in 2016, France became the first country in the world to pass a unanimous legislation that bans supermarkets from throwing away or destroying unsold food. Instead, supermarkets are expected to donate such food to charities and food banks. In addition to donating food, many businesses claim to prevent food waste by selling soon-to-be wasted products at discounted prices. The National Pact Against Food Waste in France has outlined eleven measures to achieve a food waste reduction by half by 2025.",1
"According to the research of National Food Chain Safety Office in 2019 based on the official EU methodological framework, an average Hungarian consumer generates 68 kg food waste annually. 49% of this amount would be avoidable. The research team (Wasteless project) replicated the study in 2019 involving 165 households. According to the data, food waste generated by the Hungarian households was estimated to be 65.5 kg per capita annually. Between the two periods, a 4% decrease was observed, despite significant economic expansion. In 2021, The Fidesz government of Viktor Orbán passed a law dealing with food waste.",1
"According to REDUCE project, which produced the first baseline dataset for Italy based on official EU methodological framework, food waste is 530 g per person per week at household stage (only edible fraction); food waste in school canteens corresponds to 586 g per pupil per week; retail food waste per capita, per year corresponds to 2.9 kg. See [2]",1
"According to Meeusen & Hagelaar (2008), between 30% and 50% of all food produced was estimated to be lost or thrown away at that time in the Netherlands, while a 2010 Agriculture Ministry (LNV) report stated that the Dutch population wasted 'at least 9.5m tonnes of food per year, worth at least €4.4bn.': 15 In 2019, three studies into food waste in households in the Netherlands commissioned by the LNV were conducted, showing that the average household waste per capita had been reduced from 48 kilograms of ""solid food (including dairy products, fats, sauces and soups)"" in 2010, to 41.2",1
"kilograms in 2016, to 34.3 kilograms in 2019.: 3–4 The waste of liquid foods (excluding beer and wine, first measured in 2019) that ended up in the sewer through sinks or toilets was analysed to have decreased from 57.3 litres per capita in 2010 to 45.5 litres in 2019.: 3–4, 7",1
Research done on household food waste in New Zealand found that larger households and households with more young people created more food waste. The average household in this case study put 40% of food waste into the rubbish.,1
"In Singapore, 788,600 tonnes (776,100 long tons; 869,300 short tons) of food was wasted in 2014. Of that, 101,400 tonnes (99,800 long tons; 111,800 short tons) were recycled. Since Singapore has limited agriculture ability, the country spent about S$14.8 billion (US$10.6 billion) on importing food in 2014. US$1.4 billion of it ends up being wasted, or 13 percent.On January 1, 2020, Singapore implemented the Zero Waste Masterplan which aims to reduce Singapore's daily waste production by 30 percent. The project also aims to extend the lifespan of the Semaku Landfill, Singapore's only landfill, beyond 2025.",1
"As a direct result of the project, food waste dropped to 665,000 tonnes, showing a significant decrease from 2017's all-time high of 810,000 tonnes.",1
"In the UK, 6,700,000 tonnes (6,590,000 long tons; 7,390,000 short tons) per year of wasted food (purchased and edible food which is discarded) amounts to a cost of £10.2 billion each year. This represents costs of £250 to £400 a year per household.",1
"According to United States Department of Agriculture (USDA), between 30-40 percent of food is wasted in U.S. Estimates of food waste in the United States range from 35 million tons to 103 million tons. In a study done by National Geographic in 2014, Elizabeth Royte indicated more than 30 percent of food in the United States, valued at $162 billion annually, is not eaten. The University of Arizona conducted a study in 2004 that indicated that 14% to 15% of United States edible food is untouched or unopened, amounting to $43 billion worth of discarded, but edible, food.",1
"In 2010, the United States Department of Agriculture came forth with estimations from the Economic Research Service that approximates food waste in the United States to be equivalent to 141 trillion calories.USDA data from 2010 shows that 26% of fish, meat, and poultry were thrown away at the retail and consumer level. Since then, meat production has increased by more than 10%. Data scientist Harish Sethu says this means that billions of animals are raised and slaughtered only to end up in a landfill. According to United Nations, about a third of all human-caused greenhouse gas emissions is linked to food.",1
"by gathering quantitative and qualitative data about the specific food waste, helping chefs and managers reduce food waste by up to 70% by improving and optimising their workflows and menus.",1
"There are multiple initiatives that rescue food that would otherwise not be consumed by humans anymore. The food can come from supermarkets, restaurants or private households for example. Such initiatives are: climate action campaigns, such as GoodDeed and Hearts For Nature with the goal of tackling climate change by reducing food waste, food banks, online platforms like Too Good To Go and Olio, public foodsharing shelves like those from foodsharing.de and dumpster diving.",1
"One way of dealing with food waste is to reduce its creation. Consumers can reduce spoilage by planning their food shopping, avoiding potentially wasteful spontaneous purchases, and storing foods properly (and also preventing a too large buildup of perishable stock). Widespread educational campaigns have been shown to be an effective way to reduce food waste.A British campaign called ""Love Food, Hate Waste"" has raised awareness about preventative measures to address food waste for consumers.",1
"Through advertisements, information on food storage and preparation and in-store education, the UK observed a 21% decrease in avoidable household food waste over the course of 5 years.Another potential solution is for ""smart packaging"" which would indicate when food is spoiled more precisely than expiration dates currently do, for example with temperature-sensitive ink, plastic that changes color when exposed to oxygen, or gels that change color with time.An",1
"However, rebound effects may cause substitutive consumption as a result of economic savings made from food waste prevention, potentially offsetting more than half of the avoided emissions (depending on the type of food and price elasticities involved). In areas where the waste collection is a public function, food waste is usually managed by the same governmental organization as other waste collection. Most food waste is combined with general waste at the source. Separate collections, also known as source-separated organics, have the advantage that food waste can be disposed of in ways not applicable to other wastes.",1
"In the United States, companies find higher and better uses for large commercial generators of food and beverage waste. From the end of the 19th century through the middle of the 20th century, many municipalities collected food waste (called ""garbage"" as opposed to ""trash"") separately. This was typically disinfected by steaming and fed to pigs, either on private farms or in municipal piggeries.Separate curbside collection of food waste is now being revived in some areas.",1
"To keep collection costs down and raise the rate of food waste segregation, some local authorities, especially in Europe, have introduced ""alternate weekly collections"" of biodegradable waste (including, e.g., garden waste), which enable a wider range of recyclable materials to be collected at reasonable cost, and improve their collection rates. However, they result in a two-week wait before the waste will be collected. The criticism is that particularly during hot weather, food waste rots and stinks, and attracts vermin. Waste container design is therefore essential to making such operations feasible. Curbside collection of food waste is also done in the U.S.,",1
"Dumping food waste in a landfill causes odour as it decomposes, attracts flies and vermin, and has the potential to add biological oxygen demand (BOD) to the leachate. The European Union Landfill Directive and Waste Regulations, like regulations in other countries, enjoin diverting organic wastes away from landfill disposal for these reasons. Starting in 2015, organic waste from New York City restaurants will be banned from landfills.In countries such as the United States and the United Kingdom, food scraps constitute around 19% of the waste buried in landfills, where it biodegrades very easily and produces methane, a powerful greenhouse gas.Methane,",1
"In China, some food waste is being processed by feeding it to cockroaches.",1
"In landfills, organic food waste decomposes anaerobically, producing methane gas that is emitted into the atmosphere. When this biodegradable waste is composted, it decomposes aerobically and does not produce methane, but instead produces organic compost that can then be utilized in agriculture. Recently, the city of New York has begun to require that restaurants and food-producing companies begin to compost their leftover food. Another instance of composting progress is a Wisconsin-based company called WasteCap, who is dedicated towards aiding local communities create composting plans.Municipal",1
The city's economic reasoning for this controversial mandate is supported by their estimate that one business can save up to $30000 annually on garbage disposal costs with the implementation of the required composting.,1
"Composting is an economical and environmentally conscious step many homeowners could take to reduce their impact on landfill waste. Instead of food scraps and spoiled food taking up space in trashcans or stinking up the kitchen before the bag is full, it could be put outside and broken down by worms and added to garden beds.",1
"this process of composting produces high volumes of biogas, there are potential safety issues such as explosion and poisoning. These interactions require proper maintenance and personal protective equipment is utilized. Certain U.S. states, such as Oregon, have implemented the requirement for permits on such facilities, based on the potential danger to the population and surrounding environment.Food waste coming through the sanitary sewers from garbage disposal units is treated along with other sewage and contributes to sludge.",1
"Commercially, food waste in the form of wastewater coming from commercial kitchens' sinks, dishwashers and floor drains is collected in holding tanks called grease interceptors to minimize flow to the sewer system. This often foul-smelling waste contains both organic and inorganic waste (chemical cleaners, etc.) and may also contain hazardous hydrogen sulfide gases. It is referred to as fats, oils, and grease (FOG) waste or more commonly ""brown grease"" (versus ""yellow grease"", which is fryer oil that is easily collected and processed into biodiesel) and is an overwhelming problem, especially in the US, for the aging sewer systems.",1
"Per the US EPA, sanitary sewer overflows also occur due to the improper discharge of FOGs to the collection system. Overflows discharge 3–10 billion U.S. gallons (11–38 million cubic meters) of untreated wastewater annually into local waterways, and up to 3,700 illnesses annually are due to exposure to contamination from sanitary sewer overflows into recreational waters. Gleaning Anaerobic digestion Waste & Resources Action Programme List of waste types Post-harvest losses (grains) Post-harvest losses (vegetables) Source Separated Organics Waste management This article incorporates text from a free content work. Licensed under CC BY-SA 3.0 (license statement/permission).",1
"Text taken from The State of Food and Agriculture 2019. Moving forward on food loss and waste reduction, In brief​, 24, FAO, FAO. Porpino, Gustavo (2016). ""Household Food Waste Behavior: Avenues for Future Research"". Journal of the Association for Consumer Research. 1 (1): 41–51. doi:10.1086/684528. S2CID 56005307. Baylen J. Linnekin (2016). Biting the Hands that Feed Us: How Fewer, Smarter Laws Would Make Our Food System More Sustainable. Island Press. ISBN 978-1610916752. NRDC page on food waste (advocacy site with suggestions) Reduced Food Waste - Solution Summary Project Drawdown, 2020.",1
"Food Waste and Rescue Report in Israel low down food waste Wasting Nothing, Project Regeneration, 2021.",1
"Noise-silencing technologies: The FAA should give high priority to the goal of reducing by at least half the current ""noise quotient"" near existing airports within ten years using noise-sensitive routing protocols and noise cancellation and silencing technologies. Furthermore, substantial cash prizes should be awarded to designers and builders of prototypes of ""the world's quietest airplanes"" for selected categories of aircraft. The manufacturers of such aircraft should be granted significant tax benefits and other competitive advantages by Congress. Limitations on ""piped-in"" music: The FAA shall set a maximum decibel limit for music ""piped in"" to airport terminals under its jurisdiction.",1
Limitations on car stereos: The National Highway Traffic Safety Administration should impose standards on allowable decibel levels for car stereos. http://valleypost.org/2015/08/22/groups-work-reduce-noise NoiseFree.org,1
"This list of widely accepted noise calculation standards is incomplete, and new standards may be under development: ISO 9613 parts 1 and 2 defines the calculation methods for outdoor sound propagation (International) VDI2714 and VDI2720 Schallausbreitung und Schallschutz im Freien (outdoor sound propagation, Germany) DIN18005 Schallschutz im Städtebau (noise protection in cities, Germany) TA Laerm Technische Anleitung zum Schutz gegen Lärm (Germany) VDI-Richtlinie 3745 Blatt 1 Beurteilung von Schießgeräuschimmissionen (Germany) BS 5228 Code of practice for noise and vibration control on construction and open sites (UK) RLS-90 Richtlinien für den Lärmschutz an Straßen (noise protection at roads/traffic, Germany) CRTN calculation of",1
"road traffic noise (UK) Schall03 Schienenlärm (calculation of rail noise, Germany) NoiseScore is a mobile app for crowdsourcing community noise. Noise experts and some small specialized companies have slowly developed a limited number of calculation tools, which have increased in number and become more user-friendly, covering more application cases, and adding service elements to the noise calculation tools.",1
"The noise calculation process is complex in input (gathering data, correctly modeling acoustic elements in the field) and from a pure compute power perspective, recently advances involved: moving calculation routines into self-contained calculation engines adapting CAD systems for input of acoustic models moving into 3D for displaying models or even data capture moving into cloud services and web enabled calculation tools.The quality of results from the noise calculation depends on the quality of the acoustic data provided and the capability of the noise calculation engine.o take decisions.",1
"In England and Wales, theoretically all criminal offences cognizable by English law involve ""a breach of the King's peace"", and all indictments formerly concluded ""against the peace of our Lord the King, his crown and dignity"" before the passage of the Indictments Act 1915 and the Rules that formed that Act's first schedule. The conclusion has also found its way into constitutional law in many United States state constitutions, which mandate that indictments within the state end in a similar manner to the above, usually omitting the ""crown"" part or substituting ""government"".",1
"For example, New Jersey's is ""against the peace of this State, the government and dignity of the same"".Historically that concluding phrase, now legally superfluous, represents the last trace of the process by which the royal courts assume jurisdiction over all offences, and gradually eroded the jurisdiction of the sheriff and of lords of manor and franchises, making crime a matter of national concern as distinguished from civil wrongs or infractions of the rights of local magnates.",1
"The Peace of the King was sworn on his accession or full recognition, and the jurisdiction of his courts to punish all violations of that peace was gradually asserted. The completion of this process is marked by the institution of the office of Justice of the Peace.In England, Wales and Northern Ireland, breach of the peace is descended from the Justices of the Peace Act 1361, which refers to riotous and barratous behaviour that disturbs the peace of the King.",1
"More modern authority defines a breach of the peace as ""when a person reasonably believes harm will be caused, or is likely to be caused, to a person or in his presence to his property, or a person is in fear of being harmed through an assault, affray, riot, unlawful assembly, or some other form of disturbance"".The breach of the peace power of arrest is provided by the common law and therefore an 'any person' power of arrest and entry both within the same definition.Section",1
"17(5) of the Police and Criminal Evidence Act 1984 (PACE) abolished all powers of a Constable to enter under the common law with the specific exception (subsection 6) when dealing with or preventing a common law breach of the peace. This ""offence"" definition and power of arrest are contained under the common law definition of ""breach of the peace"". Breach of the peace powers are unusual in the fact they originate from the laws Alfred the Great consolidated into the common law approximately 1,000 years before the modern constable was thought up.",1
"The first legislative reference to the common law breach of the peace was under the Justice of the Peace Act 1361.In England and Wales, breach of the peace is a civil proceeding (rather than a criminal offence), although the case must be proved to the criminal standard of proof, 'beyond reasonable doubt', rather than the civil standard of proof, 'on the balance of probabilities'. Sometimes the Crown Prosecution Service conduct the case on behalf of the police, but the police service is liable for any costs awarded in favour or against the prosecutor.",1
"Breach of the peace is not an offence, in the sense that it is not punishable either by a fine or imprisonment either at statute or common law and nor do proceedings for breach of the peace give rise to any conviction. In England and Wales, constables (or other persons) are permitted to arrest a person to ""prevent a further breach of the peace"" which allows for the police or the public to arrest a person before a breach of the peace has occurred.",1
"This is permitted when it is reasonable to believe should the person remain, that they would continue with their course of conduct and that a breach of the peace would occur.The only immediate sanction that can be imposed by a court for breach of the peace is to bind over the offender to keep the peace: that is, justices of the peace can require a person to enter into a recognizance to keep the peace.",1
Any punishment (in the sense of a loss of freedom or permanent financial penalty) takes the form of loss of the surety if the defendant fails to keep the peace or be of good behaviour during the period for which he is bound over. The binding over itself does not amount to a conviction (but any following behaviour causing loss of the surety might well result in conviction for an associated offence). A failure to enter into a recognizance may of itself lead to a person being committed to custody under s.115(3) Magistrates' Courts Act 1980.,1
"Nowadays a person causing a public disturbance may be arrested for, and/or charged with, causing harassment, alarm or distress contrary to the Public Order Act 1986.",1
"There are major differences between English law and Scots law with respect to dealing with breach of the peace; unlike England and Wales where criminal penalties apply to the behaviour leading to or liable to cause a breach of the peace, it is a specific criminal offence in Scotland which is prosecuted daily in the sheriff courts and due to its common law definition it can be applied to a number of scenarios.",1
"The maximum punishment if a case is remitted to the High Court remains imprisonment for life although such severe punishment is now rarely applied, usually being associated with breaches of licence during an existing life sentence. Breach of the peace consists of ""conduct severe enough to cause alarm to ordinary people and threaten serious disturbance to the community"".A constable may arrest any person, without warrant, who commits a breach of the peace. A member of the public may not arrest a person for behaviour which amounts to no more than a breach of the peace (i.e.",1
"an arrest is not always for the offence for which someone is eventually prosecuted but can be for a more serious crime that appears to be occurring). Breach of the peace can include, but is not limited to, any riotous behaviours (which includes ""rowdiness"" or ""brawling"") and any disorderly behaviour. This behaviour need not be noisy but still of a nature that would cause concern to other people. Examples include persistently following someone, delivering threatening letters and ""streaking"" or ""mooning"". One of the leading cases in Scots law is that of Smith v Donnelly, a case concerning a Faslane protester.Section",1
"38 of the Criminal Justice and Licensing (Scotland) Act 2010 created an offence of behaving in a threatening or abusive manner in a way likely to cause a reasonable person to suffer fear or alarm, similar to the Section 5 Public Order act in England and Wales. This subsists alongside breach of the peace.",1
"In the United States, prosecutions for breach of the peace are subject to constitutional constraints. In Terminiello v. City of Chicago (1949), the United States Supreme Court held that an ordinance of the City of Chicago that banned speech which ""stirs the public to anger, invites dispute, brings about a condition of unrest, or creates a disturbance"" was unconstitutional under the First Amendment to the United States Constitution. Justice Douglas stated: ""Accordingly a function of free speech under our system of government is to invite dispute.",1
"It may indeed best serve its high purpose when it induces a condition of unrest, creates dissatisfaction with conditions as they are, or even stirs people to anger. Speech is often provocative and challenging. It may strike at prejudices and preconceptions and have profound unsettling effects as it presses for acceptance of an idea.""In Cox v. Louisiana (1965), the Supreme Court held that a Louisiana statute criminalizing breaches of the peace was unconstitutionally vague and overbroad because it would allow persons to be prosecuted for expressing unpopular views.",1
"The statute read in part: Whoever with intent to provoke a breach of the peace, or under circumstances such that a breach of the peace may be occasioned thereby ... crowds or congregates with others ... in or upon ... a public street or public highway, or upon a public sidewalk, or any other public place or building ... and who fails or refuses to disperse and move on ...",1
"when ordered so to do by any law enforcement officer of any municipality, or parish, in which such act or acts are committed, or by any law enforcement officer of the state of Louisiana, or any other authorized person ... shall be guilty of disturbing the peace.",1
"On the state level, at least one court has reasoned that the essence of a breach of the peace was the potential to cause a disruption in tranquility or to promote the threat of violence, stating that a breach of the peace was that which ""disturbs or threatens to disturb the tranquility enjoyed by the citizens"". Common scold Public nuisance King's Peace Rule according to higher law Common law offence § England and Wales Picking quarrels and provoking trouble R v Howell 1982 (E/W case law) CPS.gov.uk",1
(self-defence / prevention of crime advice) The Crown Prosecution Service Guidance for Breach of the Peace and Bind Over Orders (Applies to England & Wales),1
"Fallout comes in two varieties. The first is a small amount of carcinogenic material with a long half-life. The second, depending on the height of detonation, is a large quantity of radioactive dust and sand with a short half-life. All nuclear explosions produce fission products, un-fissioned nuclear material, and weapon residues vaporized by the heat of the fireball. These materials are limited to the original mass of the device, but include radioisotopes with long lives. When the nuclear fireball does not reach the ground, this is the only fallout produced.",1
Its amount can be estimated from the fission-fusion design and yield of the weapon.,1
"fallout has occurred around the world; for example, people have been exposed to iodine-131 from atmospheric nuclear testing. Fallout accumulates on vegetation, including fruits and vegetables. Starting from 1951 people may have gotten exposure, depending on whether they were outside, the weather, and whether they consumed contaminated milk, vegetables or fruit. Exposure can be on an intermediate time scale or long term. The intermediate time scale results from fallout that has been put into the troposphere and ejected by precipitation during the first month. Long-term fallout can sometimes occur from deposition of tiny particles carried in the stratosphere.",1
"By the time that stratospheric fallout has begun to reach the earth, the radioactivity is very much decreased. Also, after a year it is estimated that a sizable quantity of fission products move from the northern to the southern stratosphere. The intermediate time scale is between 1 and 30 days, with long term fallout occurring after that. Examples of both intermediate and long term fallout occurred after the 1986 Chernobyl accident, which contaminated over 20,000 km2 (7,700 sq mi) of land in Ukraine and Belarus.",1
"The main fuel of the reactor was uranium, and surrounding this was graphite, both of which were vaporized by the hydrogen explosion that destroyed the reactor and breached its containment. An estimated 31 people died within a few weeks after this happened, including two plant workers killed at the scene. Although residents were evacuated within 36 hours, people started to complain of vomiting, migraines and other major signs of radiation sickness. The officials of Ukraine had to close off an 18-mile (30 km) area. Long term effects included at least 6,000 cases of thyroid cancer, mainly among children.",1
"Fallout spread throughout Western Europe, with Northern Scandinavia receiving a heavy dose, contaminating reindeer herds in Lapland, and salad greens becoming almost unavailable in France.",1
"A surface burst generates large amounts of particulate matter, composed of particles from less than 100 nm to several millimeters in diameter—in addition to very fine particles that contribute to worldwide fallout. The larger particles spill out of the stem and cascade down the outside of the fireball in a downdraft even as the cloud rises, so fallout begins to arrive near ground zero within an hour. More than half the total bomb debris lands on the ground within about 24 hours as local fallout.",1
"Chemical properties of the elements in the fallout control the rate at which they are deposited on the ground. Less volatile elements deposit first. Severe local fallout contamination can extend far beyond the blast and thermal effects, particularly in the case of high yield surface detonations. The ground track of fallout from an explosion depends on the weather from the time of detonation onward. In stronger winds, fallout travels faster but takes the same time to descend, so although it covers a larger path, it is more spread out or diluted.",1
"Thus, the width of the fallout pattern for any given dose rate is reduced where the downwind distance is increased by higher winds. The total amount of activity deposited up to any given time is the same irrespective of the wind pattern, so overall casualty figures from fallout are generally independent of winds. But thunderstorms can bring down activity as rain allows fallout to drop more rapidly, particularly if the mushroom cloud is low enough to be below (""washout""), or mixed with (""rainout""), the thunderstorm.",1
"Whenever individuals remain in a radiologically contaminated area, such contamination leads to an immediate external radiation exposure as well as a possible later internal hazard from inhalation and ingestion of radiocontaminants, such as the rather short-lived iodine-131, which is accumulated in the thyroid.",1
"For subsurface land bursts, the surge is made up of small solid particles, but it still behaves like a fluid. A soil earth medium favors base surge formation in an underground burst. Although the base surge typically contains only about 10% of the total bomb debris in a subsurface burst, it can create larger radiation doses than fallout near the detonation, because it arrives sooner than fallout, before much radioactive decay has occurred.",1
"Meteorological conditions greatly influence fallout, particularly local fallout. Atmospheric winds are able to bring fallout over large areas. For example, as a result of a Castle Bravo surface burst of a 15 Mt thermonuclear device at Bikini Atoll on March 1, 1954, a roughly cigar-shaped area of the Pacific extending over 500 km downwind and varying in width to a maximum of 100 km was severely contaminated. There are three very different versions of the fallout pattern from this test, because the fallout was measured only on a small number of widely spaced Pacific Atolls.",1
"Gy, while under more dire conditions of war (a bad diet, little medical care, poor nursing) the LD50 was 2.5 Gy (250 rad). There have been few documented cases of survival beyond 6 Gy. One person at Chernobyl survived a dose of more than 10 Gy, but many of the persons exposed there were not uniformly exposed over their entire body. If a person is exposed in a non-homogeneous manner then a given dose (averaged over the entire body) is less likely to be lethal.",1
"For instance, if a person gets a hand/low arm dose of 100 Gy, which gives them an overall dose of 4 Gy, they are more likely to survive than a person who gets a 4 Gy dose over their entire body. A hand dose of 10 Gy or more would likely result in loss of the hand. A British industrial radiographer who was estimated to have received a hand dose of 100 Gy over the course of his lifetime lost his hand because of radiation dermatitis. Most people become ill after an exposure to 1 Gy or more.",1
"The fetuses of pregnant women are often more vulnerable to radiation and may miscarry, especially in the first trimester. One hour after a surface burst, the radiation from fallout in the crater region is 30 grays per hour (Gy/h). Civilian dose rates in peacetime range from 30 to 100 µGy per year. Fallout radiation decays relatively quickly with time. Most areas become fairly safe for travel and decontamination after three to five weeks.For yields of up to 10 kt, prompt radiation is the dominant producer of casualties on the battlefield.",1
"Humans receiving an acute incapacitating dose (30 Gy) have their performance degraded almost immediately and become ineffective within several hours. However, they do not die until five to six days after exposure, assuming they do not receive any other injuries. Individuals receiving less than a total of 1.5 Gy are not incapacitated. People receiving doses greater than 1.5 Gy become disabled, and some eventually die. A dose of 5.3 Gy to 8.3 Gy is considered lethal but not immediately incapacitating.",1
"Personnel exposed to this amount of radiation have their cognitive performance degraded in two to three hours, depending on how physically demanding the tasks they must perform are, and remain in this disabled state at least two days. However, at that point they experience a recovery period and can perform non-demanding tasks for about six days, after which they relapse for about four weeks. At this time they begin exhibiting symptoms of radiation poisoning of sufficient severity to render them totally ineffective. Death follows at approximately six weeks after exposure, although outcomes may vary.",1
"Late or delayed effects of radiation occur following a wide range of doses and dose rates. Delayed effects may appear months to years after irradiation and include a wide variety of effects involving almost all tissues or organs. Some of the possible delayed consequences of radiation injury, with the rates above the background prevalence, depending on the absorbed dose, include carcinogenesis, cataract formation, chronic radiodermatitis, decreased fertility, and genetic mutations.Presently,",1
"the only teratological effect observed in humans following nuclear attacks on highly populated areas is microcephaly which is the only proven malformation, or congenital abnormality, found in the in utero developing human fetuses present during the Hiroshima and Nagasaki bombings. Of all the pregnant women who were close enough to be exposed to the prompt burst of intense neutron and gamma doses in the two cities, the total number of children born with microcephaly was below 50.",1
No statistically demonstrable increase of congenital malformations was found among the later conceived children born to survivors of the nuclear detonations at Hiroshima and Nagasaki. The surviving women of Hiroshima and Nagasaki who could conceive and were exposed to substantial amounts of radiation went on and had children with no higher incidence of abnormalities than the Japanese average.The,1
"results of the Baby Tooth Survey were published in the November 24, 1961, edition of the journal Science, and showed that levels of strontium-90 had risen steadily in children born in the 1950s, with those born later showing the most pronounced increases. The results of a more comprehensive study of the elements found in the teeth collected showed that children born after 1963 had levels of strontium-90 in their baby teeth that was 50 times higher than that found in children born before large-scale atomic testing began. The findings helped convince U.S. President John F.",1
"Kennedy to sign the Partial Nuclear Test Ban Treaty with the United Kingdom and Soviet Union, which ended the above-ground nuclear weapons testing that created the greatest amounts of atmospheric nuclear fallout.The baby tooth survey was a ""campaign [that] effectively employed a variety of media advocacy strategies"" to alarm the public and ""galvanized"" support against atmospheric nuclear testing, with putting an end to such testing being commonly viewed as a positive outcome for a myriad of other reasons.",1
"The survey could not show then at the time, nor in the decades that have elapsed, that the levels of global strontium-90 or fallout in general, were in any way life-threatening, primarily because ""50 times the strontium-90 from before nuclear testing"" is a minuscule number, and multiplication of minuscule numbers results in only a slightly larger minuscule number.",1
"Moreover, the Radiation and Public Health Project which currently retains the teeth has had their stance and publications heavily criticized: A 2003 article in The New York Times states that the group's work has been controversial and has little credibility with the scientific establishment.",1
"Similarly, in an April 2014 article in Popular Science, Sarah Fecht explains that the group's work, specifically the widely discussed case of cherry-picking data to suggest that fallout from the 2011 Fukushima accident caused infant deaths in America, is ""junk science"", as despite their papers being peer-reviewed, all independent attempts to corroborate their results return findings that are not in agreement with what the organization suggests. The organization had earlier also tried to suggest the same thing occurred after the 1979 Three Mile Island accident but this was likewise exposed to be without merit.",1
"The tooth survey, and the expansion of the organization into attempting the same test-ban approach with US nuclear electric power stations as the new target, is likewise detailed and critically labelled as the ""Tooth Fairy issue"" by the Nuclear Regulatory Commission.",1
"conducted hundreds of nuclear weapon tests. Atmospheric testing took place over the US mainland during this time and as a consequence scientists have been able to study the effect of nuclear fallout on the environment. Detonations conducted near the surface of the earth irradiated thousands of tons of soil. Of the material drawn into the atmosphere, portions of radioactive material will be carried by low altitude winds and deposited in surrounding areas as radioactive dust. The material intercepted by high altitude winds will continue to travel.",1
"When a radiation cloud at high altitude is exposed to rainfall, the radioactive fallout will contaminate the downwind area below.Agricultural fields and plants will absorb the contaminated material and animals will consume the radioactive material. As a result, the nuclear fallout may cause livestock to become ill or die, and if consumed the radioactive material will be passed on to humans.The damage to other living organism as a result to nuclear fallout depends on the species. Mammals particularly are extremely sensitive to nuclear radiation, followed by birds, plants, fish, reptiles, crustaceans, insects, moss, lichen, algae, bacteria, mollusks, and viruses.Climatologist",1
"the USSR, Great Britain, and China attempted to educate their citizens about surviving a nuclear attack by providing procedures on minimizing short-term exposure to fallout. This effort commonly became known as Civil Defense. Fallout protection is almost exclusively concerned with protection from radiation. Radiation from a fallout is encountered in the forms of alpha, beta, and gamma radiation, and as ordinary clothing affords protection from alpha and beta radiation, most fallout protection measures deal with reducing exposure to gamma radiation.",1
A shelter built with these materials for the purposes of fallout protection is known as a fallout shelter.,1
"As the nuclear energy sector continues to grow, the international rhetoric surrounding nuclear warfare intensifies, and the ever-present threat of radioactive materials falling into the hands of dangerous people persists, many scientists are working hard to find the best way to protect human organs from the harmful effects of high energy radiation. Acute radiation syndrome (ARS) is the most immediate risk to humans when exposed to ionizing radiation in dosages greater than around 0.1 Gy/hr. Radiation in the low energy spectrum (alpha and beta radiation) with minimal penetrating power is unlikely to cause significant damage to internal organs.",1
"The high penetrating power of gamma and neutron radiation, however, easily penetrates the skin and many thin shielding mechanisms to cause cellular degeneration in the stem cells found in bone marrow. While full body shielding in a secure fallout shelter as described above is the most optimal form of radiation protection, it requires being locked in a very thick bunker for a significant amount of time.",1
"In the event of a nuclear catastrophe of any kind, it is imperative to have mobile protection equipment for medical and security personnel to perform necessary containment, evacuation, and any number of other important public safety objectives. The mass of the shielding material required to properly protect the entire body from high energy radiation would make functional movement essentially impossible. This has led scientists to begin researching the idea of partial body protection: a strategy inspired by hematopoietic stem cell transplantation (HSCT).",1
"The danger of radiation from fallout also decreases rapidly with time due in large part to the exponential decay of the individual radionuclides. A book by Cresson H. Kearny presents data showing that for the first few days after the explosion, the radiation dose rate is reduced by a factor of ten for every seven-fold increase in the number of hours since the explosion.",1
"He presents data showing that ""it takes about seven times as long for the dose rate to decay from 1000 roentgens per hour (1000 R/hr) to 10 R/hr (48 hours) as to decay from 1000 R/hr to 100 R/hr (7 hours)."" This is a rule of thumb based on observed data, not a precise relation.",1
"The United States government, often the Office of Civil Defense in the Department of Defense, provided guides to fallout protection in the 1960s, frequently in the form of booklets. These booklets provided information on how to best survive nuclear fallout. They also included instructions for various fallout shelters, whether for a family, a hospital, or a school shelter were provided. There were also instructions for how to create an improvised fallout shelter, and what to do to best increase a person's chances for survival if they were unprepared.The",1
"central idea in these guides is that materials like concrete, dirt, and sand are necessary to shield a person from fallout particles and radiation. A significant amount of materials of this type are necessary to protect a person from fallout radiation, so safety clothing cannot protect a person from fallout radiation. However, protective clothing can keep fallout particles off a person's body, but the radiation from these particles will still permeate through the clothing. For safety clothing to be able to block the fallout radiation, it would have to be so thick and heavy that a person could not function.These",1
"guides indicated that fallout shelters should contain enough resources to keep its occupants alive for up to two weeks. Community shelters were preferred over single-family shelters. The more people in a shelter, the greater quantity and variety of resources that shelter would be equipped with. These communities’ shelters would also help facilitate efforts to recuperate the community in the future. Single family shelters should be built below ground if possible. Many different types of fallout shelters could be made for a relatively small amount of money.",1
"A common format for fallout shelters was to build the shelter underground, with solid concrete blocks to act as the roof. If a shelter could only be partially underground, it was recommended to mound over that shelter with as much dirt as possible. If a house had a basement, it is best for a fallout shelter to be constructed in a corner of the basement. The center of a basement is where the most radiation will be because the easiest way for radiation to enter a basement is from the floor above.",1
"People in these buildings should get as close to the center of the building as possible and avoid the top and ground floors.Schools were preferred fallout shelters according to the Office of Civil Defense. Schools, not including universities, contained one-quarter of the population of the United States when they were in session at that time. Schools distribution across the nation reflected the density of the population and were often a best building in a community to act as a fallout shelter. Schools also already had organization with leaders set in place.",1
"US Department of Homeland Security and the Federal Emergency Management Agency in coordination with other agencies concerned with public protection in the aftermath of a nuclear detonation have developed more recent guidance documents that build on the older Civil Defense frameworks. Planning Guidance for Response to a Nuclear Detonation was published in 2022 and provided in-depth analysis and response planning for local government jurisdictions. Fallout can also refer to nuclear accidents, although a nuclear reactor does not explode like a nuclear weapon.",1
The isotopic signature of bomb fallout is very different from the fallout from a serious power reactor accident (such as Chernobyl or Fukushima). The key differences are in volatility and half-life.,1
The boiling point of an element (or its compounds) is able to control the percentage of that element that a power reactor accident releases. The ability of an element to form a solid controls the rate it is deposited on the ground after having been injected into the atmosphere by a nuclear detonation or accident.,1
"A half life is the time it takes half of the radiation of a specific substance to decay. A large amount of short-lived isotopes such as 97Zr are present in bomb fallout. This isotope and other short-lived isotopes are constantly generated in a power reactor, but because the criticality occurs over a long length of time, the majority of these short lived isotopes decay before they can be released.",1
"Nuclear fallout can occur due to a number of different sources. One of the most common potential sources of nuclear fallout is that of nuclear reactors. Because of this, steps must be taken to ensure the risk of nuclear fallout at nuclear reactors is controlled. In the 1950s and 60's, the United States Atomic Energy Commission (AEC) began developing safety regulations against nuclear fallout for civilian nuclear reactors. Because the effects of nuclear fallout are more widespread and longer lasting than other forms of energy production accidents, the AEC desired a more proactive response towards potential accidents than ever before.",1
"One step to prevent nuclear reactor accidents was the Price-Anderson Act. Passed by Congress in 1957, the Price-Anderson Act ensured government assistance above the $60 million covered by private insurance companies in the case of a nuclear reactor accident. The main goal of the Price-Anderson Act was to protect the multi-billion-dollar companies overseeing the production of nuclear reactors. Without this protection, the nuclear reactor industry could potentially come to a halt, and the protective measures against nuclear fallout would be reduced.",1
"However, because of the limited experience in nuclear reactor technology, engineers had a difficult time calculating the potential risk of released radiation. Engineers were forced to imagine every unlikely accident, and the potential fallout associated with each accident. The AEC's regulations against potential nuclear reactor fallout were centered on the ability of the power plant to the Maximum Credible Accident (MCA). The MCA involved a ""large release of radioactive isotopes after a substantial meltdown of the reactor fuel when the reactor coolant system failed through a Loss-of-Coolant Accident"".",1
"The NRC was committed to 'regulations through research', which gave the regulatory committee a knowledge bank of research on which to draw their regulations. Much of the research done by the NRC sought to move safety systems from a deterministic viewpoint into a new probabilistic approach. The deterministic approach sought to foresee all problems before they arose. The probabilistic approach uses a more mathematical approach to weigh the risks of potential radiation leaks. Much of the probabilistic safety approach can be drawn from the radiative transfer theory in Physics, which describes how radiation travels in free space and through barriers.",1
"The scale, which was developed in 1990 by the International Atomic Energy Agency and the Nuclear Energy Agency of the Organization for Economic Co-operation and Development, classifies these nuclear accidents based on the potential impact of the fallout: Defence-in-Depth: This is the lowest form of nuclear accidents and refers to events that have no direct impact on people or the environment but must be taken note of to improve future safety measures. Radiological Barriers and Control: This category refers to events that have no direct impact on people or the environment and only refer to the damage caused within major facilities.",1
"People and the Environment: This section of the scale consists of more serious nuclear accidents. Events in this category could potentially cause radiation to spread to people close to the location of the accident. This also includes an unplanned, widespread release of the radioactive material.The INES scale is composed of seven steps that categorize the nuclear events, ranging from anomalies that must be recorded to improve upon safety measures to serious accidents that require immediate action.",1
"The explosion itself resulted in the deaths of two plant workers, while 28 people died over the weeks that followed of severe radiation poisoning. Furthermore, young children and adolescents in the areas most contaminated by the radiation exposure showed an increase in the risk for thyroid cancer, although the United Nations Scientific Committee on the Effects of Atomic Radiation stated that ""there is no evidence of a major public health impact"" apart from that.",1
"The nuclear accident also took a heavy toll on the environment, including contamination in urban environments caused by the deposition of radionuclides and the contamination of ""different crop types, in particular, green leafy vegetables ... depending on the deposition levels, and time of the growing season"".Three Mile Island The nuclear meltdown at Three Mile Island in 1979 was categorized as a Level 5 accident on the INES scale because of the ""severe damage to the reactor core"" and the radiation leak caused by the incident.",1
"Three Mile Island was the most serious accident in the history of American commercial nuclear power plants, yet the effects were different from those of the Chernobyl accident. A study done by the Nuclear Regulatory Commission following the incident reveals that the nearly 2 million people surrounding the Three Mile Island plant ""are estimated to have received an average radiation dose of only 1 millirem above the usual background dose"". Furthermore, unlike those affected by radiation in the Chernobyl accident, the development of thyroid cancer in the people around Three Mile Island was ""less aggressive and less advanced"".Fukushima",1
"Like the Three Mile Island incident, the incident at Fukushima was initially categorized as a Level 5 accident on the INES scale after a tsunami disabled the power supply and cooling of three reactors, which then suffered significant melting in the days that followed. However, after combining the events at the three reactors rather than assessing them individually, the accident was upgraded to an INES Level 7. The radiation exposure from the incident caused a recommended evacuation for inhabitants up to 30 km away from the plant.",1
"However, the fallout from the Fukushima accident had a minimal impact on the surrounding population. According to the Institut de Radioprotection et de Surêté Nucléaire, over 62 percent of assessed residents within the Fukushima prefecture received external doses of less than 1 mSv in the four months following the accident. In addition, comparing screening campaigns for children inside the Fukushima prefecture and in the rest of the country revealed no significant difference in the risk of thyroid cancer. Founded in 1974, the International Atomic Energy Agency (IAEA) was created to set forth international standards for nuclear reactor safety.",1
"The soviets, however, had their own priority: keeping the plant running at all costs. In the end, the same shift between deterministic safety designs to probabilistic safety designs prevailed. In 1989, the World Association of Nuclear Operators (WANO) was formed to cooperate with the IAEA to ensure the same three pillars of reactor safety across international borders. In 1991, WANO concluded (using a probabilistic safety approach) that all former communist-controlled nuclear reactors could not be trusted, and should be closed.",1
"(Smyth Report) The Effects of Nuclear War, Office of Technology Assessment (May 1979), (Available Online Archived 2016-08-28 at the Wayback Machine) T. Imanaka, S. Fukutani, M. Yamamoto, A. Sakaguchi and M. Hoshi, J. Radiation Research, 2006, 47, Suppl A121–A127. Sheldon Novick, The Careless Atom (Boston MA: Houghton Mifflin Co., 1969), p. 98 NUKEMAP3D – a 3D nuclear weapons effects simulator powered by Google Maps. It simulates the effects of nuclear weapons upon geographic areas.",1
"In 2003, participating governments and stakeholders of the organization issued Sustainable Development Strategy for the Seas of East Asia (SDS-SEA) to promote a common vision in the area of sustainable development in the region. In 2007, PEMSEA committed itself to implementing the SDS-SEA as a part of Phase I project (2007-2017). The latest phase's aim is to make PEMSEA a self-sustaining regional operating mechanism.PEMSEA's",1
"Every three years, PEMSEA hosts the East Asian Seas Congress that consists of a Ministerial Forum, an International Conference and other events. The conference focuses on tracking progress of SDS-SEA, encourages knowledge exchange and raises important issues regarding coastal management in the region. It also tries to engage private sector in helping develop sustainable financial and business solutions to coastal management problems. The first East Asian Seas Congress was held in December 2003 in Putrajaya, Malaysia. It was organized following the recommendations of the World Summit on Sustainable Development (WSSD) with the goal to improve situation related to coasts and oceans.",1
"The following two congresses were held in Haikou City, Hainan Province, PR China, in the year 2006 and in Philippines in the year 2009. The 2012 congress was held with the theme ""Building a Blue Economy: Strategy, Opportunities, and Partnerships in the Seas of East Asia"" in July 2012 in Changwon City, the Republic of Korea.",1
"The programme was instrumental to the adoption of several national and regional agreements, including: Putrajaya Declaration: Brunei Darussalam, Cambodia, PR China, DPR Korea, Indonesia, Japan, Malaysia, Philippines, RO Korea, Singapore, Thailand and Vietnam adopted the Putrajaya Declaration of Regional Cooperation for the Sustainable Development of the Seas of East Asia on 12 December 2003. The declaration formally adopted the SDS-SEA as a regional strategy for the sustainable development of the seas of the region.",1
"UNDP/GEF Yellow Sea LME ProjectCollaboratorsDepartment of Sustainability and Environment, Victoria, Australia National Oceanic and Atmospheric Administration, United States Department of Commerce Victorian Coastal Council, Victoria, Australia",1
"Road dust from tyre and road wear and road dust from unpaved road. Wet cooling towers in cooling systems. Various industrial processes such as mining, smelting and oil refining. Disasters (both natural or caused by humans, e.g, wildfires, earthquakes, wars, and September 11 attacks, etc). Microplastics (gaining attention as a type of airborne PM).In 2010 it was estimated that human-made (anthropogenic) aerosols account for about 10 percent of the total mass of aerosols in the atmosphere.",1
"In addition, sea spray aerosols may contain organic compounds like fatty acids and sugars, which influence their chemistry.Some secondary particles derive from the oxidation of primary gases such as sulfur and nitrogen oxides into sulfuric acid (liquid) and nitric acid (gaseous) or from biogenic emissions. The precursors for these aerosols—i.e. the gases from which they originate—may have an anthropogenic origin (from biomass and fossil fuel combustion) as well as a natural biogenic origin. In the presence of ammonia, secondary aerosols often take the form of ammonium salts; i.e.",1
"ammonium sulfate and ammonium nitrate (both can be dry or in aqueous solution); in the absence of ammonia, secondary compounds take an acidic form as sulfuric acid (liquid aerosol droplets) and nitric acid (atmospheric gas), all of which probably contribute to the health effects of particulates.Secondary sulfate and nitrate aerosols are strong light-scatterers. This is mainly because the presence of sulfate and nitrate causes the aerosols to increase to a size that scatters light effectively.",1
"Organic matter (OM) found in aerosols can be either primary or secondary, the latter part deriving from the oxidation of volatile organic compounds (VOCs); organic material in the atmosphere may either be biogenic or anthropogenic. Organic matter influences the atmospheric radiation field by both scattering and absorption. Some aerosols are predicted to include strongly light-absorbing material and are thought to yield large positive radiative forcing. Some secondary organic aerosols (SOAs) resulting from combustion products of internal combustion engines, have been identified as a danger to health.",1
"Particulate toxicity has been found to vary by region and source contribution which affects the particles chemical composition. The chemical composition of the aerosol directly affects how it interacts with solar radiation. The chemical constituents within the aerosol change the overall refractive index. The refractive index will determine how much light is scattered and absorbed. The composition of particulate matter that generally causes visual effects, haze, consists of sulfur dioxide, nitrogen oxides, carbon monoxide, mineral dust, and organic matter.",1
"Among the most obvious patterns that the size distribution time series shows is that in the planet's most southerly latitudes, nearly all the aerosols are large, but in the high northern latitudes, smaller aerosols are very abundant. Most of the Southern Hemisphere is covered by the ocean, where the largest source of aerosols is natural sea salt from dried sea spray. Because the land is concentrated in the Northern Hemisphere, the amount of small aerosols from fires and human activities is greater there than in the Southern Hemisphere.",1
"Larger particles (greater than 10 micrometers in diameter) tend to settle to the ground by gravity in a matter of hours whereas the smallest particles (less than 1 micrometer) can stay in the atmosphere for weeks and are mostly removed by precipitation. There are also evidence that it is not uncommon for aerosols to ""travel across the ocean"". For example, in September 2017 wildfires burning across the western United States and Canada, and the smoke was found to have arrived over the United Kingdom and northern France in three days, as shown by satellite images.",1
"general building construction, some places that have acknowledged the possible health risks of construction dust for decades legally require the relevant contractor to adopt effective dust control measures, although inspections, fines and imprisonments are rare in recent years (for example, two prosecutions with a total fines of HKD$6000 in Hong Kong in the year 2021).Some",1
"Atmospheric aerosols affect the climate of the earth by changing the amount of incoming solar radiation and outgoing terrestrial longwave radiation retained in the earth's system. This occurs through several distinct mechanisms which are split into direct, indirect and semi-direct aerosol effects. The aerosol climate effects are the biggest source of uncertainty in future climate predictions. The Intergovernmental Panel on Climate Change (IPCC), Third Assessment Report, says:While the radiative forcing due to greenhouse gases may be determined to a reasonably high degree of accuracy...",1
"the uncertainties relating to aerosol radiative forcings remain large, and rely to a large extent on the estimates from global modeling studies that are difficult to verify at the present time.",1
"The direct aerosol effect consists of any direct interaction of radiation with atmospheric aerosols, such as absorption or scattering. It affects both short and longwave radiation to produce a net negative radiative forcing. The magnitude of the resultant radiative forcing due to the direct effect of an aerosol is dependent on the albedo of the underlying surface, as this affects the net amount of radiation absorbed or scattered to space. For example, if a highly scattering aerosol is above a surface of low albedo it has a greater radiative forcing than if it was above a surface of high albedo.",1
"The converse is true of absorbing aerosol, with the greatest radiative forcing arising from a highly absorbing aerosol over a surface of high albedo. The direct aerosol effect is a first-order effect and is therefore classified as a radiative forcing by the IPCC. The interaction of an aerosol with radiation is quantified by the single-scattering albedo (SSA), the ratio of scattering alone to scattering plus absorption (extinction) of radiation by a particle. The SSA tends to unity if scattering dominates, with relatively little absorption, and decreases as absorption increases, becoming zero for infinite absorption.",1
"For example, the sea-salt aerosol has an SSA of 1, as a sea-salt particle only scatters, whereas soot has an SSA of 0.23, showing that it is a major atmospheric aerosol absorber.",1
"This has the effect of suppressing precipitation, increasing the cloud lifetime, known as the cloud lifetime aerosol effect, second indirect effect or Albrecht effect. This has been observed as the suppression of drizzle in ship exhaust plume compared to ambient clouds, and inhibited precipitation in biomass burning plumes. This cloud lifetime effect is classified as a climate feedback (rather than a radiative forcing) by the IPCC due to the interdependence between it and the hydrological cycle. However, it has previously been classified as a negative radiative forcing.",1
"However, it has previously been classified as a negative radiative forcing.",1
"Some of them are biogenic (typically produced via atmospheric chemical reactions with dimethyl sulfide from mostly marine plankton) or geological via volcanoes or weather-driven from wildfires and other natural combustion events, but in the recent decades anthropogenic sulfate aerosols produced through combustion of fossil fuels with a high sulfur content, primarily coal and certain less-refined fuels, like aviation and bunker fuel, had dominated.",1
"Black carbon (BC), or carbon black, or elemental carbon (EC), often called soot, is composed of pure carbon clusters, skeleton balls and fullerenes, and is one of the most important absorbing aerosol species in the atmosphere. It should be distinguished from organic carbon (OC): clustered or aggregated organic molecules on their own or permeating an EC buckyball. Black carbon from fossil fuels is estimated by the IPCC in the Fourth Assessment Report of the IPCC, 4AR, to contribute a global mean radiative forcing of +0.2 W/m2 (was +0.1",1
"W/m2 in the Second Assessment Report of the IPCC, SAR), with a range +0.1 to +0.4 W/m2. A study published in 2013 however, states that ""the best estimate for the industrial-era (1750 to 2005) direct radiative forcing of atmospheric black carbon is +0.71 W/m2 with 90% uncertainty bounds of (+0.08, +1.27) W/m2"" with ""total direct forcing by all-black carbon sources, without subtracting the preindustrial background, is estimated as +0.88 (+0.17, +1.48) W/m2"".",1
"Volcanoes are a large natural source of aerosol and have been linked to changes in the earth's climate often with consequences for the human population. Eruptions linked to changes in climate include the 1600 eruption of Huaynaputina which was linked to the Russian famine of 1601–1603, leading to the deaths of two million, and the 1991 eruption of Mount Pinatubo which caused a global cooling of approximately 0.5 °C lasting several years. Research tracking the effect of light-scattering aerosols in the stratosphere during 2000 and 2010 and comparing its pattern to volcanic activity show a close correlation.",1
"studies of the Sahel drought and major increases since 1967 in rainfall in Australia over the Northern Territory, Kimberley, Pilbara and around the Nullarbor Plain have led some scientists to conclude that the aerosol haze over South and East Asia has been steadily shifting tropical rainfall in both hemispheres southward.",1
"Particle size is the main determinant of where in the respiratory tract it will come to rest when inhaled. Larger particles are generally filtered in the nose and throat via cilia and mucus, but particulate matter smaller than about 10 micrometers can settle in the bronchi and lungs and cause health problems. The 10-micrometer size does not represent a strict boundary between respirable and non-respirable particles but has been agreed upon for monitoring of airborne PM by most regulatory agencies.",1
"Because of their small size, particles on the order of 10 micrometers or less (coarse particulate matter, PM10) can penetrate the deepest part of the lungs such as the bronchioles or alveoli. When asthmatics are exposed to these conditions it can trigger bronchoconstriction.Similarly, fine particulate matter (PM2.5) tends to penetrate into the gas exchange regions of the lung (alveoli), and very small particles (ultrafine particulate matter PM0.1) may pass through the lungs to affect other organs. Penetration of particles is not wholly dependent on their size; shape and chemical composition also play a part.",1
"The thoracic fraction is the fraction that enters the thorax and is deposited within the lung's airways. The respirable fraction is what is deposited in the gas exchange regions (alveoli).The smallest particles, nanoparticles, which are less than 180 nanometers in size, may be even more damaging to the cardiovascular system. Nanoparticles can pass through cell membranes and migrate into other organs, including the brain. Particles emitted from modern diesel engines (commonly referred to as Diesel Particulate Matter, or DPM) are typically in the size range of 100 nanometers (0.1 micrometers).",1
"These soot particles also carry carcinogens like benzopyrenes adsorbed on their surface. Particulate mass is not a proper measure of the health hazard. A particle of 10 μm diameter has approximately the same mass as 1 million particles of 100 nm diameter, but is much less hazardous, as it is unlikely to enter the alveoli. Legislative limits for engine emissions based on mass are therefore not protective. Proposals for new regulations exist in some countries, with suggestions to limit the particle surface area or the particle count (numerical quantity) / particle number concentration (PNC) instead.",1
"Another complexity not entirely documented is how the shape of PM can affect health, except for the needle-like shape of asbestos fibres which can lodge in the lungs. Geometrically angular shapes have more surface area than rounder shapes, which in turn affects the binding capacity of the particle to other, possibly more dangerous substances. The table below lists the colours and shapes of some common atmospheric particulates:",1
"Composition of particles can vary greatly depending on their sources and how they are produced. For example, dust emitted from the burning of living and dead vegetation would be different from those emitted from the burning of joss paper or construction wastes. Particles emitted from fuel combustion are not the same as those emitted from waste combustion. The particulate matter generated from the fire of a recycling yard or a ship full of scrap metal may contain more toxic substances than other types of burning. Different types of building refurbishment activities produce different kinds of dust too.",1
"The composition of PM generated from cutting or mixing concrete made with Portland Cement would be different from those generated from cutting or mixing concrete made with different types of slag (e.g. GGBFS, EAF slag), fly ash or even EAF dust (EAFD), while EFAD, slag and fly ash are likely to be more toxic as they contain heavy metals.",1
"Higher rates of infertility have been correlated with exposure to particulates.In addition, inhalation of PM2.5 – PM10 is associated with elevated risk of adverse pregnancy outcomes, such as low birth weight. Maternal PM2.5 exposure during pregnancy is also associated with high blood pressure in children. Exposure to PM2.5 has been associated with greater reductions in birth weight than exposure to PM10. PM exposure can cause inflammation, oxidative stress, endocrine disruption, and impaired oxygen transport access to the placenta, all of which are mechanisms for heightening the risk of low birth weight.",1
"Overall epidemiologic and toxicological evidence suggests that a causal relationship exists between long-term exposures to PM2.5 and developmental outcomes (i.e. low birth weight). However, studies investigating the significance of trimester-specific exposure have proven to be inconclusive, and results of international studies have been inconsistent in drawing associations of prenatal particulate matter exposure and low birth weight. As perinatal outcomes have been associated with lifelong health and exposure to particulate matter is widespread, this issue is of critical public health importance and additional research will be essential to inform public policy on the matter.",1
"and 10 micrometers in diameter was published 2008 and found an association with hospital admissions for cardiovascular diseases but no evidence of an association with the number of hospital admissions for respiratory diseases. After taking into account fine particle levels (PM2.5 and less), the association with coarse particles remained but was no longer statistically significant, which means the effect is due to the subsection of fine particles. The Mongolian government agency recorded a 45% increase in the rate of respiratory illness in the past five years (reported in 2011).",1
"Bronchial asthma, chronic obstructive pulmonary disease, and interstitial pneumonia were the most common ailments treated by area hospitals. Levels of premature death, chronic bronchitis, and cardiovascular disease are increasing at a rapid rate.",1
"also appear to have a role in the pathogenesis of Alzheimer's disease and premature brain aging. There is increasing evidence to suggest a correlation between PM2.5 exposure and the prevalence of neurodegenerative diseases such as Alzheimer's. Several epidemiological studies have suggested a link between PM2.5 exposure and cognitive decline, particularly in the development of neurodegenerative diseases such as Alzheimer's. While the exact mechanisms behind the link between PM2.5",1
"exposure and cognitive decline are not fully understood, research suggests that the fine particles may be able to enter the brain through the olfactory nerve and cause inflammation and oxidative stress, which can damage brain cells and contribute to the development of neurodegenerative diseases.",1
"risk of all disease for every 10 micrograms per cubic meter. Levels averaged 65 in 1996, 68 in 2002, and 52 in 2004. Decreasing levels may be attributed to conversions of diesel to natural gas combustion as well as improved regulations.",1
"This reality is made worse by the finding that ""health care occurs in the context of broader historic and contemporary social and economic inequality and persistent racial and ethnic discrimination in many sectors of American life"". Residential proximity to particulate emitting facilities increases exposure to PM 2.5 which is linked to increased morbidity and mortality rates. Multiple studies confirm the burden of PM emissions is higher among non-White and poverty ridden populations, though some say that income does not drive these differences.",1
"A 2020 article relates the long term health effects of living in high PM concentrations to increased risk, spread, and mortality rates from the SARS-CoV-2 or COVID-19, and faults a history of racism for this outcome.",1
"Wildfires also have been associated with increased emergency department visits due to particulate matter exposure, as well as an increased risk of asthma related events. Furthermore, a link between PM2.5 from wildfires and increased risk of hospitalizations for cardiopulmonary diseases has been discovered. Various lines of evidence also suggest wildfire smoke reduces mental performance.",1
"Similar lobbying and corporate public relations efforts were undertaken by the American Petroleum Institute, a trade association of the oil and gas industry, and the climate change denier private think tank, The Heartland Institute. ""The response from fossil-fuel interests has been from the same playbook – first they know, then they scheme, then they deny and then they delay. They've fallen back on delay, subtle forms of propaganda and the undermining of regulation,"" said Geoffrey Supran, a Harvard University researcher of the history of fossil-fuel companies and climate change.",1
"In 2013, the ESCAPE study involving 312,944 people in nine European countries revealed that there was no safe level of particulates and that for every increase of 10 μg/m3 in PM10, the lung cancer rate rose 22%. For PM2.5 there was a 36% increase in lung cancer per 10 μg/m3. In a 2014 meta-analysis of 18 studies globally including the ESCAPE data, for every increase of 10 μg/m3 in PM2.5, the lung cancer rate rose 9%.",1
In Canada the standard for particulate matter is set nationally by the federal-provincial Canadian Council of Ministers of the Environment (CCME). Jurisdictions (provinces and territories) may set more stringent standards. The CCME standard for particulate matter 2.5 (PM2.5) as of 2015 is 28 μg/m3 (calculated using the 3-year average of the annual 98th percentile of the daily 24-hr average concentrations) and 10 μg/m3 (3-year average of annual mean). PM2.5 standards will increase in stringency in 2020.,1
"To mitigate the problem of wood burning, starting from May 2021, traditional house coal (bituminous coal) and wet wood, two of the most polluting fuels, can no longer be sold. Wood sold in volumes of less than 2m3 must be certified as 'Ready to Burn', which means it has a moisture content of 20% or less. Manufactured solid fuels must also be certified as 'Ready to Burn' to ensure they meet sulphur and smoke emission limits.",1
"The law places the responsibility to provide this information to the Department on those who manufacture or import the chemicals. On 22 January 2009, a formal information request letter was sent to manufacturers who produce or import carbon nanotubes in California, or who may export carbon nanotubes into the State. This letter constitutes the first formal implementation of the authorities placed into statute by AB 289 and is directed to manufacturers of carbon nanotubes, both industry, and academia within the State, and to manufacturers outside California who export carbon nanotubes to California.",1
"This request for information must be met by the manufacturers within one year. DTSC is waiting for the upcoming 22 January 2010 deadline for responses to the data call-in. The California Nano Industry Network and DTSC hosted a full-day symposium on 16 November 2009 in Sacramento, California. This symposium provided an opportunity to hear from nanotechnology industry experts and discuss future regulatory considerations in California.DTSC is expanding the Specific Chemical Information Call-in to members of the nanometal oxides, the latest information can be found on their website.",1
"Of the top ten cleanest cities, five are from Australia. They are Hobart, Wollongong, Launceston, Sydney and Perth. Honolulu is the only U.S. city in the top ten list, ranking tenth with levels of 4 μg/m3, with a tiny increase since 2019. Almost all of the top ten most polluted cities are in the Middle East and Asia. The worst is Dammam in Saudi Arabia with a PM2.5 level of 155 μg/m3. Lahore in Pakistan is the second worst with 98.1 μg/m3. The third is Dubai, home to the world's tallest building.",1
"In the bottom ten are three cities from India, Muzaffarnagar, Delhi and New Delhi. Here is a list of the 30 most polluted cities by PM2.5, Jan to Sep 2022: There are limits to the above survey. For example, not every city in the world is covered, and that the number of monitoring stations for each city would not be the same. So the data is for reference only.",1
"Control of dust from construction and demolition activities Controlling construction dust with on-tool extraction (4 page PDF with photos) Beware of dust - Hilti Canada | Dust control - Hilti Hong Kong What is Local Exhaust Ventilation (LEV)? Welding fume: protect your workers NASA's Earth Minute: My Name is Aerosol SARS-CoV-2 Aerosol Mechanisms, The Aerosol Society Current global map of PM1 distribution | Current global map of PM1 and PM2.5 distribution | Current global map of PM1, PM2.5",1
"The word cenosphere is derived from two Greek words, κενός (kenos: hollow, empty) and σφαίρα (sphaira: sphere), literally meaning ""hollow sphere."" The process of burning coal in thermal power plants produces fly ash containing ceramic particles made largely of alumina and silica. They are produced at temperatures of 1,500 to 1,750 °C (2,730 to 3,180 °F) through complicated chemical and physical transformation. Their chemical composition and structure varies considerably depending on the composition of coal that generated them. The ceramic particles in fly ash have three types of structures. The first type of particles are solid and are called precipitator.",1
"The second type of particles are hollow and are called cenospheres. The third type of particles are called plerospheres, which are hollow particles of large diameter filled with smaller size precipitator and cenospheres.",1
The definition of cenosphere has changed over the last 30 years. Up until the 1990s it was limited to a largely carbonaceous sphere caused by the oxygen-deficient combustion of a liquid fuel droplet that was cooled below 200 °C (392 °F) before it was consumed. These fuel cenospheres indicated a combustion source using injected droplets of fuel or the open burning of heavy liquid fuels such as asphalt or a thermoplastic material that were bubbling as they burned; the bursting of the bubbles created airborne droplets of fuel.,1
Syntactic foam Cores of sandwich structure Removal of nitrogen oxides Dry reforming of methane Cenocell – Concrete material using fly ash in place of cement Fly ash – Residue of coal combustion Glass microsphere Microbead (research) – Uniform polymer particles,1
"A subsequent effort to call ozone ""electrified oxygen"" he ridiculed by proposing to call the ozone from white phosphorus ""phosphorized oxygen"". The formula for ozone, O3, was not determined until 1865 by Jacques-Louis Soret and confirmed by Schönbein in 1867.For much of the second half of the 19th century and well into the 20th, ozone was considered a healthy component of the environment by naturalists and health-seekers. Beaumont, California had as its official slogan ""Beaumont: Zone of Ozone"", as evidenced on postcards and Chamber of Commerce letterhead. Naturalists working outdoors often considered the higher elevations beneficial because of their ozone content.",1
"In 1911, Leonard Hill and Martin Flack stated in the Proceedings of the Royal Society B that ozone's healthful effects ""have, by mere iteration, become part and parcel of common belief; and yet exact physiological evidence in favour of its good effects has been hitherto almost entirely wanting ... The only thoroughly well-ascertained knowledge concerning the physiological effect of ozone, so far attained, is that it causes irritation and œdema of the lungs, and death if inhaled in relatively strong concentration for any time.""During",1
"World War I, ozone was tested at Queen Alexandra Military Hospital in London as a possible disinfectant for wounds. The gas was applied directly to wounds for as long as 15 minutes. This resulted in damage to both bacterial cells and human tissue. Other sanitizing techniques, such as irrigation with antiseptics, were found preferable.Until the 1920s, it was not certain whether small amounts of oxozone, O4, were also present in ozone samples due to the difficulty of applying analytical chemistry techniques to the explosive concentrated chemical.",1
2 O 3 ⟶ 3 O 2 {\displaystyle {\ce {2 O3 -> 3 O2}}} This reaction proceeds more rapidly with increasing temperature. Deflagration of ozone can be triggered by a spark and can occur in ozone concentrations of 10 wt% or higher.Ozone can also be produced from oxygen at the anode of an electrochemical cell. This reaction can create smaller quantities of ozone for research purposes. O 3 ( g ) + 2 H + + 2 e − ↽ − − ⇀ O 2 ( g ) + H 2 O ( E ∘ = 2.075,1
"Ozone will oxidize most metals (except gold, platinum, and iridium) to oxides of the metals in their highest oxidation state. For example: CuO + O2}}\\&{\ce {Ag + O3 -> AgO + O2}}\end{aligned}}}""> Cu + O 3 ⟶ CuO + O 2 Ag + O 3 ⟶ AgO + O 2 {\displaystyle {\begin{aligned}&{\ce {Cu + O3 -> CuO + O2}}\\&{\ce {Ag + O3 -> AgO + O2}}\end{aligned}}}",1
Ozone also oxidizes nitric oxide to nitrogen dioxide: NO + O 3 ⟶ NO 2 + O 2 {\displaystyle {\ce {NO + O3 -> NO2 + O2}}} This reaction is accompanied by chemiluminescence. The NO2 can be further oxidized to nitrate radical: NO 2 + O 3 ⟶ NO 3 + O 2 {\displaystyle {\ce {NO2 + O3 -> NO3 + O2}}} The NO3 formed can react with NO2 to form dinitrogen pentoxide (N2O5).,1
"Solid nitronium perchlorate can be made from NO2, ClO2, and O3 gases: NO 2 + ClO 2 + 2 O 3 ⟶ NO 2 ClO 4 + 2 O 2 {\displaystyle {\ce {NO2 + ClO2 + 2 O3 -> NO2ClO4 + 2 O2}}} Ozone does not react with ammonium salts, but it oxidizes ammonia to ammonium nitrate: 2 NH 3 + 4 O 3 ⟶ NH 4 NO 3 + 4 O 2 + H 2 O {\displaystyle {\ce {2 NH3 + 4 O3 -> NH4NO3 + 4 O2 + H2O}}} Ozone reacts with carbon to form carbon dioxide, even at",1
room temperature: C + 2 O 3 ⟶ CO 2 + 2 O 2 {\displaystyle {\ce {C + 2 O3 -> CO2 + 2 O2}}},1
"3 H2O + O3 -> 3 H2SO4}}\end{aligned}}} In the gas phase, ozone reacts with hydrogen sulfide to form sulfur dioxide: H 2 S + O 3 ⟶ SO 2 + H 2 O {\displaystyle {\ce {H2S + O3 -> SO2 + H2O}}} In an aqueous solution, however, two competing simultaneous reactions occur, one to produce elemental sulfur, and one to produce sulfuric acid: S + O2 + H2O}}\\&{\ce {3 H2S + 4 O3 -> 3 H2SO4}}\end{aligned}}}""> H 2 S + O 3 ⟶ S + O 2 + H 2 O 3 H 2 S + 4 O 3 ⟶ 3",1
H 2 SO 4 {\displaystyle {\begin{aligned}&{\ce {H2S + O3 -> S + O2 + H2O}}\\&{\ce {3 H2S + 4 O3 -> 3 H2SO4}}\end{aligned}}},1
"zinc in acetic acid or dimethyl sulfide), ketones and aldehydes will be formed, with oxidative workup (e.g. aqueous or alcoholic hydrogen peroxide), carboxylic acids will be formed.",1
"All three atoms of ozone may also react, as in the reaction of tin(II) chloride with hydrochloric acid and ozone: 3 SnCl 2 + 6 HCl + O 3 ⟶ 3 SnCl 4 + 3 H 2 O {\displaystyle {\ce {3 SnCl2 + 6 HCl + O3 -> 3 SnCl4 + 3 H2O}}} Iodine perchlorate can be made by treating iodine dissolved in cold anhydrous perchloric acid with ozone: I 2 + 6 HClO 4 + O 3 ⟶ 2 I ( ClO 4 ) 3 + 3 H 2 O {\displaystyle {\ce {I2 + 6 HClO4 + O3 -> 2",1
I(ClO4)3 + 3 H2O}}} Ozone could also react with potassium iodide to give oxygen and iodine gas that can be titrated for quantitative determination : 2 KI + O 3 + H 2 O ⟶ 2 KOH + O 2 + I 2 {\displaystyle {\ce {2KI + O3 + H2O -> 2KOH + O2 + I2}}},1
"°F), atomic hydrogen reacts with liquid ozone to form a hydrogen superoxide radical, which dimerizes: HO2 + O}}\\&{\ce {2 HO2 -> H2O4}}\end{aligned}}}""> H + O 3 ⟶ HO 2 + O 2 HO 2 ⟶ H 2 O 4 {\displaystyle {\begin{aligned}&{\ce {H + O3 -> HO2 + O}}\\&{\ce {2 HO2 -> H2O4}}\end{aligned}}}",1
"The second one is a photochemical decomposition, which consists of radiating ozone with ultraviolet radiation (UV) and it gives rise to oxygen and radical peroxide.",1
"The process of ozone decomposition is a complex reaction involving two elementary reactions that finally lead to molecular oxygen, and this means that the reaction order and the rate law cannot be determined by the stoichiometry of the fitted equation.",1
"Overall reaction: 2 O 3 ⟶ 3 O 2 {\displaystyle {\ce {2 O3 -> 3 O2}}} Rate law (observed): V = K ⋅ [ O 3 ] 2 [ O 2 ] {\displaystyle V={\frac {K\cdot [{\ce {O3}}]^{2}}{[{\ce {O2}}]}}} It has been determined that the ozone decomposition follows a first order kinetics, and from the rate law above it can be determined that the partial order respect to molecular oxygen is -1 and respect to ozone is 2, therefore the global reaction order is 1.",1
"The ozone decomposition consists of two elementary steps: The first one corresponds to a unimolecular reaction because one only molecule of ozone decomposes into two products (molecular oxygen and oxygen). Then, the oxygen from the first step is an intermediate because it participates as a reactant in the second step, which is a bimolecular reaction because there are two different reactants (ozone and oxygen) that give rise to one product, that corresponds to molecular oxygen in the gas phase.",1
"The reaction rate laws for every step are the ones that follow: V 1 = K 1 ⋅ [ O 3 ] V 2 = K 2 ⋅ [ O ] ⋅ [ O 3 ] {\displaystyle V_{1}=K_{1}\cdot [{\ce {O3}}]\qquad V_{2}=K_{2}\cdot [{\ce {O}}]\cdot [{\ce {O3}}]} The following mechanism allows to explain the rate law of the ozone decomposition observed experimentally, and also it allows to determine the reaction orders with respect to ozone and oxygen, with which the overall reaction order will be determined.",1
"The slower step, the bimolecular reaction, is the one that determines the rate of product formation, and considering that this step gives rise to two oxygen molecules the rate law has this form: V = 2 K 2 ⋅ [ O ] ⋅ [ O 3 ] {\displaystyle V=2K_{2}\cdot [{\ce {O}}]\cdot [{\ce {O3}}]} However, this equation depends on the concentration of oxygen (intermediate), which can be determined considering the first step.",1
"Since the first step is faster and reversible and the second step is slower, the reactants and products from the first step are in equilibrium, so the concentration of the intermediate can be determined as follows: K 1 = K 1 K − 1 = [ O 2 ] ⋅ [ O ] [ O 3 ] {\displaystyle K_{1}={\frac {K_{1}}{K_{-1}}}={\frac {[{\ce {O2}}]\cdot [{\ce {O}}]}{[{\ce {O3}}]}}} [ O ] = K 1 ⋅ [ O 3 ] K − 1 ⋅ [ O 2 ] {\displaystyle [{\ce {O}}]={\frac {K_{1}\cdot [{\ce {O3}}]}{K_{-1}\cdot [{\ce {O2}}]}}} Then using these equations, the formation rate of molecular",1
"oxygen is as shown below: V = 2 K 2 ⋅ K 1 ⋅ [ O 3 ] 2 K − 1 ⋅ [ O 2 ] {\displaystyle V={2K_{2}\cdot K_{1}\cdot [{\ce {O_3}}]^{2} \over K_{-1}\cdot [{\ce {O_2}}]}} Finally, the mechanism presented allows to establish the rate observed experimentally, with a rate constant (Kobs) and corresponding to a first order kinetics, as follows: V = K obs ⋅ [ O 3 ] 2 [ O 2 ] = K obs ⋅ [ O 3 ] 2 ⋅ [ O 2 ] − 1 {\displaystyle V={K_{\text{obs}}\cdot [{\ce {O_3}}]^{2} \over [{\ce {O_2}}]}=K_{\text{obs}}\cdot [{\ce {O_3}}]^{2}\cdot [{\ce",1
{O_2}}]^{-1}} where K obs = 2 K 2 ⋅ K 1 K − 1 {\displaystyle K_{\text{obs}}={2K_{2}\cdot K_{1} \over K_{-1}}},1
"Reduction of ozone gives the ozonide anion, O−3. Derivatives of this anion are explosive and must be stored at cryogenic temperatures. Ozonides for all the alkali metals are known.",1
"KO3, RbO3, and CsO3 can be prepared from their respective superoxides: KO 2 + O 3 ⟶ KO 3 + O 2 {\displaystyle {\ce {KO2 + O3 -> KO3 + O2}}} Although KO3 can be formed as above, it can also be formed from potassium hydroxide and ozone: 2 KOH + 5 O 3 ⟶ 2 KO 3 + 5 O 2 + H 2 O {\displaystyle {\ce {2 KOH + 5 O3 -> 2 KO3 + 5 O2 + H2O}}} NaO3 and LiO3 must be prepared by action of CsO3 in liquid NH3 on an ion-exchange resin containing Na+ or",1
Li+ ions: CsO 3 + Na + ⟶ Cs + + NaO 3 {\displaystyle {\ce {CsO3 + Na+ -> Cs+ + NaO3}}} A solution of calcium in ammonia reacts with ozone to give ammonium ozonide and not calcium ozonide: 3 Ca + 10 NH 3 + 6 O 3 ⟶ Ca ⋅ 6 NH 3 + Ca ( OH ) 2 + Ca ( NO 3 ) 2 + 2 NH 4 O 3 + 2 O 2 + H 2 {\displaystyle {\begin{aligned}{\ce {3 Ca + 10 NH3 + 6 O3 ->\ }}&{\ce {Ca*6NH3 + Ca(OH)2 + Ca(NO3)2}}\\&+{\ce {2 NH4O3 +,1
2 O2 + H2}}\end{aligned}}},1
"CN − + O 3 ⟶ CNO − + O 2 {\displaystyle {\ce {CN- + O3 -> CNO- + O2}}} Ozone will also completely decompose urea: ( NH 2 ) 2 CO + O 3 ⟶ N 2 + CO 2 + 2 H 2 O {\displaystyle {\ce {(NH2)2CO + O3 -> N2 + CO2 + 2 H2O}}} Ozone is a bent triatomic molecule with three vibrational modes: the symmetric stretch (1103.157 cm−1), bend (701.42 cm−1) and antisymmetric stretch (1042.096 cm−1).",1
"The most important absorption is the Hartley band, extending from slightly above 300 nm down to slightly above 200 nm. It is this band that is responsible for absorbing UV C in the stratosphere. On the high wavelength side, the Hartley band transitions to the so-called Huggins band, which falls off rapidly until disappearing by ~360 nm. Above 400 nm, extending well out into the NIR, are the Chappius and Wulf bands. There, unstructured absorption bands are useful for detecting high ambient concentrations of ozone, but are so weak that they do not have much practical effect.",1
"There are additional absorption bands in the far UV, which increase slowly from 200 nm down to reaching a maximum at ~120 nm. The standard way to express total ozone levels (the amount of ozone in a given vertical column) in the atmosphere is by using Dobson units. Point measurements are reported as mole fractions in nmol/mol (parts per billion, ppb) or as concentrations in μg/m3. The study of ozone concentration in the atmosphere started in the 1920s.",1
"The highest levels of ozone in the atmosphere are in the stratosphere, in a region also known as the ozone layer between about 10 and 50 km above the surface (or between about 6 and 31 miles). However, even in this ""layer"", the ozone concentrations are only two to eight parts per million, so most of the oxygen there is dioxygen, O2, at about 210,000 parts per million by volume.Ozone in the stratosphere is mostly produced from short-wave ultraviolet rays between 240 and 160 nm.",1
"Oxygen starts to absorb weakly at 240 nm in the Herzberg bands, but most of the oxygen is dissociated by absorption in the strong Schumann–Runge bands between 200 and 160 nm where ozone does not absorb. While shorter wavelength light, extending to even the X-Ray limit, is energetic enough to dissociate molecular oxygen, there is relatively little of it, and, the strong solar emission at Lyman-alpha, 121 nm, falls at a point where molecular oxygen absorption is a minimum.The",1
"process of ozone creation and destruction is called the Chapman cycle and starts with the photolysis of molecular oxygen O 2 → ( radiation λ < 240 nm ) photon 2 O {\displaystyle {\ce {O2->[{\ce {photon}}][({\ce {radiation}}\ \lambda \ <\ 240\ {\ce {nm}})]2O}}} followed by reaction of the oxygen atom with another molecule of oxygen to form ozone. O + O 2 + M ⟶ O 3 + M {\displaystyle {\ce {O + O2 + M -> O3 + M}}} where ""M"" denotes the third body that carries off the excess energy of the reaction.",1
The ozone molecule can then absorb a UV-C photon and dissociate O 3 ⟶ O + O 2 + kinetic energy {\displaystyle {\ce {O3 -> O + O2}}+{\text{kinetic energy}}} The excess kinetic energy heats the stratosphere when the O atoms and the molecular oxygen fly apart and collide with other molecules. This conversion of UV light into kinetic energy warms the stratosphere. The oxygen atoms produced in the photolysis of ozone then react back with other oxygen molecule as in the previous step to form more ozone.,1
"In the clear atmosphere, with only nitrogen and oxygen, ozone can react with the atomic oxygen to form two molecules of O2: O 3 + O ⟶ 2 O 2 {\displaystyle {\ce {O3 + O -> 2 O2}}} An estimate of the rate of this termination step to the cycling of atomic oxygen back to ozone can be found simply by taking the ratios of the concentration of O2 to O3. The termination reaction is catalysed by the presence of certain free radicals, of which the most important are hydroxyl (OH), nitric oxide (NO) and atomic chlorine (Cl) and bromine (Br).",1
"In the second half of the 20th century, the amount of ozone in the stratosphere was discovered to be declining, mostly because of increasing concentrations of chlorofluorocarbons (CFC) and similar chlorinated and brominated organic molecules. The concern over the health effects of the decline led to the 1987 Montreal Protocol, the ban on the production of many ozone depleting chemicals and in the first and second decade of the 21st century the beginning of the recovery of stratospheric ozone concentrations.",1
"Ozone's effect on mid-range UV-B rays is illustrated by its effect on UV-B at 290 nm, which has a radiation intensity 350 million times as powerful at the top of the atmosphere as at the surface. Nevertheless, enough of UV-B radiation at similar frequency reaches the ground to cause some sunburn, and these same wavelengths are also among those responsible for the production of vitamin D in humans.",1
"The ozone layer has little effect on the longer UV wavelengths called UV-A (315–400 nm), but this radiation does not cause sunburn or direct DNA damage, and while it probably does cause long-term skin damage in certain humans, it is not as dangerous to plants and to the health of surface-dwelling organisms on Earth in general (see ultraviolet for more information on near ultraviolet).",1
"The first major change was that car emission testing was expanded across the state to more counties that did not previously mandate emissions testing, like areas of Larimer and Weld County. There have also been changes made to decrease Nitrogen Oxides (NOx) and Volatile Organic Compound (VOC) emissions, which should help lower ozone levels. One large contributor to high ozone levels in the area is the oil and natural gas industry situated in the Denver-Julesburg Basin (DJB) which overlaps with a majority of Colorado's metropolitan areas.",1
"Ozone is created naturally in the Earth's stratosphere, but is also created in the troposphere from human efforts. Briefly mentioned above, NOx and VOCs react with sunlight to create ozone through a process called photochemistry. One hour elevated ozone events (<75 ppb) ""occur during June–August indicating that elevated ozone levels are driven by regional photochemistry"". According to an article from the University of Colorado-Boulder, ""Oil and natural gas VOC emission have a major role in ozone production and bear the potential to contribute to elevated O3 levels in the Northern Colorado Front Range (NCFR)"".",1
It will take many years and a systems-thinking approach to combat this issue of high ozone levels in the Front Range of Colorado.,1
"Ozone gas attacks any polymer possessing olefinic or double bonds within its chain structure, such as natural rubber, nitrile rubber, and styrene-butadiene rubber. Products made using these polymers are especially susceptible to attack, which causes cracks to grow longer and deeper with time, the rate of crack growth depending on the load carried by the rubber component and the concentration of ozone in the atmosphere. Such materials can be protected by adding antiozonants, such as waxes, which bond to the surface to create a protective film or blend with the material and provide long term protection.",1
"the Intergovernmental Panel on Climate Change Third Assessment Report) suggest that the radiative forcing of tropospheric ozone is about 25% that of carbon dioxide. The annual global warming potential of tropospheric ozone is between 918 and 1022 tons carbon dioxide equivalent/tons tropospheric ozone. This means on a per-molecule basis, ozone in the troposphere has a radiative forcing effect roughly 1,000 times as strong as carbon dioxide. However, tropospheric ozone is a short-lived greenhouse gas, which decays in the atmosphere much more quickly than carbon dioxide.",1
"This means that over a 20-year span, the global warming potential of tropospheric ozone is much less, roughly 62 to 69 tons carbon dioxide equivalent / ton tropospheric ozone.Because of its short-lived nature, tropospheric ozone does not have strong global effects, but has very strong radiative forcing effects on regional scales. In fact, there are regions of the world where tropospheric ozone has a radiative forcing up to 150% of carbon dioxide. For example, ozone increase in the troposphere is shown to be responsible for ~30% of upper Southern Ocean interior warming between 1955 and 2000.",1
"For the last few decades, scientists studied the effects of acute and chronic ozone exposure on human health. Hundreds of studies suggest that ozone is harmful to people at levels currently found in urban areas. Ozone has been shown to affect the respiratory, cardiovascular and central nervous system. Early death and problems in reproductive health and development are also shown to be associated with ozone exposure.",1
"The American Lung Association has identified five populations who are especially vulnerable to the effects of breathing ozone: Children and teens People 65 years old and older People who work or exercise outdoors People with existing lung diseases, such as asthma and chronic obstructive pulmonary disease (also known as COPD, which includes emphysema and chronic bronchitis) People with cardiovascular diseaseAdditional evidence suggests that women, those with obesity and low-income populations may also face higher risk from ozone, although more research is needed.",1
"Acute ozone exposure ranges from hours to a few days. Because ozone is a gas, it directly affects the lungs and the entire respiratory system. Inhaled ozone causes inflammation and acute—but reversible—changes in lung function, as well as airway hyperresponsiveness. These changes lead to shortness of breath, wheezing, and coughing which may exacerbate lung diseases, like asthma or chronic obstructive pulmonary disease (COPD) resulting in the need to receive medical treatment. Acute and chronic exposure to ozone has been shown to cause an increased risk of respiratory infections, due to the following mechanism.Multiple",1
"studies have been conducted to determine the mechanism behind ozone's harmful effects, particularly in the lungs. These studies have shown that exposure to ozone causes changes in the immune response within the lung tissue, resulting in disruption of both the innate and adaptive immune response, as well as altering the protective function of lung epithelial cells. It is thought that these changes in immune response and the related inflammatory response are factors that likely contribute to the increased risk of lung infections, and worsening or triggering of asthma and reactive airways after exposure to ground-level ozone pollution.The",1
"innate (cellular) immune system consists of various chemical signals and cell types that work broadly and against multiple pathogen types, typically bacteria or foreign bodies/substances in the host. The cells of the innate system include phagocytes, neutrophils, both thought to contribute to the mechanism of ozone pathology in the lungs, as the functioning of these cell types have been shown to change after exposure to ozone.",1
"Macrophages, cells that serve the purpose of eliminating pathogens or foreign material through the process of ""phagocytosis"", have been shown to change the level of inflammatory signals they release in response to ozone, either up-regulating and resulting in an inflammatory response in the lung, or down-regulating and reducing immune protection. Neutrophils, another important cell type of the innate immune system that primarily targets bacterial pathogens, are found to be present in the airways within 6 hours of exposure to high ozone levels. Despite high levels in the lung tissues, however, their ability to clear bacteria appears impaired by exposure to ozone.The",1
"adaptive immune system is the branch of immunity that provides long-term protection via the development of antibodies targeting specific pathogens and is also impacted by high ozone exposure. Lymphocytes, a cellular component of the adaptive immune response, produce an increased amount of inflammatory chemicals called ""cytokines"" after exposure to ozone, which may contribute to airway hyperreactivity and worsening asthma symptoms.The airway epithelial cells also play an important role in protecting individuals from pathogens. In normal tissue, the epithelial layer forms a protective barrier, and also contains specialized ciliary structures that work to clear foreign bodies, mucus and pathogens from the lungs.",1
"When exposed to ozone, the cilia become damaged and mucociliary clearance of pathogens is reduced. Furthermore, the epithelial barrier becomes weakened, allowing pathogens to cross the barrier, proliferate and spread into deeper tissues. Together, these changes in the epithelial barrier help make individuals more susceptible to pulmonary infections.Inhaling ozone not only affects the immune system and lungs, but it may also affect the heart as well.",1
"Ozone causes short-term autonomic imbalance leading to changes in heart rate and reduction in heart rate variability; and high levels exposure for as little as one-hour results in a supraventricular arrhythmia in the elderly, both increase the risk of premature death and stroke. Ozone may also lead to vasoconstriction resulting in increased systemic arterial pressure contributing to increased risk of cardiac morbidity and mortality in patients with pre-existing cardiac diseases.",1
"Breathing ozone for periods longer than eight hours at a time for weeks, months or years defines chronic exposure. Numerous studies suggest a serious impact on the health of various populations from this exposure. One study finds significant positive associations between chronic ozone and all-cause, circulatory, and respiratory mortality with 2%, 3%, and 12% increases in risk per 10 ppb and report an association (95% CI) of annual ozone and all-cause mortality with a hazard ratio of 1.02 (1.01–1.04), and with cardiovascular mortality of 1.03 (1.01–1.05).",1
"A similar study finds similar associations with all-cause mortality and even larger effects for cardiovascular mortality. An increased risk of mortality from respiratory causes is associated with long-term chronic exposure to ozone.Chronic ozone has detrimental effects on children, especially those with asthma. The risk for hospitalization in children with asthma increases with chronic exposure to ozone; younger children and those with low-income status are even at greater risk.Adults",1
"suffering from respiratory diseases (asthma, COPD, lung cancer) are at a higher risk of mortality and morbidity and critically ill patients have an increased risk of developing acute respiratory distress syndrome with chronic ozone exposure as well.",1
"There is a great deal of evidence to show that ground-level ozone can harm lung function and irritate the respiratory system. Exposure to ozone (and the pollutants that produce it) is linked to premature death, asthma, bronchitis, heart attack, and other cardiopulmonary problems.Long-term exposure to ozone has been shown to increase risk of death from respiratory illness. A study of 450,000 people living in U.S. cities saw a significant correlation between ozone levels and respiratory illness over the 18-year follow-up period.",1
"In the EU, the current target value for ozone concentrations is 120 µg/m3 which is about 60 nmol/mol. This target applies to all member states in accordance with Directive 2008/50/EC. Ozone concentration is measured as a maximum daily mean of 8 hour averages and the target should not be exceeded on more than 25 calendar days per year, starting from January 2010. Whilst the directive requires in the future a strict compliance with 120 µg/m3 limit (i.e.",1
"μmol/mol in the 2008 final rule, should instead be set at a lower level within the range of 0.060 to 0.070 μmol/mol, to provide increased protection for children and other at risk populations against an array of O3 – related adverse health effects that range from decreased lung function and increased respiratory symptoms to serious indicators of respiratory morbidity including emergency department visits and hospital admissions for respiratory causes, and possibly cardiovascular-related morbidity as well as total non- accidental and cardiopulmonary mortality ...",1
"An investigation to assess the joint mortality effects of ozone and heat during the European heat waves in 2003, concluded that these appear to be additive.",1
"Ozone, along with reactive forms of oxygen such as superoxide, singlet oxygen, hydrogen peroxide, and hypochlorite ions, is produced by white blood cells and other biological systems (such as the roots of marigolds) as a means of destroying foreign bodies. Ozone reacts directly with organic double bonds. Also, when ozone breaks down to dioxygen it gives rise to oxygen free radicals, which are highly reactive and capable of damaging many organic molecules. Moreover, it is believed that the powerful oxidizing properties of ozone may be a contributing factor of inflammation.",1
"inhaled, ozone reacts with compounds lining the lungs to form specific, cholesterol-derived metabolites that are thought to facilitate the build-up and pathogenesis of atherosclerotic plaques (a form of heart disease). These metabolites have been confirmed as naturally occurring in human atherosclerotic arteries and are categorized into a class of secosterols termed atheronals, generated by ozonolysis of cholesterol's double bond to form a 5,6 secosterol as well as a secondary condensation product via aldolization.",1
"Because of the strongly oxidizing properties of ozone, ozone is a primary irritant, affecting especially the eyes and respiratory systems and can be hazardous at even low concentrations. The Canadian Centre for Occupation Safety and Health reports that: Even very low concentrations of ozone can be harmful to the upper respiratory tract and the lungs. The severity of injury depends on both the concentration of ozone and the duration of exposure. Severe and permanent lung injury or death could result from even a very short-term exposure to relatively low concentrations."" To protect workers potentially exposed to ozone, U.S.",1
"In the laboratory, ozone can be produced by electrolysis using a 9 volt battery, a pencil graphite rod cathode, a platinum wire anode and a 3 molar sulfuric acid electrolyte. The half cell reactions taking place are: O3 + 6 H+ + 6 e-}}&&(\Delta E^{\circ }=-{\text{1.53 V}})\\&{\ce {6 H+ + 6 e- -> 3 H2}}&&(\Delta E^{\circ }={\text{0 V}})\\&{\ce {2 H2O -> O2 + 4 H+ + 4 e-}}&&(\Delta E^{\circ }={\text{1.23 V}})\end{aligned}}}""> 3 H 2 O ⟶ O 3 + 6 H + + 6 e − ( Δ E ∘ = − 1.53",1
V ) 6 H + + 6 e − ⟶ 3 H 2 ( Δ E ∘ = 0 V ) 2 H 2 O ⟶ O 2 + 4 H + + 4 e − ( Δ E ∘ = 1.23 V ) {\displaystyle {\begin{aligned}&{\ce {3 H2O -> O3 + 6 H+ + 6 e-}}&&(\Delta E^{\circ }=-{\text{1.53 V}})\\&{\ce {6 H+ + 6 e- -> 3 H2}}&&(\Delta E^{\circ }={\text{0 V}})\\&{\ce {2 H2O -> O2 + 4 H+ + 4 e-}}&&(\Delta E^{\circ }={\text{1.23 V}})\end{aligned}}} where E° represents the standard electrode potential.,1
This can be done with an apparatus consisting of two concentric glass tubes sealed together at the top with gas ports at the top and bottom of the outer tube. The inner core should have a length of metal foil inserted into it connected to one side of the power source. The other side of the power source should be connected to another piece of foil wrapped around the outer tube. A source of dry O2 is applied to the bottom port.,1
"When high voltage is applied to the foil leads, electricity will discharge between the dry dioxygen in the middle and form O3 and O2 which will flow out the top port. This is called a Siemen's ozoniser. The reaction can be summarized as follows: 3 O 2 → electricity 2 O 3 {\displaystyle {\ce {3O2->[{\text{electricity}}]2O3}}}",1
"Ozone application on freshly cut pineapple and banana shows increase in flavonoids and total phenol contents when exposure is up to 20 minutes. Decrease in ascorbic acid (one form of vitamin C) content is observed but the positive effect on total phenol content and flavonoids can overcome the negative effect. Tomatoes upon treatment with ozone show an increase in β-carotene, lutein and lycopene. However, ozone application on strawberries in pre-harvest period shows decrease in ascorbic acid content.Ozone facilitates the extraction of some heavy metals from soil using EDTA.",1
"EDTA forms strong, water-soluble coordination compounds with some heavy metals (Pb, Zn) thereby making it possible to dissolve them out from contaminated soil. If contaminated soil is pre-treated with ozone, the extraction efficacy of Pb, Am and Pu increases by 11.0–28.9%, 43.5% and 50.7% respectively.",1
"Crop pollination is an essential part of an ecosystem. Ozone can have detrimental effects on plant-pollinator interactions. Pollinators carry pollen from one plant to another. This is an essential cycle inside of an ecosystem. Causing changes in certain atmospheric conditions around pollination sites or with xenobiotics could cause unknown changes to the natural cycles of pollinators and flowering plants. In a study conducted in North-Western Europe, crop pollinators were negatively affected more when ozone levels were higher.",1
"The implementation of check dams combined with vegetation reduced peak flow discharge and total runoff volume as large parts of runoff infiltrated in the sediments deposited behind the check dams. As gully check dams are implemented in a large areas of northern Ethiopia, this contributes to groundwater recharge and increased river base flow.",1
"This is typically seen during the construction process of large-scale permanent dams or erosion control. As such, check dams serve as temporary grade-control mechanisms along waterways until resolute stabilization is established or along permanent swales that need protection prior to installation of a non-erodible lining.",1
"As a strategy to stabilize mountain streams, the construction of check dams has a long tradition in many mountainous regions dating back to the 19th century in Europe. Steep slopes impede access by heavy construction machinery to mountain streams, so check dams have been built in place of larger dams. Because the typical high slope causes high flow velocity, a terraced system of multiple closely spaced check dams is typically necessary to reduce velocity and thereby counteract erosion.",1
"In the UK planning laws, applications and restrictions delay flood mitigation work. This can be counteracted by setting up Temporary Test Dams in watercourses that can then be monitored and valued. This does however require the landowners support. TTDs have proven to be a great way to get rapid action following a flood event and a way to get communities involved in the defence against future flood events.",1
"the site is permanently stabilized and the check dam is no longer needed, it is fully removed, including components washed downstream, and bare spots are stabilized. Drop structure Gabion Groyne Nagashima Dam Flexible debris-resisting barrier Trap Function of Bed Road by Steel-Slit Dam Sabo Gakkaishi Vol.45 (1992-1993) No.4 P22-29",1
"The EPA, the states of Oklahoma, Kansas, and Missouri, local communities, and private companies continue to work together in implementing and monitoring response actions that reduce or remove potential adverse impacts posed by remaining mine wastes contaminated with lead, zinc, cadmium, and other metals. Ore production consisted of crushing and grinding the rock to standard sizes and separating the ore. Ore processing was accomplished in either a dry gravity separation or through a wet washing or flotation separation. Dry processes produced a fine gravel waste commonly called “chat.”",1
"The composition of CCA products is usually described in terms of the mass percentages of chromium trioxide or ""chromic acid"" CrO3, arsenic pentoxide As2O5, and copper(II) oxide CuO.The preservative is applied as a water-based mixture containing 0.6–6.0% (by weight) of chromic acid, copper oxide, and arsenic acid (USDA, 1980), with pH 1.6–2.5. The mixture is infused into wood at high pressure.In the treated wood, arsenic is believed to be in the form of chromium (III) arsenate CrAsO4 and/or copper(II) arsenate Cu3(AsO4)2, or fairly stable chromium dimer-arsenic clusters.",1
"The chromium acts as a chemical fixing agent and has little or no preserving properties; it helps the other chemicals to fix in the timber, binding them through chemical complexes to the wood's cellulose and lignin. The copper acts primarily to protect the wood against decay, fungi, and bacteria, while the arsenic is the main insecticidal component, providing protection from wood-attacking insects including termites and marine borers. It also improves the weather resistance of treated timber and may assist paint adherence in the long term.",1
"These compounds are toxic to the human system when inside the bloodstream, usually from burning wood treated with these compounds which is very dangerous. Alternative heavy-duty preservatives include creosote and pentachlorophenol. Similar water-borne preservatives include alkaline copper quaternary (ACQ) compounds, copper azole (CuAz), ammoniacal copper zinc arsenate (ACZA), copper citrate, and copper HDO (CuHDO). Usually more expensive options, but safer, are pressure and heat treated lumber which contains no chemicals. Usually they lack the long-term robust qualities and resistance of chemically treated lumber.",1
"Itching, burning rashes, neurological symptoms, and breathing problems have been associated with handling unmarked chromated arsenical wood preservatives, including contact with the sap draining from treated wood.Regulatory action was motivated in the 1990s by studies suggesting that CCA could pose a risk to children in playgrounds built with CCA-treated timber. Later studies however found that, while concentrations of arsenic in the soil and hand rinses were considerably higher among children who played on CCA-treated playground toys than in the control group, there was no significant difference in the arsenic concentrations in urine and saliva samples.",1
"Machining (sawing, sanding, drilling) CCA-treated wood also exposes construction workers and amateur carpenters to chronic and acute health risks via inhalation.",1
"CCA treated wood has relatively low toxicity, and animals would need to ingest unlikely amounts (28 g daily for a month, for an adult horse) in order to become poisoned. However, ashes from burned timber are much more toxic, and cattle have been poisoned in this way.Use of CCA-treated wood for beehive construction has been associated with increased levels of arsenic in the honey and winter loss of bee colonies.",1
"Another concern is the leaching of chromium and arsenic from CCA-treated timber and their release to the environment.The amount and rate of arsenic leaching varies considerably depending on numerous factors, such as local climate, acidity of rain and soil, age of the wood product, and how much CCA was applied. A study has found that soil contamination due to the presence of CCA-treated wood after 45 years was minimal.Many studies in less aggressive soil types show leaching to be as low as 0.5 ppm (red pine poles in service,) or up to 14 ppm (treated pine in garden beds).",1
"These especially harmful particulate contaminants are at their peak when such engines are run without sufficient oxygen to fully combust the fuel; when a diesel engine runs at idle, enough oxygen is usually present to burn the fuel completely. (The oxygen requirement in non-idling engines is usually satisfied using turbocharging.) From the particle emission standpoint, exhaust from diesel vehicles has been reported to be significantly more harmful than those from petrol vehicles. Diesel exhausts, long known for their characteristic smells, changed significantly with the reduction of sulfur content of diesel fuel, and again when catalytic converters were introduced in exhaust systems.",1
"Even so, diesel exhausts continue to contain an array of inorganic and organic pollutants, in various classes, and in varying concentrations (see below), depending on fuel composition and engine running conditions. The following are classes of chemical compounds that have been found in diesel exhaust.",1
"Exposure to diesel exhaust and diesel particulate matter (DPM) is an occupational hazard to truckers, railroad workers, occupants of residential homes in vicinity of a rail yard, and miners using diesel-powered equipment in underground mines. Adverse health effects have also been observed in the general population at ambient atmospheric particle concentrations well below the concentrations in occupational settings. In March 2012, U.S. government scientists showed that underground miners exposed to high levels of diesel fumes have a threefold increased risk for contracting lung cancer compared with those exposed to low levels. The $11.5",1
"Diesel particulate matter (DPM), sometimes also called diesel exhaust particles (DEP), is the particulate component of diesel exhaust, which includes diesel soot and aerosols such as ash particulates, metallic abrasion particles, sulfates, and silicates. When released into the atmosphere, DPM can take the form of individual particles or chain aggregates, with most in the invisible sub-micrometre range of 100 nanometers, also known as ultrafine particles (UFP) or PM0.1. The main particulate fraction of diesel exhaust consists of fine particles. Because of their small size, inhaled particles may easily penetrate deep into the lungs.",1
"The polycyclic aromatic hydrocarbons (PAHs) in the exhaust stimulate nerves in the lungs, causing reflex coughing, wheezing and shortness of breath. The rough surfaces of these particles makes it easy for them to bind with other toxins in the environment, thus increasing the hazards of particle inhalation.A",1
"It is clear, that diesel health detriments of fine particle emissions are severe and pervasive. Although one study found no significant evidence that short-term exposure to diesel exhaust results in adverse extrapulmonary effects, effects that are correlated with an increase in cardiovascular disease, a 2011 study in The Lancet concluded that traffic exposure is the single most serious preventable trigger of heart attack in the general public, as the cause of 7.4% of all attacks.",1
"It is impossible to tell how much of this effect is due to the stress of being in traffic and how much is due to exposure to exhaust.Since the study of the detrimental health effects of nanoparticles (nanotoxicology) is still in its infancy, and the nature and extent of negative health impacts from diesel exhaust continues to be discovered, it remains controversial whether the public health impact of diesels is higher than that of petrol-fuelled vehicles.",1
"The types and quantities of nanoparticles can vary according to operating temperatures and pressures, presence of an open flame, fundamental fuel type and fuel mixture, and even atmospheric mixtures. As such, the resulting types of nanoparticles from different engine technologies and even different fuels are not necessarily comparable. One study has shown that 95% of the volatile component of diesel nanoparticles is unburned lubricating oil. Long-term effects still need to be further clarified, as well as the effects on susceptible groups of people with cardiopulmonary diseases. Diesel engines can produce black soot (or more specifically diesel particulate matter) from their exhaust.",1
"As the ""black smoke limit"" is still considerably lean of stoichiometric, it is possible to obtain more power by exceeding it, but the resultant inefficient combustion means that the extra power comes at the price of reduced combustion efficiency, high fuel consumption and dense clouds of smoke. This is only done in high performance applications where these disadvantages are of little concern. When starting from cold, the engine's combustion efficiency is reduced because the cold engine block draws heat out of the cylinder in the compression stroke.",1
"The result is that fuel is not burned fully, resulting in blue and white smoke and lower power outputs until the engine has warmed. This is especially the case with indirect injection engines, which are less thermally efficient. With electronic injection, the timing and length of the injection sequence can be altered to compensate for this.",1
"Older engines with mechanical injection can have mechanical and hydraulic governor control to alter the timing, and multi-phase electrically controlled glow plugs, that stay on for a period after start-up to ensure clean combustion; the plugs are automatically switched to a lower power to prevent their burning out. Wärtsilä states that there are two ways of forming smoke, on large diesel engines, one being fuel hitting metal and not having time to burn off. The other being, when too much fuel is in the combustion chamber.",1
"Wärtsilä have tested an engine and compared smoke-output, when using conventional fuel system and common rail fuel system, the result shows improvement on all operation conditions when using the common rail system. Experiments in 2013 showed that diesel exhaust impaired bees' ability to detect the scent of oilseed rape flowers.",1
"With emission standards tightening, diesel engines are having to become more efficient and have fewer pollutants in their exhaust. For instance, light duty truck must now have NOx emissions less than 0.07 g/mile, and in the U.S., by 2010, NOx emissions must be less than 0.03 g/mile. Moreover, in recent years the United States, Europe, and Japan have extended emissions control regulations from covering on-road vehicles to include farm vehicles and locomotives, marine vessels, and stationary generator applications. Changing to a different fuel (i.e.",1
"In addition to changing the fuel, US engineers have also come up with two other principles and distinct systems to all on-market products that meet the U.S. 2010 emissions criteria, selective non-catalytic reduction (SNCR), and exhaust gas recirculation (EGR). Both are in the exhaust system of diesel engines, and are further designed to promote efficiency.",1
"John Deere, the farm equipment manufacturer, is implementing such a combined SCR-EGR design, in a 9-liter ""inline 6"" diesel engine that involves both system types, a PM filter and additional oxidation catalyst technologies. The combined system incorporates two turbochargers, the first on the exhaust manifold, with variable geometry and containing the EGR system; and a second a fixed geometry turbocharger.",1
"Monforton, C (2006). ""Weight of the Evidence or Wait for the Evidence? Protecting Underground Miners from Diesel Particulate Matter"". American Journal of Public Health. 96 (2): 271–276. doi:10.2105/ajph.2005.064410. PMC 1470492. PMID 16380560. Archived from the original on 2011-05-25. Steenland, K; Silverman, DT; Hornung, DW (1990). ""Case control study of lung cancer and truck driving in the Teamsters union"". American Journal of Public Health. 80 (6): 670–674. doi:10.2105/ajph.80.6.670. PMC 1404737. PMID 1693040. Steenland, K; Silverman, DT; Zaebst, D (1992). ""Exposure to diesel exhaust in the trucking industry and possible relationships with lung cancer"". American Journal of Industrial Medicine. 21 (6): 887–890. doi:10.1002/ajim.4700210612.",1
"PMID 1621697. Bruske-Holhfield, I; Mohner, M; Ahrens, W; et al. (1999). ""Lung cancer risk in male workers occupationally exposed to diesel motor emissions in Germany"". American Journal of Industrial Medicine. 36 (4): 405–414. doi:10.1002/(sici)1097-0274(199910)36:4<405::aid-ajim1>3.3.co;2-n. PMID 10470005. Wichmann, H.-E. Abschaetzung positiver gesundheitlicher Auswirkungen durch den Einsatz von Partikelfiltern bei Dieselfahrzeugen in Deutschland Umweltbundesamt Berlin 2003. Report 2352, especially page 32. Umweltbundesamt Berlin Future Diesel. Abgasgesetzgebung Pkw, leichte Nfz und Lkw – Fortschreibung der Grenzwerte bei Dieselfahrzeugen 2003. Report 2353, especially page 25.",1
"Diesel Information Hub Archived 2020-02-24 at the Wayback Machine, AECC Emission of different pollutants from diesel engines, EnggStudy NIOSH Mining Safety and Health Topic: Diesel Exhaust Diesel Particulate Matter, a case study at www.defendingscience.org Clean School Bus USA, EPA Initiative Weight of the Evidence or Wait for the Evidence? Protecting Underground Miners from Diesel Particulate Matter Article by Celeste Monforton. American Journal of Public Health, February 2006. Diesel exhaust – peer-reviewed studies by Health Effects Institute Safety and Health Topics: Diesel Exhaust, U.S.",1
"Department of Labor Occupational Safety & Health Administration Safety and Health Topics: Diesel Exhaust - Partial List of Chemicals Associated with Diesel Exhaust, U.S.",1
"Department of Labor Occupational Safety & Health Administration Diesel Exhaust Particulates: Reasonably Anticipated to Be A Human Carcinogen Impact of Fuel Metal Impurities on the Durability of a Light-Duty Diesel Aftertreatment System National Renewable Energy Laboratory Acute Inflammatory Responses in the Airways and Peripheral Blood After Short-Term Exposure to Diesel Exhaust in Healthy Human Volunteers, American Journal of Respiratory and Critical Care Medicine Diesel exhaust: what you need to know Health Effects of Diesel Exhaust Archived 2019-12-09 at the Wayback Machine - fact sheet by Cal/EPA and American Lung Association",1
"CieloBuio is divided into the following bodies, more or less formal: CieloBuio mailing list, an organ of free association of ideas and activities to support actions on the ground; CieloBuio non-profit association, legally recognized, bringing together all those who wish to support more effectively the activities of the working groups; the governing council, composed of six members and an honorary president, who makes decisions and sets the strategies for action CieloBuio; the technical-scientific committee, composed of six experts who research and develop environmentally friendly lighting solutions to offer and promote.",1
"A diffusion tube consists of a small, hollow, usually transparent, acrylic or polypropylene plastic tube, roughly 70mm long, with a cap at each end. One of the caps (coloured white) is either completely removed to activate the tube (in the case of nitrogen dioxide sampling) or contains a filter allowing in just the gas being studied. The other cap (a different colour) contains metal mesh discs coated with a chemical reagent that absorbs the gas being studied as it enters the tube.",1
"As the DPF does not function with low-sulfur diesel fuel, diesel engines that conform to 2007 EPA emissions standards require ultra-low-sulfur diesel (ULSD) fuel to prevent damage to the DPF. After a brief transition period, ULSD fuel became common at fuel pumps in the United States and Canada. The 2007 EPA regulations were meant to be an interim solution to allow manufacturers time to prepare for the more stringent 2010 EPA regulations, which reduced NOx levels even further. In 2008, the concerns about compliance shifted to the infrastructure for DEF distribution.The",1
"injection rate of DEF into the exhaust depends on the specific after-treatment system, but is typically 2–6% of diesel consumption volume. This low dosing rate ensures long fluid refill intervals and minimizes the tank's size and intrusion into vehicle packaging space. An electronic control unit adjusts the addition of fluid in accordance with parameters such as NOx level in the exhaust gas (before catalytic converter, after catalytic converter, and possibly between catalytic converters if there is more than one), current ammonia filling level, engine operating temperature and speed. DEF is a 32.5% solution of urea, (NH2)2CO.",1
"H2O (""NO2 SCR selective catalytic reduction"") NO + NO2 + 2 NH3 → 2 N2 + 3 H2O (""fast SCR"")The overall reduction of NOx by urea is then: 2 (NH2)2CO + 4 NO + O2 → 4 N2 + 4 H2O + 2 CO2 and 4 (NH2)2CO + 6 NO2 → 7 N2 + 8 H2O + 4 CO2 and (NH2)2CO + NO + NO2 → 2 N2 + 2 H2O + CO2The ratio between NO2 and NO determines which reactions take place and how fast.",1
"The highest conversion rates are achieved if equal amounts of NO2 and NO are present, especially at temperatures between 200°C and 350°C. If there is more NO than NO2, fast SCR and standard SCR take place sequentially. If there is more NO2 than NO, fast SCR and NO2 SCR take place sequentially, however, NO2 SCR is slower than standard SCR, and ammonium nitrate can form and temporarily deactivate the catalytic converter. DEF freezes at −11 °C (12 °F).",1
"For the SCR exhaust cleaning system to function at low temperatures, a sufficient amount of the frozen DEF must be melted in as short time as possible, preferably on the order of minutes. For example, 2010 EPA emissions requirements require full DEF coolant flow within 70 minutes.In Europe, Regulation (EC) No 692/2008 specified in Annex XVI point 10 that DEF from a frozen tank at a core temperature of −15 °C (5 °F) must become available within 20 minutes when starting the engine at −15 °C (5 °F). Typically, the frozen DEF is melted by heat from the engine, e.g.",1
"engine coolant passing through the DEF tank, governed by a thermostatic coolant control valve. This method may take significant time before the SCR exhaust cleaning system is fully operational, often up to an hour.Another method to thaw DEF (and thus allow for full SCR operation) is to integrate an electrical heater into the DEF tank. This heater must be sized, positioned, and powered adequately to rapidly melt sufficient frozen DEF. It should preferably be self-regulating not to overheat if (part of) the heater is outside of the liquid.",1
"Vehicles' selective catalytic reduction (SCR) systems and DEF dispensers are designed in a manner that there is no corrosive impact of urea on them. It is recommended that DEF be stored in a cool, dry, and well-ventilated area that is out of direct sunlight. Bulk volumes of DEF are compatible for storage within polyethylene containers (HDPE, XLPE), fiberglass reinforced plastic (FRP), and steel tanks. DEF is also often handled in intermediate bulk containers for storage and shipping.",1
"DEF is offered to consumers in a variety of quantities ranging from containers for single or repeated small usage, up to bulk carriers for consumers requiring a large amount of DEF. As of 2013, many truck stops have added DEF pumps. These are usually adjacent to fuel pumps so the driver can fill both tanks without moving the truck. In Europe, increasing numbers of fuel stations offer AdBlue pumps, not only for large commercial vehicles but also for passenger cars.",1
"At airports, where DEF can sometimes be required for diesel ground service vehicles, its labelling and storage must be carefully managed to avoid accidentally servicing jet aircraft with DEF instead of fuel system icing inhibitor, a mistake that has been attributed to multiple in-flight engine failure and grounding incidents.",1
"The South Korean government started rationing urea solution, and banned its resale as panic buying by drivers exacerbated an acute shortage that could cause transport and industry to grind to a halt.",1
"In early December 2021, the Australian National Road Transport Association also raised concerns about a shortage of DEF in the country due to the shortage of urea in China. China capped exports to protect its domestic supplies and rising DEF prices. By mid-December there was approximately 7 weeks’ supply of AdBlue left in Australia. On 14 December, an Australian company stated that it would build a new plant. ISO 22241-1:2019 Diesel engines — NOx reduction agent AUS 32 — Part 1: Quality requirements Adblue consumption by vehicle type",1
"A season of artworks and exhibits on the theme of dirt was sponsored by the Wellcome Trust in 2011. The centrepiece was an exhibition at the Wellcome Collection showing pictures and histories of notable dirt such as the great dust heaps at Euston and King's Cross in the 19th century and the Fresh Kills landfill which was once the world's largest landfill. When things are dirty, they are usually cleaned with solutions like hard surface cleaner and other chemical solutions; much domestic activity is for this purpose—washing, sweeping, and so forth.In a commercial setting, a dirty appearance gives a bad impression.",1
"In the United Kingdom, the Public Health Act 1875 required households to place their refuse into a container that could be moved so that it could be carted away. This was the first legal creation of the dustbin. Modern society is now thought to be more hygienic. Lack of contact with microorganisms in dirt when growing up is hypothesised to be the cause of the epidemic of allergies such as asthma. The human immune system requires activation and exercise in order to function properly and exposure to dirt may achieve this.",1
"For example, the presence of staphylococcus bacteria on the surface of the skin regulates the inflammation which results from injury.Even when no visible dirt is present, contamination by microorganisms, especially pathogens, can still cause an object or location to be considered dirty. For example, computer keyboards are especially dirty as they contain on average 70 times more microbes than a lavatory seat.People and animals may eat dirt. This is thought to be caused by mineral deficiency and so the condition is commonly seen in pregnant women.",1
"People may become obsessed by dirt and engage in fantasies and compulsive behaviour about it, such as making and consuming mud pies and pastries. The source of such thinking may be genetic, as the emotion of disgust is common and the location for this activity in the brain has been proposed.",1
"Cleaner Terence McLaughlin (1971), Dirt: a social history as seen through the uses and abuses of dirt, Stein and Day, ISBN 9780812814125 Suellen Hoy (1996), Chasing Dirt: The American Pursuit of Cleanliness, Oxford University Press, ISBN 9780195111286 Pamela Janet Wood (2005), Dirt: filth and decay in a new world arcadia, Auckland University Press, ISBN 9781869403485 Ben Campkin, Rosie Cox (2007), Dirt: new geographies of cleanliness and contamination, I.B. Tauris, ISBN 9781845116729 Virginia Smith; et al.",1
"(2011), Dirt: The Filthy Reality of Everyday Life, Profile Books Limited, ISBN 9781846684791 Media related to Dirtiness at Wikimedia Commons Dirt season at the Wellcome Collection",1
"This also encompasses the narrower definition of salvage, that is, property that has been recovered from a wreckage, or the recovery of the ship itself There are a number of factors that contribute to the formation of a shipwreck, which can be divided into physical and cultural processes. A site can be affected by physical processes, that is, naturally occurring processes, such as the corrosion caused by salinity and ocean currents, or the growth of native and foreign marine organisms.",1
"It can also be affected by cultural processes, that is, by human interactions, such as adding or removing materials from the site of the wreck. Any archaeological activity, such as excavation, may also be considered invasive and tampering.In maritime law, different meanings are attributed to the terms, based on jurisdiction as well as context. For example, a distinction is made between goods that wash ashore and those that are for some reason not salvageable and/or lost at sea. Ownership of a wreck is a highly controversial issue, as there are no clear lines within which it is defined.",1
"It may be acquired through various means that range from succession to confiscation. There is also a distinction to be made between the ownership of the hull itself and the cargo it contains, as the hull may be abandoned intentionally, whereas the cargo may be out of necessity (in the case of an emergency or the need to shed weight from the vessel). In these parameters, abandonment of the ship by its passengers constitutes a loss of possession, but to abandon the claim on the title itself, intention to relinquish it is required.",1
"In terms of compensation, it is seen as being awarded to anyone who voluntarily assisted in the recuperation of the wreck, whether it be saved from upcoming danger, or from loss. The law of salvage has its origins in the Roman practice of negotiorum gestio, which dictated that one who preserved or improved upon the property of another was owed compensation from the owner, even if the service was not requested by the latter.",1
"The law did not apply to maritime regulations, but were the basis for following ordinances, such as the Marine Ordinance of Trani, which stated that a ""finder"" was to be rewarded, whether the owner claimed the goods or not. The laws have evolved since negotiorum gestio, and today, in the United States, a salvor who voluntarily brings the goods back into port may legally lay claim to them, or deliver them to a marshal, in return for a reward.",1
"This occurred with up to 110 cargo containers lost by MSC Zoe in heavy seas in January 2019 off the German shore of Borkum; the lost goods found on the Dutch coast were considered flotsam. Jetsam designates any cargo that is intentionally discarded from a ship or wreckage. Legally jetsam also floats, although floating is not part of the etymological meaning. Generally, ""jettisoning"" connotes the action of throwing goods overboard to lighten the load of the ship if it is in danger of sinking.Per",1
"maritime law, one who discovers these artifacts is not required to return them to their rightful owner except in the case where the latter makes a legally abiding claim.However, according to the U.S. National Oceanic and Atmospheric Administration ""flotsam may be claimed by the original owner, whereas jetsam may be claimed as property of whoever discovers it"". Lagan (also called ""ligan"") are goods cast overboard and heavy enough to sink to the ocean floor, but linked to a floating marker, such as a buoy or cork, so that they can be found again by the person who marked the item.",1
"Lagan can also be large objects trapped within the sinking vessel.According to maritime law, a buoy or other floating object constitutes sufficient grounds for laying claim to an artifact. Lagan must be returned to the rightful owner. Derelict can refer to goods that have sunk to the ocean floor, relinquished willingly or forcefully by its owner, and thus abandoned, but which no one has any hope of reclaiming.",1
"In terms of maritime law, derelict is considered property abandoned on navigable waters which has no hope of being recovered, or sine spe recuperandi, and no expectation of it being returned to its owner, or sine animo revertendi. Curtis Ebbesmeyer Driftwood Ghost ship Great Pacific garbage patch Marine debris Receiver of Wreck Ship graveyard Treasure trove - the legal ramifications of the notion include the distinction between deliberate and accidental loss",1
"These disinfectants may react with naturally present fulvic and humic acids, amino acids, and other natural organic matter, as well as iodide and bromide ions, to produce a range of DBPs such as the trihalomethanes (THMs), haloacetic acids (HAAs), bromate, and chlorite (which are regulated in the US), and so-called ""emerging"" DBPs such as halonitromethanes, haloacetonitriles, haloamides, halofuranones, iodo-acids such as iodoacetic acid, iodo-THMs (iodotrihalomethanes), nitrosamines, and others.Chloramine",1
"has become a popular disinfectant in the US, and it has been found to produce N-nitrosodimethylamine (NDMA), which is a possible human carcinogen, as well as highly genotoxic iodinated DBPs, such as iodoacetic acid, when iodide is present in source waters.Residual chlorine and other disinfectants may also react further within the distribution network – both by further reactions with dissolved natural organic matter and with biofilms present in the pipes.",1
"Methods of removing sulfur dioxide from boiler and furnace exhaust gases have been studied for over 150 years. Early ideas for flue gas desulfurization were established in England around 1850. With the construction of large-scale power plants in England in the 1920s, the problems associated with large volumes of SO2 from a single site began to concern the public. The SO2 emissions problem did not receive much attention until 1929, when the House of Lords upheld the claim of a landowner against the Barton Electricity Works of the Manchester Corporation for damages to his land resulting from SO2 emissions.",1
"Shortly thereafter, a press campaign was launched against the erection of power plants within the confines of London. This outcry led to the imposition of SO2 controls on all such power plants.The first major FGD unit at a utility was installed in 1931 at Battersea Power Station, owned by London Power Company. In 1935, an FGD system similar to that installed at Battersea went into service at Swansea Power Station. The third major FGD system was installed in 1938 at Fulham Power Station.",1
"SO2 can further oxidize into sulfur trioxide (SO3) when excess oxygen is present and gas temperatures are sufficiently high. At about 800 °C, formation of SO3 is favored. Another way that SO3 can be formed is through catalysis by metals in the fuel. Such reaction is particularly true for heavy fuel oil, where a significant amount of vanadium is present. In whatever way SO3 is formed, it does not behave like SO2 in that it forms a liquid aerosol known as sulfuric acid (H2SO4) mist that is very difficult to remove.",1
"Most FGD systems employ two stages: one for fly ash removal and the other for SO2 removal. Attempts have been made to remove both the fly ash and SO2 in one scrubbing vessel. However, these systems experienced severe maintenance problems and low removal efficiency. In wet scrubbing systems, the flue gas normally passes first through a fly ash removal device, either an electrostatic precipitator or a baghouse, and then into the SO2-absorber. However, in dry injection or spray drying operations, the SO2 is first reacted with the lime, and then the flue gas passes through a particulate control device.",1
"The reaction taking place in wet scrubbing using a CaCO3 (limestone) slurry produces calcium sulfite (CaSO3) and may be expressed in the simplified dry form as: CaCO3(s) + SO2(g) → CaSO3(s) + CO2(g)When wet scrubbing with a Ca(OH)2 (hydrated lime) slurry, the reaction also produces CaSO3 (calcium sulfite) and may be expressed in the simplified dry form as: Ca(OH)2(s) + SO2(g) → CaSO3(s) + H2O(l)When wet scrubbing with a Mg(OH)2 (magnesium hydroxide) slurry, the reaction produces MgSO3 (magnesium sulfite) and may be expressed in the simplified dry form as: Mg(OH)2(s) + SO2(g) → MgSO3(s) + H2O(l)To partially offset the cost of",1
"The chief drawback of spray towers is that they require a higher liquid-to-gas ratio requirement for equivalent SO2 removal than other absorber designs. FGD scrubbers produce a scaling wastewater that requires treatment to meet U.S. federal discharge regulations. However, technological advancements in ion-exchange membranes and electrodialysis systems has enabled high-efficiency treatment of FGD wastewater to meet recent EPA discharge limits. The treatment approach is similar for other highly scaling industrial wastewaters.",1
"In fact, many of the industrial sodium-based throwaway systems are venturi scrubbers originally designed to remove particulate matter. These units were slightly modified to inject a sodium-based scrubbing liquor. Although removal of both particles and SO2 in one vessel can be economic, the problems of high pressure drops and finding a scrubbing medium to remove heavy loadings of fly ash must be considered. However, in cases where the particle concentration is low, such as from oil-fired units, it can be more effective to remove particulate and SO2 simultaneously.",1
"This is not a problem in a kraft pulp mill for example, where this can be a source of makeup chemicals to the recovery cycle.",1
"It is possible to scrub sulfur dioxide by using a cold solution of sodium sulfite; this forms a sodium hydrogen sulfite solution. By heating this solution it is possible to reverse the reaction to form sulfur dioxide and the sodium sulfite solution. Since the sodium sulfite solution is not consumed, it is called a regenerative treatment. The application of this reaction is also known as the Wellman–Lord process.",1
"A new, emerging flue gas desulfurization technology has been described by the IAEA. It is a radiation technology where an intense beam of electrons is fired into the flue gas at the same time as ammonia is added to the gas. The Chendu power plant in China started up such a flue gas desulfurization unit on a 100 MW scale in 1998. The Pomorzany power plant in Poland also started up a similar sized unit in 2003 and that plant removes both sulfur and nitrogen oxides. Both plants are reported to be operating successfully.",1
"Dry scrubbers and spray scrubbers have generally been applied to units smaller than 300 MW. FGD has been fitted by RWE npower at Aberthaw Power Station in south Wales using the seawater process and works successfully on the 1,580 MW plant. Approximately 85% of the flue gas desulfurization units installed in the US are wet scrubbers, 12% are spray dry systems, and 3% are dry injection systems. The highest SO2 removal efficiencies (greater than 90%) are achieved by wet scrubbers and the lowest (less than 80%) by dry scrubbers.",1
"However, the newer designs for dry scrubbers are capable of achieving efficiencies in the order of 90%. In spray drying and dry injection systems, the flue gas must first be cooled to about 10–20 °C above adiabatic saturation to avoid wet solids deposition on downstream equipment and plugging of baghouses.",1
"The capital, operating and maintenance costs per short ton of SO2 removed (in 2001 US dollars) are: For wet scrubbers larger than 400 MW, the cost is $200 to $500 per ton For wet scrubbers smaller than 400 MW, the cost is $500 to $5,000 per ton For spray dry scrubbers larger than 200 MW, the cost is $150 to $300 per ton For spray dry scrubbers smaller than 200 MW, the cost is $500 to $4,000 per ton An alternative to removing sulfur from the flue gases after burning is to remove the sulfur from the fuel before or during",1
"It further contains a small percentage of a number of pollutants, such as particulate matter (like soot), carbon monoxide, nitrogen oxides, and sulfur oxides.",1
"At power plants, flue gas is often treated with a series of chemical processes and scrubbers, which remove pollutants. Electrostatic precipitators or fabric filters remove particulate matter and flue-gas desulfurization captures the sulfur dioxide produced by burning fossil fuels, particularly coal. Nitrogen oxides are treated either by modifications to the combustion process to prevent their formation, or by high temperature or catalytic reaction with ammonia or urea. In either case, the aim is to produce nitrogen gas, rather than nitrogen oxides.",1
"In the United States, there is a rapid deployment of technologies to remove mercury from flue gas—typically by absorption on sorbents or by capture in inert solids as part of the flue-gas desulfurization product. Such scrubbing can lead to meaningful recovery of sulfur for further industrial use.Technologies based on regenerative capture by amines for the removal of CO2 from flue gas have been deployed to provide high purity CO2 gas to the food industry, and for enhanced oil recovery.",1
"The steam generators in large power plants and the process furnaces in large refineries, petrochemical and chemical plants, and incinerators burn considerable amounts of fossil fuels and therefore emit large amounts of flue gas to the ambient atmosphere. The table below presents the total amounts of flue gas typically generated by the burning of fossil fuels such as natural gas, fuel oil and coal. The data were obtained by stoichiometric calculations.The",1
total amount of wet flue gas generated by coal combustion is only 10 percent higher than the flue gas generated by natural-gas combustion (the ratio for dry flue gas is higher).,1
"The first free-standing industrial chimneys were probably those erected at the end of the long condensing flues associated with smelting lead. The powerful association between industrial chimneys and the characteristic smoke-filled landscapes of the industrial revolution was due to the universal application of the steam engine for most manufacturing processes. The chimney is part of a steam-generating boiler, and its evolution is closely linked to increases in the power of the steam engine. The chimneys of Thomas Newcomen’s steam engine were incorporated into the walls of the engine house.",1
"Q = C A 2 g H T i − T o T i {\displaystyle Q=CA{\sqrt {2gH{\frac {T_{i}-T_{o}}{T_{i}}}}}} where: Q: flue-gas flow-rate, m³/s A: cross-sectional area of chimney, m² (assuming it has a constant cross-section) C : discharge coefficient (usually taken to be 0.65–0.70) g: gravitational acceleration at sea level = 9.807",1
Chimney Flue gas Flue-gas desulfurization Flue-gas emissions from fossil-fuel combustion Incineration Stack effect List of tallest chimneys ASHRAE's Fundamentals Handbook is available here from ASHRAE ASME Codes and Standards available from ASME,1
"Commonly, an individual fluorotelomer alcohol molecule is named by the number of carbons that are fluorinated versus the number that are hydrocarbon-based. For example, 8:2 fluorotelomer alcohol would represent a molecule with 8 fluorinated carbons and a 2 carbon ethyl alcohol group. The structure of a fluorotelomer alcohol is most commonly F(CF2)nCH2CH2OH, where n is an even number. The synthesis of fluorotelomer alcohols requires a varying number of tetrafluoroethylene monomers that form an oligomer with a pentafluoroethyl iodide telogen. The fluorinated iodide then undergoes an addition with ethylene to form an organoiodine compound with increased synthesis possibilities.",1
"Fly ash material solidifies while suspended in the exhaust gases and is collected by electrostatic precipitators or filter bags. Since the particles solidify rapidly while suspended in the exhaust gases, fly ash particles are generally spherical in shape and range in size from 0.5 µm to 300 µm. The major consequence of the rapid cooling is that few minerals have time to crystallize, and that mainly amorphous, quenched glass remains. Nevertheless, some refractory phases in the pulverized coal do not melt (entirely), and remain crystalline. In consequence, fly ash is a heterogeneous material.",1
"SiO2, Al2O3, Fe2O3 and occasionally CaO are the main chemical components present in fly ashes. The mineralogy of fly ashes is very diverse. The main phases encountered are a glass phase, together with quartz, mullite and the iron oxides hematite, magnetite and/or maghemite. Other phases often identified are cristobalite, anhydrite, free lime, periclase, calcite, sylvite, halite, portlandite, rutile and anatase. The Ca-bearing minerals anorthite, gehlenite, akermanite and various calcium silicates and calcium aluminates identical to those found in Portland cement can be identified in Ca-rich fly ashes.",1
"The mercury content can reach 1 ppm, but is generally included in the range 0.01–1 ppm for bituminous coal. The concentrations of other trace elements vary as well according to the kind of coal combusted to form it.",1
"Two classes of fly ash are defined by American Society for Testing and Materials (ASTM) C618: Class F fly ash and Class C fly ash. The chief difference between these classes is the amount of calcium, silica, alumina, and iron content in the ash. The chemical properties of the fly ash are largely influenced by the chemical content of the coal burned (i.e., anthracite, bituminous, and lignite).Not all fly ashes meet ASTM C618 requirements, although depending on the application, this may not be necessary.",1
Embankments and other structural fills (usually for road construction) Grout and Flowable fill production Waste stabilization and solidification Cement clinker production (as a substitute material for clay) Mine reclamation Stabilization of soft soils Road subbase construction As aggregate substitute material (e.g.,1
"for brick production) Mineral filler in asphaltic concrete Agricultural uses: soil amendment, fertilizer, cattle feeders, soil stabilization in stock feed yards, and agricultural stakes Loose application on rivers to melt ice Loose application on roads and parking lots for ice controlOther applications include cosmetics, toothpaste, kitchen counter tops, floor and ceiling tiles, bowling balls, flotation devices, stucco, utensils, tool handles, picture frames, auto bodies and boat hulls, cellular concrete, geopolymers, roofing tiles, roofing granules, decking, fireplace mantles, cinder block, PVC pipe, structural insulated panels, house siding and trim, running tracks, blasting grit, recycled plastic lumber, utility poles and crossarms, railway sleepers,",1
"highway noise barriers, marine pilings, doors, window frames, scaffolding, sign posts, crypts, columns, railroad ties, vinyl flooring, paving stones, shower stalls, garage doors, park benches, landscape timbers, planters, pallet blocks, molding, mail boxes, artificial reef, binding agent, paints and undercoatings, metal castings, and filler in wood and plastic products.",1
"Proponents of fly ash claim that replacing Portland cement with fly ash reduces the greenhouse gas ""footprint"" of concrete, as the production of one ton of Portland cement generates approximately one ton of CO2, compared to no CO2 generated with fly ash. New fly ash production, i.e., the burning of coal, produces approximately 20 to 30 tons of CO2 per ton of fly ash.",1
"Since the worldwide production of Portland cement is expected to reach nearly 2 billion tons by 2010, replacement of any large portion of this cement by fly ash could significantly reduce carbon emissions associated with construction, as long as the comparison takes the production of fly ash as a given.",1
"This allows for the establishment of design criteria, and determination of the proper chemical additive and admixture rate that achieves the desired engineering properties. Stabilization process benefits can include: Higher resistance (R) values, Reduction in plasticity, Lower permeability, Reduction of pavement thickness, Elimination of excavation – material hauling/handling – and base importation, Aids compaction, Provides ""all-weather"" access onto and within projects sites. Another form of soil treatment closely related to soil stabilization is soil modification, sometimes referred to as ""mud drying"" or soil conditioning.",1
"Fly ash has also been shown to increase the stiffness of the asphalt matrix, improving rutting resistance and increasing mix durability.",1
Another application of using fly ash is in roller compacted concrete dams. Many dams in the US have been constructed with high fly ash contents. Fly ash lowers the heat of hydration allowing thicker placements to occur. Data for these can be found at the US Bureau of Reclamation. This has also been demonstrated in the Ghatghar Dam Project in India.,1
"Fly ash particles have proved their potential as good reinforcement with aluminum alloys and show the improvement of physical and mechanical properties. In particular, the compression strength, tensile strength, and hardness increase when the percentage of fly ash content is increased, whereas the density decreases. The presence of fly ash cenospheres in a pure Al matrix decreases its coefficient of thermal expansion (CTE).",1
"Constellation Energy disposed fly ash generated by its Brandon Shores Generating Station at a former sand and gravel mine in Gambrills, Maryland, during 1996 to 2007. The ash contaminated groundwater with heavy metals. The Maryland Department of the Environment issued a fine of $1 million to Constellation. Nearby residents filed a lawsuit against Constellation and in 2008 the company settled the case for $54 million.",1
"In 2014, residents living near the Buck Steam Station in Dukeville, North Carolina, were told that ""coal ash pits near their homes could be leaching dangerous materials into groundwater.""",1
"Illinois has many coal ash dumpsites with coal ash generated by coal-burning electric power plants. Of the state's 24 coal ash dumpsites with available data, 22 have released toxic pollutants including arsenic, cobalt, and lithium, into groundwater, rivers and lakes.",1
billion gallons of coal ash into the Emory and Clinch Rivers and damaged nearby residential areas. It is the largest industrial spill in the U.S.,1
"At 10 of the sites, lithium, which causes neurological disease, was found in the groundwater at concentrations more than 1,000 micrograms per liter, which is 25 times the maximum acceptable level. The report concludes that the fossil fuel industry in Texas has failed to comply with federal regulations on coal ash processing, and state regulators have failed to protect the groundwater.",1
"The effect of fly ash on the environment can vary based on the thermal power plant where it is produced, as well as the proportion of fly ash to bottom ash in the waste product. This is due to the different chemical make-up of the coal based on the geology of the area the coal is found and the burning process of the coal in the power plant. When the coal is combusted, it creates an alkaline dust. This alkaline dust can have a pH ranging from 8 to as high as 12.",1
"Microbial communities in contaminated soil have shown reductions in respiration and nitrification. These contaminated soils can be detrimental or beneficial to plant development. Fly ash typically has beneficial outcomes when it corrects nutrient deficiencies in the soil. Most detrimental effects were observed when boron phytotoxicity was observed. Plants absorb elements elevated by the fly ash from the soil. Arsenic, molybdenum, and selenium were the only elements found at potentially toxic levels for grazing animals. Terrestrial organisms exposed to fly ash only showed increased levels of selenium.In",1
"the UK, fly ash lagoons from old coal-fired power stations have been made into nature reserves such as Newport Wetlands, providing habitat for rare birds and other wildlife.",1
"Where fly ash is stored in bulk, it is usually stored wet rather than dry to minimize fugitive dust. The resulting impoundments (ash ponds) are typically large and stable for long periods, but any breach of their dams or bunding is rapid and on a massive scale. In December 2008, the collapse of an embankment at an impoundment for wet storage of fly ash at the Tennessee Valley Authority's Kingston Fossil Plant caused a major release of 5.4 million cubic yards of coal fly ash, damaging three homes and flowing into the Emory River. Cleanup costs may exceed $1.2 billion.",1
"The agency continued to classify coal ash as non-hazardous (thereby avoiding strict permitting requirements under Subtitle C of the Resource Conservation and Recovery Act (RCRA), but with new restrictions: Existing ash ponds that are contaminating groundwater must stop receiving CCR, and close or retrofit with a liner. Existing ash ponds and landfills must comply with structural and location restrictions, where applicable, or close. A pond no longer receiving CCR is still subject to all regulations unless it is dewatered and covered by 2018. New ponds and landfills must include a geomembrane liner over a layer of compacted soil.The",1
"regulation was designed to prevent pond failures and protect groundwater. Enhanced inspection, record keeping and monitoring is required. Procedures for closure are also included and include capping, liners, and dewatering. The CCR regulation has since been subject to litigation.",1
"Fly ash contains trace concentrations of heavy metals and other substances that are known to be detrimental to health in sufficient quantities. Potentially toxic trace elements in coal include arsenic, beryllium, cadmium, barium, chromium, copper, lead, mercury, molybdenum, nickel, radium, selenium, thorium, uranium, vanadium, and zinc. Approximately 10% of the mass of coals burned in the United States consists of unburnable mineral material that becomes ash, so the concentration of most trace elements in coal ash is approximately 10 times the concentration in the original coal.",1
"A 1997 analysis by the United States Geological Survey (USGS) found that fly ash typically contained 10 to 30 ppm of uranium, comparable to the levels found in some granitic rocks, phosphate rock, and black shale.In 1980 the U.S. Congress defined coal ash as a ""special waste"" that would not be regulated under the stringent hazardous waste permitting requirements of RCRA. In its amendments to RCRA, Congress directed EPA to study the special waste issue and make a determination as to whether stricter permit regulation was necessary.",1
"These include wearing protective goggles, respirators and disposable clothing and avoiding agitating the fly ash in order to minimize the amount which becomes airborne. The National Academy of Sciences noted in 2007 that ""the presence of high contaminant levels in many CCR (coal combustion residue) leachates may create human health and ecological concerns"".",1
In March 2023 EPA published a proposed rule that would reverse some aspects of the 2020 rule and impose more stringent wastewater limitations for some facilities.,1
the applications for PFA. Asian Coal Ash Association A web site providing further information on technologies and trade related to coal combustion products.,1
Access: Make emissions data and information about emissions more readily available Analysis: Improve the scientific basis for emissions information and policy making Community: Strengthen the science and policy relationships to enhance access to and analysis of emissionsinformation Emissions of atmospheric Compounds & Compilation of Ancillary Data (ECCAD) provides data access to many emissions inventory datasets. GEIA website ECCAD website,1
"The project asks members of the public to go outside on dark moonless nights and report how many stars are visible in particular constellations. The project focuses on students, teachers, and families, and has produced activity packets in 13 languages. NASA encourages students in its INSPIRE program to participate.Participating individuals are asked to go outside on specified dates at least an hour after sunset, then let their eyes adjust to the ambient light level, and observe a specific constellation: Orion or Leo in the Northern Hemisphere, Crux in the Southern Hemisphere.",1
"Assuming normal visible acuity and clear skies, it is possible to approximately convert Globe at Night naked eye limiting maximum estimates into other units: The Globe at Night project was launched as a NASA program in the United States. The project quickly expanded internationally, and was part of the outreach effort of the International Year of Astronomy in 2009. The size of the project (in terms of number of observations) expanded dramatically in that year.",1
"In 2014, the project expanded to also include data obtained via the Loss of the Night app for Android devices, and the Dark Sky Meter app for iOS devices. In addition, new star charts were added to extend the standard map based campaign throughout the whole year. In 2015, as part of the International Year of Light, two ""International Nights of Skyglow Observation"" were introduced, to encourage data submission in March and September.The",1
"the 1980s, research in Israel and the Netherlands revealed an apparent reduction in the amount of sunlight, and Atsumu Ohmura, a geography researcher at the Swiss Federal Institute of Technology, found that solar radiation striking the Earth's surface had declined by more than 10% over the three previous decades, even as the global temperature had been generally rising since the 1970s. In the 1990s, this was followed by the papers describing multi-decade declines in Estonia, Germany and across the former Soviet Union, which prompted the researcher Gerry Stanhill to coin the term ""global dimming"".",1
"Subsequent research estimated an average reduction in sunlight striking the terrestrial surface of around 4–5% per decade over late 1950s–1980s, and 2–3% per decade when 1990s were included. Notably, solar radiation at the top of the atmosphere did not vary by more than 0.1-0.3% in all that time, strongly suggesting that the reasons for the dimming were on Earth. Additionally, only visible light and infrared radiation were dimmed, rather than the ultraviolet part of the spectrum.",1
"Since nearly 90% of the human population lives in the Northern Hemisphere, clouds there are far more affected by aerosols than in the Southern Hemisphere, but these differences have halved in the two decades since 2000, providing further evidence for the ongoing global brightening. Global dimming had been widely attributed to the increased presence of aerosol particles in Earth's atmosphere, predominantly those of sulfates.",1
"While natural dust is also an aerosol with some impacts on climate, and volcanic eruptions considerably increase sulfate concentrations in the short term, these effects have been dwarfed by increases in sulfate emissions since the start of the Industrial Revolution. According to the IPCC First Assessment Report, the global human-caused emissions of sulfur into the atmosphere were less than 3 million tons per year in 1860, yet they increased to 15 million tons in 1900, 40 million tons in 1940 and about 80 millions in 1980.",1
"This meant that the human-caused emissions became ""at least as large"" as all natural emissions of sulfur-containing compounds: the largest natural source, emissions of dimethyl sulfide from the ocean, was estimated at 40 million tons per year, while volcano emissions were estimated at 10 million tons. Moreover, that was the average figure: according to the report, ""in the industrialized regions of Europe and North America, anthropogenic emissions dominate over natural emissions by about a factor of ten or even more"". Aerosols and other atmospheric particulates have direct and indirect effects on the amount of sunlight received at the surface.",1
"In the 1990s, experiments comparing the atmosphere over the northern and southern islands of the Maldives, showed that the effect of macroscopic pollutants in the atmosphere at that time (blown south from India) caused about a 10% reduction in sunlight reaching the surface in the area under the Asian brown cloud – a much greater reduction than expected from the presence of the particles themselves. Prior to the research being undertaken, predictions were of a 0.5–1% effect from particulate matter; the variation from prediction may be explained by cloud formation with the particles acting as the focus for droplet creation.",1
"In 1990, the IPCC First Assessment Report acknowledged that ""Human-made aerosols, from sulphur emitted largely in fossil fuel combustion can modify clouds and this may act to lower temperatures"", while ""a decrease in emissions of sulphur might be expected to increase global temperatures"". However, lack of observational data and difficulties in calculating indirect effects on clouds left the report unable to estimate whether the total impact of all anthropogenic aerosols on the global temperature amounted to cooling or warming.",1
"By 2021, the northeastern coast of the United States was instead one of the fastest-warming regions of North America, as the slowdown of the Atlantic Meridional Overturning Circulation increased temperatures in that part of the North Atlantic Ocean.Globally, the emergence of extreme heat beyond the preindustrial records was delayed by aerosol cooling, and hot extremes accelerated as global dimming abated: it has been estimated that since the mid-1990s, peak daily temperatures in northeast Asia and hottest days of the year in Western Europe would have been substantially less hot if aerosol concentrations had stayed the same as before.",1
"Some of the acceleration of sea level rise, as well as Arctic amplification and the associated Arctic sea ice decline, was also attributed to the reduction in aerosol masking.Pollution from black carbon, mostly represented by soot, also contributes to global dimming. However, because it absorbs heat instead of reflecting it, it warms the planet instead of cooling it like sulfates.",1
"This warming is much weaker than that of greenhouse gases, but it can be regionally significant when black carbon is deposited over ice masses like mountain glaciers and the Greenland ice sheet, where it reduces their albedo and increases their absorption of solar radiation. Even the indirect effect of soot particles acting as cloud nuclei is not strong enough to provide cooling: the ""brown clouds"" formed around soot particles were known to have a net warming effect since the 2000s.",1
"Climate models started to account for the effects of sulfate aerosols around the IPCC Second Assessment Report; when the IPCC Fourth Assessment Report was published in 2007, every climate model had integrated sulfates, but only 5 were able to account for less impactful particulates like black carbon. By 2021, CMIP6 models estimated total aerosol cooling in the range from 0.1 °C (0.18 °F) to 0.7 °C (1.3 °F); The IPCC Sixth Assessment Report selected the best estimate of a 0.5 °C (0.90 °F) cooling provided by sulfate aerosols, while black carbon amounts to about 0.1 °C (0.18 °F) of warming.",1
"To avoid confounders, many observations of aerosol effects focus on ship tracks, but post-2020 research found that visible ship tracks are a poor proxy for other clouds, and estimates derived from them overestimate aerosol cooling by as much as 200%. At the same time, other research found that the majority of ship tracks are ""invisible"" to satellites, meaning that the earlier research had underestimated aerosol cooling by overlooking them.",1
"Finally, 2023 research indicates that all climate models have underestimated sulfur emissions from volcanoes which occur in the background, outside of major eruptions, and so had consequently overestimated the cooling provided by anthropogenic aerosols, especially in the Arctic climate. Regardless of the current strength of aerosol cooling, all future climate change scenarios project decreases in particulates and this includes the scenarios where 1.5 °C (2.7 °F) and 2 °C (3.6 °F) targets are met: their specific emission reduction targets assume the need to make up for lower dimming.",1
"Unfortunately, because historical records of aerosols are sparser in some regions than in others, accurate regional projections of aerosol impacts are difficult. Even the latest CMIP6 climate models can only accurately represent aerosol trends over Europe, but struggle with representing North America and Asia, meaning that their near-future projections of regional impacts are likely to contain errors as well.",1
"In general, aircraft contrails (also called vapor trails) are believed to trap outgoing longwave radiation emitted by the Earth and atmosphere more than they reflect incoming solar radiation, resulting in a net increase in radiative forcing. In 1992, this warming effect was estimated between 3.5 mW/m2 and 17 mW/m2. Global radiative forcing impact of aircraft contrails has been calculated from the reanalysis data, climate models, and radiative transfer codes; estimated at 12 mW/m2 for 2005, with an uncertainty range of 5 to 26 mW/m2, and with a low level of scientific understanding.",1
"When no commercial aircraft flew across the USA following the September 11 attacks, the diurnal temperature variation was widened by 1.1 °C (2.0 °F). Measured across 4,000 weather stations in the continental United States, this increase was the largest recorded in 30 years. Without contrails, the local diurnal temperature range was 1 °C (1.8 °F) higher than immediately before. In the southern US, the difference was diminished by about 3.3 °C (6 °F), and by 2.8 °C (5 °F) in the US midwest. However, follow-up studies found that a natural change in cloud cover can more than explain these findings.",1
"On the other hand, the decline in sulfate emissions caused by the curtailed road traffic and industrial output during the COVID-19 lockdowns did have a detectable warming impact: it was estimated to have increased global temperatures by 0.01–0.02 °C (0.018–0.036 °F) initially and up to 0.03 °C (0.054 °F) by 2023, before disappearing. Regionally, the lockdowns were estimated to increase temperatures by 0.05–0.15 °C (0.090–0.270 °F) in eastern China over January–March, and then by 0.04–0.07 °C (0.072–0.126 °F) over Europe, eastern United States, and South Asia in March–May, with the peak impact of 0.3 °C (0.54",1
"In 2011, it was found that anthropogenic aerosols had been the predominant factor behind 20th century changes in rainfall over the Atlantic Ocean sector, when the entire tropical rain belt shifted southwards between 1950 and 1985, with a limited northwards shift afterwards. Future reductions in aerosol emissions are expected to result in a more rapid northwards shift, with limited impact in the Atlantic but a substantially greater impact in the Pacific.Most",1
"An increase in planetary albedo of 1% would eliminate most of radiative forcing from anthropogenic greenhouse gas emissions and thereby global warming, while a 2% albedo increase would negate the warming effect of doubling the atmospheric carbon dioxide concentration. This is the theory behind solar geoengineering, and the high reflective potential of sulfate aerosols means that they were considered in this capacity for a long time. In 1974, Mikhail Budyko suggested that if global warming became a problem, the planet could be cooled by burning sulfur in the stratosphere, which would create a haze.",1
"starting with the seminal 2006 paper by Paul Crutzen, the solution advocated is known as stratospheric aerosol injection, or SAI. It would transport sulfates into the next higher layer of the atmosphere – stratosphere, where they would last for years instead of weeks, so far less sulfur would have to be emitted. It has been estimated that the amount of sulfur needed to offset a warming of around 4 °C (7.2 °F) relative to now (and 5 °C (9.0 °F) relative to the preindustrial), under the highest-emission scenario RCP 8.5",1
"°F) through stratospheric aerosol injection would cost at least $18 billion annually (at 2020 USD value), meaning that only the largest economies or economic blocs could afford this intervention. Even so, these approaches would still be ""orders of magnitude"" cheaper than greenhouse gas mitigation, let alone the costs of unmitigated effects of climate change.The main downside to SAI is that any such cooling would still cease 1–3 years after the last aerosol injection, while the warming from CO2 emissions lasts for hundreds to thousands of years unless they are reversed earlier.",1
"risks include limited knowledge about the regional impacts of solar geoengineering (beyond the certainty that even stopping or reversing the warming entirely would still result in significant changes in weather patterns in many areas) and, correspondingly, the impacts on ecosystems. It is generally believed that relative to now, crop yields and carbon sinks would be largely unaffected or may even increase slightly, because reduced photosynthesis due to lower sunlight would be offset by CO2 fertilization effect and the reduction in thermal stress, but there's less confidence about how specific ecosystems may be affected.",1
"Drops in temperature large enough to result in deposition can occur when chemicals are blown from warmer to cooler climates, or when seasons change. The net effect is atmospheric transport from low to high latitude and altitude. Since global distillation is a relatively slow process that relies on successive evaporation/condensation cycles, it is only effective for semi-volatile chemicals that break down very slowly in the environment, like DDT, polychlorinated biphenyls, and lindane.",1
"It was formed by the deposit of large amounts of sand blown by prevailing winds.At the point of Kamilo, waves have cut a large indentation, creating a variety of rocky points, ponds, and channels. Most of these are exposed during low tides, and are awash during high tides. The backshore at Kamilo contains such vegetation as naupaka, milo, and ironwood. The beach is an accumulation zone for plastic trash. The debris is forced onto the beach by constant trade winds and converging ocean currents.",1
"Keep Wales Tidy started as a campaign in 1972, funded by the Welsh Office. At this time it was an offshoot of the charity Keep Britain Tidy. In 2000 Keep Wales Tidy established itself as a separate company, beginning the process of separation from the parent group, and this was completed in 2005. Today there are no formal ties between the two groups, although they often collaborate on common issues.In 2008 the organisation adopted a Fair Trade policy, sourcing items like coffee, tea and biscuits from Fair Trade outlets. Larger items such as staff T-shirts are also Fair Trade sourced.",1
"Keep Wales Tidy runs a number of projects, including:",1
"This project works to improve the environment in Wales. The Welsh Assembly Government has given all Welsh local authorities a Tidy Towns grant, and each one now has a Tidy Towns Officer. Much of their work in this area is on general litter issues. Through this initiative, Keep Wales Tidy is also able to offer financial assistance to groups who wish to improve their home areas, with grants awarded to cover the cost of tools, equipment, publicity and training.",1
"This project works with children and young people in the school environment. Sustainability issues are a part of the scheme, and 3 awards can be earned - Bronze, Silver, and Green Flag.",1
The full criteria for Resort Beach status can be found here.The full criteria for Rural Beach status can be found here.,1
"Keep Wales Tidy promoted its ""I Will for Wales"" / ""Fe Wnaf dros Gymru"" campaign at the National Eisteddfod in Wrexham in 2011. Earth Day Keep Britain Tidy National Cleanup Day World Cleanup Day Plogging",1
"To raise awareness, understanding and appreciation among Hong Kong youth about the state of the ocean and the health of its ecosystem. Picture Drawing Competition Hong Kong Kids Ocean Film Festival Ocean Education Program for Schools Beach Education Class Human Aerial Art Project Ocean Recovery Alliance Kids Ocean Week on Facebook Short Video Kids Ocean Day HK Extended Video Kids Ocean Day HK Malibu Foundation Spectral Q National CleanUp Day",1
"Keep America Beautiful was founded in December 1953 by a group of American corporations.Keep America Beautiful conducted many local PSA campaigns early in its history. One of these early campaigns in Pennsylvania (PennDOT) some attribute to having coined the term ""litterbug,"" although the National Council of State Garden Clubs representative exhibited a ""litter bug"" emblem at the first Keep America Beautiful organizational meeting. Author and Federated Garden Clubs of Maryland president Alice Rush McKeon published ""The Litterbug Family"" in 1931 containing poems and illustrations about the problem of roadside litter.Others report, however, that the term was coined by Paul B.",1
"Its study concluded that 90% of Americans agree litter is a problem in their community, roadside litter is down 54% in the last ten years and there are approximately 50 billion pieces of litter on the ground in the United States. In concert with the study's release, Keep America Beautiful launched their hashtag #152AndYou on Earth Day representing that if all individuals picked up 152 pieces of litter, there would be no litter on the ground until someone littered again.",1
"Keep America Beautiful distributes programming and materials through a network of organizations. In addition to KAB's certified affiliates, the organization partners with other groups to expand its reach. These include multiple state recycling organizations, Boys & Girls Clubs of America, Hands on Network and the Points of Light Institute, the Arbor Day Foundation, Pennsylvania Horticultural Society, National CleanUp Day, Ocean Conservancy, Sustainable Urban Forests Coalition, EARTHDAY.ORG, and Take Pride in America, among others.Scouting Keep America Beautiful Day was first cosponsored by Keep America Beautiful and the Boy Scouts of America in 1971 as a national cleanup and recycling program.",1
"Keep America Beautiful also co-sponsors the ""Keep America Beautiful Hometown USA Award"" with the Boy Scouts of America that boy scouts can earn by completing a non-paid, community service project, with the approved scout project being designed to ""help keep America beautiful and benefit the community either physically or financially."" Keep America Beautiful's actions have been criticized as greenwashing. The organization's narrow focus on littering and recycling diverts responsibility away from corporations and industries.Despite self-identifying as having Native American ancestry with the stage name of Iron Eyes Cody, Espera Oscar DeCorti was of Italian descent.",1
"She asserts that the group was created in response to Vermont's 1953 attempt to legislate a mandatory deposit to be paid at point of purchase on disposable beverage containers and banning the sale of beer in non-refillable bottles.Keep America Beautiful's narrow focus on litter, and its characterization of litter as a consumer created problem, is seen as an attempt to divert an extended producer responsibility from the industries that manufacture and sell disposable products to consumers who improperly dispose of the non-returnable wrappers, filters, and beverage containers.Elizabeth",1
"Royte, author of Garbage Land, describes Keep America Beautiful as a ""masterful example of corporate greenwash"", writing that in contrast to its anti-litter campaigns, it ignores the potential of recycling legislation and resists changes to packaging.The tobacco industry developed programs with Keep America Beautiful that focused on cigarette litter solutions acceptable to the industry such as volunteer clean-ups and ashtrays, in lieu of smoking bans at parks and beaches. The tobacco industry has funded Keep America Beautiful and similar organizations internationally.",1
"Clean Up Australia Container deposit legislation Keep Britain Tidy Keep Northern Ireland Beautiful Litter in the United States National Cleanup Day Recycling in the United States Roads Beautifying Association (in the UK) Official website ""Keep America Beautiful"" 1970s ""Crying Indian"" PSA on YouTube",1
Ion exchange is a reversible ion exchange process in which an insoluble substance (resin) takes ions from an electrolytic solution and releases additional ions of the same charge in a chemically comparable amount without changing the resin's structure.,1
Electrodialysis (ED) Membrane electrolysis (ME) Electrochemical precipitation (EP),1
"Adsorption is a mass transfer process in which a substance is transported from the liquid phase to the surface of a solid/liquid (adsorbent) and becomes physically and chemically bonded (adsorbate). Adsorption can be classified into two forms based on the type of attraction between the adsorbate and the adsorbent: physical and chemical adsorption, commonly known as physisorption and chemisorptions.",1
"Because of its high surface area, porosity, and flexibility, activated carbon has a lot of potential in wastewater treatment.",1
"This is the method by which dissolved and suspended organic chemical components are eliminated through biodegradation, in which an optimal amount of microorganism is given to re-enact the same natural self-purification process. Through two distinct biological process, such as biological oxidation and biosynthesis, microorganisms can degrade organic materials in wastewater. Microorganisms involved in wastewater treatment produce end products such as minerals, carbon dioxide, and ammonia during the biological oxidation process. The minerals (products) remained in the wastewater and were discharged with the effluent.",1
"The cause for this can be lack of sanitation procedures or poorly functioning on-site sanitation systems (septic tanks, pit latrines), sewage treatment plants without disinfection steps, sanitary sewer overflows and combined sewer overflows (CSOs) during storm events and intensive agriculture (poorly managed livestock operations).",1
"Oxygen-depleting substances may be natural materials such as plant matter (e.g. leaves and grass) as well as man-made chemicals. Other natural and anthropogenic substances may cause turbidity (cloudiness) which blocks light and disrupts plant growth, and clogs the gills of some fish species.",1
"with secondary treatment stages or more advanced tertiary treatment) can remove 90 percent or more of the pollutant load in sewage. Some plants have additional systems to remove nutrients and pathogens. While such advanced treatment techniques will undoubtedly reduce the discharges of micropollutants, they can also result in large financial costs, as well as environmentally undesirable increases in energy consumption and greenhouse gas emissions.Sewer overflows during storm events can be addressed by timely maintenance and upgrades of the sewerage system.",1
"In the US, cities with large combined systems have not pursued system-wide separation projects due to the high cost, but have implemented partial separation projects and green infrastructure approaches. In some cases municipalities have installed additional CSO storage facilities or expanded sewage treatment capacity.",1
"Because of the potential adverse quality effects (see chlorine below), this has largely been discontinued.",1
"Within seconds, negative charges on the particles are neutralised by inorganic coagulants. Also within seconds, metal hydroxide precipitates of the iron and aluminium ions begin to form. These precipitates combine into larger particles under natural processes such as Brownian motion and through induced mixing which is sometimes referred to as flocculation. Amorphous metal hydroxides are known as ""floc"". Large, amorphous aluminium and iron (III) hydroxides adsorb and enmesh particles in suspension and facilitate the removal of particles by subsequent processes of sedimentation and filtration.: 8.2–8.3 Aluminum hydroxides are formed within a fairly narrow pH range, typically: 5.5 to about 7.7.",1
"Iron (III) hydroxides can form over a larger pH range including pH levels lower than are effective for alum, typically: 5.0 to 8.5.:",1
The amount of ground surface area occupied by a sedimentation basin with inclined plates or tubes can be far smaller than a conventional sedimentation basin.,1
Filters out virtually all particles larger than their specified pore sizes. They are quite thin and so liquids flow through them fairly rapidly. They are reasonably strong and so can withstand pressure differences across them of typically 2–5 atmospheres. They can be cleaned (back flushed) and reused.,1
Particularly important are distillation (desalination of seawater) and reverse osmosis.,1
"Bioremediation uses microorganisms to remove waste products from a contaminated area. Since 1991 bioremediation has been a suggested tactic to remove impurities such as alkanes, perchlorates, and metals. Bioremediation has seen success because perchlorates are highly soluble, making them difficult to remove. Example applications of Dechloromonas agitata strain CKB include field studies conducted in Maryland and the US Southwest.",1
"Confusion between ""grassed waterway"" and ""vegetative filter strips"" should be avoided. The latter are generally narrower (only a few metres wide) and rather installed along rivers as well as along or within cultivated fields. However, buffer strip can be a synonym, with shrubs and trees added to the plant component, as does a riparian zone. Runoff generated on cropland during storms or long winter rains concentrates in the thalweg where it can lead to rill or gully erosion. Rills and gullies further concentrate runoff and speed up its transfer, which can worsen damage occurring downstream.",1
"This can result in a muddy flood. In this context, a grassed waterway allows increasing soil cohesion and roughness. It also prevents the formation of rills and gullies. Furthermore, it can slow down runoff and allow its re-infiltration during long winter rains. In contrast, its infiltration capacity is generally not sufficient to reinfiltrate runoff produced by heavy spring and summer storms. It can therefore be useful to combine it with extra measures, like the installation of earthen dams across the grassed waterway, in order to buffer runoff temporarily.",1
"The inaugural National CleanUp Day was held in 2017 and had more than 225,000 volunteers. The 2018 event had over 1,500,000 volunteers, 14 million pounds of waste collected, and was held in conjunction with the inaugural World Cleanup Day.The 2019 cleanup received nearly two million volunteers and resulted in the collection of 18 million pounds of waste. The U.S. event is coordinated with World Cleanup Day and saw a combined 20 million volunteers in 170 countries, which is the largest, single day global volunteer event. Beginning in 2018, the U.S.",1
"Department of Transportation participated in cleanups on their local and interstate highway systems.In April 2019, Earth Day partnered with National CleanUp Day and Keep America Beautiful for the inaugural Earth Day CleanUp and had over 500,000 volunteers working to clean up trash and litter nationally. Earth Day and presenting partners World CleanUp Day, National CleanUp Day and Keep America Beautiful organized individual activities like Plogging and the TrashTag Challenge.In 2020, National CleanUp Day introduced the Tailored CleanUp program for businesses and cities. The program is available to any participating business, educational institution, land manager, government entity or nonprofit.",1
"The United States Nuclear Regulatory Commission defines this as ""Types and amounts of radioactive or hazardous material released to the environment following an accident.""Contamination does not include residual radioactive material remaining at a site after the completion of decommissioning. Therefore, radioactive material in sealed and designated containers is not properly referred to as contamination, although the units of measurement might be the same.",1
"Containment is the primary way of preventing contamination from being released into the environment or coming into contact with or being ingested by humans. Being within the intended Containment differentiates radioactive material from radioactive contamination. When radioactive materials are concentrated to a detectable level outside a containment, the area affected is generally referred to as ""contaminated"". There are a large number of techniques for containing radioactive materials so that it does not spread beyond the containment and become contaminated.",1
"A variety of radionuclides occur naturally in the environment. Elements like uranium and thorium, and their decay products, are present in rock and soil. Potassium-40, a primordial nuclide, makes up a small percentage of all potassium and is present in the human body. Other nuclides, like carbon-14, which is present in all living organisms, are continuously created by cosmic rays. These levels of radioactivity pose little danger but can confuse measurement. A particular problem is encountered with naturally generated radon gas which can affect instruments that are set to detect contamination close to normal background levels and can cause false alarms.",1
Contamination monitoring depends entirely upon the correct and appropriate deployment and utilisation of radiation monitoring instruments.,1
"Access to such areas is controlled by a variety of barrier techniques, sometimes involving changes of clothing and footwear as required. The contamination within a controlled area is normally regularly monitored. Radiological protection instrumentation (RPI) plays a key role in monitoring and detecting any potential contamination spread, and combinations of hand held survey instruments and permanently installed area monitors such as Airborne particulate monitors and area gamma monitors are often installed. Detection and measurement of surface contamination of personnel and plant are normally by Geiger counter, scintillation counter or proportional counter.",1
"Proportional counters and dual phosphor scintillation counters can discriminate between alpha and beta contamination, but the Geiger counter cannot. Scintillation detectors are generally preferred for hand-held monitoring instruments and are designed with a large detection window to make monitoring of large areas faster. Geiger detectors tend to have small windows, which are more suited to small areas of contamination.",1
"Modern instruments consequently have ""radon compensation"" to overcome this effect.",1
"Department of Energy (DOE) and the commercial nuclear industry for decades to minimize contamination on radioactive equipment and surfaces and fix contamination in place. ""Contamination control products"" is a broad term that includes fixatives, strippable coatings, and decontamination gels. A fixative product functions as a permanent coating to stabilize residual loose/transferable radioactive contamination by fixing it in place; this aids in preventing the spread of contamination and reduces the possibility of the contamination becoming airborne, reducing workforce exposure and facilitating future deactivation and decommissioning (D&D) activities.",1
"Stripping out the key radioisotope threatening health (caesium-137) from low-level waste could also dramatically decrease the volume of waste requiring special disposal. A goal is to find techniques that might be able to strip out 80 to 95% of the caesium from contaminated soil and other materials, efficiently and without destroying the organic content in the soil. One being investigated is termed hydrothermal blasting. The caesium is broken away from soil particles and then precipitated with ferric ferricyanide (Prussian blue). It would be the only component of the waste requiring special burial sites.",1
"The aim is to get annual exposure from the contaminated environment down to one millisievert (mSv) above background. The most contaminated area where radiation doses are greater than 50 mSv/year must remain off-limits, but some areas that are currently less than 5 mSv/year may be decontaminated allowing 22,000 residents to return. To help protect people living in geographical areas which have been radioactively contaminated, the International Commission on Radiological Protection has published a guide: ""Publication 111 – Application of the Commission's Recommendations to the Protection of People Living in Long-term Contaminated Areas after a Nuclear Accident or a Radiation Emergency"".",1
"The hazards to people and the environment from radioactive contamination depend on the nature of the radioactive contaminant, the level of contamination, and the extent of the spread of contamination. Low levels of radioactive contamination pose little risk, but can still be detected by radiation instrumentation. If a survey or map is made of a contaminated area, random sampling locations may be labeled with their activity in becquerels or curies on contact. Low levels may be reported in counts per minute using a scintillation counter.",1
"In the case of low-level contamination by isotopes with a short half-life, the best course of action may be to simply allow the material to naturally decay. Longer-lived isotopes should be cleaned up and properly disposed of because even a very low level of radiation can be life-threatening when in long exposure to it. Facilities and physical locations that are deemed to be contaminated may be cordoned off by a health physicist and labeled ""Contaminated area."" Persons coming near such an area would typically require anti-contamination clothing (""anti-Cs"").",1
"High levels of contamination may pose major risks to people and the environment. People can be exposed to potentially lethal radiation levels, both externally and internally, from the spread of contamination following an accident (or a deliberate initiation) involving large quantities of radioactive material. The biological effects of external exposure to radioactive contamination are generally the same as those from an external radiation source not involving radioactive materials, such as x-ray machines, and are dependent on the absorbed dose.",1
"When radioactive contamination is being measured or mapped in situ, any location that appears to be a point source of radiation is likely to be heavily contaminated. A highly contaminated location is colloquially referred to as a ""hot spot."" On a map of a contaminated place, hot spots may be labeled with their ""on contact"" dose rate in mSv/h. In a contaminated facility, hot spots may be marked with a sign, shielded with bags of lead shot, or cordoned off with warning tape containing the radioactive trefoil symbol. The hazard from contamination is the emission of ionizing radiation.",1
"The principal radiations which will be encountered are alpha, beta and gamma, but these have quite different characteristics. They have widely differing penetrating powers and radiation effects, and the accompanying diagram shows the penetration of these radiations in simple terms. For an understanding of the different ionising effects of these radiations and the weighting factors applied, see the article on absorbed dose. Radiation monitoring involves the measurement of radiation dose or radionuclide contamination for reasons related to the assessment or control of exposure to radiation or radioactive substances, and the interpretation of the results.",1
"Radioactive contamination by definition emits ionizing radiation, which can irradiate the human body from an external or internal origin.",1
"This is due to radiation from contamination located outside the human body. The source can be in the vicinity of the body or can be on the skin surface. The level of health risk is dependent on duration and the type and strength of irradiation. Penetrating radiation such as gamma rays, X-rays, neutrons or beta particles pose the greatest risk from an external source. Low penetrating radiation such as alpha particles have a low external risk due to the shielding effect of the top layers of skin. See the article on sievert for more information on how this is calculated.",1
"Radioactive contamination can be ingested into the human body if it is airborne or is taken in as contamination of food or drink, and will irradiate the body internally. The art and science of assessing internally generated radiation dose is Internal dosimetry. The biological effects of ingested radionuclides depend greatly on the activity, the biodistribution, and the removal rates of the radionuclide, which in turn depends on its chemical form, the particle size, and route of entry. Effects may also depend on the chemical toxicity of the deposited material, independent of its radioactivity.",1
"ICRP states ""Radionuclides incorporated in the human body irradiate the tissues over time periods determined by their physical half-life and their biological retention within the body. Thus they may give rise to doses to body tissues for many months or years after the intake. The need to regulate exposures to radionuclides and the accumulation of radiation dose over extended periods of time has led to the definition of committed dose quantities"". The ICRP further states ""For internal exposure, committed effective doses are generally determined from an assessment of the intakes of radionuclides from bioassay measurements or other quantities (e.g.,",1
"activity retained in the body or in daily excreta). The radiation dose is determined from the intake using recommended dose coefficients"".The ICRP defines two dose quantities for individual committed dose: Committed equivalent dose, H T(t) is the time integral of the equivalent dose rate in a particular tissue or organ that will be received by an individual following intake of radioactive material into the body by a Reference Person, where t is the integration time in years. This refers specifically to the dose in a specific tissue or organ, in a similar way to external equivalent dose.",1
"Committed effective dose, E(t) is the sum of the products of the committed organ or tissue equivalent doses and the appropriate tissue weighting factors WT, where t is the integration time in years following the intake. The commitment period is taken to be 50 years for adults, and to age 70 years for children. This refers specifically to the dose to the whole body, in a similar way to external effective dose.",1
"A 2015 report in Lancet explained that serious impacts of nuclear accidents were often not directly attributable to radiation exposure, but rather social and psychological effects. The consequences of low-level radiation are often more psychological than radiological. Because damage from very low-level radiation cannot be detected, people exposed to it are left in anguished uncertainty about what will happen to them. Many believe they have been fundamentally contaminated for life and may refuse to have children for fear of birth defects. They may be shunned by others in their community who fear a sort of mysterious contagion.Forced",1
"evacuation from a radiological or nuclear accident may lead to social isolation, anxiety, depression, psychosomatic medical problems, reckless behavior, even suicide. Such was the outcome of the 1986 Chernobyl nuclear disaster in Ukraine. A comprehensive 2005 study concluded that ""the mental health impact of Chernobyl is the largest public health problem unleashed by the accident to date"". Frank N. von Hippel, a U.S. scientist, commented on 2011 Fukushima nuclear disaster, saying that ""fear of ionizing radiation could have long-term psychological effects on a large portion of the population in the contaminated areas"".",1
"Evacuation and long-term displacement of affected populations create problems for many people, especially the elderly and hospital patients.Such great psychological danger does not accompany other materials that put people at risk of cancer and other deadly illness. Visceral fear is not widely aroused by, for example, the daily emissions from coal burning, although, as a National Academy of Sciences study found, this causes 10,000 premature deaths a year in the US population of 317,413,000. Medical errors leading to death in U.S. hospitals are estimated to be between 44,000 and 98,000.",1
"It is ""only nuclear radiation that bears a huge psychological burden – for it carries a unique historical legacy"". Nuclear technology portal Measurement Good Practice Guide No. 30 ""Practical Radiation Monitoring"" Oct 2002 – National Physical Laboratory, Teddington Q&A: Health effects of radiation exposure, BBC News, 21 July 2011. Alliance for Nuclear Responsibility training guide Brookhaven National Laboratory Training Guide. International Fund for Animal Welfare report on impact of radiation on animals",1
"The mothballed C-3 Liberty ship John F. Shafroth was taken from the National Defense Reserve Fleet at Suisun Bay and towed to the Concord Naval Weapons Station for stripping and loading. A major fraction of the munitions in CHASE 1 was Bofors 40 mm gun ammunition from the Naval Ammunition Depot at Hastings, Nebraska. CHASE 1 also included bombs, torpedo warheads, naval mines, cartridges, projectiles, fuzes, detonators, boosters, overage UGM-27 Polaris motors, and a quantity of contaminated cake mix an army court had ordered dumped at sea.",1
"Shafroth was sunk 47 miles (76 km) off San Francisco on 23 July 1964 with 9,799 tons of munitions.",1
"Village was loaded with 7,348 short tons of munitions at the Naval Weapons Station Earle and towed to a deep-water dump site on 17 September 1964. There were three large and unexpected detonations five minutes after Village slipped beneath the surface. An oil slick and some debris appeared on the surface. The explosion registered on seismic equipment all over the world.",1
"Inquiries were received regarding seismic activity off the east coast of the United States, and the Office of Naval Research and Advanced Research Projects Agency expressed interest in measuring the differences between seismic shocks and underwater explosive detonations to detect underwater nuclear detonations then banned by treaty.",1
"Coastal Mariner was loaded with 4040 short tons of munitions at the Naval Weapons Station Earle. The munitions included 512 tons of explosives. Four SOFAR bombs were packed in the explosives cargo hold with booster charges of 500 pounds (227 kg) of TNT to detonate the cargo at a depth of 1,000 feet (300 m). The United States Coast Guard issued a notice to mariners and the United States Department of Fish and Wildlife and the United States Bureau of Commercial Fisheries sent observers. The explosives detonated seventeen seconds after Coastal Mariner slipped below the surface on 14 July 1965.",1
The detonation created a 600-foot (200 m) waterspout but was not deep enough to be recorded on seismic instruments.,1
"Santiago Iglesias was loaded with 8,715 tons of munitions at the Naval Weapons Station Earle, rigged for detonation at 1,000 feet (300 m), and detonated 31 seconds after sinking on 16 September 1965.",1
"Isaac Van Zandt was loaded with 8,000 tons of munitions (including 400 tons of high explosives) at the Naval Base Kitsap and rigged for detonation at 4,000 feet (1.2 km). On 23 May 1966 the tow cable parted en route to the planned disposal area. Navy tugs USS Tatnuck (ATA-195) and USS Koka (ATA-185) recovered the tow within six hours, but the location of sinking was changed by the delay.",1
The tug Tatnuck involved in towing Robert Louis Stevenson was reported by Proceedings as towing Izaac Van Zandt a year earlier for CHASE 5.,1
Michael J. Monahan was loaded with overage UGM-27 Polaris motors at the Naval Weapons Station Charleston and sunk without detonation on 30 April 1967.,1
Eric G. Gibson was sunk on 15 June 1967.,1
"CHASE 10 dumped 3,000 tons of United States Army nerve agent filled rockets encased in concrete vaults. Public controversy delayed CHASE 10 disposal until August 1970. Public awareness of operation CHASE 10 was increased by mass media reporting following delivery of information from the Pentagon to the office of U.S. Representative Richard McCarthy in 1969. Both American television and print media followed the story with heavy coverage. In 1970, 58 separate reports were aired on the three major network news programs on NBC, ABC and CBS concerning Operation CHASE.",1
"Similarly, The New York Times included Operation CHASE coverage in 42 separate issues during 1970, 21 of those in the month of August.",1
"CHASE 11 occurred in June 1968 and disposed of United States Army GB and VX, all sealed in tin containers.",1
"CHASE 12, in August 1968, again disposed of United States Army mustard agent and was numerically (although not chronologically) the final mission to dispose of chemical weapons. Operation CHASE was exposed to the public during a time when the army was under increasing public criticism, especially the army's Chemical Corps. CHASE was one of the incidents which led to the near disbanding of the Chemical Corps in the aftermath of the Vietnam War. Concerns were raised over the program's effect on the ocean environment as well as the risk of chemical weapons washing up on shore.",1
"The concerns led to the Marine Protection, Research, and Sanctuaries Act of 1972, which prohibited such future missions. After a treaty was drafted by the United Nations' London Convention in 1972, an international ban came into effect as well. Dugway sheep incident Operation Red Hat",1
"Coal naturally concentrates lead and zinc during its formation, as well as other heavy metals to a lesser degree. When the coal is burned, most of these metals become concentrated in the ash (the principal exception being mercury). Coal ash and slag may contain sufficient lead to qualify as a ""characteristic hazardous waste"", defined in the US as containing more than 5 mg/L of extractable lead using the TCLP procedure. In addition to lead, coal ash typically contains variable but significant concentrations of polynuclear aromatic hydrocarbons (PAHs; e.g., benzo(a)anthracene, benzo(b)fluoranthene, benzo(k)fluoranthene, benzo(a)pyrene, indeno(cd)pyrene, phenanthrene, anthracene, and others).",1
"This group works by preventing normal nerve transmission as cholinesterase is prevented from breaking down the transmitter substance acetylcholine, resulting in uncontrolled muscle movements.",1
"The disposal of munitions, and a lack of care in manufacture of munitions caused by the urgency of production, can contaminate soil for extended periods. There is little published evidence on this type of contamination largely because of restrictions placed by governments of many countries on the publication of material related to war effort. However, mustard gas stored during World War II has contaminated some sites for up to 50 years and the testing of Anthrax as a potential biological weapon contaminated the whole island of Gruinard.",1
"Most exposure is accidental, and exposure can happen through: Ingesting dust or soil directly Ingesting food or vegetables grown in contaminated soil or with foods in contact with contaminants Skin contact with dust or soil Vapors from the soil Inhaling clouds of dust while working in soils or windy environmentsHowever, some studies estimate that 90% of exposure is through eating contaminated food.",1
"Health consequences from exposure to soil contamination vary greatly depending on pollutant type, the pathway of attack, and the vulnerability of the exposed population. Researchers suggest that pesticides and heavy metals in soil may harm cardiovascular health, including inflammation and change in the body's internal clock.Chronic exposure to chromium, lead , and other metals, petroleum, solvents, and many pesticide and herbicide formulations can be carcinogenic, can cause congenital disorders, or can cause other chronic health conditions.",1
"Industrial or man-made concentrations of naturally occurring substances, such as nitrate and ammonia associated with livestock manure from agricultural operations, have also been identified as health hazards in soil and groundwater.Chronic exposure to benzene at sufficient concentrations is known to be associated with a higher incidence of leukemia. Mercury and cyclodienes are known to induce higher incidences of kidney damage and some irreversible diseases. PCBs and cyclodienes are linked to liver toxicity. Organophosphates and carbonates can cause a chain of responses leading to neuromuscular blockage. Many chlorinated solvents induce liver changes, kidney changes, and depression of the central nervous system.",1
"There is an entire spectrum of further health effects such as headache, nausea, fatigue, eye irritation and skin rash for the above cited and other chemicals. At sufficient dosages a large number of soil contaminants can cause death by exposure via direct contact, inhalation or ingestion of contaminants in groundwater contaminated through soil.The Scottish Government has commissioned the Institute of Occupational Medicine to undertake a review of methods to assess risk to human health from contaminated land.",1
The overall aim of the project is to work up guidance that should be useful to Scottish Local Authorities in assessing whether sites represent a significant possibility of significant harm (SPOSH) to human health. It is envisaged that the output of the project will be a short document providing high level guidance on health risk assessment with reference to existing published guidance and methodologies that have been identified as being particularly relevant and helpful.,1
"The project will examine how policy guidelines have been developed for determining the acceptability of risks to human health and propose an approach for assessing what constitutes unacceptable risk in line with the criteria for SPOSH as defined in the legislation and the Scottish Statutory Guidance. Not unexpectedly, soil contaminants can have significant deleterious consequences for ecosystems. There are radical soil chemistry changes which can arise from the presence of many hazardous chemicals even at low concentration of the contaminant species. These changes can manifest in the alteration of metabolism of endemic microorganisms and arthropods resident in a given soil environment.",1
"The result can be virtual eradication of some of the primary food chain, which in turn could have major consequences for predator or consumer species. Even if the chemical effect on lower life forms is small, the lower pyramid levels of the food chain may ingest alien chemicals, which normally become more concentrated for each consuming rung of the food chain. Many of these effects are now well known, such as the concentration of persistent DDT materials for avian consumers, leading to weakening of egg shells, increased chick mortality and potential extinction of species.Effects",1
"occur to agricultural lands which have certain types of soil contamination. Contaminants typically alter plant metabolism, often causing a reduction in crop yields. This has a secondary effect upon soil conservation, since the languishing crops cannot shield the Earth's soil from erosion. Some of these chemical contaminants have long half-lives and in other cases derivative chemicals are formed from decay of primary soil contaminants.",1
"Heavy metals and other soil contaminants can adversely affect the activity, species composition and abundance of soil microorganisms, thereby threatening soil functions such as biochemical cycling of carbon and nitrogen. However, soil contaminants can also become less bioavailable by time, and microorganisms and ecosystems can adapt to altered conditions. Soil properties such as pH, organic matter content and texture are very important and modify mobility, bioavailability and toxicity of pollutants in contaminated soils. The same amount of contaminant can be toxic in one soil but totally harmless in another soil. This stresses the need for soil-specific risks assessment and measures.",1
EPA RBCs) and National Environment Protection Council of Australia Guideline on Investigation Levels in Soil and Groundwater.,1
"In total, the area accounts for one-tenth of China's cultivatable land, and is mostly in economically developed areas. An estimated 12 million tonnes of grain are contaminated by heavy metals every year, causing direct losses of 20 billion yuan ($2.57 billion USD). Recent survey shows that 19% of the agricultural soils are contaminated which contains heavy metals and metalloids. And the rate of these heavy metals in the soil has been increased dramatically.",1
"According to the received data from Member states, in the European Union the number of estimated potential contaminated sites is more than 2.5 million and the identified contaminated sites around 342 thousand. Municipal and industrial wastes contribute most to soil contamination (38%), followed by the industrial/commercial sector (34%). Mineral oil and heavy metals are the main contaminants contributing around 60% to soil contamination. In terms of budget, the management of contaminated sites is estimated to cost around 6 billion Euros (€) annually.",1
"These values should not be considered as remedial targets but values above which further detailed assessment should be considered; see Dutch standards. Three sets of CLEA SGVs have been produced for three different land uses, namely residential (with and without plant uptake) allotments commercial/industrialIt is intended that the SGVs replace the former ICRCL values. The CLEA SGVs relate to assessing chronic (long term) risks to human health and do not apply to the protection of ground workers during construction, or other potential receptors such as groundwater, buildings, plants or other ecosystems.",1
"The CLEA SGVs are not directly applicable to a site completely covered in hardstanding, as there is no direct exposure route to contaminated soils.To date, the first ten of fifty-five contaminant SGVs have been published, for the following: arsenic, cadmium, chromium, lead, inorganic mercury, nickel, selenium ethyl benzene, phenol and toluene. Draft SGVs for benzene, naphthalene and xylene have been produced but their publication is on hold.",1
"Toxicological data (Tox) has been published for each of these contaminants as well as for benzo[a]pyrene, benzene, dioxins, furans and dioxin-like PCBs, naphthalene, vinyl chloride, 1,1,2,2 tetrachloroethane and 1,1,1,2 tetrachloroethane, 1,1,1 trichloroethane, tetrachloroethene, carbon tetrachloride, 1,2-dichloroethane, trichloroethene and xylene. The SGVs for ethyl benzene, phenol and toluene are dependent on the soil organic matter (SOM) content (which can be calculated from the total organic carbon (TOC) content). As an initial screen the SGVs for 1% SOM are considered to be appropriate.",1
"Furthermore, upon examining the different vegetation surrounding the smelter it was evident that they too had been affected; the results show that the plants contained nickel, copper and aluminium as a result of soil contamination.",1
Article on soil contamination in China Arsenic in groundwater Book on arsenic in groundwater by IAH's Netherlands Chapter and the Netherlands Hydrological Society,1
"trillion pieces of plastic weighing 269,000 tons were dispersed in oceans in similar amount in the Northern and Southern Hemispheres.",1
"In 2003, a study was conducted to identify types, amounts, sources, and effects of persistent industrial marine debris in the coastal waters and along the shores of Charlotte County, New Brunswick, and examine any relationship between the amount and types of persistent industrial marine debris, and the types and numbers of industrial operations nearby. Materials like plastic or foam can break down into smaller particles and may look like small sea creatures to wildlife such as birds, cetaceans, and fish, and they may eat these particles.",1
Indigestible material may accumulate in the gut creating blockages or a false sense of fullness and eventually death from lack of appropriate nutrient intake.,1
"They are also mostly limited to one-off projects that do not extend long enough to show significant effects of deep-sea debris over time. Research thus far has shown that debris in the deep-ocean is in fact impacted by anthropogenic activities, and plastic has been frequently observed in the deep-sea, especially in areas off-shore of heavily populated regions, such as the Mediterranean.Litter,",1
"Other oceanic processes that affect circulation, such as coastal storms and offshore convection, play a part in transferring large volumes of particles and debris. Submarine topographic features can also augment downwelling currents, leading to the retention of microplastics at certain locations.A Deep-sea Debris database by the Global Oceanographic Data Center of the Japan Agency for Marine-Earth Science and Technology (JAMSTEC), showing thirty years of photos and samples of marine debris since 1983, was made public in 2017. From the 5,010 dives in the database, using both ROVs and deep-sea submersibles, 3,425 man-made debris items were counted.",1
"The two most significant types of debris were macro-plastic, making up 33% of the debris found – 89% of which was single-use – and metal, making up 26%. Plastic debris was even found at the bottom of the Mariana Trench, at a depth of 10,898m, and plastic bags were found entangled in hydrothermal vent and cold seep communities.",1
"The toys have since been found all over the world, providing a better understanding of ocean currents. Similar incidents have happened before, such as when Hansa Carrier dropped 21 containers (with one notably containing buoyant Nike shoes).In 2007, MSC Napoli beached in the English Channel, dropping hundreds of containers, most of which washed up on the Jurassic Coast, a World Heritage Site. A 2021 study following a 2014 loss of a container carrying printer cartridges calculated that some cartridges had dispersed at an average speed of between 6 cm and 13 cm per second.",1
"studies show that marine debris may be dominant in particular locations. For example, a 2016 study of Aruba found that debris found the windward side of the island was predominantly marine debris from distant sources. In 2013, debris from six beaches in Korea was collected and analyzed: 56% was found to be ""ocean-based"" and 44% ""land-based"".In the 1987 Syringe Tide, medical waste washed ashore in New Jersey after having been blown from Fresh Kills Landfill. On the remote sub-Antarctic island of South Georgia, fishing-related debris, approximately 80% plastics, are responsible for the entanglement of large numbers of Antarctic fur seals.",1
"Many animals that live on or in the sea consume flotsam by mistake, as it often looks similar to their natural prey. Overall, 1288 marine species are known to ingest plastic debris, with fish making up the largest fraction. Bulky plastic debris may become permanently lodged in the digestive tracts of these animals, blocking the passage of food and causing death through starvation or infection. Tiny floating plastic particles also resemble zooplankton, which can lead filter feeders to consume them and cause them to enter the ocean food chain.",1
"In addition, plastic in the marine environment that contaminates the food chain can have repercussions on the viability of fish and shellfish species.",1
"Additional impacts of the COVID-19 pandemic have been seen in Hong Kong, where disposable masks have ended up along the beaches of Soko’s islands. This may be attributed to the increased production of medical products (masks and gloves) during the pandemic, leading to a rise in unconventional disposal of these products.",1
"Project AWARE for example promotes the idea of letting dive clubs clean up litter, for example as a diving exercise.Once a year there is a diving marine debris removal operation in Scapa Flow in the Orkneys, run by Ghost Fishing UK, funded by World Animal Protection and Fat Face Foundation.Cleanup of marine debris can be stymied by inadequate collaboration across levels of government, and a patchwork of regulatory authorities (responsibility often differs for the ocean surface, the seabed, and the shore). For example, there are an estimated 1600 abandoned and derelict boats in the waters of British Columbia.",1
"He suggested using platforms with arms to gather the debris, situated inside the current of gyres. The SAS Ocean Phoenix ship is somewhat similar in design.In June 2019, Ocean Voyages Institute, conducted a cleanup utilizing GPS trackers and existing maritime equipment in the North Pacific Subtropical Convergence Zone setting the record for the largest mid-ocean cleanup accomplished in the North Pacific Gyre and removed over 84,000 pounds of polymer nets and consumer plastic trash from the ocean.In",1
"May/June 2020, Ocean Voyages Institute conducted a cleanup expedition in the Gyre and set a new record for the largest mid-ocean cleanup accomplished in the North Pacific Gyre which removed over 170 tons (340,000 pounds) of consumer plastics and ghostnets from the ocean. Utilizing custom designed GPS satellite trackers which are deployed by vessels of opportunity, Ocean Voyages Institute is able to accurately track and send cleanup vessels to remove ghostnets.",1
"The GPS Tracker technology is being combined with satellite imagery increasing the ability to locate plastic trash and ghostnets in real time via satellite imagery which will greatly increase cleanup capacity and efficiency.Another issue is that removing marine debris from the ocean can potentially cause more harm than good. Cleaning up microplastics could also accidentally take out plankton, which are the main lower level food group for the marine food chain and over half of the photosynthesis on earth.",1
"One of the earliest anti-dumping laws was Australia's Beaches, Fishing Grounds and Sea Routes Protection Act 1932, which prohibited the discharge of ""garbage, rubbish, ashes or organic refuse"" from ""any vessel in Australian waters"" without prior written permission from the federal government. It also required permission for scuttling. The act was passed in response to large amounts of garbage washing up on the beaches of Sydney and Newcastle from vessels outside the reach of local governments and the New South Wales government.",1
"It was repealed and replaced by the Environment Protection (Sea Dumping) Act 1981, which gave effect to the London Convention.",1
"In the United Kingdom, the Marine and Coastal Access Act 2009 is designed to ""ensure clean healthy, safe, productive and biologically diverse oceans and seas, by putting in place better systems for delivering sustainable development of marine and coastal environment"". In 2019, the EU parliament voted for an EU-wide ban on single-use plastic products such as plastic straws, cutlery, plates, and drink containers, polystyrene food and drink containers, plastic drink stirrers and plastic carrier bags and cotton buds. The law will take effect in 2021.",1
"Property law, admiralty law and the law of the sea may be of relevance when lost, mislaid, and abandoned property is found at sea. Salvage law rewards salvors for risking life and property to rescue the property of another from peril. On land the distinction between deliberate and accidental loss led to the concept of a ""treasure trove"". In the United Kingdom, shipwrecked goods should be reported to a Receiver of Wreck, and if identifiable, they should be returned to their rightful owner. A large number of groups and individuals are active in preventing or educating about marine debris.",1
"On 11 April 2013 in order to create awareness, artist Maria Cristina Finucci founded the Garbage Patch State at UNESCO –Paris in front of Director General Irina Bokova. First of a series of events under the patronage of UNESCO and of Italian Ministry of the Environment.Forty-eight plastics manufacturers from 25 countries, are members of the Global Plastic Associations for solutions on Marine Litter, have made the pledge to help prevent marine debris and to encourage recycling.",1
"Marine debris is a widespread problem, not only the result of activities in coastal regions.Plastic debris from inland states come from two main sources: ordinary litter and materials from open dumps and landfills that blow or wash away to inland waterways and wastewater outflows. The refuse finds its way from inland waterways, rivers, streams and lakes to the ocean. Though ocean and coastal area cleanups are important, it is crucial to address plastic waste that originates from inland and landlocked states.At",1
"NOAA Marine Debris Program – US National Oceanic and Atmospheric Administration Marine Research, Education and Restoration – Algalita Marine Research Foundation UK Marine Conservation Society Harmful Marine Debris – Australian Government High Seas GhostNet Survey – US National Oceanic and Atmospheric Administration Social & Economic Costs of Marine Debris – NOAA Economics Tiny Plastic Bits Too Small To See Are Destroying The Oceans, Business Insider Ghost net remediation program – NASA, NOAA and ATI collaborating to detect ghost nets Dunning, Brian (16 December 2008). ""Skeptoid #132: The Sargasso Sea and the Pacific Garbage Patch"". Skeptoid.",1
"Nuclear decommissioning is the administrative and technical process leading to the irreversible closure of a nuclear facility such as a nuclear power plant (NPP), a research reactor, an isotope production plant, a particle accelerator, or uranium mine. It refers to the administrative and technical actions taken to remove all or some of the regulatory controls from the facility to bring about that its site can be reused. Decommissioning includes planning, decontamination, dismantling and materials management.Decommissioning is the final step in the lifecycle of a nuclear installation.",1
"In the US, the decommissioning must be completed within 60 years of the plant ceasing operations, unless a longer time is necessary to protect public health and safety; up to 50 years are for radioactive decay and 10 years to dismantle the facility. The decommissioning process encompasses: pre-decommissioningdevelopment of a decommissioning plan involvement of the public (in democracies) application for a decommissioning license permanent shutdown removal and disposal of nuclear fuel, coolant(s) and/or moderatordecommissioningdismantling and decontamination in the US, a License Termination Plan (LTP) has to be submitted two years prior to (the expected) termination of the plant license.",1
restoration of the environment termination of the operating license; turn over responsibilities monitoring of the site (in case of deferred dismantling/Safstor) monitoring and maintenance of the interim storage of spent fuel final disposal of radioactive waste,1
"Radioactive waste that remains after the decommissioning is either moved to an on-site storage facility where it still is under control of the plant owner, or moved to a dry cask storage or disposal facility at another location. The problem of long-term disposal of nuclear waste is still unsolved. Pending the availability of geologic repository sites for long-term disposal, interim storage is necessary. As the planned Yucca Mountain nuclear waste repository – like elsewhere in the world – is controversial, on- or off-site storage in the US usually takes place in Independent Spent Fuel Storage Facilities (ISFSI's).In",1
"the UK, all eleven Magnox reactors are in decommissioning under responsibility of the NDA. The spent fuel was removed and transferred to the Sellafield site in Cumbria for reprocessing. Facilities for ""temporary"" storage of nuclear waste – mainly 'Intermediate Level Waste' (ILW) – are in the UK called Interim Storage Facilities (ISF's).",1
"With deferred dismantling, costs are shifted to the future, but this entails the risk of rising expenditures for decades to come and changing rules. Moreover, the site cannot be re-used until the decommissioning is finished, while there are no longer revenues from production. Partial entombment The US has introduced the so-called In Situ Decommissioning (ISD) closures. All aboveground structures are dismantled; all remaining belowground structures are entombed by grouting all spaces. Advantages are lower decommissioning costs and safer execution. Disadvantages are main components remaining undismantled and definitively inaccessible. The site has to be monitored indefinitely.",1
"This method was implemented at the Savannah River Site in South Carolina for the closure of the P and R Reactors. With this method, the cost of decommissioning for each reactor was about $73 million. In comparison, the decommissioning of each reactor using traditional methods would have been an estimated $250 million. This resulted in a 71% decrease in cost. Other examples are the Hallam nuclear reactor and the Experimental Breeder Reactor II. Complete entombment The facility will not be dismantled.",1
"Instead it is entombed and maintained indefinitely, and surveillance is continued until the entombed radioactive waste is decayed to a level permitting termination of the license and unrestricted release of the property. The licensee maintains the license previously issued. This option is likely the only possible one in case of a nuclear disaster where the reactor is destroyed and dismantling is impossible or too dangerous. An example of full entombment is the Chernobyl reactor.",1
"In IAEA terms, entombment is not considered an acceptable strategy for decommissioning a facility following a planned permanent shutdown, except under exceptional circumstances, such as a nuclear disaster. In that case, the structure has to be maintained and surveillance continued until the radioactive material is decayed to a level permitting termination of the licence and unrestricted release of the structure.,p.",1
"50 The calculation of the total cost of decommissioning is challenging, as there are large differences between countries regarding inclusion of certain costs, such as on-site storage of fuel and radioactive waste from decommissioning, dismanting of non-radioactive buildings and structures, and transport and (final) disposal of radioactive waste.,p. 61Moreover, estimates of future costs of deferred decommissioning are virtually impossible, due to the long periode, where inflation and rising costs are unpredictable. Nuclear decommissioning projects are characterized by high and highly variable costs, long schedule and a range of risks.",1
"Compared with non-nuclear decommissioning, additional costs are usually related with radiological hazards and safety & security requirements, but also with higher wages for requiered higher qualified personal. Benchmarking, comparing projects in different countries, may be useful in estimating the cost of decommissioning. While, for instance, costs for spent fuel and high-level-waste management significantly impacts the budget and schedule of decommissioning projects, it is necessary to clarify which is the starting and the ending point of the decommissioning process.The",1
"effective decommissioning activities begin after all nuclear fuel has been removed from the plant areas that will be decommissioned and these activities form a critical component of pre-decommissioning operations, thus should be factored into the decommissioning plan. The chosen option – immediate or deferred decommissioning – impacts the overall costs. Many other factors also influence the cost. A 2018 KPMG article about decommissioning costs observes that many entities do not include the cost of managing spent nuclear fuel, removed from the plant areas that will be decommissioned (in the US routinely stored in ISFSIs).In",1
"2004, in a meeting in Vienna, the International Atomic Energy Agency estimated the total cost for the decommissioning of all nuclear facilities. Decommissioning of all nuclear power reactors in the world would require US$187 billion; US$71 billion for fuel cycle facilities; less than US$7 billion for all research reactors; and US$640 billion for dismantling all military reactors for the production of weapons-grade plutonium, research fuel facilities, nuclear reprocessing chemical separation facilities, etc. The total cost to decommission the nuclear fission industry in the World (from 2001 to 2050) was estimated at US$1 trillion.",1
"Market Watch estimated (2019) the global decommissioning costs in the nuclear sector in the range of US$1 billion to US$1.5 billion per 1,000-megawatt plant.The huge costs of research and development for (geological) longterm disposal of nuclear waste are collectively defrayed by the taxpayers in different countries, not by the companies.",1
"The costs of decommissioning are to be covered by funds that are provided for in a decommissioning plan, which is part of the facility's initial authorization, before the start of the operations. In this way, it is ensured that there will be sufficient money to pay for the eventual decommissioning of the facility. This may for example be through saving in a trust fund or a guarantee from the parent companySwitzerland has a central fund for decommissioning its five nuclear power reactors, and another one for disposal the nuclear waste.",1
"Germany has also a state-owned fund for decommissioning of the plants and managing radioactive waste, for which the reactor owners have to pay. The UK Government (the taxpayers) will pay most of the costs for both nuclear decommissioning and existing waste. The decommissioning of all Magnox reactors is entirely funded by the state.Since 2010, owners of new nuclear plants in the Netherlands are obliged to set up a decommissioning fund before construction is started.",1
"The economic costs of decommissioning will increase as more assets reach the end of their life, but few operators have put aside sufficient funds.In 2016 the European Commission assessed that European Union's nuclear decommissioning liabilities were seriously underfunded by about 118 billion euros, with only 150 billion euros of earmarked assets to cover 268 billion euros of expected decommissioning costs covering both dismantling of nuclear plants and storage of radioactive parts and waste.In Feb 2017, a committee of the French parliament warned that the state-controlled EDF has underestimated the costs for decommissioning.",1
"France had set aside only €23 billion for decommissioning and waste storage of its 58 reactors, which was less than a third of 74 billion in expected costs, while the UK's NDA estimated that clean-up of UK's 17 nuclear sites will cost between €109-€250 billion. EDF estimated the total cost at €54 billion. According to the parliamentary commission, the clean-up of French reactors will take longer, be more challenging and cost much more than EDF anticipates. It said that EDF showed ""excessive optimism"" concerning the decommissioning.",1
"EDF values some €350 million per reactor, whereas European operators count with between 900 million and 1.3 billion euros per reactor. The EDF's estimate was primarily based on the single historic example of the already dismantled Chooz A reactor. The committee argued that costs like restoration of the site, removal of spent fuel, taxes and insurance and social costs should be included.Similar concerns about underfunding exist in the United States, where the U.S. Nuclear Regulatory Commission has located apparent decommissioning funding assurance shortfalls and requested 18 power plants to address that issue.",1
The decommissioning cost of Small modular reactors is expected to be twice as much respect to Large Reactors.,1
"In France, decommissioning of Brennilis Nuclear Power Plant, a fairly small 70 MW power plant, already cost €480 million (20x the estimate costs) and is still pending after 20 years. Despite the huge investments in securing the dismantlement, radioactive elements such as plutonium, caesium-137 and cobalt-60 leaked out into the surrounding lake.In the UK, the decommissioning of civil nuclear assets were estimated to be £99 to £232 billion (2020), earlier in 2005 under-estimated to be £20-40 billion.",1
"The Sellafield site (Calder Hall, Windscale and the reprocessing facility) alone accounts for most of the decommissioning cost and increase in cost; as of 2015, the costs were estimated £53.2 billion. In 2019, the estimate was even much higher: £97 billion. A 2013 estimate by the United Kingdom's Nuclear Decommissioning Authority predicted costs of at least £100 billion to decommission the 19 existing United Kingdom nuclear sites.In Germany, decommissioning of Niederaichbach nuclear power plant, a 100 MW power plant, amounted to more than €143 million.Lithuania",1
has increased the prognosis of decommissioning costs from €2019 million in 2010 to €3376 million in 2015.,1
"As the plan for the Yucca Mountain nuclear waste repository has been canceled, DOE announced in 2021 the establishing of an interim repository for nuclear waste.Because the government has failed to establish a central repository, the federal government pays about half-a-billion dollars a year to the utilities as penalty, to compensate the cost of storage at more than 80 ISFSI sites in 35 states as of 2021. As of 2021, the government had paid $9 billion to utility companies for their interim storage costs, which may grow to $31 billion or more.Nuclear",1
"waste costed the American taxpayers through the Department of Energy (DOE) budget as of 2018 about $30 billion per year, $18 billion for nuclear power and $12 billion for waste from nuclear weapons programs.KPMG estimated the total cost of decommissioning the US nuclear fleet as of 2018 to be greater than US$150 billion. About two-thirds can be attributed to costs for termination of the NRC operating licence; 25% to management of spent fuel; and 10% to site restoration. The decommissioning of only the three uranium enrichment facilities would have an estimated cost (2004) of US$18.7",1
"to 62 billion, with an additional US$2 to 6 billion for the dismantling of a large inventory of depleted uranium hexafluoride. The cost will exceed the revenues by billions. Organizations that promote the international sharing of information, knowledge, and experiences related to nuclear decommissioning include the International Atomic Energy Agency, the Organization for Economic Co-operation and Development's Nuclear Energy Agency and the European Atomic Energy Community.",1
"Russia has a fleet of nuclear-powered vessels in decommissioning, dumped in the Barents Sea. Estimated cost for the decommissioning of the two K-27 and K-159 submarines alone was €300 million (2019), or $330 million. Marine power plants are generally smaller than land-based electrical generating stations. The biggest American military nuclear facility for the production of weapons-grade plutonium was Hanford site (in the State of Washington), now defueled, but in a slow and problematic process of decontamination, decommissioning, and demolition. There is ""the canyon"", a large structure for the chemical extraction of plutonium with the PUREX process.",1
"As May 2022, about 700 nuclear reactors have been retired from operation in several early and intermediate stages (cold shut-down, defueling, SAFSTOR, internal demolition), but only about 25 have been taken to fully ""greenfield status"". Many of these sites still host spent nuclear fuel in the form of dry casks embedded in concrete filled steel drums.As of 2017, most nuclear plants operating in the United States were designed for a life of about 30–40 years and are licensed to operate for 40 years by the US Nuclear Regulatory Commission.",1
"As of 2020, the average age of these reactors was about 39 years. Many plants are coming to the end of their licensing period and if their licenses are not renewed, they must go through a decontamination and decommissioning process.Generally are not included the costs of storage of nuclear waste, including spent fuel, and maintenance of the storage facility, pending the realization of repository sites for long-term disposal,p. 246 (in the US Independent Spent Fuel Storage Installations (ISFSI's). Thus many entities do not include the cost of managing spent nuclear fuel, removed from the plant areas that will be decommissioned.",1
"There are, however, large differences between countries regarding inclusion of certain costs, such as on-site storage of fuel and radioactive waste from decommissioning, dismanting of non-radioactive buildings and structures, and transport and (final) disposal of radioactive waste.,p. 61 The year of costs may refer to the value corrected for exchange rates and inflation until that year (e.g. 2020-dollars). The stated power in the list is preferably given in design net capacity (reference unit power) in MWe, similar to the List of commercial nuclear reactors.",1
"Lists of nuclear disasters and radioactive incidents Marcoule Nuclear Site in France Nuclear Decommissioning Authority Nuclear entombment Ship-Submarine Recycling Program Media related to Nuclear decommissioning at Wikimedia Commons NUCLEAR ENERGY AGENCY of the Organisation for Economic Co-operation & Development: Cost of Decommissioning Nuclear Energy Plants (2016) UNITED STATES NUCLEAR REGULATORY COMMISSION: Backgrounder on Decommissioning Nuclear Power Plants Business Insider – UK: Getting Rid Of Old Nuclear Reactors Worldwide Is Going To Cost Way More Than People Think Germany's economy minister Sigmar Gabriel says state won't pay for nuclear decommissioning (May 18, 2014) Nuclear Decommissioning Report (www.ndreport.com)",1
"is the multi-media platform for the nuclear decommissioning industry. decommissioning.info is a portal with information on nuclear decommissioning US Sites Undergoing Decommissioning European website on decommissioning of nuclear installations Decommissioning Fund Methodologies for Nuclear Installations in the EU, rapport by the German Wuppertal Institute, commissioned by the European Commission. May 2007. Master 'Nuclear Energy' – Decommissioning and Waste management Archived April 12, 2019, at the Wayback Machine",1
"The nine chapters of Bogard's book map to the nine levels of the Bortle scale, which attempts to quantify the subjective brightness and suitability for astronomy of the sky in different environments. Bogard has said of the scale, invented in 2001, ""one of the reasons why identifying different depths of darkness is so important is that we don’t recognize that we’re losing it, unless we have a name to recognize it by.""Bogard begins at a Bortle level 9 environment, by the Luxor Sky Beam, the brightest spotlight on Earth, located on the Las Vegas Strip.",1
"Bogard ultimately finds a Bortle level 1 environment: a remote area so perfectly free of stray light that, with eyes fully adapted, the Milky Way casts noticeable shadows.Bogard argues against the long-held assumption of a correlation between bright light and reduced crime, citing research that finds no such link. Rather than suggesting a return to the completely unlit nights of centuries past, however, he argues for a careful consideration of where and how artificial light is deployed, in order to provide sufficient nighttime illumination for safety, without creating glare and other unwanted effects.",1
"Telegraph reviewer Stephanie Cross wrote that ""the appeal of Bogard’s book derives not just from his often wide-eyed enthusiasm for his subject, but also from the constellation of characters he encounters on his journeys into the night."" In The Guardian, novelist Salley Vickers wrote that ""Bogard sets about his investigations with an energetic purposiveness and enterprise,"" but complained that ""the book comes to seem a little thin, moving too rapidly from one chatty anecdotal meeting to another.""",1
"The Wall Street Journal questioned Bogard's statements on the relationship between light and safety, and concluded ambivalently: ""The End of Night delivers a forceful, if incomplete, critique of our overexposed world.""",1
"The book was awarded the 2014 Nautilus Silver Award. It was named an Amazon Best Book of the Month and Nonfiction Editor's Pick for July 2013, and Gizmodo selected it as one of its Best Books of 2013. The book was shortlisted for the PEN/E. O. Wilson Literary Science Writing Award, and was a finalist for the Sigurd F. Olson Nature Writing Award. International Dark-Sky Association Skyglow – Diffuse luminance of the night sky",1
"Road debris can be caused by various factors, including objects falling off vehicles or natural disasters and weather, specifically wind, storms, tornadoes, hurricanes, etc. Examples of road debris include: Particulates, dust, dirt, sand, and mud Asphalt, concrete, pebbles, rocks/stones/boulders, etc. Particles of road salt and other de-icers Litter, food waste, animal feces/manure, furniture, electrical appliances, mattresses, and other items of garbage, trash, rubbish and refuse Broken glass, nails, screws, and other often sharp objects Car parts, tire tread, etc.",1
"Road debris is a hazard that can cause loss of vehicle control with damages ranging from a flat tire, vehicular rollover, penetration of the passenger compartment by the debris, or collision, with accompanying injuries or deaths. In the year 2011, the National Highway Traffic Safety Administration's Traffic Safety Facts found that more than 800 persons were killed across America by ""non-fixed objects"" (a term that includes roadway debris). California had the highest number of total deaths for any state, while New Mexico had the greatest probability for death from a vehicle-debris crash in that year.In",1
"2004, a AAA Foundation for Traffic Safety study revealed that vehicle-related road debris caused 25,000 accidents—and nearly 100 deaths—each year. At highway speeds, even small debris can be deadly. On June 16, 1925, in the United States, a passenger train carrying German and American tourists from Chicago, Illinois to Hoboken, New Jersey struck debris washed into a road crossing and derailed during a heavy thunderstorm. Collision with road debris resulted in a solar vehicle accident at the World Solar Challenge 2007 in Australia. Road debris tends to collect in areas where two-track vehicles such as cars and buses do not drive.",1
"In urban areas, this tends to be on the edges (shoulder) and on the crown of the road, and debris frequently collects around traffic islands and junctions. In rural areas, debris collects in the middle of the lane and on the outside of corners and bends. Road debris can be especially dangerous to bicyclists, who may have to travel outside the cycle lane and into traffic to avoid debris. Flooding can also occur if storm drains and street gutters are not kept clear of road debris and litter.",1
"The 2005 Scion TC's wind deflector was recalled because of potential shatter from road debris impact. The 2004 Mitsubishi Endeavor was recalled in February 2010 when it was determined that a mixture of road salt and road debris (mud) might be trapped between a reinforcing bracket and the fuel filler pipe, causing corrosion. The 2001 Chevrolet C/K chassis cab truck was also recalled on discovery that road debris could strike and damage its pressure relief valves.",1
Road spray is lessened on stone mastic asphalt and open-graded asphalt and can be further reduced with fenders (more so on a bicycle since most motor vehicles tend to already have fenders) and/or mud flaps. Street sweepers and winter service vehicles remove most solid road debris and the Adopt a Highway program also helps. Road signs and variable-message signs may warn drivers of special situations involving road debris. The American Automobile Association (AAA) publishes the following recommendations:,1
"Motor vehicle operators should know and understand how to secure their loads, load securement requirements, littering laws, and penalties for failing to comply with the regulations. Drivers carrying loads should periodically inspect their vehicles and cargo to make sure they remain safe and secure. All drivers should be aware of the surroundings and continuously inspect the road for potential hazards. Drivers should immediately report unsafe vehicles and unsecured loads.",1
"Maintenance organizations should perform regular road inspection and timely removal of debris. Better roadway design provides adequate visibility of stationary objects in the roadway to motorists traveling at highway speeds. Increasing the dispersion of Traffic cones around roadway areas. Ocean Colour Scene, an English Britpop band, made a song about Birmingham, England called ""Debris Road"" (reputed to be about the road running past the band's recording studios in Ladywood) on their Marchin' Already 1997 album. Some video games (particularly racing games) include road debris that damages vehicles or obstructs visibility.",1
"Three forms (or allotropes) of oxygen are involved in the ozone-oxygen cycle: oxygen atoms (O or atomic oxygen), oxygen gas (O2 or diatomic oxygen), and ozone gas (O3 or triatomic oxygen). Ozone is formed in the stratosphere when oxygen gas molecules photodissociate after absorbing UVC photons. This converts a single O2 into two atomic oxygen radicals. The atomic oxygen radicals then combine with separate O2 molecules to create two O3 molecules. These ozone molecules absorb UVB light, following which ozone splits into a molecule of O2 and an oxygen atom.",1
The oxygen atom then joins up with an oxygen molecule to regenerate ozone. This is a continuing process that terminates when an oxygen atom recombines with an ozone molecule to make two O2 molecules. It is worth noting that ozone is the only atmospheric gas that absorbs UVB light. O + O3 → 2 O2The total amount of ozone in the stratosphere is determined by a balance between photochemical production and recombination.,1
"Ozone can be destroyed by a number of free radical catalysts; the most important are the hydroxyl radical (OH·), nitric oxide radical (NO·), chlorine radical (Cl·) and bromine radical (Br·). The dot is a notation to indicate that each species has an unpaired electron and is thus extremely reactive. All of these have both natural and man-made sources; at present, most of the OH· and NO· in the stratosphere is naturally occurring, but human activity has drastically increased the levels of chlorine and bromine.",1
"These elements are found in stable organic compounds, especially chlorofluorocarbons, which can travel to the stratosphere without being destroyed in the troposphere due to their low reactivity. Once in the stratosphere, the Cl and Br atoms are released from the parent compounds by the action of ultraviolet light, e.g. CFCl3 + electromagnetic radiation → Cl· + ·CFCl2Ozone is a highly reactive molecule that easily reduces to the more stable oxygen form with the assistance of a catalyst. Cl and Br atoms destroy ozone molecules through a variety of catalytic cycles.",1
"In the simplest example of such a cycle, a chlorine atom reacts with an ozone molecule (O3), taking an oxygen atom to form chlorine monoxide (ClO) and leaving an oxygen molecule (O2). The ClO can react with a second molecule of ozone, releasing the chlorine atom and yielding two molecules of oxygen.",1
"The chemical shorthand for these gas-phase reactions is: Cl· + O3 → ClO + O2 A chlorine atom removes an oxygen atom from an ozone molecule to make a ClO molecule ClO + O3 → Cl· + 2 O2 This ClO can also remove an oxygen atom from another ozone molecule; the chlorine is free to repeat this two-step cycleThe overall effect is a decrease in the amount of ozone, though the rate of these processes can be decreased by the effects of null cycles. More complicated mechanisms have also been discovered that lead to ozone destruction in the lower stratosphere.",1
"A single chlorine atom would continuously destroy ozone (thus a catalyst) for up to two years (the time scale for transport back down to the troposphere) except for reactions that remove it from this cycle by forming reservoir species such as hydrogen chloride (HCl) and chlorine nitrate (ClONO2). Bromine is even more efficient than chlorine at destroying ozone on a per-atom basis, but there is much less bromine in the atmosphere at present. Both chlorine and bromine contribute significantly to overall ozone depletion. Laboratory studies have also shown that fluorine and iodine atoms participate in analogous catalytic cycles.",1
"The ozone hole is usually measured by reduction in the total column ozone above a point on the Earth's surface. This is normally expressed in Dobson units; abbreviated as ""DU"". The most prominent decrease in ozone has been in the lower stratosphere. Marked decreases in column ozone in the Antarctic spring and early summer compared to the early 1970s and before have been observed using instruments such as the Total Ozone Mapping Spectrometer (TOMS).Reductions of up to 70 percent in the ozone column observed in the austral (southern hemispheric) spring over Antarctica and first reported in 1985 (Farman et al.)",1
"are continuing. Antarctic total column ozone in September and October have continued to be 40–50 percent lower than pre-ozone-hole values since the 1990s. A gradual trend toward ""healing"" was reported in 2016. In 2017, NASA announced that the ozone hole was the weakest since 1988 because of warm stratospheric conditions. It is expected to recover around 2070.The amount lost is more variable year-to-year in the Arctic than in the Antarctic. The greatest Arctic declines are in the winter and spring, reaching up to 30 percent when the stratosphere is coldest.Reactions",1
"that take place on polar stratospheric clouds (PSCs) play an important role in enhancing ozone depletion. PSCs form more readily in the extreme cold of the Arctic and Antarctic stratosphere. This is why ozone holes first formed, and are deeper, over Antarctica. Early models failed to take PSCs into account and predicted a gradual global depletion, which is why the sudden Antarctic ozone hole was such a surprise to many scientists.It is more accurate to speak of ozone depletion in middle latitudes rather than holes. Total column ozone declined below pre-1980 values between 1980 and 1996 for mid-latitudes.",1
"In the northern mid-latitudes, it then increased from the minimum value by about two percent from 1996 to 2009 as regulations took effect and the amount of chlorine in the stratosphere decreased. In the Southern Hemisphere's mid-latitudes, total ozone remained constant over that time period. There are no significant trends in the tropics, largely because halogen-containing compounds have not had time to break down and release chlorine and bromine atoms at tropical latitudes.Large volcanic eruptions have been shown to have substantial albeit uneven ozone-depleting effects, as observed with the 1991 eruption of Mt. Pinatubo in the Philippines.Ozone",1
"depletion also explains much of the observed reduction in stratospheric and upper tropospheric temperatures. The source of the warmth of the stratosphere is the absorption of UV radiation by ozone, hence reduced ozone leads to cooling. Some stratospheric cooling is also predicted from increases in greenhouse gases such as CO2 and CFCs themselves; however, the ozone-induced cooling appears to be dominant.Predictions of ozone levels remain difficult, but the precision of models' predictions of observed values and the agreement among different modeling techniques have increased steadily. The World Meteorological Organization Global Ozone Research and Monitoring Project—Report No.",1
"44 comes out strongly in favor of the Montreal Protocol, but notes that a UNEP 1994 Assessment overestimated ozone loss for the 1994–1997 period.",1
"No significant natural sources have ever been identified for these compounds—their presence in the atmosphere is due almost entirely to human manufacture. As mentioned above, when such ozone-depleting chemicals reach the stratosphere, they are dissociated by ultraviolet light to release chlorine atoms. The chlorine atoms act as a catalyst, and each can break down tens of thousands of ozone molecules before being removed from the stratosphere. Given the longevity of CFC molecules, recovery times are measured in decades.",1
"It is calculated that a CFC molecule takes an average of about five to seven years to go from the ground level up to the upper atmosphere, and it can stay there for about a century, destroying up to one hundred thousand ozone molecules during that time.1,1,1-Trichloro-2,2,2-trifluoroethane, also known as CFC-113a, is one of four man-made chemicals newly discovered in the atmosphere by a team at the University of East Anglia. CFC-113a is the only known CFC whose abundance in the atmosphere is still growing. Its source remains a mystery, but illegal manufacturing is suspected by some.",1
"CFC-113a seems to have been accumulating unabated since 1960. Between 2012 and 2017, concentrations of the gas jumped by 40 percent.A study by an international team of researchers published in Nature found that since 2013 emissions that are predominately from north-eastern China have released large quantities of the banned chemical Chlorofluorocarbon-11 (CFC-11) into the atmosphere. Scientists estimate that without action, these CFC-11 emissions will delay the recovery of the planet's ozone hole by a decade.",1
"Scientists have attributed ozone depletion to the increase of man-made (anthropogenic) halogen compounds from CFCs by combining observational data with computer models. These complex chemistry transport models (e.g. SLIMCAT, CLaMS—Chemical Lagrangian Model of the Stratosphere) work by combining measurements of chemicals and meteorological fields with chemical reaction rate constants. They identify key chemical reactions and transport processes that bring CFC photolysis products into contact with ozone. The Antarctic ozone hole is an area of the Antarctic stratosphere in which the recent ozone levels have dropped to as low as 33 percent of their pre-1975 values.",1
"The ozone hole occurs during the Antarctic spring, from September to early December, as strong westerly winds start to circulate around the continent and create an atmospheric container. Within this polar vortex, over 50 percent of the lower stratospheric ozone is destroyed during the Antarctic spring.As explained above, the primary cause of ozone depletion is the presence of chlorine-containing source gases (primarily CFCs and related halocarbons). In the presence of UV light, these gases dissociate, releasing chlorine atoms, which then go on to catalyze ozone destruction.",1
"There are three types of PSC clouds—nitric acid trihydrate clouds, slowly cooling water-ice clouds, and rapid cooling water-ice (nacreous) clouds—provide surfaces for chemical reactions whose products will, in the spring lead to ozone destruction.The photochemical processes involved are complex but well understood. The key observation is that, ordinarily, most of the chlorine in the stratosphere resides in ""reservoir"" compounds, primarily chlorine nitrate (ClONO2) as well as stable end products such as HCl. The formation of end products essentially removes Cl from the ozone depletion process.",1
"The former sequester Cl, which can be later made available via absorption of light at shorter wavelengths than 400 nm. During the Antarctic winter and spring, however, reactions on the surface of the polar stratospheric cloud particles convert these ""reservoir"" compounds into reactive free radicals (Cl and ClO). Denitrification is the process by which the clouds remove NO2 from the stratosphere by converting it to nitric acid in PSC particles, which then are lost by sedimentation. This prevents newly formed ClO from being converted back into ClONO2.",1
"The role of sunlight in ozone depletion is the reason why the Antarctic ozone depletion is greatest during spring. During winter, even though PSCs are at their most abundant, there is no light over the pole to drive chemical reactions. During the spring, however, sunlight returns and provides energy to drive photochemical reactions and melt the polar stratospheric clouds, releasing considerable ClO, which drives the hole mechanism. Further warming temperatures near the end of spring break up the vortex around mid-December.",1
"The ""ozone hole"" is more of a depression, less ""a hole in the windshield"". The ozone does not disappear through the layer, nor is there a uniform ""thinning"" of the ozone layer. However, they resonated better with non-scientists and their concerns. The ozone hole was seen as a ""hot issue"" and imminent risk as laypeople feared severe personal consequences such as skin cancer, cataracts, damage to plants, and reduction of plankton populations in the ocean's photic zone. Not only on the policy level, ozone regulation compared to climate change fared much better in public opinion.",1
"Americans voluntarily switched away from aerosol sprays before legislation was enforced, while climate change failed to achieve comparable concern and public action. The sudden identification in 1985 that there was a substantial ""hole"" was widely reported in the press. The especially rapid ozone depletion in Antarctica had previously been dismissed as a measurement error. Scientific consensus was established after regulation.While",1
"the Antarctic ozone hole has a relatively small effect on global ozone, the hole has generated a great deal of public interest because: Many have worried that ozone holes might start appearing over other areas of the globe, though to date the only other large-scale depletion is a smaller ozone ""dimple"" observed during the Arctic spring around the North Pole. Ozone at middle latitudes has declined, but by a much smaller extent (a decrease of about 4–5 percent). If stratospheric conditions become more severe (cooler temperatures, more clouds, more active chlorine), global ozone may decrease at a greater pace.",1
"This was the reason for the Montreal Protocol. Although decreases in stratospheric ozone are well-tied to CFCs and increases in surface UVB, there is no direct observational evidence linking ozone depletion to higher incidence of skin cancer and eye damage in human beings. This is partly because UVA, which has also been implicated in some forms of skin cancer, is not absorbed by ozone, and because it is nearly impossible to control statistics for lifestyle changes over time. Ozone depletion may also influence wind patterns.",1
"Ozone, while a minority constituent in Earth's atmosphere, is responsible for most of the absorption of UVB radiation. The amount of UVB radiation that penetrates through the ozone layer decreases exponentially with the slant-path thickness and density of the layer. When stratospheric ozone levels decrease, higher levels of UVB reach the Earth's surface. UV-driven phenolic formation in tree rings has dated the start of ozone depletion in northern latitudes to the late 1700s.In October 2008, the Ecuadorian Space Agency published a report called HIPERION.",1
"The main public concern regarding the ozone hole has been the effects of increased surface UV radiation on human health. So far, ozone depletion in most locations has been typically a few percent and, as noted above, no direct evidence of health damage is available in most latitudes. If the high levels of depletion seen in the ozone hole were to be common across the globe, the effects could be substantially more dramatic.",1
"In addition, increased surface UV leads to increased tropospheric ozone, which is a health risk to humans.",1
"The most common forms of skin cancer in humans, basal and squamous cell carcinomas, have been strongly linked to UV-B exposure. The mechanism by which UVB induces these cancers is well understood—absorption of UV-B radiation causes the pyrimidine bases in the DNA molecule to form dimers, resulting in transcription errors when the DNA replicates. These cancers are relatively mild and rarely fatal, although the treatment of squamous cell carcinoma sometimes requires extensive reconstructive surgery.",1
"By combining epidemiological data with results of animal studies, scientists have estimated that every one percent decrease in long-term stratospheric ozone would increase the incidence of these cancers by 2%.",1
"Another form of skin cancer, malignant melanoma, is much less common but far more dangerous, being lethal in about 15–20 percent of the cases diagnosed. The relationship between malignant melanoma and ultraviolet exposure is not yet fully understood, but it appears that both UV-B and UV-A are involved. Because of this uncertainty, it is difficult to estimate the effect of ozone depletion on melanoma incidence. One study showed that a 10 percent increase in UV-B radiation was associated with a 19 percent increase in melanomas for men and 16 percent for women.",1
"A study of people in Punta Arenas, at the southern tip of Chile, showed a 56 percent increase in melanoma and a 46 percent increase in nonmelanoma skin cancer over a period of seven years, along with decreased ozone and increased UVB levels.",1
"Epidemiological studies suggest an association between ocular cortical cataracts and UV-B exposure, using crude approximations of exposure and various cataract assessment techniques. A detailed assessment of ocular exposure to UV-B was carried out in a study on Chesapeake Bay Watermen, where increases in average annual ocular exposure were associated with increasing risk of cortical opacity. In this highly exposed group of predominantly white males, the evidence linking cortical opacities to sunlight exposure was the strongest to date. Based on these results, ozone depletion is predicted to cause hundreds of thousands of additional cataracts by 2050.",1
"Increased surface UV leads to increased tropospheric ozone. Ground-level ozone is generally recognized to be a health risk, as ozone is toxic due to its strong oxidant properties. The risks are particularly high for young children, the elderly, and those with asthma or other respiratory difficulties. At this time, ozone at ground level is produced mainly by the action of UV radiation on combustion gases from vehicle exhausts.",1
"Vitamin D is produced in the skin by ultraviolet light. Thus, higher UVB exposure raises human vitamin D in those deficient in it. Recent research (primarily since the Montreal Protocol) shows that many humans have less than optimal vitamin D levels. In particular, in the U.S. population, the lowest quarter of vitamin D (<17.8 ng/ml) were found using information from the National Health and Nutrition Examination Survey to be associated with an increase in all-cause mortality in the general population.",1
"While blood level of vitamin D in excess of 100 ng/ml appear to raise blood calcium excessively and to be associated with higher mortality, the body has mechanisms that prevent sunlight from producing vitamin D in excess of the body's requirements.",1
"A November 2011 report by scientists at the Institute of Zoology in London found that whales off the coast of California have shown a sharp rise in sun damage, and these scientists ""fear that the thinning ozone layer is to blame"". The study photographed and took skin biopsies from over 150 whales in the Gulf of California and found ""widespread evidence of epidermal damage commonly associated with acute and severe sunburn"", having cells that form when the DNA is damaged by UV radiation.",1
"The findings suggest ""rising UV levels as a result of ozone depletion are to blame for the observed skin damage, in the same way that human skin cancer rates have been on the increase in recent decades."" Apart from whales many other animals such as dogs, cats, sheep and terrestrial ecosystems also suffer the negative effects of increased UV-B radiations.",1
"An increase of UV radiation would be expected to affect crops. A number of economically important species of plants, such as rice, depend on cyanobacteria residing on their roots for the retention of nitrogen. Cyanobacteria are sensitive to UV radiation and would be affected by its increase. ""Despite mechanisms to reduce or repair the effects of increased ultraviolet radiation, plants have a limited ability to adapt to increased levels of UVB, therefore plant growth can be directly affected by UVB radiation.""",1
"Over the years, the Arctic ozone layer has depleted severely. As a consequence species that live above the snow cover or in areas where snow has melted abundantly, due to hot temperatures, are negatively impacted due to UV radiation that reaches the ground. Depletion of the ozone layer and allowing excess UVB radiation would initially be assumed to increase damage done to plant DNA.",1
"Reports have found that when plants are exposed to UVB radiation similar to stratospheric ozone depletion, there was no significant change in plant height or leaf mass, but showed a response in shoot biomass and leaf area with a small decrease. However, UVB radiation has been shown to decrease quantum yield of photosystem II. UVB damage only occurs under extreme exposure, and most plants also have UVB absorbing flavonoids which allow them to acclimatize to the radiation present. Plants experience different levels of UV radiation throughout the day.",1
"It is known that they are able to shift the levels and types of UV sunscreens (i.e. flavonoids), that they contain, throughout the day. This allows them to increase their protection against UV radiation. Plants that have been affected by radiation throughout development are more affected by the inability to intercept light with a larger leaf area than having photosynthetic systems compromised. Damage from UVB radiation is more likely to be significant on species interactions than on plants themselves.Another significant impact of ozone depletion on plant life is the stress experienced by plants when exposed to UV radiation.",1
"This can cause a decrease in plant growth and an increase in oxidative stress, due to the production of nitric oxide and hydrogen peroxide. Reduction in plant growth will have important consequences in the long-term. It is projected that the plant productivity would decrease by 6% and there will be a reduction in the amount of carbon, plants would capture/sequester from the environment.Moreover, if plants are exposed to high levels of UV radiation, it can elicit the production of harmful volatile organic compounds, like isoprenes.",1
"Under Ruckelshaus and his successor, Lee Thomas, the EPA pushed for an international approach to halocarbon regulations. In 1985 twenty nations, including most of the major CFC producers, signed the Vienna Convention for the Protection of the Ozone Layer, which established a framework for negotiating international regulations on ozone-depleting substances. That same year, the discovery of the Antarctic ozone hole was announced, causing a revival in public attention to the issue. In 1987, representatives from 43 nations signed the Montreal Protocol. Meanwhile, the halocarbon industry shifted its position and started supporting a protocol to limit CFC production.",1
"However, this shift was uneven with DuPont acting more quickly than its European counterparts. DuPont may have feared court action related to increased skin cancer, especially as the EPA had published a study in 1986 claiming that an additional 40 million cases and 800,000 cancer deaths were to be expected in the U.S. in the next 88 years. The EU shifted its position as well after Germany gave up its defence of the CFC industry and started supporting moves towards regulation.",1
"Government and industry in France and the UK tried to defend their CFC producing industries even after the Montreal Protocol had been signed.At Montreal, the participants agreed to freeze production of CFCs at 1986 levels and to reduce production by 50 percent by 1999. After a series of scientific expeditions to the Antarctic produced convincing evidence that the ozone hole was indeed caused by chlorine and bromine from manmade organohalogens, the Montreal Protocol was strengthened at a 1990 meeting in London.",1
"The major companies claimed that no alternatives to HFC existed. An ozone-safe hydrocarbon refrigerant was developed at a Hamburg technological institute in Germany, consisting of a mixture of the hydrocarbon gases propane and butane, and in 1992 came to the attention of the non-governmental organization (NGO) Greenpeace. Greenpeace called it ""Greenfreeze"". The NGO then worked successfully first with a small and struggling company to market an appliance beginning in Europe, then Asia and later Latin America, receiving a 1997 UNEP award. By 1995, Germany had already made CFC refrigerators illegal.",1
"Chemical companies like Du Pont, whose representatives even disparaged Greenfreeze as ""that German technology,"" maneuvered the EPA to block the technology in the U.S. until 2011. Ben & Jerry's of Unilever and General Electric, spurred by Greenpeace, had expressed formal interest in 2008 which figured in the EPA's final approval.The EU recast its Ozone Regulation in 2009. The law bans ozone-depleting substances with the goal of protecting the ozone layer. The list of ODS that are subject to the regulation is the same as those under the Montreal Protocol, with some additions.More",1
"recently, policy experts have advocated for efforts to link ozone protection efforts to climate protection efforts. Many ODS are also greenhouse gases, some thousands of times more powerful agents of radiative forcing than carbon dioxide over the short and medium term. Thus policies protecting the ozone layer have had benefits in mitigating climate change. In fact, the reduction of the radiative forcing due to ODS probably masked the true level of climate change effects of other greenhouse gases, and was responsible for the ""slow down"" of global warming from the mid-90s.",1
"The IMO has amended MARPOL Annex VI Regulation 12 regarding ozone depleting substances. As from July 1, 2010, all vessels where MARPOL Annex VI is applicable should have a list of equipment using ozone depleting substances. The list should include name of ODS, type and location of equipment, quantity in kg and date. All changes since that date should be recorded in an ODS Record book on board recording all intended or unintended releases to the atmosphere. Furthermore, new ODS supply or landing to shore facilities should be recorded as well.",1
"Since the adoption and strengthening of the Montreal Protocol has led to reductions in the emissions of CFCs, atmospheric concentrations of the most-significant compounds have been declining. These substances are being gradually removed from the atmosphere; since peaking in 1994, the Effective Equivalent Chlorine (EECl) level in the atmosphere had dropped about 10 percent by 2008. The decrease in ozone-depleting chemicals has also been significantly affected by a decrease in bromine-containing chemicals. The data suggest that substantial natural sources exist for atmospheric methyl bromide (CH3Br).",1
"The phase-out of CFCs means that nitrous oxide (N2O), which is not covered by the Montreal Protocol, has become the most highly emitted ozone-depleting substance and is expected to remain so throughout the 21st century.According to the IPCC Sixth Assessment Report, global stratospheric ozone levels experienced rapid decline in the 1970s and 1980s and have since been increasing, but have not reached preindustrial levels.",1
"Although considerable variability is expected from year to year, including in polar regions where depletion is largest, the ozone layer is expected to continue recovering in coming decades due to declining ozone-depleting substance concentrations, assuming full compliance with the Montreal Protocol.The Antarctic ozone hole is expected to continue for decades. Ozone concentrations in the lower stratosphere over Antarctica increased by 5–10 percent by 2020 and will return to pre-1980 levels by about 2060–2075.",1
"This is 10–25 years later than predicted in earlier assessments, because of revised estimates of atmospheric concentrations of ozone-depleting substances, including a larger predicted future usage in developing countries. Another factor that may prolong ozone depletion is the drawdown of nitrogen oxides from above the stratosphere due to changing wind patterns. A gradual trend toward ""healing"" was reported in 2016. In 2019, the ozone hole was at its smallest in the previous thirty years, due to the warmer polar stratosphere weakening the polar vortex.",1
"The basic physical and chemical processes that lead to the formation of an ozone layer in the Earth's stratosphere were discovered by Sydney Chapman in 1930. Short-wavelength UV radiation splits an oxygen (O2) molecule into two oxygen (O) atoms, which then combine with other oxygen molecules to form ozone. Ozone is removed when an oxygen atom and an ozone molecule ""recombine"" to form two oxygen molecules, i.e. O + O3 → 2O2.",1
"In the 1950s, David Bates and Marcel Nicolet presented evidence that various free radicals, in particular hydroxyl (OH) and nitric oxide (NO), could catalyze this recombination reaction, reducing the overall amount of ozone. These free radicals were known to be present in the stratosphere, and so were regarded as part of the natural balance—it was estimated that in their absence, the ozone layer would be about twice as thick as it currently is.",1
"In the following year, Crutzen and (independently) Harold Johnston suggested that NO emissions from supersonic passenger aircraft, which would fly in the lower stratosphere, could also deplete the ozone layer. However, more recent analysis in 1995 by David W. Fahey, an atmospheric scientist at the National Oceanic and Atmospheric Administration, found that the drop in ozone would be from 1–2 percent if a fleet of 500 supersonic passenger aircraft were operated. This, Fahey expressed, would not be a showstopper for advanced supersonic passenger aircraft development.",1
"In 1974 Frank Sherwood Rowland, Chemistry Professor at the University of California at Irvine, and his postdoctoral associate Mario J. Molina suggested that long-lived organic halogen compounds, such as CFCs, might behave in a similar fashion as Crutzen had proposed for nitrous oxide. James Lovelock had recently discovered, during a cruise in the South Atlantic in 1971, that almost all of the CFC compounds manufactured since their invention in 1930 were still present in the atmosphere. Molina and Rowland concluded that, like N2O, the CFCs would reach the stratosphere where they would be dissociated by UV light, releasing chlorine atoms.",1
"A year earlier, Richard Stolarski and Ralph Cicerone at the University of Michigan had shown that Cl is even more efficient than NO at catalyzing the destruction of ozone. Similar conclusions were reached by Michael McElroy and Steven Wofsy at Harvard University. Neither group, however, had realized that CFCs were a potentially large source of stratospheric chlorine—instead, they had been investigating the possible effects of HCl emissions from the Space Shuttle, which are very much smaller. The Rowland–Molina hypothesis was strongly disputed by representatives of the aerosol and halocarbon industries.",1
"The Chair of the Board of DuPont was quoted as saying that ozone depletion theory is ""a science fiction tale … a load of rubbish … utter nonsense"". Robert Abplanalp, the President of Precision Valve Corporation (and inventor of the first practical aerosol spray can valve), wrote to the Chancellor of UC Irvine to complain about Rowland's public statements. Nevertheless, within three years most of the basic assumptions made by Rowland and Molina were confirmed by laboratory measurements and by direct observation in the stratosphere.",1
"The concentrations of the source gases (CFCs and related compounds) and the chlorine reservoir species (HCl and ClONO2) were measured throughout the stratosphere, and demonstrated that CFCs were indeed the major source of stratospheric chlorine, and that nearly all of the CFCs emitted would eventually reach the stratosphere. Even more convincing was the measurement, by James G. Anderson and collaborators, of chlorine monoxide (ClO) in the stratosphere. ClO is produced by the reaction of Cl with ozone—its observation thus demonstrated that Cl radicals not only were present in the stratosphere but also were actually involved in destroying ozone.",1
"Early estimates were that, if CFC production continued at 1977 levels, the total atmospheric ozone would after a century or so reach a steady state, 15 to 18 percent below normal levels. By 1984, when better evidence on the speed of critical reactions was available, this estimate was changed to 5 to 9 percent steady-state depletion.Crutzen, Molina, and Rowland were awarded the 1995 Nobel Prize in Chemistry for their work on stratospheric ozone.",1
"The discovery of the Antarctic ""ozone hole"" by British Antarctic Survey scientists Farman, Gardiner and Shanklin (first reported in a paper in Nature in May 1985) came as a shock to the scientific community, because the observed decline in polar ozone was far larger than anyone had anticipated. Satellite measurements (TOMS onboard Nimbus 7) showing massive depletion of ozone around the south pole were becoming available at the same time.",1
"However, these were initially rejected as unreasonable by data quality control algorithms (they were filtered out as errors since the values were unexpectedly low); the ozone hole was detected only in satellite data when the raw data was reprocessed following evidence of ozone depletion in in situ observations. When the software was rerun without the flags, the ozone hole was seen as far back as 1976.Susan",1
"Solomon, an atmospheric chemist at the National Oceanic and Atmospheric Administration (NOAA), proposed that chemical reactions on polar stratospheric clouds (PSCs) in the cold Antarctic stratosphere caused a massive, though localized and seasonal, increase in the amount of chlorine present in active, ozone-destroying forms. The polar stratospheric clouds in Antarctica are only formed when there are very low temperatures, as low as −80 °C, and early spring conditions. In such conditions the ice crystals of the cloud provide a suitable surface for conversion of unreactive chlorine compounds into reactive chlorine compounds, which can deplete ozone easily.",1
"Moreover, the polar vortex formed over Antarctica is very tight and the reaction occurring on the surface of the cloud crystals is far different from when it occurs in atmosphere. These conditions have led to ozone hole formation in Antarctica. This hypothesis was decisively confirmed, first by laboratory measurements and subsequently by direct measurements, from the ground and from high-altitude airplanes, of very high concentrations of chlorine monoxide (ClO) in the Antarctic stratosphere.Alternative hypotheses, which had attributed the ozone hole to variations in solar UV radiation or to changes in atmospheric circulation patterns, were also tested and shown to be untenable.Meanwhile,",1
"analysis of ozone measurements from the worldwide network of ground-based Dobson spectrophotometers led an international panel to conclude that the ozone layer was in fact being depleted, at all latitudes outside of the tropics. These trends were confirmed by satellite measurements. As a consequence, the major halocarbon-producing nations agreed to phase out production of CFCs, halons, and related compounds, a process that was completed in 1996. Since 1981 the United Nations Environment Programme, under the auspices of the World Meteorological Organization, has sponsored a series of technical reports on the Scientific Assessment of Ozone Depletion, based on satellite measurements.",1
"The 2007 report showed that the hole in the ozone layer was recovering and the smallest it had been for about a decade. The 2010 report found, ""Over the past decade, global ozone and ozone in the Arctic and Antarctic regions is no longer decreasing but is not yet increasing. The ozone layer outside the Polar regions is projected to recover to its pre-1980 levels some time before the middle of this century. In contrast, the springtime ozone hole over the Antarctic is expected to recover much later.""",1
"The ozone hole has influenced atmospheric circulation all the way to the tropics and increased rainfall at low, subtropical latitudes in the Southern Hemisphere.",1
"On March 3, 2005, the journal Nature published an article linking 2004's unusually large Arctic ozone hole to solar wind activity. On March 15, 2011, a record ozone layer loss was observed, with about half of the ozone present over the Arctic having been destroyed. The change was attributed to increasingly cold winters in the Arctic stratosphere at an altitude of approximately 20 km (12 mi), a change associated with global warming in a relationship that is still under investigation.",1
"By March 25, the ozone loss had become the largest compared to that observed in all previous winters with the possibility that it would become an ozone hole. This would require that the quantities of ozone to fall below 200 Dobson units, from the 250 recorded over central Siberia. It is predicted that the thinning layer would affect parts of Scandinavia and Eastern Europe on March 30–31.On",1
"October 2, 2011, a study was published in the journal Nature, which said that between December 2010 and March 2011 up to 80 percent of the ozone in the atmosphere at about 20 kilometres (12 mi) above the surface was destroyed. The level of ozone depletion was severe enough that scientists said it could be compared to the ozone hole that forms over Antarctica every winter. According to the study, ""for the first time, sufficient loss occurred to reasonably be described as an Arctic ozone hole.""",1
"The study analyzed data from the Aura and CALIPSO satellites, and determined that the larger-than-normal ozone loss was due to an unusually long period of cold weather in the Arctic, some 30 days more than typical, which allowed for more ozone-destroying chlorine compounds to be created.",1
"According to Lamont Poole, a co-author of the study, cloud and aerosol particles on which the chlorine compounds are found ""were abundant in the Arctic until mid March 2011—much later than usual—with average amounts at some altitudes similar to those observed in the Antarctic, and dramatically larger than the near-zero values seen in March in most Arctic winters"".In 2013, researchers analyzed the data and found the 2010–11 Arctic event did not reach the ozone depletion levels to classify as a true hole.",1
"A hole in the ozone is generally classified as 220 Dobson units or lower; the Arctic hole did not approach that low level. It has since been classified as a ""mini-hole.""Following the ozone depletion in 1997 and 2011, a 90% drop in ozone was measured by weather balloons over the Arctic in March 2020, as they normally recorded 3.5 parts per million of ozone, compared to only around 0.3 parts per million lastly, due to cold temperatures ever recorded since 1979, and a strong polar vortex which allowed chemicals, including chlorine and bromine, to gnaw away.A",1
"rare hole, the result of unusually low temperatures in the atmosphere above the North Pole, was studied in 2020.",1
"As winters that are colder are more affected, at times there is an ozone hole over Tibet. In 2006, a 2.5 million square kilometer ozone hole was detected over Tibet. Also again in 2011 an ozone hole appeared over mountainous regions of Tibet, Xinjiang, Qinghai and the Hindu Kush, along with an unprecedented hole over the Arctic, though the Tibet one is far less intense than the ones over the Arctic or Antarctic.",1
"Research in 2012 showed that the same process that produces the ozone hole over Antarctica occurs over summer storm clouds in the United States, and thus may be destroying ozone there as well.",1
"Physicist Qing-Bin Lu, of the University of Waterloo, claimed to have discovered a large, all-season ozone hole in the lower stratosphere over the tropics in July 2022. However, other researchers in the field refuted this claim, stating that the research was riddled with ""serious errors and unsubstantiated assertions."" According to Dr Paul Young, a lead author of the 2022 WMO/UNEP Scientific Assessment of Ozone Depletion, ""The author's identification of a ‘tropical ozone hole’ is down to him looking at percentage changes in ozone, rather than absolute changes, with the latter being much more relevant for damaging UV reaching the surface.""",1
"Specifically, Lu's work defines ""ozone hole"" as ""an area with O3 loss in percent larger than 25%, with respect to the undisturbed O3 value when there were no significant CFCs in the stratosphere (~ in the 1960s)"" instead of the general definition of 220 Dobson units or lower. Dr Marta Abalos Alvarez has added ""Ozone depletion in the tropics is nothing new and is mainly due to the acceleration of the Brewer-Dobson circulation."" Among others, Robert Watson had a role in the science assessment and in the regulation efforts of ozone depletion and global warming.",1
"Prior to the 1980s, the EU, NASA, NAS, UNEP, WMO and the British government had dissenting scientific reports and Watson played a role in the process of unified assessments. Based on the experience with the ozone case, the IPCC started to work on a unified reporting and science assessment to reach a consensus to provide the IPCC Summary for Policymakers. There are various areas of linkage between ozone depletion and global warming science: The same CO2 radiative forcing that produces global warming is expected to cool the stratosphere.",1
"This cooling, in turn, is expected to produce a relative increase in ozone (O3) depletion in polar area and the frequency of ozone holes. Conversely, ozone depletion represents a radiative forcing of the climate system. There are two opposing effects: Reduced ozone causes the stratosphere to absorb less solar radiation, thus cooling the stratosphere while warming the troposphere; the resulting colder stratosphere emits less long-wave radiation downward, thus cooling the troposphere. Overall, the cooling dominates; the IPCC concludes ""observed stratospheric O3 losses over the past two decades have caused a negative forcing of the surface-troposphere system"" of about −0.15 ± 0.10",1
"watts per square meter (W/m2). One of the strongest predictions of the greenhouse effect is that the stratosphere will cool. Although this cooling has been observed, it is not trivial to separate the effects of changes in the concentration of greenhouse gases and ozone depletion since both will lead to cooling. However, this can be done by numerical stratospheric modeling. Results from the National Oceanic and Atmospheric Administration's Geophysical Fluid Dynamics Laboratory show that above 20 km (12 mi), the greenhouse gases dominate the cooling. As noted under 'Public Policy', ozone depleting chemicals are also often greenhouse gases.",1
"The increases in concentrations of these chemicals have produced 0.34 ± 0.03 W/m2 of radiative forcing, corresponding to about 14 percent of the total radiative forcing from increases in the concentrations of well-mixed greenhouse gases. The long term modeling of the process, its measurement, study, design of theories and testing take decades to document, gain wide acceptance, and ultimately become the dominant paradigm. Several theories about the destruction of ozone were hypothesized in the 1980s, published in the late 1990s, and are currently being investigated.",1
"Dr Drew Schindell, and Dr Paul Newman, NASA Goddard, proposed a theory in the late 1990s, using computational modeling methods to model ozone destruction, that accounted for 78 percent of the ozone destroyed. Further refinement of that model accounted for 89 percent of the ozone destroyed, but pushed back the estimated recovery of the ozone hole from 75 years to 150 years. (An important part of that model is the lack of stratospheric flight due to depletion of fossil fuels.)In 2019, NASA reported that there was no significant relation between size of the ozone hole and the climate change.",1
"Another misconception is that ""it is generally accepted that natural sources of tropospheric chlorine are four to five times larger than man-made ones."" While this statement is strictly true, tropospheric chlorine is irrelevant; it is stratospheric chlorine that affects ozone depletion. Chlorine from ocean spray is soluble and thus is washed by rainfall before it reaches the stratosphere. CFCs, in contrast, are insoluble and long-lived, allowing them to reach the stratosphere. In the lower atmosphere, there is much more chlorine from CFCs and related haloalkanes than there is in HCl from salt spray, and in the stratosphere halocarbons are dominant.",1
"Only methyl chloride, which is one of these halocarbons, has a mainly natural source, and it is responsible for about 20 percent of the chlorine in the stratosphere; the remaining 80 percent comes from manmade sources. Very violent volcanic eruptions can inject HCl into the stratosphere, but researchers have shown that the contribution is not significant compared to that from CFCs. A similar erroneous assertion is that soluble halogen compounds from the volcanic plume of Mount Erebus on Ross Island, Antarctica are a major contributor to the Antarctic ozone hole.Nevertheless,",1
"a 2015 study showed that the role of Mount Erebus volcano in the Antarctic ozone depletion was probably underestimated. Based on the NCEP/NCAR reanalysis data over the last 35 years and by using the NOAA HYSPLIT trajectory model, researchers showed that Erebus volcano gas emissions (including hydrogen chloride (HCl)) can reach the Antarctic stratosphere via high-latitude cyclones and then the polar vortex. Depending on Erebus volcano activity, the additional annual HCl mass entering the stratosphere from Erebus varies from 1.0 to 14.3 kt.",1
"G.M.B. Dobson mentioned that when springtime ozone levels in the Antarctic over Halley Bay were first measured in 1956, he was surprised to find that they were ~320 DU, or about 150 DU below spring Arctic levels of ~450 DU. These were at that time the only known Antarctic ozone values available. What Dobson describes is essentially the baseline from which the ozone hole is measured: actual ozone hole values are in the 150–100 DU range.The",1
"discrepancy between the Arctic and Antarctic noted by Dobson was primarily a matter of timing: during the Arctic spring ozone levels rose smoothly, peaking in April, whereas in the Antarctic they stayed approximately constant during early spring, rising abruptly in November when the polar vortex broke down. The behavior seen in the Antarctic ozone hole is completely different. Instead of staying constant, early springtime ozone levels suddenly drop from their already low winter values, by as much as 50 percent, and normal values are not reached again until December.",1
"Some people thought that the ozone hole should be above the sources of CFCs. However, CFCs are well mixed globally in the troposphere and stratosphere. The reason for occurrence of the ozone hole above Antarctica is not because there are more CFCs concentrated but because the low temperatures help form polar stratospheric clouds. In fact, there are findings of significant and localized ""ozone holes"" above other parts of the earth, like above Central Asia. In 1994, the United Nations General Assembly voted to designate September 16 as the International Day for the Preservation of the Ozone Layer, or ""World Ozone Day"".",1
"The designation commemorates the signing of the Montreal Protocol on that date in 1987. Climate change in the Arctic Section 608 ""WMO/UNEP Scientific Assessments of Ozone Depletion (Latest Report 2022)"". Chemical Sciences Laboratory, National Oceanic and Atmospheric Administration (NOAA). Andersen, S. O. and K. M. Sarma. (2002). Protecting the Ozone Layer: The United Nations History, Earthscan Press. London. Benedick, Richard Elliot; World Wildlife Fund (U.S.); Institute for the Study of Diplomacy. Georgetown University. (1998). Ozone Diplomacy: New Directions in Safeguarding the Planet (2nd ed.). Harvard University Press. ISBN 978-0-674-65003-9. Retrieved May 28, 2016. (Ambassador Benedick was the Chief U.S.",1
"Oxford: Oxford University Press. Ozone layer at Curlie NOAA/ESRL Ozone Depletion NOAA Ozone Depleting Gas Index MACC stratospheric ozone service delivers maps, datasets and validation reports about the past and current state of the ozone layer. Green Cooling Initiative on alternative natural refrigerants cooling technologies ""Ozone Hole: How We Saved the Planet"" premiered April 10, 2019 PBS",1
"Modern drainage systems did not appear until the 19th century in Western Europe, although most of these systems were primarily built to deal with sewage issues rising from rapid urbanization. One such example is that of the London sewerage system, which was constructed to combat massive contamination of the River Thames. At the time, the River Thames was the primary component of London's drainage system, with human waste concentrating in the waters adjacent to the densely populated urban center.",1
Stormwater planters can easily fit between other street landscapes and ideal in areas where spacing is tight.,1
"With climate change intensifying, heavy storms are becoming more frequent and so is the increasing risk of flooding and sewer system overflows. According to the EPA, the average size of a 100-year floodplain is likely to increase by 45% in the next ten years. Another growing problem is urban flooding being caused by too much rain on impervious surfaces, urban floods can destroy neighborhoods. They particularly affect minority and low-income neighborhoods and can leave behind health problems like asthma and illness caused by mold.",1
"Green infrastructure reduces flood risks and bolsters the climate resiliency of communities by keeping rain out of sewers and waterways, capturing it where it falls.",1
"And green roofs can reduce heating and cooling costs, leading to energy savings of as much as 15 percent. Aquifer storage and recovery Blue roof Detention basin Drainage system (disambiguation) French drain Low-impact development (U.S. and Canada) Rain garden Resin-bound paving Retention basin Sponge city Stream restoration Sustainable city Urban runoff Tree box filter Water-sensitive urban design SUDS solutions from the British Geological Survey International Best Management Practices Database – Detailed data sets & summaries on performance of Urban BMPs Portland Guide to Sustainable Stormwater – City of Portland, Oregon",1
"intervals are also set to require a crop or livestock product not be harvested before a certain period after application in order to allow the pesticide residue to decrease below maximum residue limits or other tolerance levels. Likewise, restricted entry intervals are the amount of time to allow residue concentrations to decrease before a worker can reenter an area where pesticides have been applied without protective equipment.",1
Food Standards Australia New Zealand develops the standards for levels of pesticide residues in foods through a consultation process. The New Zealand Food Safety Authority publishes the maximum limits of pesticide residues for foods produced in New Zealand.,1
"Monitoring of pesticide residues in the UK began in the 1950s. From 1977 to 2000 the work was carried out by the Working Party on Pesticide Residues (WPPR), until in 2000 the work was taken over by the Pesticide Residue Committee (PRC). The PRC advise the government through the Pesticides Safety Directorate and the Food Standards Agency (FSA).",1
"In the US, tolerances for the amount of pesticide residue that may remain on food are set by the EPA, and measures are taken to keep pesticide residues below the tolerances. The US EPA has a web page for the allowable tolerances. In order to assess the risks associated with pesticides on human health, the EPA analyzed individual pesticide active ingredients as well as the common toxic effect that groups of pesticides have, called the cumulative risk assessment.",1
"In 2016, over 99% of samples of US produce had no pesticide residue or had residue levels well below the EPA tolerance levels for each pesticide.",1
"In Japan, pesticide residues are regulated by the Food Safety Act.Pesticide tolerances are set by the Ministry of Health, Labour and Welfare through the Drug and Food Safety Committee. Unlisted residue amounts are restricted to 0.01ppm.",1
"Due to similarities in brain biochemistry among many different organisms, there is much speculation that these chemicals can have a negative impact on humans as well. There are epidemiological studies that show positive correlations between exposure to pesticides through occupational hazard, which tends to be significantly higher than that ingested by the general population through food, and the occurrence of certain cancers. Although most of the general population may not exposed to large portion of pesticides, many of the pesticide residues that are attached tend to be lipophilic and can bio-accumulate in the body.According",1
to the American Cancer Society there is no evidence that pesticide residues increase the risk of people getting cancer. Pesticide exposure cannot be studied in placebo controlled trials as this would be unethical. A definitive cause effect relationship therefore cannot be established. The ACA advises washing fruit and vegetables before eating to remove both pesticide residue and other undesirable contaminants.,1
"Neurotoxins and other chemicals that originate from pesticides pose the biggest threat to the developing human brain and nervous system. Presence of pesticide metabolites in urine samples have been implicated in disorders such as attention deficit hyperactivity disorder (ADHD), autism, behavioral and emotional problems, and delays in development. There is a lack of evidence of a direct cause-and-effect relationship between long-term, low-dose exposure to pesticide residues and neurological disease, partly because manufacturers are not always legally required to examine potential long-term threats.",1
"Singapore has been regularly hit by smoke haze from forest fires in nearby Sumatra, Indonesia, brought over by wind. These forest fires have been attributed to the slash-and-burn method favoured by several large plantation owners to clear their land, as opposed to a more expensive and inconvenient mechanical approach using excavators and bulldozers. In June 2013, severe haze hit Singapore, pushing the nation's PSI into Hazardous levels for the first time in its history. Presently, the highest 3-hour PSI reading on record in Singapore is 471 on 20 October 2015 at 11 pm (GMT+8).",1
"Singapore's computation of PSI and NEA's definitions of PSI ranges have been shown to correlate with a number of health outcomes including all-cause mortality. For sudden cardiac deaths, every increment of 30 units in PSI correlated with 8.15% increased risk of out-of-hospital cardiac arrest on the same day of exposure. This risk was found to remain elevated for 1–5 days after exposure. Similar short-term associations were subsequently found for acute myocardial infarction and acute ischemic stroke in analyses of national registries. In terms of healthcare utilization, both country-wide Emergency Department visits and hospital admissions were increased per unit increase in PSI.",1
Past and present PSI readings in Singapore published by the NEA,1
"A quenching system can be as simple as spraying liquid into the duct just preceding the main scrubbing vessel, or it can be a separate chamber (or tower) with its own spray system identical to a spray tower. Quenchers are designed using the same principles as scrubbers. Increasing the gas-liquid contact in them increases their operational efficiency. Small liquid droplets cool the exhaust stream more quickly than large droplets because they evaporate more easily. Therefore, less liquid is required. However, in most scrubbing systems, approximately one-and-a-half to two and- a-half times the theoretical evaporation demand is required to ensure proper cooling.",1
"Evaporation also depends on time; it does not occur instantaneously. Therefore, the quencher should be sized to allow for an adequate exhaust stream residence time. Normal residence times range from 0.15 to 0.25 seconds for gases under 540°C (1000°F) to 0.2 to 0.3 seconds for gases hotter than 540°C. Quenching with recirculated scrubber liquor could potentially reduce overall scrubber performance, since recycled liquid usually contains a high level of suspended and dissolved solids. As the liquid droplets evaporate, these solids could become re-entrained in the exhaust gas stream.",1
"From 1962 until 1993, operations at Heathrow were subject to a simple limit on the number of aircraft movements that were allowed to take place during the night period. In 1993 a new Quota Count system was introduced based on aircraft noise certification data. Each aircraft type is classified and awarded a quota count (QC) value depending on the amount of noise it generated under controlled certification conditions. The quieter the aircraft the smaller the QC value. Aircraft are classified separately for landing and take-off.",1
"Take-off quota count values are based on the average of the certificated flyover and sideline noise levels at maximum take-off weight, with 1.75 EPNdB added for Chapter 2 aircraft. Landing quota count values are based on the certificated approach noise level at maximum landing weight minus 9.0 EPNdB. Aircraft were originally divided into six QC bands from 0.5 to 16, but following a review by the Department for Transport a seventh category – Quota Count 0.25 – was added in March 2007 and an eighth category – Quota Count 0.125 – in September 2018.",1
"For example, the Boeing 747-400 is classed as QC/2 on landing and QC/4 on takeoff, while the larger yet quieter Airbus A380 is rated QC/0.5 on landing and QC/2 on takeoff. Each A380 therefore uses approximately 42% of the quota of a 747, while potentially carrying more passengers, thus providing airlines with an incentive to operate quieter types of aircraft. Field measurements suggest the approach quota allocation for the A380 may be overly generous compared to the older Boeing 747. Rolls-Royce is supporting CAA in understanding the relatively high A380/Trent 900 monitored noise levels.",1
"The CWA has another means of addressing sewage discharges, through establishment of no-discharge zones (NDZs) for vessel sewage. A state may completely prohibit the discharge of both treated and untreated sewage from all vessels with installed toilets into some or all waters over which it has jurisdiction (up to 3 miles (4.8 km) from land). To create a no-discharge zone to protect waters from sewage discharges by vessels, the state must apply to EPA under one of three categories.",1
"Ship discharges of solid waste are governed by two laws. Title I of the Marine Protection, Research, and Sanctuaries Act (MPRSA) applies to cruise ships and other vessels and makes it illegal to transport garbage from the United States for the purpose of dumping it into ocean waters without a permit or to dump any material transported from a location outside the United States into U.S. territorial seas or the contiguous zone (within 12 nautical miles (22 km) from shore) or ocean waters.",1
"km) of shore, certain types of garbage within 12 nautical miles (22 km) offshore, and plastic anywhere. It applies to all vessels, whether seagoing or not, regardless of flag, operating in U.S. navigable waters and the Exclusive Economic Zone (EEZ). It is administered by the Coast Guard, which carries out inspection programs to insure the adequacy of port facilities to receive offloaded solid waste. EPA first issued its MSD regulations in 1976 under CWA authority.",1
"To compensate for this situation, graywater piping is rerouted to the MSD. Blackwater is another word for sewage or human body wastes and wastes from toilets. According to the international maritime organization or the IMO, untreated sewage cannot be discharged overboard unless it is 12 nautical miles from the nearest land. Due to regulations issued by the IMO and the United States Maritime Administration (MARAD), every ship must have an approved marine sanitation device aboard their ship. Blackwater is therefore treated through a process that utilizes chlorination and/or biological treatment before being discharged overboard.",1
"Due to this circumstance, maceration machinery is usually paired with some form of chlorination process in the same system. Very few places around the world allow the discharge of untreated sewage from a maceration process.",1
The person-in-charge on the dock is called a Loading master-PIC and the person-in charge on the barge will be the Tankerman-PIC. The person-in-charge on a tanker ship will be the deck officer who monitors the transfer of product in the cargo control room. All persons-in-charge must have special training in order to obtain the proper credentials such as licensing and endorsement on their merchant mariner documents. Loading Masters work closely with the marine surveyor in agreeing to the sequence of the transfer.,1
"Such as whether any product sampling will take place prior to commencement, determining if a line displacement will occur, agreeing on whether the final stop at completion will either be a shore stop or a draft stop on the vessel. The marine surveyor gauges the vessel's tanks and shore tanks to ensure the correct amount of product is transferred. Additionally, the surveyor or inspector will obtain product samples on the marine vessel and shore tank for laboratory analysis to ensure that the product meets all specifications of purity.",1
"A marine transfer operation occurs between three main stakeholders which includes the Loading Master-PIC, Vessel Person-In -Charge PIC, and marine surveyor or inspector. These individuals communicate prior to the transfer agreeing on the sequence of events that will occur before, during, and after the transfer. During the course of the transfer the Loading Master is in continuous two way radio contact with the vessel Person-In-Charge and standing by to stop the transfer immediately if any problems develop such as leaks at the transfer hose or loading arm.",1
Barge Tanker Oil tanker Marine loading arm Marine Transfer Operations Barges News Google Group Marine Transfer Operations,1
"Green waste can be collected via municipal curbside collection schemes or through private waste management businesses. Many communities, especially in the United Kingdom, have initiated green waste recycling and collection programs in order to decrease the amount of biodegradable materials in landfills. Communities are provided with, or can provide their own, compost receptacles that they fill with plant and food remains, which are then emptied on a regular basis.",1
"Green waste is an integral part of many manufactured topsoils, as it provides both nutrients for growing plants and increases the volume of manufactured topsoils. Its woody components do not decompose quickly, so they provide the bulk that is necessary for supplementary topsoils. Mixing industrial wastes such as fly ash or coal dust with green waste to create artificial topsoil not only facilitates the repurposing of industrial debris and keeps it out of landfills, but it also allows the nutrients in green waste materials to be cycled back into the environment.",1
This process decreases the amount of trash being dumped into landfills and other trash repositories and allows for the complete cycling of organic nutrients through the environment.,1
Green waste composting has also been linked to suppression of soil borne diseases such as damping off and root rots that affect large agricultural and horticultural ventures like greenhouses and large-scale farms. This disease suppressive quality has positive implications for lesser-developed nations that do not have the technology or resources to purchase expensive fertilizers. Addition of composts that contain residues and particles of heavy metals to soil can raise the soil's heavy metal content and increase the probability of these metals to transfer into crop plants.,1
"When biological, or green waste is added to these soil samples, plant uptake of heavy metal has been shown to decrease crop uptake of metals compared to other types of compost composed of things such as sewage sludge. This can protect consumers and the environment from biomagnification caused by long-term accumulation of heavy metal particles within the soil and plant life of an area. Garden waste dumping Biomass Biomass to liquid Biomass heating system Informal waste collection",1
"The quantitative and qualitative categorization of marine heatwaves establishes a naming system, typology, and characteristics for marine heatwave events. The naming system is applied by location and year: for example Mediterranean 2003. This allows researchers to compare the drivers and characteristics of each event, geographical and historical trends of marine heatwaves, and easily communicate marine heatwave events as they occur in real-time.The categorization system is on a scale from 1 to 4. Category 1 is a moderate event, Category 2 is a strong event, Category 3 is a severe event, and Category 4 is an extreme event.",1
"The category applied to each event in real-time is defined primarily by sea surface temperature anomalies (SSTA), but over time it comes to include typology and characteristics.The types of marine heatwaves are symmetric, slow onset, fast onset, low intensity, and high intensity. Marine heatwave events may have multiple categories such as slow onset, high intensity. The characteristics of marine heatwave events include duration, intensity (max, average, cumulative), onset rate, decline rate, region, and frequency.While marine heat waves have been studied at the sea surface for more than a decade, they can also occur at the sea floor.",1
"These processes contribute to regional warming trends that disproportionately effect Western boundary currents.Regional climate patterns such as interdecadal oscillations like El Niño Southern Oscillation (ENSO) have contributed to marine heatwave events such as ""The Blob"" in the Northeastern Pacific.Drivers that operate on the scale of biogeographical realms or the Earth as a whole are Decadal oscillations, like Pacific Decadal Oscillations (PDO), and anthropogenic ocean warming due to climate change.Ocean",1
areas of carbon sinks in the mid-latitudes of both hemispheres and carbon outgassing areas in upwelling regions of the tropical Pacific have been identified as places where persistent marine heatwaves occur; the air-sea gas exchange is being studied in these areas.,1
"Scientists predict that the frequency, duration, scale (or area) and intensity of marine heatwaves will continue to increase.: 1227 This is because sea surface temperatures will continue to increase with global warming, and therefore the frequency and intensity of marine heatwaves will also increase. The extent of ocean warming depends on emission scenarios, and thus humans' climate change mitigation efforts. Simply put, the more greenhouse gas emissions (or the less mitigation), the more the sea surface temperature will rise. Scientists have calculated this as follows: there would be a relatively small (but still significant) increase of 0.86°C",1
"The predictions are for the average of the future period (years 2081 to 2100) compared to the average of the past period (years 1995 to 2014). : 1227 Many species already experience these temperature shifts during the course of marine heatwave events. There are many increased risk factors and health impacts to coastal and inland communities as global average temperature and extreme heat events increase. Sea surface temperatures have been recorded since 1904 in Port Erin, UK and measurements continue through global organizations such as NOAA, NASA, and many more. Events can be identified from 1925 till present day.",1
The list below is not a complete representation of all marine heatwave events that have ever been recorded.,1
"Changes in the thermal environment of terrestrial and marine organisms can have drastic effects on their health and well-being. marine heatwave events have been shown to increase habitat degradation, change species range dispersion, complicate management of environmentally and economically important fisheries, contribute to mass mortalities of species, and in general reshape ecosystems.Habitat degradation occurs through alterations of the thermal environment and subsequent restructuring and sometimes complete loss of biogenic habitats such as seagrass beds, corals, and kelp forests. These habitats contain a significant proportion of the oceans biodiversity.",1
"Changes in ocean current systems and local thermal environments have shifted many tropical species' range northward while temperate species have lost their southern limits. Large range shifts along with outbreaks of toxic algal blooms has impacted many species across taxa. Management of these affected species becomes increasingly difficult as they migrate across management boundaries and the food web dynamics shift. Increases in sea surface temperature have been linked to a decline in species abundance such as the mass mortality of 25 benthic species in the Mediterranean in 2003, sea star wasting disease, and coral bleaching events.",1
Climate change-related exceptional marine heatwaves in the Mediterranean Sea during 2015–2019 resulted in widespread mass sealife die-offs in five consecutive years. The impact of more frequent and prolonged marine heatwave events will have drastic implications for the distribution of species.,1
"Research on how marine heatwaves influence atmospheric conditions is emerging. Marine heatwaves in the tropical Indian Ocean are found to result in dry conditions over the central Indian subcontinent. At the same time, there is an increase in rainfall over south peninsular India in response to marine heatwaves in the northern Bay of Bengal. These changes are in response to the modulation of the monsoon winds by the marine heatwaves. To address the root cause of more frequent and more intense marine heatwaves,: 416 climate change mitigation methods are needed to curb the increase in global temperature and in ocean temperatures.",1
Better forecasts of marine heatwaves and improved monitoring can also help to reduce impacts of these heatwaves.: 417 Effects of climate change on oceans Heat wave The Blob (Pacific Ocean) Marine Heatwaves International Working Group,1
Discussion of the layers in the Earth's atmosphere is needed to understand where airborne pollutants disperse in the atmosphere. The layer closest to the Earth's surface is known as the troposphere. It extends from sea-level to a height of about 18 km (11 mi) and contains about 80 percent of the mass of the overall atmosphere. The stratosphere is the next layer and extends from 18 km (11 mi) to about 50 km (31 mi). The third layer is the mesosphere which extends from 50 km (31 mi) to about 80 km (50 mi).,1
"above the inversion layer) is called the free troposphere and it extends up to the tropopause (the boundary in the Earth's atmosphere between the troposphere and the stratosphere). In tropical and mid-latitudes during daytime, the Free convective layer can comprise the entire troposphere, which is up to 10 to 18 km (6.2 to 11.2 mi) in the Intertropical convergence zone. The ABL is of the most important with respect to the emission, transport and dispersion of airborne pollutants. The part of the ABL between the Earth's surface and the bottom of the inversion layer is known as the mixing layer.",1
"The sum of the four exponential terms in g 3 {\displaystyle g_{3}} converges to a final value quite rapidly. For most cases, the summation of the series with m = 1, m = 2 and m = 3 will provide an adequate solution. σ z {\displaystyle \sigma _{z}} and σ y {\displaystyle \sigma _{y}} are functions of the atmospheric stability class (i.e., a measure of the turbulence in the ambient atmosphere) and of the downwind distance to the receptor.",1
"The two most important variables affecting the degree of pollutant emission dispersion obtained are the height of the emission source point and the degree of atmospheric turbulence. The more turbulence, the better the degree of dispersion.",1
"Equations for σ y {\displaystyle \sigma _{y}} and σ z {\displaystyle \sigma _{z}} are: σ y {\displaystyle \sigma _{y}} (x) = exp(Iy + Jyln(x) + Ky[ln(x)]2) σ z {\displaystyle \sigma _{z}} (x) = exp(Iz + Jzln(x) + Kz[ln(x)]2) (units of σ z {\displaystyle \sigma _{z}} , and σ y {\displaystyle \sigma _{y}} , and x are in meters) The classification of stability class is proposed by F. Pasquill.",1
"That was followed in 1969 by his classical critical review of the entire plume rise literature, in which he proposed a set of plume rise equations which have become widely known as ""the Briggs equations"". Subsequently, Briggs modified his 1969 plume rise equations in 1971 and in 1972.Briggs",1
List of atmospheric dispersion models provides a more comprehensive list of models than listed below. It includes a very brief description of each model.,1
There are currently five types of designation for International Dark Sky Places: International Dark Sky Sanctuaries International Dark Sky Parks International Dark Sky Reserves International Dark Sky Communities Urban Night Sky Places,1
"IDA describes Dark Sky Sanctuaries as ""the most remote (and often darkest) places in the world whose conservation state is most fragile"".",1
"!Ae!Hai Kalahari Heritage Park South Africa, designated 2019 Aotea / Great Barrier Island New Zealand, designated 2017 Boundary Waters Canoe Area Wilderness, Minnesota, United States, designated 2020 Beaver Island Cosmic Campground United States, designated 2016 Devils River State Natural Area – Del Norte Unit United States, designated 2019 Bardsey Island/Ynys Enlli - Wales (United Kingdom), designated 2023 Gabriela Mistral Dark Sky Sanctuary Elqui Valley, Chile, designated 2015 Katahdin Woods and Waters National Monument United States, designated 2020 Massacre Rim Wilderness Study Area Washoe County, Nevada United States, designated 2019 Medicine Rocks State Park United States, designated 2020 Niue, designated 2020 –",1
"the first entire country to be designated. Pitcairn Islands designated 2019 Rainbow Bridge National Monument United States, designated 2018 Stewart Island / Rakiura New Zealand, designated 2019 The Jump-Up Australia, designated 2019",1
"IDA describes Dark Sky Parks as ""publicly- or privately-owned spaces protected for natural conservation that implement good outdoor lighting and provide dark sky programs for visitors"".",1
"Natural Bridges National Monument, Utah, United States, designated 2006 Cherry Springs State Park, Pennsylvania, United States, designated 2008 Galloway Forest Park, Scotland, United Kingdom, designated 2009 Zselic National Landscape Protection Area, Hungary, designated 2009 Clayton Lake State Park, New Mexico, United States, designated 2010 Goldendale Observatory State Park, Washington, United States, designated 2010, suspended 2016, revoked 2017 Hortobágy National Park, Hungary, designated 2011 The Headlands, Michigan, United States, designated 2011 Observatory Park, Ohio, United States, designated 2011 Big Bend National Park, Texas, United States, designated 2012 Big Bend Ranch State Park, Texas, United States, designated 2017 Death Valley National Park, California,",1
"United States, designated 2013 Chaco Culture National Historical Park, New Mexico, United States, designated 2013 Northumberland National Park, England, United Kingdom, designated 2013 Eifel National Park, Germany, designated 2014 Mayland Community College Blue Ridge Observatory and Star Park, North Carolina, United States, designated 2014 Grand Canyon-Parashant National Monument, Arizona, United States, designated 2014 Hovenweep National Monument, Utah and Colorado, United States, designated 2014 Copper Breaks State Park, Texas, United States, designated 2014 Enchanted Rock State Natural Area, Texas, United States, designated 2014 Elan Valley Estate, Wales, United Kingdom, designated 2015 Yeongyang Firefly Eco Park, Yeongyang, South Korea, designated 2015 Mayo International",1
"Dark Sky Park, County Mayo, Republic of Ireland, designated 2016 Warrumbungle National Park, New South Wales, Australia, designated 2016 Dead Horse Point State Park, Utah, United States, designated 2016 Waterton-Glacier International Peace Park, Alberta, Canada and Montana, United States, designated 2017 Ramon Crater, Negev Desert, Israel, designated 2017 Kartchner Caverns State Park, Arizona, United States, designated 2017 Joshua Tree National Park, California, United States, designated 2017 Craters of the Moon National Monument and Preserve, Idaho, designated 2017 Obed Wild and Scenic River, Tennessee, United States, designated 2017 Anza-Borrego Desert State Park, California, United States, designated 2018 Iriomote-Ishigaki National Park, Okinawa Prefecture,",1
"Japan, designated 2018 Steinaker State Park, Utah, United States, designated 2018 Middle Fork River Forest Preserve, Illinois, United States, designated 2018 Grand Canyon National Park, Arizona, United States, designated 2019 Great Sand Dunes National Park and Preserve, Colorado, United States, designated 2019 Hehuan Mountain, Nantou County, Taiwan, designated 2019 El Morro National Monument, New Mexico, United States, designated 2019 Kōzu-shima, Tokyo Metropolis, Japan, designated 2020 Quetico Provincial Park, Ontario, Canada, designated 2021 Valles Caldera National Preserve, New Mexico, United States, designated 2021 Sky Meadows State Park, Virginia, United States, designated 2021 City of Rocks National Reserve, Idaho, United States, designated 2023",1
"Aenos National Park, Cephalonia, Greece, designated 2023",1
"IDA describes Dark Sky Reserves as ""dark 'core' zones surrounded by a populated periphery where policy controls are enacted to protect the darkness of the core"".",1
"Aoraki Mackenzie International Dark Sky Reserve, South Island, New Zealand, designated 2012 Brecon Beacons National Park, Wales, United Kingdom, designated 2013 Central Idaho Dark Sky Reserve, Idaho, United States, designated 2017 Exmoor National Park, England, United Kingdom, designated 2011 Kerry International Dark-Sky Reserve, County Kerry, Ireland, designated 2014 The Reserve at Mont-Mégantic, Quebec, Canada, designated 2008 Moore's Reserve (South Downs), England, designated 2016 NamibRand Nature Reserve, Namibia, Africa, designated 2012 Pic du Midi, France, designated 2013 Rhön Biosphere Reserve, Germany, designated 2014 River Murray International Dark Sky Reserve, near Swan Reach, South Australia, designated 2019 Snowdonia National Park, Wales, designated 2015",1
"Westhavelland Nature Park, Germany, designated 2014 Newport State Park, Wisconsin, United States, designated 2017 Indian Astronomical Observatory (IAO), India, designated 2022 Wairarapa Dark Sky Reserve, New Zealand, designated 2023",1
"IDA describes Dark Sky Communities as ""legally organized cities and towns that adopt quality outdoor lighting ordinances and undertake efforts to educate residents about the importance of dark skies"".",1
"Flagstaff, Arizona, United States, designated 2001 Borrego Springs, California, United States, designated 2009 Sark, Channel Islands, designated 2011 Homer Glen, Illinois, United States, designated 2011 Coll in the Inner Hebrides of Scotland, designated 2013 Dripping Springs, Texas, United States, designated 2014 Beverly Shores, Indiana, United States, designated 2014 Sedona, Arizona, United States, designated 2014 Westcliffe and Silver Cliff, Colorado, United States, designated 2015 Thunder Mountain Pootsee Nightsky, Arizona, United States, designated 2015 Bon Accord, Alberta, Canada, designated 2015 Horseshoe Bay, Texas, designated 2015 Moffat, Scotland, designated 2016 Big Park/Village of Oak Creek, Arizona, designated 2016 River Oaks, Texas, Dark Sky Friendly",1
"Development of Distinction, designated 2017 Ketchum, Idaho, designated 2017 Møn, Denmark & Nyord, Denmark, designated 2017 Fountain Hills, Arizona, designated 2018 Torrey, Utah, designated 2018 Camp Verde, Arizona, designated 2018 Wimberley and Woodcreek, Texas designated 2018 Crestone, Colorado, designated in 2020",1
"IDA describes Urban Night Sky Places as ""sites near or surrounded by large urban environs whose planning and design actively promote an authentic nighttime experience in the midst of significant artificial light at night, and that otherwise do not qualify for designation within any other International Dark Sky Places category"". Fry Family Park, Ohio, U.S., designated 2021 Palos Preserves, Illinois, U.S., designated 2021 Stacy Park, Missouri, U.S., designated 2021 Timpanogos Cave National Monument, Utah, U.S., designated 2020 Valle de Oro National Wildlife Refuge, New Mexico, U.S.,",1
"4'33"" Ambient noise level Electronic noise The Hum Colors of noise Sound masking How low noise levels are achieved in concert halls Background noise in acoustics (demo)",1
"Most of the Solar System appears hostile to life as we know it. No extraterrestrial life has ever been discovered. But if extraterrestrial life exists, it may be vulnerable to interplanetary contamination by foreign microorganisms. Some extremophiles may be able to survive space travel to another planet, and foreign life could possibly be introduced by spacecraft from Earth. If possible, some believe this poses scientific and ethical concerns.",1
"The same applies to other more complex biosignatures. Life on other planets could have a common origin with Earth life, since in the early Solar System there was much exchange of material between the planets which could have transferred life as well. If so, it might be based on nucleic acids too (RNA or DNA). The majority of the species isolated are not well understood or characterized and cannot be cultured in labs, and are known only from DNA fragments obtained with swabs.",1
"On a contaminated planet, it might be difficult to distinguish the DNA of extraterrestrial life from the DNA of life brought to the planet by the exploring. Most species of microorganisms on Earth are not yet well understood or DNA sequenced. This particularly applies to the unculturable archaea, and so are difficult to study. This can be either because they depend on the presence of other microorganisms, are slow growing, or depend on other conditions not yet understood. In typical habitats, 99% of microorganisms are not culturable.",1
"Introduced Earth life could contaminate resources of value for future human missions, such as water.Invasive species could out compete native life or consume it, if there is life on the planet. However, the experience on earth shows that species moved from one continent to another may be able to out compete the native life adapted to that continent. Additionally, evolutionary processes on Earth might have developed biological pathways different from extraterrestrial organisms, and so may be able to out-compete it. The same is also possible the other way around for contamination introduced to Earth's biosphere.",1
"It was also found that abraded silicates (quartz and basalt) lead to the formation of toxic reactive oxygen species. The researchers concluded that ""the surface of Mars is lethal to vegetative cells and renders much of the surface and near-surface regions uninhabitable."" This research demonstrates that the present-day surface is more uninhabitable than previously thought, and reinforces the notion to inspect at least a few meters into the ground to ensure the levels of radiation would be relatively low.",1
"The Cassini spacecraft directly sampled the plumes escaping from Enceladus. Measured data indicates that these geysers are made primarily of salt rich particles with an 'ocean-like' composition, which is thought to originate from a subsurface ocean of liquid saltwater, rather than from the moon's icy surface. Data from the geyser flythroughs also indicate the presence of organic chemicals in the plumes. Heat scans of Enceladus's surface also indicate warmer temperatures around the fissures where the geysers originate, with temperatures reaching −93 °C (−135 °F), which is 115 °C (207 °F) warmer than the surrounding surface regions.",1
"Missions are classified depending on whether their destinations are of interest for the search for life, and whether there is any chance that Earth life could reproduce there. NASA made these policies official with the issuing of Management Manual NMI-4-4-1, NASA Unmanned Spacecraft Decontamination Policy on September 9, 1963. Prior to NMI-4-4-1 the same sterilization requirements were required on all outgoing spacecraft regardless of their target. Difficulties in the sterilization of Ranger probes sent to the Moon are the primary reasons for NASA's change to a target-by-target basis in assessing the likelihood forward contamination.",1
"Some destinations such as Mercury need no precautions at all. Others such as the Moon require documentation but nothing more, while destinations such as Mars require sterilization of the rovers sent there. Back contamination would be prevented by containment or quarantine. However, there have been no sample-returns thought to have any possibility of a back contamination risk since the Apollo missions. The Apollo regulations have been rescinded and new regulations have yet to be developed. See Suggested precautions for sample-returns.",1
"Crewed spacecraft are of particular concern for interplanetary contamination because of the impossibility to sterilize a human to the same level as a robotic spacecraft. Therefore, the chance of forwarding contamination is higher than for a robotic mission. Humans are typically host to a hundred trillion microorganisms in ten thousand species in the human microbiome which cannot be removed while preserving the life of the human. Containment seems the only option, but effective containment to the same standard as a robotic rover appears difficult to achieve with present-day technology.",1
"Humans in close orbit around the target planet could control equipment on the surface in real time via telepresence, so bringing many of the benefits of a surface mission, without its associated increased forward and back contamination risks. Since the Moon is now generally considered to be free from life, the most likely source of contamination would be from Mars during either a Mars sample-return mission or as a result of a crewed mission to Mars.",1
"These analyses could also be carried out without the communication delays for experiments carried out by Martian rovers. It would also make it possible to repeat experiments in multiple laboratories with different instruments to confirm key results.Carl Sagan was first to publicise back contamination issues that might follow from a Mars sample-return. In Cosmic Connection (1973) he wrote: Precisely because Mars is an environment of great potential biological interest, it is possible that on Mars there are pathogens, organisms which, if transported to the terrestrial environment, might do enormous biological damage.",1
"Later in Cosmos (1980) Carl Sagan wrote: Perhaps Martian samples can be safely returned to Earth. But I would want to be very sure before considering a returned-sample mission. NASA and ESA views are similar. The findings were that with present-day technology, Martian samples can be safely returned to Earth provided the right precautions are taken.",1
"A sample-return mission would be designed to break the chain of contact between Mars and the exterior of the sample container, for instance, by sealing the returned container inside another larger container in the vacuum of space before it returns to Earth. In order to eliminate the risk of parachute failure, the capsule could fall at terminal velocity and the impact would be cushioned by the capsule's thermal protection system. The sample container would be designed to withstand the force of the impact.",1
"To receive, analyze and curate extraterrestrial soil samples, NASA has proposed to build a biohazard containment facility, tentatively known as the Mars Sample Return Receiving Facility (MSRRF). This future facility must be rated biohazard level 4 (BSL-4). While existing BSL-4 facilities deal primarily with fairly well-known organisms, a BSL-4 facility focused on extraterrestrial samples must pre-plan the systems carefully while being mindful that there will be unforeseen issues during sample evaluation and curation that will require independent thinking and solutions.The facility's systems must be able to contain unknown biohazards, as the sizes of any putative Martian microorganisms are unknown.",1
"In consideration of this, additional requirements were proposed. Ideally it should filter particles of 0.01 µm or larger, and release of a particle 0.05 µm or larger is unacceptable under any circumstance.The reason for this extremely small size limit of 0.01 µm is for consideration of gene transfer agents (GTAs) which are virus-like particles that are produced by some microorganisms that package random segments of DNA capable of horizontal gene transfer. These randomly incorporate segments of the host genome and can transfer them to other evolutionarily distant hosts, and do that without killing the new host.",1
"In this way many archaea and bacteria can swap DNA with each other. This raises the possibility that Martian life, if it has a common origin with Earth life in the distant past, could swap DNA with Earth microorganisms in the same way. In one experiment reported in 2010, researchers left GTAs (DNA conferring antibiotic resistance) and marine bacteria overnight in natural conditions and found that by the next day up to 47% of the bacteria had incorporated the genetic material from the GTAs. Another reason for the 0.05",1
"µm limit is because of the discovery of ultramicrobacteria as small as 0.2 µm across.The BSL-4 containment facility must also double as a cleanroom to preserve the scientific value of the samples. A challenge is that, while it is relatively easy to simply contain the samples once returned to Earth, researchers would also want to remove parts of the sample and perform analyses. During all these handling procedures, the samples would need to be protected from Earthly contamination.",1
"A cleanroom is normally kept at a higher pressure than the external environment to keep contaminants out, while a biohazard laboratory is kept at a lower pressure to keep the biohazards in. This would require to compartmentalize the specialized rooms in order to combine these in a single building. Solutions suggested include a triple walled containment facility, and one of the suggestions include extensive robotic handling of the samples.The facility would be expected to take 7 to 10 years from design to completion, and an additional two years is recommended for the staff to become accustomed to the facilities.",1
"Robert Zubrin, from the Mars Society, maintains that the risk of back contamination is negligible. He supports this using an argument based on the possibility of transfer of life from Earth to Mars on meteorites.",1
"Other agencies such as the Environment Protection Agency, Occupational Health and Safety Administration, etc., may also get involved in the decision-making process. The laws on quarantine will also need to be clarified as the regulations for the Apollo program were rescinded. In the Apollo era, NASA delayed announcement of its quarantine regulations until the day Apollo was launched, so bypassing the requirement for public debate - something that would be unlikely to be tolerated today.",1
"Several exobiologists have suggested that a Mars sample-return is not necessary at this stage, and that it is better to focus more on in situ studies on the surface first. Although it is not their main motivation, this approach of course also eliminates back contamination risks. Some of these exobiologists advocate more in situ studies followed by a sample-return in the near future. Others go as far as to advocate in situ study instead of a sample-return at the present state of understanding of Mars.Their reasoning is that life on Mars is likely to be hard to find.",1
"Any present day life is likely to be sparse and occur in only a few niche habitats. Past life is likely to be degraded by cosmic radiation over geological time periods if exposed in the top few meters of the Mars surface. Also, only certain special deposits of salts or clays on Mars would have the capability to preserve organics for billions of years.",1
"So, they argue, there is a high risk that a Mars sample-return at our current stage of understanding would return samples that are no more conclusive about the origins of life on Mars or present day life than the Martian meteorite samples we already have. Another consideration is the difficulty of keeping the sample completely free from Earth life contamination during the return journey and during handling procedures on Earth. This might make it hard to show conclusively that any biosignatures detected does not result from contamination of the samples. Instead they advocate sending more sensitive instruments on Mars surface rovers.",1
"These could examine many different rocks and soil types, and search for biosignatures on the surface and so examine a wide range of materials which could not all be returned to Earth with current technology at reasonable cost. A sample-return to Earth would then be considered at a later stage, once we have a reasonably thorough understanding of conditions on Mars, and possibly have already detected life there, either current or past life, through biosignatures and other in situ analyses.",1
"NASA Marshall Space Flight Center is leading a research effort to develop a Miniaturized Variable Pressure Scanning Electron Microscope (MVP-SEM) for future lunar and Martian missions.Several teams, including Jonathan Rothberg, and J. Craig Venter, are separately developing solutions for sequencing alien DNA directly on the Martian surface itself. Levin is working on updated versions of the Labeled release instrument flown on Viking. For instance versions that rely on detecting chirality. This is of special interest because it can enable detection of life even if it is not based on standard life chemistry.",1
"The Urey Mars Organic and Oxidant Detector instrument for detection of biosignatures has been descoped, but was due to be flown on ExoMars in 2018. It is designed with much higher levels of sensitivity for biosignatures than any previous instruments",1
"In August 2019, scientists reported that a capsule containing tardigrades (a resilient microbial animal) in a cryptobiotic state may have survived for a while on the Moon after the April 2019 crash landing of Beresheet, a failed Israeli lunar lander.",1
"The preceding fundraiser, Team Trees, was started on October 25, 2019, by MrBeast and Mark Rober. They set to raise 20 million dollars, which was achieved. As of the start date of Team Seas, donations are still able to be made on the Team Trees website and planting progress is updated there. Team Seas aimed to remove 30,000,000 pounds (14,000,000 kg) of marine debris from the ocean by the end of 2021 by raising 30 million dollars, with one pound removed for every dollar donated.",1
"The project was mass released over the internet on many different social media platforms on Friday October 29, 2021, at 1 PM (PT). On YouTube, thousands of creators from 145 countries, with a combined follow count of 1 billion, created videos about the fundraiser. Most creators explained the purpose of Team Seas and convinced viewers to donate to Team Seas throughout the entirety of their videos, while some added a short explanatory segment in theirs. Videos on TikTok also featured a donation sticker for the campaign.MrBeast",1
"released a video on October 29, 2021, showing his team cleaning the polluted beaches of Bajos de Haina, Dominican Republic as volunteers for Ocean Conservancy. Mark Rober released a video on the same day, filmed with The Ocean Cleanup.On November 1, 2021, Tobi Lütke, CEO of Shopify, donated $1,200,001, exceeding the $1,000,001 he donated to Team Trees. Official website",1
"When a sufficient pressure drop (ΔP) occurs, the cleaning process begins. Cleaning can take place while the baghouse is online (filtering) or is offline (in isolation). When the compartment is clean, normal filtering resumes.Baghouses are very efficient particulate collectors because of the dust cake formed on the surface of the bags. The fabric provides a surface on which dust collects through the following four mechanisms: Inertial collection – Dust particles strike the fibers placed perpendicular to the gas-flow direction instead of changing direction with the gas stream.",1
"The three most common types of baghouses are mechanical shakers, reverse gas, and pulse jet.",1
"In mechanical-shaker baghouses, tubular filter bags are fastened onto a cell plate at the bottom of the baghouse and suspended from horizontal beams at the top. Dirty gas enters the bottom of the baghouse and passes through the filter, and the dust collects on the inside surface of the bags. Cleaning a mechanical-shaker baghouse is accomplished by shaking the top horizontal bar from which the bags are suspended. Vibration produced by a motor-driven shaft and cam creates waves in the bags to shake off the dust cake. Shaker baghouses range in size from small, handshaker devices to large, compartmentalized units.",1
"However, because of the simplicity of design, they are popular in the minerals processing industry.",1
"The pressure makes the bags collapse partially, causing the dust cake to crack and fall into the hopper below. At the end of the cleaning cycle, reverse airflow is discontinued, and the compartment is returned to the main stream. The flow of the dirty gas helps maintain the shape of the bag. However, to prevent total collapse and fabric chafing during the cleaning cycle, rigid rings are sewn into the bags at intervals. Space requirements for a reverse-air baghouse are comparable to those of a shaker baghouse; however, maintenance needs are somewhat greater.",1
"Some baghouses have ultrasonic horns installed to provide supplementary vibration to increase dust cleaning. The horns, which generate high intensity sound waves at the low end of the ultrasonic spectrum, are turned on just before or at the start of the cleaning cycle to help break the bonds between particles on the filter media surface and aid in dust removal.",1
"Pulse jet cleaning does not require taking compartments offline. Continuously cleaned baghouses are designed to prevent complete shutdown during bag maintenance and failures to the primary system. Baghouse performance is dependent upon inlet and outlet gas temperature, pressure drop, opacity, and gas velocity. The chemical composition, moisture, acid dew point, and particle loading and size distribution of the gas stream are essential factors as well. Gas temperature – Fabrics are designed to operate within a certain temperature range. Fluctuation outside of these limits, even for a small period of time, can weaken, damage, or ruin the bags.",1
"Pressure drop – Baghouses operate most effectively within a certain pressure drop range. This spectrum is based on a specific gas volumetric flow rate. Opacity – Opacity measures the quantity of light scattering that occurs as a result of the particles in a gas stream. Opacity is not an exact measurement of the concentration of particles; however, it is a good indicator of the amount of dust leaving the baghouse. Gas volumetric flow rate – Baghouses are created to accommodate a range of gas flows. An increase in gas flow rates causes an increase in operating pressure drop and air-to-cloth ratio.",1
The air-to-cloth ratio (ft/min or cm/s) is defined as the amount of gas entering the baghouse divided by the surface area of the filter cloth.,1
"Fabric filter bags are oval or round tubes, typically 15–30 feet (4.6–9.1 m) long and 5 to 12 inches (130 to 300 mm) in diameter, made of woven or felted material.Nonwoven materials are either felted or membrane. Nonwoven materials are attached to a woven backing (scrim). Felted filters contain randomly placed fibers supported by a woven backing material (scrim). In a membrane filter, a thin, porous membrane is bound to the scrim. High energy cleaning techniques such as pulse jet require felted fabrics. Woven filters have a definite repeated pattern.",1
"Astroscale was founded in 2013 by IT entrepreneur Mitsunobu ""Nobu"" Okada in Singapore. In April 2013, Okada attended an academic conference in Germany on space development where space junk was a hot topic. Many experts gave presentations on the issue and talked about potential solutions, but Okada was not impressed because no one had a real plan of action. Ten days later, he founded Astroscale to tackle the issue.On 16 February 2015, the company raised US$7.7 million in venture capital financing.",1
"21 November 2017, Astroscale and Surrey Satellite Technology (SSTL) signed a memorandum of understanding (MOU) to pursue joint opportunities in areas of innovative on-orbit technologies and missions designed to safeguard the orbital environment for future generations. As a first step, Astroscale contracted SSTL to supply the Client satellite and avionics for its ELSA-d mission. Astroscale established a ground station in Totsuka-ku, Yokohama on 4 July 2018. The primary purpose of the ground station is to enable the operation of ELSA-d.On",1
"24 July 2018, Astroscale received a £4 million grant from the Government of the United Kingdom and established the National In-orbit Servicing Control Centre Facility at the Satellite Applications Catapult in Harwell, Oxfordshire. The facility will support advanced robotics activities in the very hostile environment of space, specifically enabling the provision of a commercial service for de-orbiting small satellites. The new facility will initially control Astroscale's ELSA-d mission.On 31 October 2018, Astroscale obtained additional funding of US$50 million, bringing total amount of capital investment to US$102 million.Astroscale announced the incorporation of Astroscale U.S. Inc.",1
"and the opening of its Denver, Colorado office at the 35th Space Symposium in Colorado Springs, Colorado. With an additional US$30 million secured in an extension of its Series D investment round, Astroscale announced its plans to expand its United States presence, focusing on business development, policy influence and technology growth.On 23 January 2020, Astroscale announced it had been awarded a grant of up to US$4.5 million from the Tokyo Metropolitan Government's ""Innovation Tokyo Project"" to build a roadmap for commercializing active debris removal (ADR) services.On 3 June 2020, Astroscale U.S. Inc.",1
"announced it had entered into a definitive agreement to acquire the intellectual property and other assets and to hire certain members of the staff of Effective Space Solutions R&D Ltd., an Israeli satellite life-extension and servicing company. These moves make Astroscale the only company solely dedicated to on-orbit services across low Earth orbit (LEO) and geostationary orbit (GEO) and bring the company closer to realizing its vision of orbital sustainability for future generations.On 11 January 2022, Astroscale announced it has reached an agreement to prebuy fuel for its Life Extension In-orbit (LEXI™) Servicer.",1
"Between 2015 and 2017 Astroscale designed, built, tested and launched a 25 kg micro-lite satellite called IDEA OSG 1, an In-situ Debris Environment Analysis mission. The mission was designed to measure sub-millimetre size debris in low Earth orbit. Unfortunately, IDEA OSG1, Meteor-M No.2-1, and 17 other satellites on the Soyuz-2.1b launch vehicle failed to reach orbit due to human error in the programming of the rocket.",1
"The End-of-Life Services by Astroscale (ELSA) program is a spacecraft retrieval service for satellite operators. ELSA-d (demonstration) is the first mission to demonstrate the core technologies necessary for debris docking and removal. It was launched on 22 March 2021. ELSA-d consists of two spacecraft, a Servicer (~184 kg) and a Client (~16 kg), launched stacked together. The Servicer is equipped with proximity rendezvous technologies and a magnetic docking mechanism, while the Client has a ferromagnetic plate which enables it to be docked with.",1
"The Servicer will repeatedly release and dock with the Client in a series of technical demonstrations proving the capability to find and dock with debris. Demonstrations include target search, target inspection, target rendezvous, and both non-tumbling and tumbling docking. The first release and docking test was successfully conducted on 25 August 2021.ELSA-d is operated from the National In-orbit Servicing Control Centre Facility in Harwell, United Kingdom, a facility developed by Astroscale as a key part of the ground segment.",1
"In February 2020, Astroscale announced its selection as the commercial partner for Phase I of JAXA's first debris removal project. The JAXA Commercial Removal of Debris Demonstration project (CRD2) consists of two mission phases to achieve one of the world's first debris removal missions of a large object, the first of which has been awarded to Astroscale. This first phase will be demonstrated by the end of the Japan Fiscal Year 2022 and will focus on data acquisition on an upper stage Japanese rocket body.",1
"Astroscale will be responsible for the manufacturing, launch and operations of the satellite that will characterize the rocket body, acquiring and delivering movement observational data to better understand the debris environment. In September 2021, Rocket Lab and Astroscale announced that the ADRAS-J mission will launch on an Electron launch vehicle in 2023.",1
42 A number of factors are relevant in selecting a hydrodynamic separator product for a site.,1
"Costs for HDS systems depend on site-specific conditions such as land characteristics, amount of runoff to be treated, system depth and performance requirements. Be aware that not all HDS systems are alike in treatment performance, and basing a decision solely on the installation and operating cost of a system may compromise system performance and the environment. Long-term maintenance costs should also be considered with overall costs when purchasing or selecting a stormwater BMP as initial installation and operating costs may not reflect the long-term investment needed to maintain the system.",1
"Physically based models (sometimes known as deterministic, comprehensive or process-based models) try to represent the physical processes observed in the real world. Typically, such models contain representations of surface runoff, subsurface flow, evapotranspiration, and channel flow, but they can be far more complicated. ""Large scale simulation experiments were begun by the U.S. Army Corps of Engineers in 1953 for reservoir management on the main stem of the Missouri River"".",1
"In the United States the EPA has had difficulty interpreting diverse proprietary contaminant models and has to develop its own models more often than conventional resource agencies, who, focused on flood forecasting, have had more of a centroid of common basin models. Liden applied the HBV model to estimate the riverine transport of three different substances, nitrogen, phosphorus and suspended sediment in four different countries: Sweden, Estonia, Bolivia and Zimbabwe. The relation between internal hydrological model variables and nutrient transport was assessed. A model for nitrogen sources was developed and analysed in comparison with a statistical method.",1
"Metals are predominantly accumulated in the roots causing an unbalanced shoot to root ratio of metal concentrations in most plants. However, in hyperaccumulators, the shoot to root ratio of metal concentrations are abnormally higher in the leaves and much lower in the roots. As this process occurs, metals are efficiently shuttled from the root to the shoot as an enhanced ability in order to protect the roots from metal toxicity.Delving into tolerance: Throughout the research of hyperaccumulation, there is a conundrum with tolerance. There are several different understandings of tolerance associated with accumulation; however, there are a few similarities.",1
"Evidence has conveyed that the traits of tolerance and accumulation are separate to each other and are moderated by genetic and physiological mechanisms. Moreover, the physiological mechanisms, in relation to tolerance, are classified as exclusion: when the movement of metals at the interfaces of soil/root or root/shoot are blocked, or accumulation: when the uptake of metals that have been rendered as non-toxic are allowed into the aerial plant parts.Characteristics from certain physiological elements: There are certain characteristics that are specific to certain species.",1
"For example, when presented with a low supply of zinc, Thlaspi caerulescens had higher zinc concentrations accumulated compared to other non-accumulator plant species. Further evidence indicated that when T. caerulescens were grown on soil with an adequate amount of contamination, the species accumulated an amount of zinc that was 24-60 times more than Raphanus sativus (radish) had accumulated. Additionally, the capacity to experimentally manipulate soil metal concentrations with soil amendments has allowed researchers to identify the maximum soil concentrations that hyperaccumulation species can tolerate and the minimum soil concentrations in order to reach hyperaccumulation.",1
"It has been shown that hyperaccumulation capacities can be inherited in Thlaspi caerulescens (Brassicaceae) and others. As there is a wide variety among hyperaccumulating species that span across different plant families, it is likely that HA genes were eco typically selected for. In most hyperaccumulating plants, the main mechanism for metal transport are the proteins coded by genes in the ZIP family, however other families such as the HMA, MATE, YSL and MTP families have also been observed to be involved. The ZIP gene family is a novel, plant-specific gene family that encodes Cd, Mn, Fe and Zn transporters.",1
"The ZIP family plays a role in supplying Zn to metalloproteins.In one study on Arabidopsis, it was found that the metallophyte Arabidopsis halleri expressed a member of the ZIP family that was not expressed in a non-metallophyte sister species. This gene was an iron regulated transporter (IRT-protein) that encoded several primary transporters involved with cellular uptake of cations above the concentration gradient. When this gene was transformed into yeast, hyperaccumulation was observed. This suggests that overexpression of ZIP family genes that encode cation transporters is a characteristic genetic feature of hyperaccumulation.",1
"Another gene family that has been observed ubiquitously in hyperaccumulators are the ZTP and ZNT families. A study on T. caerulescens identified the ZTP family as a plant specific family with high sequence similarity to other zinc transporter4. Both the ZTP and ZNT families, like the ZIP family, are zinc transporters. It has been observed in hyperaccumulating species, that these genes, specifically ZNT1 and ZNT2 alleles are chronically overexpressed.While the precise mechanism by which these genes facilitate hyperaccumulation is unknown, expression patterns strongly correlate with individual hyperaccumulation capacity and metal exposure, implying that these gene families play a regulatory role.",1
"Because the presence and expression of zinc transporter gene families are highly prevalent in hyperaccumulators, the ability to accumulate a diverse range of heavy metals is most likely due to the zinc transporters' inability to discriminate against specific metal ions. The response of the plants to hyperaccumulation of any metal also supports this theory as it has been observed that AhHMHA3 is expressed in hyperaccumulating individuals. AhHMHA3 has been identified to be expressed in response to and aid of Zn detoxification. In another study, using metallophytic and non-metallophytic Arabidopsis populations, back crosses indicated pleiotropy between Cd and Zn tolerances.",1
"This response suggests that plants are unable to detect specific metals, and that hyperaccumulation is likely a result of an overexpressed Zn transportation system.The overall effect of these expression patterns has been hypothesized to assist in plant defense systems. In one hypothesis, ""the elemental defense hypothesis"", provided by Poschenrieder, it is suggested that the expression of these genes assist in antiherbivory or pathogen defenses by making tissues toxic to organisms attempting to feed on that plant. Another hypothesis, ""the joint hypothesis"", provided by Boyd, suggests that expression of these genes assists in systemic defense.",1
"An important trait of hyperaccumulating plant species is enhanced translocation of the absorbed metal to the shoot. Metal toxicity is tolerated by plant species that are native to metalliferous soils. Exclusion, in which plants resist undue metal uptake and transport, and absorption and sequestration, in which plants pick up vast quantities of metal and pass it to the shoot, where it is accumulated, are the two basic methods for metal tolerance. Hyperaccumulators are plants that have both the second technique and the ability to absorb more than 100 times higher metal concentrations than typical organisms.T.",1
"caerulescens is found mostly in Zn/Pb-rich soils, as well as serpentines and non-mineralized soils. It was discovered to be a Zn hyperaccumulator. Because of its ability to extract vast quantities of heavy metals from soils. When grown on mildly polluted soils, a closely related species, Thlaspi ochroleucum, is a heavy metal-tolerant plant, but it accumulates much less Zn in the shoots than T. caerulescens. Thus, Thlaspi ochroleucum is a non-hyperaccumulator and of the same family T. caerulescens is a hyperaccumulator. The transfer of Zn from roots to shoots varied significantly between these two species. T.",1
"caerulescens had much higher shoot/root Zn concentration levels than T. ochroleucum, which always had higher Zn concentrations in the roots. When Zn was withheld, the amount of Zn previously accumulated in the roots in T. caerulescens decreased even more than in T. ochroleucum, with a concomitantly greater rise in the amount of Zn in the shoots. The decreases in Zn in roots may be mostly due to transport to shoots, since the volume of Zn in shoots increased during the same time span.A heavy metal transporter, cDNA, mediates high-affinity Zn2+ uptake as well as low-affinity Cd2+ uptake.",1
"This transporter is expressed at very high levels in roots and shoots of the hyperaccumulator. According to (Pence et., al. 1999), an overexpression of a Zn transporter gene, ZNT1, in root and shoot tissue is an essential component of the Zn hyperaccumulation trait in T. caerulescens. This increased gene expression has been shown to be the basis for increased Zn21 uptake from the soil in T. caerulescens roots, and it is possible that the same process underpins the enhanced Zn21 uptake into leaf cells. List of hyperaccumulators Phytoremediation Metallophyte 13. Souri Z, Karimi N, Luisa M. Sandalio. 2017.",1
"Arsenic Hyperaccumulation Strategies: An Overview. Frontiers in Cell and Developmental Biology. 5, 67. DOI: 10.3389/fcell.2017.00067.",1
"were so equipped by voluntary industry action so as to avoid having to make multiple state-specific versions of vehicles. PCV quickly became standard equipment on all vehicles worldwide because of its benefits not only in emissions reduction but also in engine internal cleanliness and oil lifespan.In 1967, several years after its introduction into production, the PCV system became the subject of a U.S. federal grand jury investigation, when it was alleged by some industry critics that the Automobile Manufacturers Association (AMA) was conspiring to keep several such smog reduction devices on the shelf to delay additional smog control.",1
"A properly designed crankcase breather will also be designed in a manner that promotes the scavenging effect, or the creation of suction within the crankcase breather to further aid in the removal of blow-by gases. It is this effect that keeps the crankcase at slightly negative pressure when a properly functioning PCV system is in place.",1
"The PCV valve controls the flow of crankcase gases entering the intake system. At idle, with almost closed throttle, the manifold vacuum is high, which would draw in a large quantity of crankcase gases, causing the engine to run too lean. The PCV valve closes when the manifold vacuum is high, restricting the quantity of crankcase gases entering the intake system.When the engine is under load or operating at higher RPM, a higher quantity of blow-by gases are produced.",1
"The PCV valve gains an even more important function in increasingly popular forced induction applications. Excessive crankcase pressure will not only occur due to blow-by gases escaping past the piston rings but can also be introduced when positive pressure from the intake manifold makes its way into the crankcase. As previously mentioned, in vehicles with forced induction systems such as turbochargers or superchargers, the engine's intake manifold experiences positive pressure under load. This differs from naturally aspirated applications where the intake manifold will remain in vacuum while under load.",1
"In addition to this added role, in boosted applications cylinder pressures are much higher, and consequently, more blow-by gases are pushed into the crankcase thus making a fully functional PCV system all the more important.",1
"The references are so far mostly from academic trial papers, experiments and generally of exploration of that field. Phytoremediation, Hyperaccumulators List of hyperaccumulators Hyperaccumulators table – 3",1
"Uranium: The symbol for Uranium is sometimes given as Ur instead of U. According to Ulrich Schmidt and others, plants' concentration of uranium is considerably increased by an application of citric acid, which solubilizes the uranium (and other metals). Radionuclides: Cs-137 and Sr-90 are not removed from the top 0.4 meters of soil even under high rainfall, and migration rate from the top few centimeters of soil is slow. Radionuclides: Plants with mycorrhizal associations are often more effective than non-mycorrhizal plants at the uptake of radionuclides.",1
"Radionuclides: In general, soils containing higher amounts of organic matter will allow plants to accumulate higher amounts of radionuclides. See also note on Lolium multiflorum in Paasikallio 1984. Plant uptake is also increased with a higher cation exchange capacity for Sr-90 availability, and a lower base saturation for uptake of both Sr-90 and Cs-137. Radionuclides: Fertilizing the soil with nitrogen if needed will indirectly increase the take-up of radionuclides by generally boosting the plant's overall growth and more specifically roots' growth.",1
"But some fertilizers such as K or Ca compete with the radionuclides for cation exchange sites, and will not increase the take-up of radionuclides. Radionuclides: Zhu and Smolders, lab test: Cs uptake is mostly influenced by K supply. The uptake of radiocaesium depends mainly on two transport pathways on plant root cell membranes: the K+ transporter and the K+ channel pathway. Cs is likely transported by the K+ transport system.",1
"When external concentration of K is limited to low levels, le K+ transporter shows little discrimination against Cs+; if K supply is high, the K+ channel is dominant and shows high discrimination against Cs+. Caesium is very mobile within the plant, but the ratio Cs/K is not uniform within the plant. Phytoremediation as a possible option for the decontamination of caesium-contaminated soils is limited mainly by that it takes tens of years and creates large volumes of waste. Alpine pennycress or Alpine Pennygrass is found as Alpine Pennycrest in (some books).",1
"The references are so far mostly from academic trial papers, experiments and generally of exploration of that field. Radionuclides: Broadley and Willey find that across 30 taxa studied, Gramineae and Chenopodiaceae show the strongest correlation between Rb (K) and Cs concentration. The fast-growing Chenopodiaceae discriminate approx. 9 times less between Rb and Cs than the slow-growingGramineae, and this correlate with highest and lowest concentrations achieved respectively. Caesium: In Chernobyl-derived radioactivity, the amount of contamination is dependent on the roughness of bark, absolute bark surface and the existence of leaves during the deposition.",1
"The major contamination of the shoots is from direct deposition on the trees. Hyperaccumulators table – 1 : Al, Ag, As, Be, Cr, Cu, Mn, Hg, Mo, Naphthalene, Pb, Pd, Pt, Se, Zn Hyperaccumulators table – 2 : Nickel",1
"In 2013, Dr. Earle McBride, a researcher studying sandstone diagenesis and the textual and compositional maturation of sand during transportation, mixed samples collected from Omaha Beach in 1988 with a blue epoxy, creating an ""artificial sandstone"", before slicing it into thin sections. Utilising an optical microscope and an external light source, shiny, opaque grains could be identified. Although wave action had elicited rounding on the edges of some coarser grains, the shard-like angularity and corrosion of both coarse and fine grains suggested these grains were man-made.",1
"It is believed that the roughness of said grains was imparted by microporous surfaces produced during production and corrosion products post-explosion.This inspection, alongside tests revealing that the grains were magnetic, led McBride to conclude these grains were pieces of shrapnel.",1
Runoff Footprint Calculator EPA's National Stormwater Calculator James River Association Runoff Calculator,1
"This demonstration project was led by Cao Jun Ji, a chemist at the Chinese Academy of Sciences' Key Laboratory of Aerosol Chemistry and Physics. This work has since been published on, with the performance data and modelling.",1
"Private wells are not regulated by the federal government. In general, private well owners are responsible for testing their wells. Some state or local governments regulate well construction and may require well testing. Generally well testing required by local governments is limited to a handful of contaminants including coliform and E. Coli bacteria and perhaps a few predominant local contaminants such as nitrates or arsenic. EPA publishes test methods for contaminants that it regulates under the SDWA.",1
Several trends to monitor include digital sensor plug-and-play techniques and luminescent dissolved oxygen meters replacing sensors.,1
"Companies tend to employ the ""direct-to-end-user"" model for most products, but may also try to sell low-end equipment via the Internet to reduce distribution costs.",1
Pricing depends on application and type of product. Instruments range from as low as $10 to thousands of dollars.,1
"Most of the commercial laboratories are single-site firms that only service institutions in the geographical region. The employee head count for each laboratory is usually fewer than five people, and revenues are under $1 million. These laboratories account for one quarter of all tests. There are several major laboratory groups, such as UK-based Inspicio and Australia-based ALS, which account for another quarter of all tests.",1
"In 2011, Hong Kong Education Secretary Michael Suen was diagnosed with Legionnaires' disease. The bacteria contamination stemmed from Hong Kong's HK$5.5 billion government headquarters site, where traces of the bacteria were found to be up to 14 times above acceptable levels.",1
The motion to dismiss was based on the lawyer's argument that the documents referred to in the indictment were not signed and were not submitted to a government agency.,1
"The device is defined by the American Society for Testing and Materials (ASTM) in their Standard D2156 ""Standard Test Method for Smoke Density in Flue Gases"", first published in 1965, revised several times, most recently in 2018. The instrument provides the technician with a dark spot on a filter paper strip which is then compared with a standard darkness chart, commonly numbered 0 to 10, 0 being entirely white and 10 being entirely black.",1
Original text Overview - United Nations Economic Commission for Europe webpage Amended text (April 2010) Signatures and ratifications,1
"Abandoned footwear is a feature in a number of artistic works, including: Some artists derive insight and inspiration from abandoned footwear - a form of art known as objet trouvé.The lost slipper in the Cinderella folktale is a classic example of the literary device of the ""lost object"".A fisherman hauling up an old boot, rather than a fish, is a comic-strip cliché.The theme of abandoned footwear and their untold story is explored in detail in Julie Ann Shapiro's novel, Jen-Zen and the One Shoe Diaries.",1
"The titular character describes the phenomenon, “The forgotten shoes are everywhere: littering the side of the highway, floating in the tide, going upstream with the salmon, or occupying a field like a dead body, discarded and left to rot.” Leaving behind shoes can be a symbol of retirement in sport. For example, as ESPN's Sherry Skalko describes about Rulon Gardner's last wrestling bout in Athens, Greece: An emotional Rulon Gardner prepares to leave his shoes on the mat -- a symbol of retirement.",1
"After the referee raised Gardner's hand in victory -- first to one side of the arena, then to the other -- Gardner grabbed an American flag, wiped away tears and parked himself in the middle of Mat B like ""a 33-year-old kid"" and took off his size 13 shoes. First the right one, the one that contains the constant reminder of the snowmobiling accident that almost took his life two years ago, then the left.",1
"Then the super heavyweight bronze medalist stood up, bowed his head at each side of the mat and walked off, leaving his shoes behind, a wrestler's signal that he had fought his final bout. An unusual abundance of abandoned shoes was found on Miami's Palmetto Expressway on Friday, 2 January 2009. Thousands of assorted shoes of all kinds and conditions were scattered across the highway, disrupting traffic for many hours. The shoes were collected for the charity Soles4Souls which redistributes shoes to needy people. This unusually large batch of shoes was expected to go to Haiti.",1
"Shoe tossing, shoes tied by their laces hanging from overhead wires Ghost shoes (traffic fatality memorial) Salish Sea human foot discoveries The Secret Language of Sneakers, Snopes.com",1
"drainage is prevalent in the United States state of Pennsylvania, as well as several other states that have historically had large mining industries. In Pennsylvania, nearly 2,500 miles (4,000 km) of streams have been affected by abandoned mine drainage, and more than 7,500 miles (12,100 km) have been affected in the Appalachian Mountains, and more than 10,000 miles (16,000 km) are affected in Pennsylvania and West Virginia.In one watershed affected by abandoned mine drainage, the value of homes within 200 feet (61 m) of an affected stream decreased by $2500 per 1 acre (0.40 ha), as of 2009.Algae",1
"When gas stored under pressure in a closed vessel is discharged to the atmosphere through a hole or other opening, the gas velocity through that opening may be choked (i.e., it has attained a maximum) or it may be non-choked.",1
"Choked velocity, also referred to as sonic velocity, occurs when the ratio of the absolute source pressure to the absolute downstream pressure is equal to or greater than [(k + 1) / 2]k / (k − 1), where k is the specific heat ratio of the discharged gas (sometimes called the isentropic expansion factor and sometimes denoted as γ {\displaystyle \gamma } ). For many gases, k ranges from about 1.09 to about 1.41, and therefore [(k + 1) / 2]k / (k − 1 ) ranges from 1.7 to about 1.9,",1
which means that choked velocity usually occurs when the absolute source vessel pressure is at least 1.7 to 1.9 times as high as the absolute downstream ambient atmospheric pressure.,1
"When the gas velocity is choked, the equation for the mass flow rate in SI metric units is: Q = C A k ρ P ( 2 k + 1 ) k + 1 k − 1 {\displaystyle Q\;=\;C\;A\;{\sqrt {\;k\;\rho \;P\;\left({\frac {2}{k+1}}\right)^{\frac {k+1}{k-1}}}}} or this equivalent form: Q = C A P ( k M Z R T ) ( 2 k + 1 ) k + 1 k − 1 {\displaystyle Q\;=\;C\;A\;P\;{\sqrt {\left({\frac {\;\,k\;M}{Z\;R\;T}}\right)\left({\frac {2}{k+1}}\right)^{\frac {k+1}{k-1}}}}} For the above equations, it is important to note that although the gas velocity reaches a maximum and becomes choked, the mass flow rate",1
"is not choked. The mass flow rate can still be increased if the source pressure is increased. Whenever the ratio of the absolute source pressure to the absolute downstream ambient pressure is less than [ (k + 1) / 2]k / (k − 1), then the gas velocity is non-choked (i.e.,",1
"sub-sonic) and the equation for mass flow rate is: Q = C A 2 ρ P [ k k − 1 ] [ ( P A P ) 2 k − ( P A P ) k + 1 k ] {\displaystyle Q\;=\;C\;A\;{\sqrt {\;2\;\rho \;P\;\left[{\frac {k}{k-1}}\right]\left[\left({\frac {P_{A}}{P}}\right)^{\frac {2}{k}}-\;\,\left({\frac {\;P_{A}}{P}}\right)^{\frac {k+1}{k}}\;\right]}}} or this equivalent form: Q = C A P [ 2 M Z R T ] [ k k − 1 ] [ ( P A P ) 2 k − ( P A P ) k + 1 k ] {\displaystyle Q\;=\;C\;A\;P\;{\sqrt {\left[{\frac {2\;M}{Z\;R\;T}}\right]\left[{\frac {k}{k-1}}\right]\left[\,\left({\frac {P_{A}}{P}}\right)^{\frac {2}{k}}-\;\,\left({\frac {P_{A}}{P}}\right)^{\frac {k+1}{k}}\;\right]}}} The",1
"above equations calculate the initial instantaneous mass flow rate for the pressure and temperature existing in the source vessel when a release first occurs. The initial instantaneous flow rate from a leak in a pressurized gas system or vessel is much higher than the average flow rate during the overall release period because the pressure and flow rate decrease with time as the system or vessel empties. Calculating the flow rate versus time since the initiation of the leak is much more complicated, but more accurate. Two equivalent methods for performing such calculations are presented and compared at.The",1
"technical literature can be very confusing because many authors fail to explain whether they are using the universal gas law constant R which applies to any ideal gas or whether they are using the gas law constant Rs which only applies to a specific individual gas. The relationship between the two constants is Rs = R/M. Notes: The above equations are for a real gas. For an ideal gas, Z = 1 and ρ is the ideal gas density. 1 kilomole (kmol) = 1000 moles = 1000 gram-moles = kilogram-mole.",1
"P.K. Ramskill's equation for the non-choked flow of an ideal gas is shown below as equation (1): (1) Q = C ρ A A 2 P ρ ⋅ k k − 1 ⋅ [ 1 − ( P A P ) k − 1 k ] {\displaystyle Q=C\;\rho _{A}\;A\;{\sqrt {{\frac {\;\,2\;P}{\rho }}\cdot {\frac {k}{k-1}}\cdot \left[\;1-{\left({\frac {P_{A}}{P}}\right)^{\frac {k-1}{k}}}\right]}}} The gas density, ρ {\displaystyle \rho } A, in Ramskill's equation is the ideal gas density at the downstream conditions of temperature and pressure and it is defined in equation (2) using the ideal gas law: (2) ρ A = M P A R",1
with Ramskill's equation (1) to determine non-choked mass flow rates for ideal gases gives identical results to the results obtained using the non-choked flow equation presented in the previous section above. Three different methods of calculating the rate of evaporation from a non-boiling liquid pool are presented in this section. The results obtained by the three methods are somewhat different.,1
TP2 P H = 760 ⋅ e 65.3319 − 7245.2 T A − 8.22 ln ⁡ ( T a ) + 0.0061557 T A {\displaystyle P_{H}=760\cdot e^{65.3319-{\frac {7245.2}{T_{A}}}-8.22\;\ln \left(T_{a}\right)+0.0061557\;T_{A}}},1
"become 1.0 = (ft/m)² × mmHg/kPa. The U.S. EPA also defined the pool depth as 0.01 m (i.e., 1 cm) so that the surface area of the pool liquid could be calculated as: A = (pool volume, in m3)/(0.01)Notes: 1 kPa = 0.0102 kgf/cm2 = 0.01 bar mol = mole atm = atmosphere",1
"The following equations are for predicting the rate at which liquid evaporates from the surface of a pool of liquid which is at or near the ambient temperature. The equations were developed by Warren Stiver and Dennis Mackay of the Chemical Engineering Department at the University of Toronto. E = k ⋅ P ⋅ M R ⋅ T A {\displaystyle E={\frac {k\cdot P\cdot M}{R\cdot T_{A}}}} The following equation is for predicting the rate at which liquid evaporates from the surface of a pool of cold liquid (i.e., at a liquid temperature of about 0 °C or less). E = 0.0001",1
"At first, the main focus in this research lay on local effects of acid rain. Waldemar Christofer Brøgger was the first to acknowledge long-distance transportation of pollutants crossing borders from the United Kingdom to Norway – a problem systematically studied by Brynjulf Ottar in the 1970s. Ottar's work was strongly influenced by Swedish soil scientist Svante Odén, who had drawn widespread attention to Europe's acid rain problem in popular newspapers and wrote a landmark paper on the subject in 1968.",1
"1980, the US Congress passed an Acid Deposition Act. This Act established an 18-year assessment and research program under the direction of the National Acidic Precipitation Assessment Program (NAPAP). NAPAP enlarged a network of monitoring sites to determine how acidic the precipitation actually was, seeking to determine long-term trends, and established a network for dry deposition. Using a statistically based sampling design, NAPAP quantified the effects of acid rain on a regional basis by targeting research and surveys to identify and quantify the effects of acid precipitation on freshwater and terrestrial ecosystems.",1
"In 1983, the panel of scientists came up with a draft report, which concluded that acid rain is a real problem and solutions should be sought. White House Office of Science and Technology Policy reviewed the draft report and sent Fred Singer's suggestions of the report, which cast doubt on the cause of acid rain. The panelists revealed rejections against Singer's positions and submitted the report to Nierenberg in April. In May 1983, the House of Representatives voted against legislation that aimed to control sulfur emissions. There was a debate about whether Nierenberg delayed to release the report.",1
"Nierenberg himself denied the saying about his suppression of the report and stated that the report was withheld after the House's vote because it was not ready to be published.In 1991, the US National Acid Precipitation Assessment Program (NAPAP) provided its first assessment of acid rain in the United States. It reported that 5% of New England Lakes were acidic, with sulfates being the most common problem. They noted that 2% of the lakes could no longer support Brook Trout, and 6% of the lakes were unsuitable for the survival of many species of minnow.",1
"Canadian Harold Harvey was among the first to research a ""dead"" lake. In 1971, he and R. J. Beamish published a report, ""Acidification of the La Cloche Mountain Lakes"", documenting the gradual deterioration of fish stocks in 60 lakes in Killarney Park in Ontario, which they had been studying systematically since 1966.In the 1970s and 80s, acid rain was a major topic of research at the Experimental Lakes Area (ELA) in Northwestern Ontario, Canada. Researchers added sulfuric acid to whole lakes in controlled ecosystem experiments to simulate the effects of acid rain.",1
"Because its remote conditions allowed for whole-ecosystem experiments, research at the ELA showed that the effect of acid rain on fish populations started at concentrations much lower than those observed in laboratory experiments. In the context of a food web, fish populations crashed earlier than when acid rain had direct toxic effects to the fish because the acidity led to crashes in prey populations (e.g. mysids). As experimental acid inputs were reduced, fish populations and lake ecosystems recovered at least partially, although invertebrate populations have still not completely returned to the baseline conditions.",1
"In 1998, all federal, provincial, and territorial Ministers of Energy and Environment signed The Canada-Wide Acid Rain Strategy for Post-2000, which was designed to protect lakes that are more sensitive than those protected by earlier policies. The most important gas which leads to acidification is sulfur dioxide. Emissions of nitrogen oxides which are oxidized to form nitric acid are of increasing importance due to stricter controls on emissions of sulfur compounds. 70 Tg(S) per year in the form of SO2 comes from fossil fuel combustion and industry, 2.8 Tg(S) from wildfires, and 7–8 Tg(S) per year from volcanoes.",1
"The principal natural phenomena that contribute acid-producing gases to the atmosphere are emissions from volcanoes. Thus, for example, fumaroles from the Laguna Caliente crater of Poás Volcano create extremely high amounts of acid rain and fog, with acidity as high as a pH of 2, clearing an area of any vegetation and frequently causing irritation to the eyes and lungs of inhabitants in nearby settlements. Acid-producing gasses are also created by biological processes that occur on the land, in wetlands, and in the oceans. The major biological source of sulfur compounds is dimethyl sulfide.",1
"Nitric acid in rainwater is an important source of fixed nitrogen for plant life, and is also produced by electrical activity in the atmosphere such as lightning.Acidic deposits have been detected in glacial ice thousands of years old in remote parts of the globe.",1
"The principal cause of acid rain is sulfur and nitrogen compounds from human sources, such as electricity generation, animal agriculture, factories, and motor vehicles. Industrial acid rain is a substantial problem in China and Russia and areas downwind from them. These areas all burn sulfur-containing coal to generate heat and electricity.The problem of acid rain has not only increased with population and industrial growth, but has become more widespread.",1
"The most important oxidation reactions are with ozone, hydrogen peroxide and oxygen (reactions with oxygen are catalyzed by iron and manganese in the cloud droplets).",1
"Wet deposition of acids occurs when any form of precipitation (rain, snow, and so on) removes acids from the atmosphere and delivers it to the Earth's surface. This can result from the deposition of acids produced in the raindrops (see aqueous phase chemistry above) or by the precipitation removing the acids either in clouds or below clouds. Wet removal of both gases and aerosols are both of importance for wet deposition.",1
"Acid deposition also occurs via dry deposition in the absence of precipitation. This can be responsible for as much as 20 to 60% of total acid deposition. This occurs when particles and gases stick to the ground, plants or other surfaces. Acid rain has been shown to have adverse impacts on forests, freshwaters and soils, killing insect and aquatic life-forms as well as causing damage to buildings and having impacts on human health.",1
"Soil biology and chemistry can be seriously damaged by acid rain. Some microbes are unable to tolerate changes to low pH and are killed. The enzymes of these microbes are denatured (changed in shape so they no longer function) by the acid. The hydronium ions of acid rain also mobilize toxins, such as aluminium, and leach away essential nutrients and minerals such as magnesium.",1
"Moreover, a plant suffering from soil acidification cannot photosynthesize; the acid-water-induced process of drying out of the plant can destroy chloroplast organelles. Without being able to photosynthesize, a plant cannot create nutrients for its own survival or oxygen for the survival of aerobic organisms, which affects most species on Earth and ultimately ends the purpose of the plant's existence.",1
"Adverse effects may be indirectly related to acid rain, like the acid's effects on soil (see above) or high concentration of gaseous precursors to acid rain. High altitude forests are especially vulnerable as they are often surrounded by clouds and fog which are more acidic than rain.Other plants can also be damaged by acid rain, but the effect on food crops is minimized by the application of lime and fertilizers to replace lost nutrients.",1
"In cultivated areas, limestone may also be added to increase the ability of the soil to keep the pH stable, but this tactic is largely unusable in the case of wilderness lands. When calcium is leached from the needles of red spruce, these trees become less cold tolerant and exhibit winter injury and even death.",1
"Acid rain has a much less harmful effect on oceans on a global scale, but it creates an amplified impact in the shallower waters of coastal waters. Acid rain can cause the ocean's pH to fall, known as ocean acidification, making it more difficult for different coastal species to create their exoskeletons that they need to survive. These coastal species link together as part of the ocean's food chain, and without them being a source for other marine life to feed off of, more marine life will die.",1
"Coral's limestone skeleton is particularly sensitive to pH decreases, because the calcium carbonate, a core component of the limestone skeleton, dissolves in acidic (low pH) solutions. In addition to acidification, excess nitrogen inputs from the atmosphere promote increased growth of phytoplankton and other marine plants, which, in turn, may cause more frequent harmful algal blooms and eutrophication (the creation of oxygen-depleted ""dead zones"") in some parts of the ocean.",1
"Acid rain can damage buildings, historic monuments, and statues, especially those made of rocks, such as limestone and marble, that contain large amounts of calcium carbonate. Acids in the rain react with the calcium compounds in the stones to create gypsum, which then flakes off. CaCO3 (s) + H2SO4 (aq) ⇌ CaSO4 (s) + CO2 (g) + H2O (l)The effects of this are commonly seen on old gravestones, where acid rain can cause the inscriptions to become completely illegible. Acid rain also increases the corrosion rate of metals, in particular iron, steel, copper and bronze.",1
"Places significantly impacted by acid rain around the globe include most of eastern Europe from Poland northward into Scandinavia, the eastern third of the United States, and southeastern Canada. Other affected areas include the southeastern coast of China and Taiwan.",1
Fluidized bed combustion also reduces the amount of sulfur emitted by power production. Vehicle emissions control reduces emissions of nitrogen oxides from motor vehicles.,1
"Following these discussions, the Acid Deposition Monitoring Network in East Asia (EANET) was established in 2001 as an intergovernmental initiative to provide science-based inputs for decision makers and promote international cooperation on acid deposition in East Asia. In 2023, the EANET member countries include Cambodia, China, Indonesia, Japan, Lao PDR, Malaysia, Mongolia, Myanmar, the Philippines, Republic of Korea, Russia, Thailand and Vietnam.",1
"ATP is a molecule found in and around living cells, and as such it gives a direct measure of biological concentration and health. ATP is quantified by measuring the light produced through its reaction with the naturally occurring firefly enzyme luciferase using a luminometer. The amount of light produced is directly proportional to the amount of ATP present in the sample.",1
"Adsorption/bio-oxidation process was invented in the mid-1970s by the professor of the RWTH Aachen University Botho Böhnke. It was based on the finding, made by the German engineer Karl Imhoff in the 50th. Imhoff stated that the treatment efficiency of 60-80 percent could be achieved in highly loaded activated sludge basins.In 1977 Böhnke published his first article on adsorption/bio-oxidation process. The same year the patent was issued. Extensive research of the following years, conducted by prof. Böhnke together with Bernd and Andreas Diering, ended up in 1985 with the establishment of the company Dr.-Ing. Bernd Diering GmbH.",1
"The same year AB-process was for the first time applied in a full-scale at the Krefeld, Germany sewage treatment plant (800 000 P.E.). In 1990, 19 full scale installations existed in Western Germany alone. Further application of the process in Europe was hindered by the tightening of the effluent discharge requirements with respect to nitrogen and phosphorus. The process came into notice in 2000th again due to the increased interest in energy recovery from wastewater. The A-stage, or adsorption stage is the most innovative component of the process. It is not preceded by primary treatment.",1
Influent organic matter is removed in the A-stage mainly by flocculation and sorption to sludge due to the high loading rates (2-10 g BOD • g VSS−1 • d−1) and low sludge age (typically 4-10 h). Hydrolysis of complex organic molecules occurs improving biodegradability of the influent of the B-stage. High loading rates and low sludge age favours development of dynamic biocoenosis with a large fraction of microorganisms present in the exponential growth phase. Diverse sludge biocoenosis increase variety of organic compounds that can be degraded in the A-stage and makes the process more stable towards the shock loads.,1
"Altogether, up to 80% of the influent organic matter can be removed in the A-stage. The required reactor volume and oxygen supply are lower if compared to the removal in the conventional activated sludge process.The B-stage, or bio-oxidation stage, is a typical low-loaded activated sludge process, where biodegradation of the remaining organic material occurs. The B-stage can be designed for nitrogen and/or phosphorus removal by alternating aerobic, anoxic and anaerobic zones in the reactor.",1
"Lower aeration requirements decrease energy consumption and aeration costs for 20 percent if compared with conventional single stage activated sludge plant. The volumes of aeration tanks are 40% lower if compared with conventional single stage activated sludge plant. Increased sludge production in the A-stage results in increased biogas production in the digester (for plants with anaerobic digestion of excess sludge). Stability towards the shock loads (pH, chemical oxygen demand (COD), toxic substances) explained by the wide-ranging biochemical potential, high mutation capacity and adaptability of sludge in the A-stage. A-stage can receive higher organic loads than conventional activated sludge systems.",1
"Effluent concentrations are more stable because of the two-stage process configuration employed. Heavy metals are mainly removed with the A-stage sludge. Therefore, B-stage sludge has lower concentrations of heavy metals than sludge from conventional activated sludge process and may comply with the agricultural standards.",1
"High retention times cause an increased need for additional reactors to maintain throughput increasing equipment costs Nitrogen removal in the A-stage can reach 30-40%, as nitrogen of organic compounds is incorporated in upflow anaerobic sludge blanket (UASB) reactor sludge. The sludge age of the B-stage is typically between 8 and 20 days promoting the growth of nitrifiers. Therefore, complete nitrification is usually achieved in the B-stage. Complete denitrification is difficult to achieve, because of the low C:N ratio in the influent of the B-stage.",1
"Insufficient carbon supply of carbon source to the B-stage occurs due to the high efficiency of organic matter removal in the A-stage. The problem can be solved by decreasing organic matter removal in the A-stage, external carbon source supply, intermittent aeration or decreased HRT of the A-stage and/or on-line control of certain operational parameters. To achieve biological nitrogen and phosphorus removal anaerobic and anoxic compartments are introduced before the aerated zone of the B-stage.Phosphorus removal from the secondary effluent of the B-stage can be achieved by coagulation with ferric and aluminium salts, e.g. FeCl3 or Al2(SO4)3.",1
"The adsorption/bio-oxidation process was applied at the Krefeld plant (800 000 P.E.) in 1985 for the first time. The plant was expanded and modified and currently treats municipal and industrial wastewater of 1 200 000 P.E.Currently adsorption/bio-oxidation process is applied at the municipal treatment plants in Germany, the Netherlands (WWTP Dokhaven (Rotterdam), WWTP Utrecht, WWTP Garmerwolde (Groningen) etc.), Austria (WWTP Salzburg, WWTP Strass etc.), Spain, USA, China etc.Adsorption/bio-oxidation process is a part of innovative wastewater treatment concept WaterSchoon, realized in the Netherlands.",1
"The following definition differentiates an aerobic granule from a simple floc with relatively good settling properties and came out of discussions which took place at the 1st IWA-Workshop Aerobic Granular Sludge in Munich (2004): Granules making up aerobic granular activated sludge are to be understood as aggregates of microbial origin, which do not coagulate under reduced hydrodynamic shear, and which settle significantly faster than activated sludge flocs Granular sludge biomass is developed in sequencing batch reactors (SBR) and without carrier materials.",1
"These systems fulfil most of the requirements for their formation as: Feast – Famine regime: short feeding periods must be selected to create feast and famine periods (Beun et al. 1999), characterized by the presence or absence of organic matter in the liquid media, respectively. With this feeding strategy the selection of the appropriate micro-organisms to form granules is achieved. When the substrate concentration in the bulk liquid is high, the granule-former organisms can store the organic matter in form of poly-β-hydroxybutyrate to be consumed in the famine period, giving an advantage over filamentous organisms.",1
"cm/s in a column SBR, and more regular, rounder, and more compact aerobic granules were developed at high hydrodynamic shear forces (Tay et al., 2001 ).Granular activated sludge is also developed in flow-through reactors using the Hybrid Activated Sludge (HYBACS) process, comprising an attached-growth reactor with short retention time upstream of a suspended growth reactor. The attached bacteria in the first reactor, known as a SMART unit, are exposed to a constant high COD, triggering the expression of high concentrations of hydrolytic enzymes in the EPS layer around the bacteria.",1
"The accelerated hydrolysis liberates soluble readily-degradable COD which promotes the formation of granular activated sludge. The development of biomass in the form of aerobic granules is being studied for its application in the removal of organic matter, nitrogen and phosphorus compounds from wastewater.",1
"Aerobic granules in an aerobic SBR present several advantages compared to conventional activated sludge process such as: Stability and flexibility: the SBR system can be adapted to fluctuating conditions with the ability to withstand shock and toxic loadingsLow energy requirements: the aerobic granular sludge process has a higher aeration efficiency due to operation at increased height, while there are neither return sludge or nitrate recycle streams nor mixing and propulsion requirementsReduced footprint: The increase in biomass concentration that is possible because of the high settling velocity of the aerobic sludge granules and the absence of a final settler result in a",1
"significant reduction in the required footprint.Good biomass retention: higher biomass concentrations inside the reactor can be achieved, and higher substrate loading rates can be treated.Presence of aerobic and anoxic zones inside the granules: to perform simultaneously different biological processes in the same system (Beun et al. 1999 )Reduced investment and operational costs: the cost of running a wastewater treatment plant working with aerobic granular sludge can be reduced by at least 20% and space requirements can be reduced by as much as 75% (de Kreuk et al., 2004).The",1
"Schwarzenbeck et al. (2004) treated malting wastewater which had a high content of particulate organic matter (0.9 g TSS/L). They found that particles with average diameters lower than 25–50 μm were removed at 80% efficiency, whereas particles bigger than 50 μm were only removed at 40% efficiency. These authors observed that the ability of aerobic granular sludge to remove particulate organic matter from the wastewaters was due to both incorporation into the biofilm matrix and metabolic activity of protozoa population covering the surface of the granules.",1
"Cassidy and Belia (2005) obtained removal efficiencies for COD and P of 98% and for N and VSS over 97% operating a granular reactor fed with slaughterhouse wastewater (Total COD: 7685 mg/L; soluble COD: 5163 mg/L; TKN: 1057 mg/L and VSS: 1520 mg/L). To obtain these high removal percentages, they operated the reactor at a DO saturation level of 40%, which is the optimal value predicted by Beun et al. (2001) for N removal, and with an anaerobic feeding period which helped to maintain the stability of the granules when the DO concentration was limited. Inizan et al.",1
"(2005) treated industrial wastewaters from pharmaceutical industry and observed that the suspended solids in the inlet wastewater were not removed in the reactor. Tsuneda et al. (2006), when treating wastewater from metal-refinery process (1.0–1.5 g NH4+-N/L and up to 22 g/L of sodium sulphate), removed a nitrogen loading rate of 1.0 kg-N/m3·d with an efficiency of 95% in a system containing autotrophic granules. Usmani et al.",1
"mm of diameter, SVI of 30 mL/g VSS and density around 60 g VSS/L-granule Farooqi et al. (2008), Wastewaters from fossil fuel refining, pharmaceuticals, and pesticides are the main sources of phenolic compounds. Those with more complex structures are often more toxic than the simple phenol. This study was aimed at assessing the efficacy of granular sludge in UASB and SBR for the treatment of mixtures of phenolics compounds.",1
"The formation of granules was performed using a synthetic substrate and after 120 days of operation, synthetic media was replaced by real winery wastewater, with a COD loading of 6 kg COD/(m3·d). Dobbeleers ""et al."" (2017), treated wastewater from potato industry. Granulation was successful achieved and simultaneous nitrification/denitrification was possible by short cutting the nitrogen cycle. Caluwé ""et al."" (2017), Compared an aerobic feast/famine strategy and an anaerobic feast, aerobic famine strategy for the formation of aerobic granular sludge during the treatment of industrial petrochemical wastewater. Both strategies were successful.",1
"Because of the high allowable volumetric load the footprint of the GSBR variants is only 25% compared to the references. However, the GSBR with only primary treatment cannot meet the present effluent standards for municipal wastewater, mainly because of exceeding the suspended solids effluent standard caused by washout of not well settleable biomass. Aerobic granulation technology is already successfully applied for treatment of wastewater. Since 2005, RoyalHaskoningDHV has implemented more than 20 full-scale aerobic granular sludge technology systems (Nereda) for the treatment of both industrial and municipal wastewater across 3 continents.",1
"That report examined all exposures dating back to 1943 which showed that all documented exposures were to high concentrations, greatly in excess of the amount present in jet engine oil. He also noted that studies in Canada and the USA were unable to detect TCP in the cabin during flight. Prof Bagshaw notes that the symptoms are ""largely the same as those reported by participants in all phase I drug trials"", and are similar to the symptoms experienced by patients with chronic fatigue syndrome, gulf war syndrome, Lyme disease, chronic stress and chronic hyperventilation.""A",1
"syndrome is a symptom complex, consistent and common to a given condition. Individuals who have 'aerotoxic syndrome' describe a wide range of inconsistent symptoms and signs with much individual variability. The evidence was independently reviewed by the Aerospace Medical Association, the US National Academy of Sciences and the Australian Civil Aviation Safety Authority Expert Panel. All concluded there is insufficient consistency to establish a medical syndrome and the 'aerotoxic syndrome' is not recognised in aviation medicine."" Aerotoxic Association website",1
"Keep Britain Tidy runs a number of programmes in England, including Eco-Schools, Seaside Awards, BeachCare, RiverCare, WatersideCare, LOVEmyBEACH, Keep Britain Tidy Network, Love Parks, Big Tidy Up, Green Flag Award for parks and green spaces and the Blue Flag Award for beaches. The organisation managed Keep Scotland Beautiful, Keep Wales Tidy and Tidy Northern Ireland until 2004, at which point they became independent devolved organisations. The Eco-Schools and Blue Flag programmes in Wales, Northern Ireland, and Scotland are now run independently by these devolved organisations.",1
Clean Up Australia Keep America Beautiful National Cleanup Day National Tidy Town Awards (disambiguation) Thames21 Official website,1
"10A/380/15, dated 2 August 1996) of this potential hazard, as the misuse of this agent was apparently widespread."": 31 On 5 November 2000, both the captain and first officer of a Jersey European Airways BAe 146 became unwell while landing at Birmingham International Airport.: 1 Both became nauseous, and the captain experienced double vision and had difficulty judging height, but managed to land the aircraft safely.: 3–4 Both pilots were taken to a hospital but no cause for their illness was found.:",1
"In 1988, the FAA banned smoking on domestic flights of less than two hours, and extended the ban in 1990 to all domestic flights and in 2000 to international flights.The",1
He pointed to an unpublished report from the Medical Toxicology Unit at Guy's Hospital in 2001 which looked at all exposures dating back to 1943 that showed that all documented exposures were to high concentrations greatly in excess of the amount present in jet oil.In,1
"evidence was independently reviewed by the Aerospace Medical Association, the US National Academy of Sciences and the Australian Civil Aviation Safety Authority (CASA) Expert Panel. All concluded there is insufficient consistency to establish a medical syndrome, and the 'aerotoxic syndrome' is not recognised in aviation medicine.""The 'nocebo effect' was among the conclusions published in a 2013 COT (Committee on Toxicity) position paper: ""The acute illness which has occurred in relation to perceived episodes of contamination might reflect a toxic effect of one or more chemicals, but it could also have occurred through nocebo effects.",1
"Sunday Sun, in an article entitled ""Flight Fumes Warning"", cited the industry pressure group AOPIS in saying that passengers jetting off to their holidays were unknowingly exposed to deadly chemicals, and that brain damage could result if they breathed the toxic fumes. The Sun also cited the UK Civil Aviation Authority finding that leakage into aircraft cabins is a very rare event occurring only if there is a fault with an aircraft.When",1
"Meaning that they all came from a group that already believed they had been damaged by contaminated air.That self-selected sample group ""was not compared to a control group."" Ross herself said ""The conclusions that can be drawn from these findings have limitations.""She further stated: ""The author ... makes no attempt to ascribe causality.""The report's conclusions were ambiguous: ""There was no evidence of ... global intellectual decline, language or perceptual deficits .... Indeed pilots were intact on the vast majority of tests. However, there was evidence of under-functioning on tests associated with psychomotor speed, executive functioning and attention ....""And",1
"finally, ""[T]he evidence available to us in this audit does not enable us to draw firm conclusions regarding a causal link with exposure to contaminated air.""In 2015, Tim van Beveren made a documentary on aerotoxic syndrome called Unfiltered Breathed In. Former British Airways Captain Tristan Loraine BCAi has produced a number of documentaries on the subject matter through Fact Not Fiction Films. Titles include Welcome Aboard Toxic Airlines (2007), Broken Wings (2011), Angel Without Wings (2010), A Dark Reflection (2015) and Everybody Flies (2019).Journalist",1
"The team is co-led by Susie Wood (Cawthron Institute) and Marcus Vandergoes (GNS Science) and has experts with a range of scientific expertise from universities and research organisations in New Zealand and overseas. It is supported by a Science, Advice and Implementation Group to provide guidance on strategy, quality and performance and prioritization of research directions. The project also has national and international collaborators and is in partnership with over 20 New Zealand organisations. Obtain a nationwide health overview for about 10% (380) of New Zealand's lakes.",1
"It was stated that combining these molecular methods with ""hyperspectral scanning and pollen data"" increased the understanding of when and why these changes occurred.There is a significant social science aspect to the project. One which this team has been exploring is public access to lakes. In this subproject, the team aimed to ""evaluate legal and practical access to lakes in the Lakes380 dataset for members of the public ... [with the lakes] ... selected based on geographic spread, altitude, species, catchment land cover, and cultural significance.""",1
"the same field sampling campaign, the Lakes380 joined with a team from the University of Waikato to gather samples from three lakes to determine the effect of prehistoric earthquake activity and provide information on the potential risk to the city of Hamilton in 2020. The study established that lake sediments in the area included layers of volcanic ash (tephra) and that five layers of this in the cores showed possible signs of liquefaction, indicating that there may have been previously unrecognised earthquakes in the Hamilton lowlands over the past 20,000 years.",1
"Professor Lowe from Waikato University said that although Hamilton was known for having a low to moderate earthquake risk, this may now need to be revised, and ""by studying the nature of the tephra layers using CT scanning and geotechnical methods, we aim to calculate the intensity of shaking and develop a new understanding of seismic hazard in and around Hamilton.""",1
"On 1 July 2020, the Otago Daily Times reported that samples collected from Queenstown lakes had revealed history going back thousands of years, providing what the University of Otago paleoclimatologist Chris Moy said was important information about how climate, environment and ecosystems in the area had changed over time. The sediment cores were analysed at the University of Otago, and other lakes in the region were also sampled.Sampling was undertaken of lakes in the Rotorua area in 2019 and 2021 to gather evidence on how the arrival of humans and the eruption of Mount Tarawera in 1886， had impacted the ecosystems.",1
"Rotoiti, in the Tasman region, has been noted by Wood as one of the most ""pristine"" in the country and she felt that the research, by working on lakes like this showed the importance of protecting the lake. The Lakes380 project has built in-depth relationships with iwi in the Wairarapa and Rangitikei districts as part of weaving together traditional knowledge, science and local history, and worked on a joint website to encourage conversations about the wellbeing of Wairarapa lakes.",1
"Environment manager Rawiri Smith of Ngāti Kahungunu ki Wairarapa, said the lake stories had provoked changes in thinking and behaviour based on ""common humanity rather than through confirmation or enforcement"", and Charlotte Šunde of the Cawthron Institute noted that ""digital storytelling like this is a fairly new and very effective way of bringing lake stories to a wide audience, reaching far beyond the impact of scientific publications."" As the Lakes380 team has travelled around Aotearoa, they have worked closely with iwi in each region.",1
"For example in 2019, Lakes380 scientists collaborated with Ngāti Kuri to study the health of the lakes in Northland, which has dune lakes that are highly threatened aquatic habitats. Harry Burkhardt, the chair of the Ngāti Kuri Trust, said the project would help to get systems in place that will ""protect the area's unique biodiversity and enhance the iwi's relationship with the natural world.""In May 2021, Ngāti Apa ki te Rā Tō, as mana whenua and kaitiaki of Nelson lakes, welcomed people to an information session to share knowledge of the work being done by Lakes380.",1
"provide essential habitat for our freshwater species and have high cultural significance.""Amy Bridges, a student at Victoria University of Wellington, worked with the Lakes380 team to follow up on oral histories which suggested that two lakes may have been affected by tsunamis in the past. Samples from Lake Whakaki in Hawke's Bay were not able to be dated because they were a mixture of reeds and shells.",1
"While those from Lake Moawhitu on D'Urville Island didn't show direct proof of tsunami, the work done was acknowledged as being useful for future research that could look at the grain sizes to figure out possible causes of this mixing. Bridges said, ""it is still possible that a tsunami did occur, so further research focusing on sediment from other parts of the lake could provide more insight.""As",1
Susie Wood on Radio 95bFM Lakes380 project – Taranaki sites Images of all lakes in the project Interactive site showing interim results,1
"Poisoning of small consumers can be passed along the food chain to affect the consumers later in the chain. Other compounds that are not normally considered toxic can be accumulated to toxic levels in organisms. The classic example is vitamin A, which becomes concentrated in livers of carnivores, e.g. polar bears: as a pure carnivore that feeds on other carnivores (seals), they accumulate extremely large amounts of vitamin A in their livers.",1
"It was known by the native peoples of the Arctic that the livers of carnivores should not be eaten, but Arctic explorers have suffered hypervitaminosis A from eating the livers of bears; and there has been at least one example of similar poisoning of Antarctic explorers eating husky dog livers. One notable example of this is the expedition of Sir Douglas Mawson, whose exploration companion died from eating the liver of one of their dogs.",1
"Coastal fish (such as the smooth toadfish) and seabirds (such as the Atlantic puffin) are often monitored for heavy metal bioaccumulation. Methylmercury gets into freshwater systems through industrial emissions and rain. As its concentration increases up the food web, it can reach dangerous levels for both fish and the humans who rely on fish as a food source.Fish are typically assessed for bioaccumulation when they have been exposed to chemicals that are in their aqueous phases. Commonly tested fish species include the common carp, rainbow trout, and bluegill sunfish.",1
"Generally, fish are exposed to bioconcentration and bioaccumulation of organic chemicals in the environment through lipid layer uptake of water-borne chemicals. In other cases, the fish are exposed through ingestion/digestion of substances or organisms in the aquatic environment which contain the harmful chemicals.Naturally produced toxins can also bioaccumulate. The marine algal blooms known as ""red tides"" can result in local filter-feeding organisms such as mussels and oysters becoming toxic; coral reef fish can be responsible for the poisoning known as ciguatera when they accumulate a toxin called ciguatoxin from reef algae. In some eutrophic aquatic systems, biodilution can occur.",1
"This is a decrease in a contaminant with an increase in trophic level, due to higher concentrations of algae and bacteria to dilute the concentration of the pollutant. Wetland acidification can raise the chemical or metal concentrations, which leads to an increased bioavailability in marine plants and freshwater biota. Plants situated there which includes both rooted and submerged plants can be influenced by the bioavailability of metals. Bioaccumulation in turtles occurs when synthetic organic contaminants (i.e., PFAS), heavy metals, or high levels of trace elements enter a singular organism, potentially affecting their health.",1
Due to their relatively limited home-range freshwater turtles can be associated with a particular catchment and its chemical contaminant profile.,1
"The World Health Organization's 2006 publication, Biorisk management: Laboratory biosecurity guidance, defines laboratory biosafety as ""the containment principles, technologies and practices that are implemented to prevent the unintentional exposure to pathogens and toxins, or their accidental release"". It defines biorisk management as ""the analysis of ways and development of strategies to minimize the likelihood of the occurrence of biorisks"".The term ""biocontainment"" is related to laboratory biosafety.",1
"Biological safety cabinets (BSC), first commercially available in 1950, are fairly common devices designed to provide effective primary biocontainment in laboratories working with highly infectious agents. Three general levels and types have been devised (Class I, Class II, and Class III). Biosafety suites are suites of laboratory rooms which are essentially equivalent to large Class III cabinets in which positive pressure personnel suits (""space suits"") serve as the ""outside"" environment for workers. Examples include the biosafety suites at USAMRIID at Fort Detrick, Maryland, USA and the Maximum Containment Facility (MCF) of the CDC in Atlanta, Georgia, USA.",1
"A ""biosafety level"" (BSL) is the level of the biocontainment precautions required to isolate dangerous biological agents in an enclosed laboratory facility. The levels of containment range from the lowest biosafety level 1 (BSL-1) to the highest at level 4 (BSL-4). In the United States, the Centers for Disease Control and Prevention (CDC) have specified these levels. In the European Union, the same biosafety levels are defined in a directive. Today, guiding publications for biosafety and containment in the US are set by the Centers for Disease Control and Prevention (CDC) and the National Institutes of Health (NIH).",1
"Best Practice Guidelines for Biological Resource Centres is a consensus report created in 2001 after experts from OECD countries came together, calling upon ""national governments to undertake actions to bring the BRC concept into being in concert with the international scientific community"". BRCs are ""repositories and providers of high-quality biological materials and information"".",1
"Components of a laboratory biosecurity program include: Physical security Personnel security Material control and accountability Transport security Information security Program management Aeromedical Isolation Team – Former US Army aeromobile biocontainment team Biorisk – Risk associated with biological materials and/or infectious agents (""pathogens"") Biosafety – Prevention of large-scale loss of biological integrity Biosafety level – Level of the biocontainment precautions required to isolate dangerous biological agents Biosecurity – Preventive measures designed to reduce the risk of infectious disease transmission Biological hazard – Biological material that poses serious risks to the health of living organisms Chemical hazard – Non-biological hazards of hazardous materials",1
"Safety engineering – Engineering discipline which assures that engineered systems provide acceptable levels of safety Security engineering – Process of incorporating security controls into an information system Select agent – Controlled biological agents in the United States Citations Other sources Biosafety in Microbiological and Biomedical Laboratories (1999), 4th Edition, U.S. Department of Health and Human Services, Public Health Service, Centers for Disease Control and Prevention, National Institutes of Health, Washington, DC: U.S. Government Printing Office.",1
"The 2013 International Conference on Biocontainment Facilities The 2014 International Conference on Biocontainment Facilities eBook Reference: Management Principles for Building and Operating Biocontainment Facilities (Kindle Edition) Archived 2013-05-26 at the Wayback Machine Wedum, A.G., W.E. Barkley, and A. Hellman (1972), ""Handling of infectious agents"", Journal of the American Veterinary Medical Association, 161(11):1557-1567. Biorisk Management: Laboratory Biosecurity Guidance. WHO, 2006 Biosafety in Microbiological and Biomedical Laboratories, 5th edition, 2007 (CDC)Clevestig, Peter (28 June 2009). Handbook of Applied Biosecurity for Life Science Laboratories (PDF). Stockholm International Peace Research Institute. ISBN 978-91-85114-61-0. (Website here) Kanabrocki, Joseph (20 January 2017).",1
"In a direct assay, the stimulus applied to the subject is specific and directly measurable, and the response to that stimulus is recorded. The variable of interest is the specific stimulus required to produce a response of interest (ex. death of the subject).",1
"In an indirect assay, the stimulus is fixed in advance and the response is measured in the subjects. The variable of interest in the experiment is the response to a fixed stimulus of interest. Quantitative response: The measurement of the response to the stimulus is on a continuous scale (ex. blood sugar content). Quantal response: The response is binary; it is a determination of whether or not an event occurs (ex. death of the subject).",1
"In the context of agriculture and food and feed production, co-existence means using cropping systems with and without genetically modified crops in parallel. In some countries, such as the United States, co-existence is not governed by any single law but instead is managed by regulatory agencies and tort law. In other regions, such as Europe, regulations require that the separation and the identity of the respective food and feed products must be maintained at all stages of the production process.",1
"Many consumers are critical of genetically modified plants and their products, while, conversely, most experts in charge of GMO approvals do not perceive concrete threats to health or the environment. The compromise chosen by some countries - notably the European Union - has been to implement regulations specifically governing co-existence and traceability. Traceability has become commonplace in the food and feed supply chains of most countries in the world, but the traceability of GMOs is made more challenging by the addition of very strict legal thresholds for unwanted mixing.",1
"Within the European Union, since 2001, conventional and organic food and feedstuffs can contain up to 0.9% of authorised GM material without being labelled GM (any trace of non-authorised GM products would cause shipments to be rejected). In the United States there is no legislation governing the co-existence of neighboring farms growing organic and GM crops; instead the US relies on a ""complex but relaxed"" combination of three federal agencies (FDA, EPA, and USDA/APHIS) and the common law tort system, governed by state law, to manage risks of co-existence.:",1
"44 To limit mixing in the first stages of production, researchers and politicians are developing codes of good agricultural practice for GM crops. In addition to the thorough cleaning of machinery, recommended measures include the establishment of ""isolation distances"" and ""pollen barriers"". Isolation distances are the minimum distances required between GM and non-GM cultivations for most of the GM pollen to fall to the ground before reaching non-GM plants. Pollen barriers attempt actively catch pollen, and can consist of hedges and trees which physically hinder pollen movement.",1
"Pollen barriers consisting of conventional crops of the same species as the GM crop have a special advantage, as the conventional plants not only physically limit the GM pollen flow, but also produce competitive, conventional pollen. During harvest, the buffer strip of conventional crops is considered part of the GM crop yield.",1
"In addition to agricultural measures, there may be also biological tools to prevent the genetically modified crop from fertilising conventional fields. Researchers are investigating methods either to prevent GM crops from producing pollen at all (for example male-sterile plants), or to develop GM crops with pollen that nonetheless does not contain the additional, genetically engineered material. In an example of the latter, transplastomic plants can be generated in which the genetic modification has been integrated in the DNA of chloroplasts. As the chloroplasts of plants are maternally inherited, the transgenes are not spread by pollen thus achieving biological containment.",1
"In other words, the cell nucleus contains no transgenes, and the pollen contains no chloroplasts and thus no transgenes. Two important research projects on co-existence are and Co-Extra. With the end of the de facto moratorium on genetically modified plants in Europe, several research programmes (e.g. SIGMEA, Co-Extra, and Transcontainer) have begun investigating biological containment strategies for GMOs. While SIGMEA was focused on co-existence at the farm level, Co-Extra studies co-existence along the whole production chain, and has a second focus on the traceability of GMOs, since co-existence cannot work without traceability.",1
"economic losses to farmers caused by unintended presence of genetically engineered materials, as well as how such mechanisms might work. The members of AC21 included representatives of the biotechnology industry, the organic food industry, farming communities, the seed industry, food manufacturers, State government, consumer and community development groups, the medical profession, and academic researchers.",1
"The AC21 recommended that a study should be conducted to answer the question of whether and to what extent there are any economic losses to US organic farmers; recommended that if the losses are serious, that a crop insurance program for organic farmers be put in place, and that an education program should be undertaken to ensure that organic farmers are putting appropriate contracts in place for their crops and that neighboring GM crop farmers are taking appropriate containment measures. Overall the report supported a diverse agriculture system in which many different farming systems could co-exist.",1
"Since GM-free products yield higher prices in many countries, some governments have introduced limits for the mixing of both production systems, with compensation for non-GM farmers for economic losses in cases where mixing inadvertently occurred. One tool for compensation is a liability fund, to which all GM farmers, and sometimes GM seed producers, contribute.: 88–91 After a notable GMO contamination event in Western Australia where a certified organic farm lost certification due to GMO contamination, a Parliamentary Inquiry considered six proactive proposals for compensating farms contaminated by GMOs, however the Inquiry did not recommend a particular mechanism of compensation.",1
"Mixing can occur already at the agricultural stage. Fundamentally, two reasons exist for the presence of GMOs in the harvest of a non-GM cultivation: first, that the seed has been contaminated already or, secondly, that the plants in the non-GM field have received pollen from neighbouring GM fields. Mixing may also occur post-harvest, anywhere in the production chain.",1
"In 1997, Percy Schmeiser discovered that canola growing on his farm was genetically modified to be resistant to Roundup although he had not planted GM seed. He had initially discovered that some canola growing by a roadside along one of his fields was Roundup resistant when he was killing weeds along the road; this led him to spray a 3- to 4‑acre section of his adjacent field and 60% of the canola survived. Schmeiser harvested the seed from the surviving, Roundup resistant plants, and planted the seed in 1998. Monsanto sued Schmeiser for patent infringement for the 1998 planting.",1
"Schmeiser claimed that because the 1997 plants grew from seed that was blown into his field from neighboring fields, that he owned the harvest and was entitled to do with it whatever he wished, including saving the seeds from the 1997 harvest and planting them in 1998. The case (Monsanto Canada Inc v Schmeiser) went to the Supreme Court which held for Monsanto by a 5‑4 vote in late May 2004.",1
"The case is widely cited or referenced by the anti-GM community in the context of a fear of a company claiming ownership of a farmer's crop based on the inadvertent presence of GM pollen grain or seed. ""The court record shows, however, that it was not just a few seeds from a passing truck, but that Mr Schmeiser was growing a crop of 95–98% pure Roundup Ready plants, a commercial level of purity far higher than one would expect from inadvertent or accidental presence.",1
"The judge could not account for how a few wayward seeds or pollen grains could come to dominate hundreds of acres without Mr Schmeiser's active participation, saying '. . .none of the suggested sources could reasonably explain the concentration or extent of Roundup Ready canola of a commercial quality evident from the results of tests on Schmeiser's crop'"" – in other words, the original presence of Monsanto seed on his land in 1997 was indeed inadvertent, but the crop in 1998 was entirely purposeful.In",1
"1999 scientists in Thailand claimed they discovered glyphosate-resistant genetically modified wheat that was not yet approved for release in a grain shipment from the Pacific Northwest of the United States, even though transgenic wheat had never been approved for sale and was only ever grown in test plots. No one could explain how the transgenic wheat got into the food supply.",1
"In 2000, Aventis StarLink corn, which had been approved only as animal feed due to concerns about possible allergic reactions in humans, was found contaminating corn products in U.S. supermarkets and restaurants. This corn became the subject of a widely publicized recall, when Taco Bell taco shells were found to contain the corn, eventually resulting in the recall of over 300 products. It was the first-ever recall of a genetically modified food. The registration for the Starlink varieties was voluntarily withdrawn by Aventis in October 2000.In",1
"2005, scientists at the UK Centre for Ecology and Hydrology reported the first evidence of horizontal gene transfer of pesticide resistance to weeds, in a few plants from a single season; they found no evidence that any of the hybrids had survived in subsequent seasons.In 2006, American exports of rice to Europe were interrupted when the U.S. crop was contaminated with rice containing the LibertyLink modification, which had not been approved for release. An investigation by the USDA's Animal and Plant Health Inspection Service (APHIS) was unable to determine the cause of the contamination.In 2007, the U.S.",1
"Department of Agriculture fined Scotts Miracle-Gro $500,000 when modified genetic material from creeping bentgrass, a new golf-course grass Scotts had been testing, was found within close relatives of the same genus (Agrostis) as well as in native grasses up to 21 km (13 mi) away from the test sites, released when freshly cut grass was blown by the wind.In 2009 the government of Mexico created a regulatory pathway for approval of genetically modified maize, but because Mexico is the center of diversity for maize, concerns have been raised about the effect that genetically modified maize could have on local strains.",1
"A 2001 report in Nature presented evidence that Bt maize was cross-breeding with unmodified maize in Mexico, although the data in this paper was later described as originating from an artifact and Nature stated that ""the evidence available is not sufficient to justify the publication of the original paper"". A subsequent large-scale study, in 2005, failed to find any evidence of contamination in Oaxaca. However, other authors have stated that they also found evidence of cross-breeding between natural maize and transgenic maize.",1
"The organic farm lost its organic certification and the organic farmer sued the GM farmer - so far without success. The certifier called it ""contamination"" and in the 2014 judgement the judge called it an ""incursion"" and rejected claims for nuisance, negligence and damages.In 2013, glyphosate-resistant genetically modified wheat that was not yet approved for release, but which had been declared safe for consumption in the USA, was discovered in a farm in Oregon, growing as a weed or ""volunteer plant"".",1
"The wheat had been created by Monsanto, and was a strain that was field-tested from 1998 to 2005 and was in the American regulatory approval process before Monsanto withdrew it based on concern that importers would avoid the crop. The last field test in Oregon had occurred in 2001. Volunteer wheat from a field two miles away owned by the same farmer and planted with the same seed was tested and it was not found to be glyphosate-resistant. Monsanto was liable for fines of up to $1 million, if violations of the Plant Protection Act were found.",1
"According to Monsanto it was ""mystified"" by its appearance, having destroyed all the material it held after completing trials in 2004 and because they did not think that seed left in the ground or pollen transfer could account for it. Later in the month, Monsanto suggested that the presence of the wheat was likely an act of ""sabotage"". The discovery could have threatened U.S. wheat exports, which totaled $8.1 billion in 2012; the US is the world's largest wheat exporter.",1
"New Scientist reported that the variety of wheat was rarely imported into Europe and doubted that the discovery of the wheat would affect Europe, but more likely destined for Asia. As a result of the discovery of the unapproved strain, Japan and South Korea halted wheat orders from the United States, leaving wheat growers in neighboring communities unable to decide what to plant next season. The crop growing when the genetically modified wheat was discovered had already been sold or insured.",1
"On June 14, 2013, the USDA announced: ""As of today, USDA has neither found nor been informed of anything that would indicate that this incident amounts to more than a single isolated incident in a single field on a single farm. All information collected so far shows no indication of the presence of GE [sic] wheat in commerce."" As of August 30, while the source of the GM wheat remained unknown, Japan, South Korea and Taiwan had all resumed placing orders, and the export market resumed. The Oregon wheat commissioner, Blake Rowe, said that ""the overall economic impact has been minimal"".",1
"Co-Extra – EU research programme on co-existence and traceability along the whole production chain SIGMEA – EU research programme on co-existence in agriculture Transcontainer – EU research programme on biological containment systems for genetically modified plants Archived 2011-09-26 at the Wayback Machine GMO-Compass – facts, numbers, and news about GM crops in Europe Research projects: Biological confinement of new genes - methods for containing the spread of genetically modified plants",1
"Biodegradable waste can be found in municipal solid waste (sometimes called biodegradable municipal waste, or as green waste, food waste, paper waste and biodegradable plastics). Other biodegradable wastes include human waste, manure, sewage, sewage sludge and slaughterhouse waste. In the absence of oxygen, much of this waste will decay to methane by anaerobic digestion.In the UK, 7.4 million tonnes of biodegradable waste was sent to landfill in 2018 having reduced from 7.8 million tonnes in 2017.",1
"Swiss Kompogas and the Danish AIKAN process are examples of anaerobic digestion of biodegradable waste. While incineration can recover the most energy, anaerobic digestion plants retain nutrients and make compost for soil amendment and still recover some of the contained energy in the form of biogas. Kompogas produced 27 million Kwh of electricity and biogas in 2009. The oldest of the company's lorries has achieved 1,000,000 kilometers driven with biogas from household waste in the last 15 years.",1
"Effects of exposure may result in shorter body length, lower body mass and malformations of limbs or other organs. The slow development, late morphological change, and small metamorph size result in increased risk of mortality and exposure to predation.",1
"Crayfish have also been hypothesized as being suitable bioindicators, under the appropriate conditions.",1
"Benthic macroinvertebrates are found within the benthic zone of a stream or river. They consist of aquatic insects, crustaceans, worms and mollusks that live in the vegetation and stream beds of rivers. Macroinvertebrate species can be found in nearly every stream and river, except in some of the world's harshest environments. They also can be found in mostly any size of stream or river, prohibiting only those that dry up within a short timeframe. This makes the beneficial for many studies because they can be found in regions where stream beds are too shallow to support larger species such as fish.",1
"EPA Bioindicators - Biological Integrity Online biomonitoring by recording bivalve mollusc activity worldwide 24/7, the MolluSCAN eye Archived 2016-11-13 at the Wayback Machine project.",1
"The former US biological warfare program (1943–1969) categorized its weaponized anti-personnel bio-agents as either ""lethal agents"" (Bacillus anthracis, Francisella tularensis, Botulinum toxin) or ""incapacitating agents"" (Brucella suis, Coxiella burnetii, Venezuelan equine encephalitis virus, Staphylococcal enterotoxin B).",1
"Since 1997, United States law has declared a list of bio-agents designated by the U.S. Department of Health and Human Services or the U.S. Department of Agriculture that have the ""potential to pose a severe threat to public health and safety"" to be officially defined as ""select agents"" and possession or transportation of them are tightly controlled as such. Select agents are divided into ""HHS select agents and toxins"", ""USDA select agents and toxins"" and ""Overlap select agents and toxins"".",1
"The U.S. Centers for Disease Control and Prevention (CDC) breaks biological agents into three categories: Category A, Category B, and Category C. Category A agents pose the greatest threat to the U.S. Criteria for being a Category ""A"" agent include high rates of morbidity and mortality; ease of dissemination and communicability; ability to cause a public panic; and special action required by public health officials to respond. Category A agents include anthrax, botulism, plague, smallpox, and viral hemorrhagic fevers. The following pathogens and toxins were weaponized by one nation or another at some time. NATO abbreviations are included where applicable.",1
"This bears a significant health risk, even if the biological agent is normally not pathogenic.",1
"2004, the United Nations Security Council passed Resolution 1540, which obligates all UN Member States to develop and enforce appropriate legal and regulatory measures against the proliferation of chemical, biological, radiological, and nuclear weapons and their means of delivery, in particular, to prevent the spread of weapons of mass destruction to non-state actors. Biological hazard Biological contamination Laboratory Response Network Pulsed ultraviolet light Rafał L. Górny, Biological agents, OSHwiki Biological Agents, OSHA Select Agents and Toxins, Centers for Disease Control and Prevention Biological weapons e-learning module in the EU's non-proliferation and disarmament course (taught by Filippa Lentzos)",1
"The following manufacturers have been involved in the development, design and planning of waste gas purification systems for a wide range of industries: Global manufacture of turnkey systems. American Fabrication and Supply, LLC Bacteria Microbiology Microorganism McGrew, Roderick. Encyclopedia of Medical History (1985), brief history pp 25–30 Our Microbial Planet A free poster from the National Academy of Sciences about the positive roles of micro-organisms.",1
Biological integrity Biosurvey Biomonitoring,1
"When eaten by another organism, fats are absorbed in the gut, carrying the substance, which then accumulates in the fats of the predator. Since at each level of the food chain there is a lot of energy loss, a predator must consume many prey, including all of their lipophilic substances. For example, though mercury is only present in small amounts in seawater, it is absorbed by algae (generally as methylmercury). Methylmercury is one of the most harmful mercury molecules. It is efficiently absorbed, but only very slowly excreted by organisms.",1
"Bioaccumulation and bioconcentration result in buildup in the adipose tissue of successive trophic levels: zooplankton, small nekton, larger fish, etc. Anything which eats these fish also consumes the higher level of mercury the fish have accumulated. This process explains why predatory fish such as swordfish and sharks or birds like osprey and eagles have higher concentrations of mercury in their tissue than could be accounted for by direct exposure alone. For example, herring contains mercury at approximately 0.01 parts per million (ppm) and shark contains mercury at greater than 1 ppm.DDT",1
"is a pesticide known to biomagnify, which is one of the most significant reasons it was deemed harmful to the environment by the EPA and other organizations. DDT is one of the least soluble chemicals known and accumulates progressively in adipose tissue, and as the fat is consumed by predators, the amounts of DDT biomagnify. A well known example of the harmful effects of DDT biomagnification is the significant decline in North American populations of predatory birds such as bald eagles and peregrine falcons due to DDT caused eggshell thinning in the 1950s.",1
"DDT is now a banned substance in many parts of the world. In a review, a large number of studies, Suedel et al. concluded that although biomagnification is probably more limited in occurrence than previously thought, there is good evidence that DDT, DDE, PCBs, toxaphene, and the organic forms of mercury and arsenic do biomagnify in nature. For other contaminants, bioconcentration and bioaccumulation account for their high concentrations in organism tissues. More recently, Gray reached a similar substances remaining in the organisms and not being diluted to non-threatening concentrations.",1
"These substances are consequently known as ""persistent organic pollutants"" or POPs.Metals are not degradable because they are chemical elements. Organisms, particularly those subject to naturally high levels of exposure to metals, have mechanisms to sequester and excrete metals. Problems arise when organisms are exposed to higher concentrations than usual, which they cannot excrete rapidly enough to prevent damage. Persistent heavy metals, such as lead, cadmium, mercury, and arsenic, can have a wide variety of adverse health effects across species.",1
"DDT (dichlorodiphenyltrichloroethane) Hexachlorobenzene (HCB) PCBs (polychlorinated biphenyls) Toxaphene Monomethylmercury. Mercury in fish Methylmercury Dichlorodiphenyldichloroethylene Toxaphene Fisk AT, Hoekstra PF, Borga K,and DCG Muir, 2003. Biomagnification. Mar. Pollut. Bull. 46 (4): 522-524",1
"Microorganisms can degrade a wide variety of hydrocarbons, including components of gasoline, kerosene, diesel, and jet fuel. Under ideal aerobic conditions, the biodegradation rates of the low- to moderate-weight aliphatic, alicyclic, and aromatic compounds can be very high. As molecular weight of the compound increases, the resistance to biodegradation increases simultaneously. This results in higher contaminated volatile compounds due to their high molecular weight and an increased difficulty to remove from the environment. Most bioremediation processes involve oxidation-reduction reactions where either an electron acceptor (commonly oxygen) is added to stimulate oxidation of a reduced pollutant (e.g.",1
"bioremediation can in principle be employed to treat a range of oxidized contaminants including chlorinated ethylenes (PCE, TCE, DCE, VC), chlorinated ethanes (TCA, DCA), chloromethanes (CT, CF), chlorinated cyclic hydrocarbons, various energetics (e.g., perchlorate, RDX, TNT), and nitrate. This process involves the addition of an electron donor to: 1) deplete background electron acceptors including oxygen, nitrate, oxidized iron and manganese and sulfate; and 2) stimulate the biological and/or chemical reduction of the oxidized pollutants. Hexavalent chromium (Cr[VI]) and uranium (U[VI]) can be reduced to less mobile and/or less toxic forms (e.g., Cr[III], U[IV]).",1
"Soluble substrates or soluble fermentation products of slow-release substrates can potentially migrate via advection and diffusion, providing broader but shorter-lived treatment zones. The added organic substrates are first fermented to hydrogen (H2) and volatile fatty acids (VFAs). The VFAs, including acetate, lactate, propionate and butyrate, provide carbon and energy for bacterial metabolism.",1
"During bioattenuation, biodegradation occurs naturally with the addition of nutrients or bacteria. The indigenous microbes present will determine the metabolic activity and act as a natural attenuation. While there is no anthropogenic involvement in bioattenuation, the contaminated site must still be monitored.",1
Windrow systems are similar to compost techniques where soil is periodically turned in order to enhance aeration. This periodic turning also allows contaminants present in the soil to be uniformly distributed which accelerates the process of bioremediation.,1
"For example, under anaerobic conditions, the reductive dehalogenation of TCE may produce dichloroethylene (DCE) and vinyl chloride (VC), which are suspected or known carcinogens. However, the microorganism Dehalococcoides can further reduce DCE and VC to the non-toxic product ethene. The molecular pathways for bioremediation are of considerable interest. In addition, knowing these pathways will help develop new technologies that can deal with sites that have uneven distributions of a mixture of contaminants.Biodegradation requires microbial population with the metabolic capacity to degrade the pollutant.",1
"The limitation or remediation of pesticides is the low bioavailability. Altering the pH and temperature of the contaminated soil is a resolution to increase bioavailability which, in turn, increased degradation of harmful compounds.The compound acrylonitrile is commonly produced in industrial setting but adversely contaminates soils. Microorganisms containing nitrile hydratases (NHase) degraded harmful acrylonitrile compounds into non-polluting substances.Since the experience with harmful contaminants are limited, laboratory practices are required to evaluate effectiveness, treatment designs, and estimate treatment times. Bioremediation processes may take several months to several years depending on the size of the contaminated area.",1
"modified organisms have been created to treat oil spills and break down certain plastics (PET). Phytoremediation, hosted by the Missouri Botanical Garden To remediate or to not remediate? Anaerobic Bioremediation",1
"Biorisk reduction involves creating expertise in managing high-consequence pathogens, by providing training on safe handling and control of pathogens that pose significant health risks. Biocontainment, related to laboratory biosafety levels Biodefense Biodiversity Biohazard Biological warfare Biological Weapons Convention Biosecurity Bioterrorism Cyberbiosecurity Endangered species",1
Each group has a number assigned to it and is multiplied by the number of organisms found in that group. This is why identifying the type of organism is important. AZTI's Marine Biotic Index Extended Biotic Index Family Biotic Index Hilsenhoff Biotic Index Sludge Biotic Index Trent Biotic Index Bioindicator Biological integrity Biosurvey Index of biological integrity Indicator species Macroinvertebrate Community Index,1
"""The Effect Of Coal Preparation On The Quality Of Clean Coal And Coke."" Welcome to the US Petabox. British Columbia Geological Survey, n.d. Web. 27 Jan. 2013. ""Uses of Coal."" World Coal Association. N.p., n.d. Web. 28 Jan. 2013.",1
"A purely scattering aerosol will reflect energy that would normally be absorbed by the earth-atmosphere system back to space and leads to a cooling effect. As one adds an absorbing component to the aerosol, it can lead to a heating of the earth-atmosphere system if the reflectivity of the underlying surface is sufficiently high. Early studies of the effects of aerosols on atmospheric radiative transfer on a global scale assumed a dominantly scattering aerosol with only a small absorbing component, since this appears to be a good representation of naturally occurring aerosols.",1
"However, as discussed above, urban aerosols have a large black carbon component and if these particles can be transported on a global scale then one would expect a heating effect over surfaces with a high surface albedo like snow or ice. Furthermore, if these particles are deposited in the snow an additional heating effect would occur due to reductions in the surface albedo.",1
Alternative methods rely on satellite based measurements of optical depth for large areas or more recently on spectral noise analysis for very local concentrations.In the late 1970s and early 1980s surprisingly large ground level concentrations of black carbon were observed throughout the western Arctic. Modeling studies indicated that they could lead to heating over polar ice. One of the major uncertainties in modeling the effects of the Arctic haze on the solar radiation balance was limited knowledge of the vertical distributions of black carbon.,1
"During 1983 and 1984 as part of the NOAA AGASP program, the first measurements of such distributions in the Arctic atmosphere were obtained with an aethalometer which had the capability of measuring black carbon on a real-time basis. These measurements showed substantial concentrations of black carbon found throughout the western Arctic troposphere including the North Pole. The vertical profiles showed either a strongly layered structure or an almost uniform distribution up to eight kilometers with concentrations within layers as large as those found at ground level in typical mid-latitude urban areas in the United States.",1
The absorption optical depths associated with these vertical profiles were large as evidenced by a vertical profile over the Norwegian arctic where absorption optical depths of 0.023 to 0.052 were calculated respectively for external and internal mixtures of black carbon with the other aerosol components.Optical depths of these magnitudes lead to a substantial change in the solar radiation balance over the highly reflecting Arctic snow surface during the March–April time frame of these measurements modeled the Arctic aerosol for an absorption optical depth of 0.021,1
"(which is close to the average of an internal and external mixtures for the AGASP flights), under cloud-free conditions. These heating effects were viewed at the time as potentially one of the major causes of Arctic warming trends as described in Archives of Dept. of Energy, Basic Energy Sciences Accomplishments.",1
"Typically, black carbon accounts for 1 to 6% but also up to 60% of the total organic carbon stored in soils is contributed by black carbon. Especially for tropical soils black carbon serves as a reservoir for nutrients. Experiments showed that soils without high amounts of black carbon are significantly less fertile than soils that contain black carbon. An example for this increased soil fertility are the Terra preta soils of central Amazonia, which are presumably human-made by pre-Columbian native populations.",1
carbon emissions are highest in and around major source regions. This results in regional hotspots of atmospheric solar heating due to black carbon. Hotspot areas include: the Indo-Gangetic plains of India eastern China most of Southeast Asia and Indonesia equatorial regions of Africa Mexico and Central America most of Brazil and Peru in South America.Approximately three billion people live in these hotspots.,1
"For example, the majority of soot emissions in South Asia are due to biomass cooking, whereas in East Asia, coal combustion for residential and industrial uses plays a larger role. In Western Europe, traffic seems to be the most important source since high concentrations coincide with proximity to major roads or participation to (motorized) traffic.Fossil fuel and biomass soot have significantly greater amounts of black carbon than climate-cooling aerosols and particulate matter, making reductions of these sources particularly powerful mitigation strategies. For example, emissions from the diesel engines and marine vessels contain higher levels of black carbon compared to other sources.",1
"Concentrations of black carbon decrease sharply with increasing distance from (traffic) sources which makes it an atypical component of particulate matter. This makes it difficult to estimate exposure of populations. For particulate matter, epidemiological studies have traditionally relied on single fixed site measurements or inferred residential concentrations. Recent studies have shown that as much black carbon is inhaled in traffic and at other locations as at the home address. Despite the fact that a large portion of the exposure occurs as short peaks of high concentrations, it is unclear how to define peaks and determine their frequency and health impact.",1
"High peak concentrations are encountered during car driving. High in-vehicle concentrations of black carbon have been associated with driving during rush hours, on highways and in dense traffic.Even relatively low exposure concentrations of black carbon have a direct effect on the lung function of adults and an inflammatory effect on the respiratory system of children. A recent study found no effect of black carbon on blood pressure when combined with physical activity. The public health benefits of reduction in the amount of soot and other particulate matter has been recognized for years.",1
"Direct effect Black carbon particles directly absorb sunlight and reduce the planetary albedo when suspended in the atmosphere. Semi-direct effect Black carbon absorb incoming solar radiation, perturb the temperature structure of the atmosphere, and influence cloud cover. They may either increase or decrease cloud cover under different conditions.Snow/ice albedo effect When deposited on high albedo surfaces like ice and snow, black carbon particles reduce the total surface albedo available to reflect solar energy back into space. Small initial snow albedo reduction may have a large forcing because of a positive feedback: Reduced snow albedo would increase surface temperature.",1
The increased surface temperature would decrease the snow cover and further decrease surface albedo.Indirect effect Black carbon may also indirectly cause changes in the absorption or reflection of solar radiation through changes in the properties and behavior of clouds. Research scheduled for publication in 2013 shows black carbon plays a role second only to carbon dioxide in climate change.,1
"Effects are complex, resulting from a variety of factors, but due to the short life of black carbon in the atmosphere, about a week as compared to carbon dioxide which last centuries, control of black carbon offers possible opportunities for slowing, or even reversing, climate change.",1
"Estimates of black carbon's globally averaged direct radiative forcing vary from the IPCC's estimate of + 0.34 watts per square meter (W/m2) ± 0.25, to a more recent estimate by V. Ramanathan and G. Carmichael of 0.9 W/m2.The IPCC also estimated the globally averaged snow albedo effect of black carbon at +0.1 ± 0.1 W/m2. Based on the IPCC estimate, it would be reasonable to conclude that the combined direct and indirect snow albedo effects for black carbon rank it as the third largest contributor to globally averaged positive radiative forcing since the pre-industrial period.",1
"In comparison, the more recent direct radiative forcing estimate by Ramanathan and Carmichael would lead one to conclude that black carbon has contributed the second largest globally averaged radiative forcing after carbon dioxide (CO2), and that the radiative forcing of black carbon is ""as much as 55% of the CO2 forcing and is larger than the forcing due to the other greenhouse gasses (GHGs) such as CH4, CFCs, N2O, or tropospheric ozone."" Table 1: Estimates of Black Carbon Radiative Forcing, by Effect Table 2: Estimated Climate Forcings (W/m2)",1
"According to the IPCC, ""the presence of black carbon over highly reflective surfaces, such as snow and ice, or clouds, may cause a significant positive radiative forcing."" The IPCC also notes that emissions from biomass burning, which usually have a negative forcing, have a positive forcing over snow fields in areas such as the Himalayas. A 2013 study quantified that gas flares contributed over 40% of the black carbon deposited in the Arctic.According",1
"to Charles Zender, black carbon is a significant contributor to Arctic ice-melt, and reducing such emissions may be ""the most efficient way to mitigate Arctic warming that we know of"". The ""climate forcing due to snow/ice albedo change is of the order of 1.0 W/m2 at middle- and high-latitude land areas in the Northern Hemisphere and over the Arctic Ocean."" The ""soot effect on snow albedo may be responsible for a quarter of observed global warming.""",1
"""Soot deposition increases surface melt on ice masses, and the meltwater spurs multiple radiative and dynamical feedback processes that accelerate ice disintegration,"" according to NASA scientists James Hansen and Larissa Nazarenko. As a result of this feedback process, ""BC on snow warms the planet about three times more than an equal forcing of CO2."" When black carbon concentrations in the Arctic increase during the winter and spring due to Arctic Haze, surface temperatures increase by 0.5 °C.",1
Everest (Qomolangma) in 2003 showed industrially induced sulfate from South Asia may cross over the highly elevated Himalaya. This indicated BC in South Asia could also have the same transport mode. And such kind of signal might have been detected in at a black carbon monitoring site in the hinterland of Tibet. Snow sampling and measurement suggested black carbon deposited in some Himalayan glaciers may reduce the surface albedo by 0.01–0.02.,1
"A general darkening trend in the mid-Himalaya glaciers revealed by MODIS data since 2000 could be partially attributed to black carbon and light absorbing impurities like dust in the springtime, which was later extended to the whole Hindu Kush-Kararoram-Himalaya glaciers research finding a widespread darkening trend of -0.001 yr−1 over the period of 2000–2011. The most rapid decrease in albedo (more negative than -0.0015 yr−1) occurred in the altitudes over 5500 m above sea level.",1
"In its 2007 report, the IPCC estimated for the first time the direct radiative forcing of black carbon from fossil fuel emissions at + 0.2 W/m2, and the radiative forcing of black carbon through its effect on the surface albedo of snow and ice at an additional + 0.1 W/m2. More recent studies and public testimony by many of the same scientists cited in the IPCC's report estimate that emissions from black carbon are the second-largest contributor to global warming after carbon dioxide emissions, and that reducing these emissions may be the fastest strategy for slowing climate change.Since",1
"Control of black carbon, particularly from fossil-fuel and biofuel sources, is very likely to be the fastest method of slowing global warming in the immediate future, and major cuts in black carbon emissions could slow the effects of climate change for a decade or two. Reducing black carbon emissions could help keep the climate system from passing the tipping points for abrupt climate changes, including significant sea-level rise from the melting of Greenland and/or Antarctic ice sheets.""Emissions of black carbon are the second strongest contribution to current global warming, after carbon dioxide emissions"".",1
"Calculation of black carbon's combined climate forcing at 1.0–1.2 W/m2, which ""is as much as 55% of the CO2 forcing and is larger than the forcing due to the other [GHGs] such as CH4, CFCs, N2O or tropospheric ozone."" Other scientists estimate the total magnitude of black carbon's forcing between + 0.2 and 1.1 W/m2 with varying ranges due to uncertainties. (See Table 1.) This compares with the IPCC's climate forcing estimates of 1.66 W/m2 for CO2 and 0.48 W/m2 for CH4. (See Table 2.)",1
"In addition, black carbon forcing is two to three times as effective in raising temperatures in the Northern Hemisphere and the Arctic than equivalent forcing values of CO2.Jacobson calculates that reducing fossil fuel and biofuel soot particles would eliminate about 40% of the net observed global warming. (See Figure 1.) In addition to black carbon, fossil fuel and biofuel soot contain aerosols and particulate matter that cool the planet by reflecting the sun's radiation away from the Earth. When the aerosols and particulate matter are accounted for, fossil fuel and biofuel soot are increasing temperatures by about 0.35 °C.Black",1
"carbon alone is estimated to have a 20-year Global Warming Potential (GWP) of 4,470, and a 100-year GWP of 1,055–2,240. Fossil fuel soot, as a result of mixing with cooling aerosols and particulate matter, has a lower 20-year GWP of 2,530, and a 100-year GWP of 840–1,280.The",1
"Integrated Assessment of Black Carbon and Tropospheric Ozone published in 2011 by the United Nations Environment Programme and World Meteorological Organization calculates that cutting black carbon, along with tropospheric ozone and its precursor, methane, can reduce the rate of global warming by half and the rate of warming in the Arctic by two-thirds, in combination with CO2 cuts. By trimming ""peak warming"", such cuts can keep current global temperature rise below 1.5 ˚C for 30 years and below 2 ˚C for 60 years, in combination with CO2 cuts. (FN: UNEP-WMO 2011.) See Table 1, on page 9 of the UNEP-WMO report.The",1
"reduction of CO2 as well as SLCFs could keep global temperature rise under 1.5 ˚C through 2030, and below 2 ˚C through 2070, assuming CO2 is also cut. See the graph on page 12 of the UNEP-WMO report. Ramanathan notes that ""developed nations have reduced their black carbon emissions from fossil fuel sources by a factor of 5 or more since 1950. Thus, the technology exists for a drastic reduction of fossil fuel related black carbon.""Jacobson believes that ""[g]iven proper conditions and incentives, [soot] polluting technologies can be quickly phased out.",1
"Already soot emissions from coal are decreasing in many regions with transition from small users to power plants with scrubbers.""Jacobson suggests converting ""[U.S.] vehicles from fossil fuel to electric, plug-in-hybrid, or hydrogen fuel cell vehicles, where the electricity or hydrogen is produced by a renewable energy source, such as wind, solar, geothermal, hydroelectric, wave, or tidal power. Such a conversion would eliminate 160 Gg/yr (24%) of U.S. (or 1.5% of world) fossil-fuel soot and about 26% of U.S. (or 5.5% of world) carbon dioxide."" According to Jacobson's estimates, this proposal would reduce soot and CO2 emissions by 1.63 GtCO2–eq. per year.",1
"He notes, however, ""that the elimination of hydrocarbons and nitrogen oxides would also eliminate some cooling particles, reducing the net benefit by at most, half, but improving human health,"" a substantial reduction for one policy in one country.For diesel vehicles in particular there are several effective technologies available. Newer, more efficient diesel particulate filters (DPFs), or traps, can eliminate over 90% of black carbon emissions, but these devices require ultra-low sulfur diesel fuel (ULSD). To ensure compliance with new particulate rules for new on-road and non-road vehicles in the U.S.,",1
"Outside of the US diesel oxidation catalysts are often available and DPFs will become available as ULSD is more widely commercialized. Another technology for reducing black carbon emissions from diesel engines is to shift fuels to compressed natural gas. In New Delhi, India, the supreme court ordered shift to compressed natural gas for all public transport vehicles, including buses, taxis, and rickshaws, resulted in a climate benefit, ""largely because of the dramatic reduction of black carbon emissions from the diesel bus engines.""",1
"Overall, the fuel switch for the vehicles reduced black carbon emissions enough to produce a 10 percent net reduction in CO2-eq., and perhaps as much as 30 percent. The main gains were from diesel bus engines whose CO2-eq. emissions were reduced 20 percent. According to a study examining these emissions reductions, ""there is a significant potential for emissions reductions through the [UNFCCC] Clean Development for such fuel switching projects.""Technologies are also in development to reduce some of the 133,000 metric tons of particulate matter emitted each year from ships.",1
"estimates that ""providing alternative energy-efficient and smoke-free cookers and introducing transferring technology for reducing soot emissions from coal combustion in small industries could have major impacts on the radiative forcing due to soot."" Specifically, the impact of replacing biofuel cooking with black carbon-free cookers (solar, bio, and natural gas) in South and East Asia is dramatic: over South Asia, a 70 to 80% reduction in black carbon heating; and in East Asia, a 20 to 40% reduction."" Condensed aromatic ring structures indicate black carbon degradation in soil.",1
"Saprophytic fungi are being researched for their potential role in the degradation of black carbon. Many countries have existing national laws to regulate black carbon emissions, including laws that address particulate emissions. Some examples include: banning or regulating slash-and-burn clearing of forests and savannas; requiring shore-based power/electrification of ships at port, regulating idling at terminals, and mandating fuel standards for ships seeking to dock at port; requiring regular vehicle emissions tests, retirement, or retrofitting (e.g.",1
"As one of a range of ferric ferrocyanides, blue billy is a compound of iron, carbon and nitrogen. Processes producing ammonia or cyanides in the presence of iron may give rise to it. Most commonly it is found around old gasworks. Part of the gas production process, producing town gas by the gasification of coal, involves a liquid bubbler scrubber to remove ammonia compounds, including ammonium cyanide compounds, from the raw gas. If left untreated, these could cause corrosion in gas pipework.",1
"This ferrous sulphate was commercially saleable for acid production, and although the economics of this were only marginally profitable, it avoided disposal costs.Coke works, where a similar process is carried out primarily to manufacture coke, either for steelmaking or as a smokeless fuel, are also common sites for its occurrence. Coke plants were noted for their iron wastes being more prone to contain ferrocyanides, not merely sulphates. If sufficiently concentrated, >5%, these would be commercially saleable.If wastes are preserved in anoxic environments, the Prussian blue colour may not yet have developed.",1
"By such screening it has been possible to separate the worst of the wastes as one-thirtieth of the total, then to stabilise that within a cementitious matrix and produce a stable form which could be re-used on site. Galligu, a contaminant from the Leblanc process of the early sodium carbonate industry Yellow boy, a yellow precipitate when iron(III) hydroxide is soluble in acidic runoff, but is then neutralised",1
"Shaw was born in Dallas, Texas, the daughter of Edward Carrington and Lois (née Bonner) Shaw.She received a Bachelor of Arts degree from the University of Texas in 1967 with a major in Plan II, an interdisciplinary honors program modeled after the Harvard Society of Fellows Program. She was selected for the UT-Chilean Exchange Program in 1964, and spent a year in Chile as a Fulbright Scholar. Shaw earned two degrees from Columbia University: an MFA degree in Film in 1970, and a doctorate in Public Health/Environmental Health Sciences (Dr.P.H.) in 1999.In",1
"Funded by the National Oceanic and Atmospheric Administration (NOAA), this region-wide effort has produced a large body of data on a wide range of persistent organic pollutants, including flame retardants, in marine mammals and fish that has placed the region in a global perspective. This work has shown that levels of toxic chemicals, such as polychlorinated biphenyls (PCBs), in northwest Atlantic harbor seals are among the highest in the world.",1
"It presented a large body of scientific evidence of the negative health effects, including cancer, that are associated with exposure to halogenated flame retardants in consumer products. The paper had national policy implications, laying the groundwork for the San Antonio Statement, which cited the need for regulatory action on halogenated flame retardant chemicals worldwide. It was signed by more than 300 scientists from 30 countries. Shaw's paper and the statement were, in turn, the basis for the Chicago Tribune's 2012 exposé of the chemical industry's campaign to market harmful flame retardant chemicals to the American public.",1
"The Shaw Institute subsequently launched Gulf EcoTox, an independent investigation into the effects of oil and chemical dispersants in the food web.Shaw predicted the decimation of deep-water coral, species known to be sensitive to the Corexit-oil mixture, and the deaths of dolphins from unavoidable inhalation of the mixture as they surfaced to breathe. Both outcomes have since occurred.",1
"She also predicted with certainty the human health crisis in the Gulf today, stating that a scientific review found that “five of the Corexit ingredients are linked to cancer, 33 are associated with skin irritation from rashes to burns, 33 are linked to eye irritation, 11 are or are suspected of being potential respiratory toxins or irritants, and 10 are suspected kidney toxins.”She delivered three TEDx talks discussing the long-term damage to the ecosystem and the impending human health crisis in the Gulf as a result of exposure to the oil-Corexit mixture.",1
"She appeared in documentary films on the oil spill, including Animal Planet's Black Tide: Voices of the Gulf and Green Planet's The Big Fix. The Shaw Institute's research examines the sources, fate, exposure pathways, tissue-specific bioaccumulation/biomagnification, and health effects of organic halogenated chemicals and other toxic man-made chemicals in the environment. The organization's current work focuses on highly exposed populations, including firefighters, to indoor contaminants including flame retardants and carcinogenic combustion by-products that may relate to their elevated rates of cancer.",1
"The study's findings suggested that chemical exposure during firefighting may carry higher risk for multiple cancers than previously demonstrated. Based on these findings, in 2014, the Institute announced plans for a long-term study of chemical exposure and cancer risk in U.S. firefighters.In 2012 Shaw launched a study into microplastics in the Gulf of Maine that influenced a nationwide ban of microbeads in cosmetics. Shaw Institute scientists led a 2018 study on the uptake and expulsion of microplastic fibers by blue mussels (Mytilus edulis) in the Gulf of Maine.",1
"In 2018, the Shaw Institute partnered with the international Plastics Health Coalition in order to advance understanding of the damaging effects of microplastics in the human body and to promote plastic reduction across multiple sectors on a global scale. Shaw's final work was to draw attention to the health hazards faced by children employed as waste pickers and e-waste recyclers. Shaw was a Woodrow Wilson Visiting Fellow to U.S. universities and was named a Gulf of Maine Visionary by the Gulf of Maine Council on the Marine Environment in 2007.",1
"In May 2011, she became the 19th recipient of the Society of Woman Geographers' Gold Medal Award dating back to 1933, when Amelia Earhart became its first recipient. In March 2012, Shaw received the Explorers Club Citation of Merit Award for her work in ocean conservation. In 2011, she was named “Woman of the Gulf” by Audubon Society Women in Conservation at the Rachel Carson Awards. She was a recipient of the 2012 Next Award from Mainebiz magazine for her work in shaping the future and the economy of Maine.",1
"On Earth Day 2019, Shaw was named one of the ""Top Eco-Warrior Women in the World"" by Make it Better magazine. Shaw met artist Cynthia Stroud, her future wife, in 1980 in New York City. They moved to Brooklin, Maine, where they lived for several decades. They played pétanque competitively, including a second-place finish at the 2012 Federation Petanque USA Women's World Qualifier. They moved back to New York City, where Shaw died on January 27, 2022, at the age of 78. ""Curriculum Vitae, Susan D. Shaw, Dr.P.H."" (PDF). shawinstitute.org. January 20, 2020. Retrieved February 5, 2022.",1
"One option involves piling the spoil onto a new bank on the still lower slope, in which case a bund or berm is formed, mitigating the natural (and often hardscape-increased) risks to slopes below and to any linked watercourse from flash flooding. In arid and seasonally dry places, vegetation (existing or planted) in the swale benefits heavily from the concentration of runoff. Trees and shrubs along the swale can provide shade and mulch which decrease evaporation.",1
"Written records, dating from as early as 1792, describe effects of offshore seeps in the Santa Barbara Channel. Oil and tar ""slicks"" have long been a trademark of the area. In 1792, Captain Cook's navigator George Vancouver recorded on passing through the channel: The surface of the sea, which was perfectly smooth and tranquil, was covered with a thick, slimy substance, which when separated or disturbed by a little agitation, became very luminous, whilst the light breeze, which came principally from the shore, brought with it a strong smell of tar, or some such resinous substance.It",1
"The location of the COP seep field offshore from the University of California, Santa Barbara (UCSB) has situated it as a natural laboratory for study of the phenomena of oil and gas introduced into the ocean from the sea bed, along with the role of geologic methane from seeps worldwide in the global methane budget. Since the 1990s almost a dozen UCSB researchers along with their graduate students have studied the geology, chemistry, oceanography and ecology of the marine seep system at COP.",1
"Many of these studies were in partnership with oil companies including Mobil and Venoco, which produced oil from reservoirs below the seeps, and the U.S. Geological Survey and California State Lands Commission.",1
"Because the COP seeps are characterized by large visible gas bubble plumes they can be detected and mapped by sonar backscatter. The first attempts at this were made by Peter Fischer and colleagues of California State University, Northridge in the early 1970s. They produced reconnaissance level maps of bubble plumes at COP and at other locations in the Santa Barbara Channel. They noted that because the COP seeps were associated with a producing oil platform then operated by ARCO, continued oil production might result in a decrease in volume of seep discharge.",1
"Comparing the surveys made in the mid 1990s with the early 1970s data of Fischer and colleagues they determined that seepage near the producing platform Holly had decreased by half. This observation was supported by gas capture data recorded by two sea floor tent structures that covered one large seepage area. Surveys continued over the 1990s and 2000s using more sophisticated sonars including chirp and multibeam sonars. These repeat sonar surveys did not detect further decrease in seepage, while during the same period oil production continued. Refugio oil spill University of California Natural Reserve System Bruce P. Luyendyk Tessa M.",1
"Hill Luyendyk, Bruce; James Kennett; Jordan F. Clark (2005). ""Hypothesis for increased atmospheric methane input from hydrocarbon seeps on exposed continental shelves during glacial low sea level"" (PDF). Marine and Petroleum Geology. Elsevier. 22 (4): 591–596. doi:10.1016/j.marpetgeo.2004.08.005. UCSB Hydrocarbon Seeps – University of California Santa Barbara Bathymetry of Groundhog Reservoir, Dolores County, Colorado, 2011 – United States Geological Survey",1
This impounded liquid waste can sometimes total billions of gallons in a single facility. Coal-water slurry fuel Pulverized coal Sludge (film) Tailings dam,1
"In this process the dried outer layer of the cherry, known as the pericarp, is removed mechanically.",1
"During the washing process the research in Nicaragua showed a clear decrease in contamination of the wastewater. The COD values drop from an average of 7,200 mg/L to less than 50 mg/L. Despite the fact that wastewater with COD values below 200 mg/L is allowed to be discharged in the natural waterways in Nicaragua it is advisable to redirect all the wastewater to the treatment system. This is because COD levels cannot be determined onsite during the washing process and discharge of the wastewater into surface waters is based on visual inspection.",1
"TP concentration in the samples ranged from 7.8 to 15.8 mg/L with an average over all samples of 10.7 mg/L. Guideline for Discharge of Industrial Effluent Characteristics. Vol. 3. Geneva: World Health Organization. 1995. pp. 231–236. Devi, Rani; Singh, Vijender; Kumar, Ashok (April 2008). ""COD and BOD reduction from coffee processing wastewater using Avocado peel carbon"". Bioresource Technology. 99 (6): 1853–1860. doi:10.1016/j.biortech.2007.03.039. PMID 17493806.",1
"The rules require some facilities to retrofit their impoundments with liners, while other facilities may propose alternative designs and request additional time to achieve compliance. In August 2021 EPA announced that it plans to publish a proposed rule in fall 2022 that would strengthen wastewater limits for discharges to surface waters. About 52 percent of CCPs in the U.S. were recycled for ""beneficial uses"" in 2019, according to the American Coal Ash Association. In Australia about 47% of coal ash was recycled in 2020.",1
"Explosives have important applications in the military and in both mining and construction work. In fact, the manufacture of explosives comprises a large amount of the chemical industry. In the course of their production, handling, loading, and disposal, explosives are released into the environment. It is there that they are dispersed by mechanical processes or dissolved or volatilized and partially converted to secondary products. Over the past 150 years, millions of tons of explosives have been produced for military applications and other activities that have led to the accidental contamination of energetic materials in the soil and groundwater.",1
"The main cause of wildlife exposure to oil is oil spills. Oil spills occur most commonly near oil-shipping routes, pipelines, wells and refineries. Oil spills have a more drastic impact in the late winter and early spring months, because large populations of overwintering birds gather near shores. The Deepwater Horizon Oil Spill (also known as the BP Oil Spill) was estimated to have killed over 8,000 birds, sea turtles and marine mammals from April to September in 2010.Animals come into direct contact with the oil, and may ingest, inhale or absorb it.",1
"Animals may also become contaminated by eating other contaminated animals. Any animal can come into direct contact with an oil spill. However, marine species are more likely to be impacted by an oil spill.",1
"Of the many species affected by direct exposure to oil, birds are usually the most severely affected. Birds that nest near the shoreline are most likely to be affected, including loons (Gavia spp.), grebes (Family: Podicipedidae), murres (Uria spp.), pelicans (Family: Pelecanidae), and penguins (Family: Spheniscidae). The species of bird and the type of oil can vary the effects of oil exposure. Birds affected often die from hypothermia, starvation, exhaustion, or drowning. Birds exposed to oil become more susceptible to other diseases due to a reduced immunologic function.Birds",1
Eggs laid prior to an oil spill can also become damaged if an affected animal sits on the nest.,1
"In some light, transparent oils may be difficult to detect visually. Animals can also be internally diagnosed via necropsy by identifying petroleum hydrocarbons in their fat, liver, or kidney tissues For damage assessments, the death of the animal must have occurred after the oil spill.The severity of damage directly correlates with the amount of oil spilled and the animal's exposure to oil. However, a small spill at a more sensitive season or environment may have more drastic impacts than a large spill in a less sensitive season or environment.",1
"External exposure to oil often leads to destroyed insulating fur or feathers, resulting in death from hypothermia. Contact with oil can also result in blindness, which impairs animals' ability to compete for food or to avoid predators.The ingestion of oil can cause a variety of internal problems. These include anemia, reproductive impairment, and damage to the stomach and intestines. These animals can also suffer from dehydration and pneumonia, due to a decreased thermo-regulation. Animals affected by oil should be cleaned and allowed to recover from stress. Animals should be kept in a quiet and warm environment while they recover.",1
"Direct contact with oil or oiled wildlife can be hazardous to human health, so it is recommended that treatment be performed by people who have received training.",1
"In Jouany's mindset, ecotoxicology is primarily linked to ecology for its goal seeks to circumscribe the influence that stress factors can have on relationships existing between organisms and their habitat. Jean-Michel Jouany was indeed the young and brilliant mentor of René Truhaut who was at the time empowered to disseminate the emerging discipline proposed by his young assistant at the international level. Jean-Michel Jouany was promoted to the rank of full professor at the University of Nancy in 1969.",1
"He then laid out the teaching and research principles for ecotoxicology at the University of Metz with his colleague, Jean-Marie Pelt, as early as 1971.In France, two universities (Metz and Paris-Sud) markedly contributed to expand this burgeoning discipline during the 1980s and 1990s. Several institutes followed suit in this respect. Indeed, CEMAGREF (now IRSTEA), INERIS, IFREMER and CNRS created research units in ecotoxicology, as did other French universities (in Rouen, Bordeaux, Le Havre, Lyon, Lille, Caen...).",1
"Chemicals propose the risk of killing off another animal's food supply that changes the overall population of the prey Animals can go to the brink of extinction because of the food chain that exists through the different communities. For example, bald eagles, ospreys, and peregrine falcons were facing extinction because their food sources (fish and other birds) were contaminated with toxins. We are all connected between the communities of living things. Plants can absorb toxins through their roots and leaves.",1
"The genetics can be affected by toxicant exposure, direct changes can occur to the DNA, and if not repaired, the changes can lead to the appearance mutations Contaminants can modify the distribution of individuals in a population, effective population size, mutation rate and migration rate Predator-prey relationships – either the predator is affected by the toxin resulting in a decline of predator population and thus increasing the prey population; or the prey population is affected by the toxin resulting in a decline in the prey population that, in essence, will cause a decline in the predator population due to lack of",1
"food resources Community ecotoxicology studies the effects of all contaminants on patterns and species abundance, diversity, community composition, and species interactions. Communities that rely heavily on competition and predation will have a difficult time responding and thriving in disturbances from contaminants. A community that is species-rich will have a better chance recovering from an exotoxin disturbance, rather than a community that is not species-rich. A species could be easily wiped out to the expense of a contamination from foreign chemicals.",1
"Protecting distinct community levels, such as species richness and diversity is essential for maintaining a healthy, well-balanced ecosystem Chemicals are shown to prohibit the growth of seed germination of an arrangement of different plant species. Plants are what make up the most vital trophic level of the biomass pyramids, known as the primary producers. Because they are at the bottom of the pyramid, every other organism in an ecosystem relies on the health and abundance of the primary producers in order to survive.",1
"Proper waste disposal Acute and chronic toxicity tests are performed terrestrial and aquatic organisms including fish, invertebrates, avians, mammalians, non-target arthropods, earthworms and rodents. The Organization for Economic Cooperation and Development (OECD) test guideline has developed specific tests to test toxicity level in organisms. Ecotoxicological studies are generally performed in compliance with international guidelines, including EPA, OECD, EPPO, OPPTTS, SETAC, IOBC, and JMAFF. LC50 is the acute toxicity, the lethal concentration at which 50% of the test organism dies within the test-specified time. The test may start with eggs, embryos, or juveniles and last from 24 hours to 96 hours.",1
"EC50 is the concentration that causes adverse effects in 50% of the test organisms (for a binary yes/no effect such as mortality or a specified sublethal effect) or causes a 50% (usually) reduction in a non-binary parameter such as growth. No observed effect concentration (NOEC) is the highest dose of stressor at which there is no statistically significant difference of effect (p<0.05) seen in the test organism. Endocrine Disruptor Screening Program (EDSP) Tier 1 screening battery Endangered species assessments. Persistent, Bioaccumulative, and Inherently Toxic (PBiT) assessments using the Quantitative Structure-Activity Relationships (QSARs) to categorize regulated substances.",1
Bioaccumulation in fish using the Bioconcentration Factor (BCF) methods. Total amount of acute toxicity is directly related to the classification of toxicity.,1
"The introduction of artificial light disrupts several natural light cycles that arise from the movements of the Earth, Moon, and Sun, as well as from meteorological factors.",1
"The axial tilt of the Earth results in seasons outside of the tropics. The change in the length of the day, or photoperiod, is the key signal for seasonal behavior (e.g. mating season) in non-tropical animals and plants. The presence of light at night can result in ""seasons out of time"", changing the behavior, thermoregulation, and hormonal functioning of affected organisms. This may result in a disconnect between body functioning and seasonality, causing disruptions to reproduction, dormancy, and migration.",1
"The behavior of some animals (e.g. coyotes, bats, toads, insects) is keyed to the lunar cycle. Near city centers the level of skyglow often exceeds that of the full moon, so the presence of light at night can alter these behaviors, potentially reducing fitness.",1
"In pristine areas, clouds blot out the stars and darken the night sky, resulting in the darkest possible nights. In urban and suburban areas, in contrast, clouds enhance the effect of skyglow, particularly for longer wavelengths. This means that the typical level of light is much higher near cities, but it also means that truly dark nights never occur in these areas.",1
"The attraction of insects to artificial light is one of the most well known examples of the effect of light at night on organisms. When insects are attracted to lamps they can be killed by exhaustion or contact with the lamp itself, and they are also vulnerable to predators like bats.Insects are affected differently by the varying wavelengths of light, and many species can see ultraviolet and infrared light that is invisible to humans.",1
"Lights on tall structures can disorient migrating birds leading to fatalities. An estimated 365-988 million fatal bird collisions with buildings occur annually in North America, making human-made structures a large contributor to the decline in bird species. The surface area of glass emitting artificial light at night is a major factor for fatal bird collisions with buildings, and turning off lights at night can minimize these fatalities. The Fatal Light Awareness Program (FLAP) works with building owners in Toronto, Canada and other cities to reduce mortality of birds by turning out lights during migration periods.",1
"Similar disorientation has also been noted for bird species migrating close to offshore production and drilling facilities. Studies carried out by Nederlandse Aardolie Maatschappij b.v. (NAM) and Shell have led to development and trial of new lighting technologies in the North Sea. In early 2007, the lights were installed on the Shell production platform L15. The experiment proved a great success since the number of birds circling the platform declined by 50–90%.[56] Juvenile seabirds may also be disoriented by lights as they leave their nests and fly out to sea. Birds migrate at night for several reasons.",1
"Lights from seashore developments repel nesting Sea turtle mothers, and their hatchlings are fatally attracted to street and hotel lights rather than to the ocean.",1
"Artificial lighting has many negative impacts on trees and plants, particularly in fall and autumn phenology. Trees and herbaceous plants rely on the photoperiod, or the amount of time in a day where sunlight is available for photosynthesis, to help determine the changing seasons. When the hours of sunlight decrease, plants can recognize that autumn is underway and begin to make preparations for winter dormancy.",1
"Small herbaceous plants that are exposed to artificial lighting potentially face a greater risk, as more of their body is illuminated. Therefore, only the root system is protected, and could potentially not be enough to sustain the whole plant as it tries to remain green through the fall and winter.",1
"At the turn of the century it was discovered that human eyes contain a non-imaging photosensor that is the primary regulator of the human circadian rhythm. This photosensor is particularly affected by blue light, and when it observes light the pineal gland stops the secretion of melatonin. The presence of light at night in human dwellings (or for shift workers) makes going to sleep more difficult and reduces the overall level of melatonin in the bloodstream, and exposure to a low-level incandescent bulb for 39 minutes is sufficient to suppress melatonin levels to 50%.",1
"In the early 20th century, cars entered mass production. The United States produced 45,000 cars in 1907, but 28 years later, in 1935, that had increased nearly 90-fold to 3,971,000. The increase in production required a large new workforce. In 1913, 14,366 people worked for the Ford Motor Company, and by 1916 that had increased to 132,702.",1
"Bradford DeLong, an economic historian, noted that ""Many more lined up outside the Ford factory for chances to work at what appeared to them to be, and (for those who did not mind the pace of the assembly line much) was an incredible boondoggle of a job"". There was a surge in the need for workers at big, new high-technology companies such as Ford. Employment increased greatly. When the motor age arrived in western countries at the beginning of the 20th century, many conservative intellectuals opposed the increase in motor vehicles on the roads.",1
"Those increases removed space for pedestrians, made walking more dangerous, and brought a tremendous increase in pedestrian deaths caused by car collisions. W.S. Gilbert, the famous British librettist, wrote to The Times on 3 June 1903: Sir,–I am delighted with the suggestion made by your spirited correspondent Sir Ralph Payne-Gallwey that all pedestrians shall be legally empowered to discharge shotguns (the size of the shot to be humanely restricted to No. 8 or No. 9) At all motorists who may appear to them to be driven to the common danger.",1
"Not only would this provide a speedy and effective punishment for the erring motorist, but it would also supply the dwellers on popular high roads with a comfortable increase of income. ""Motor shooting for a single gun"" would appeal strongly to the sporting instincts of the true Briton, and would provide ample compensation to the proprietors of eligible road-side properties for the intolerable annoyance caused by the enemies of mankind.",1
"Ten years later, Alfred Godley wrote a more elaborate protest, ""The Motor Bus"", a poem which cleverly combined a lesson in Latin grammar with an expression of distaste for the new form of motor transport. Worldwide, the car has allowed easier access to remote places. However, average journey times to regularly visited places have increased in large cities, as a result of widespread car adoption and urban sprawl, as well as the decommissioning of older tram systems. This is due to traffic congestion and the increased distances between home and work brought about by urban sprawl.",1
"In aggregate, this led to less dense settlements and made a carless lifestyle increasingly unattractive. Retail parks attract revenue away from high streets and town centres. Many new shopping centers and suburbs did not install sidewalks, making pedestrian access dangerous. This had the effect of encouraging people to drive, even for short trips that might have been walkable, thus increasing and solidifying American auto-dependency.",1
"As a result of this change, employment opportunities and activities for people who were not wealthy enough to own a car and for people who could not drive, due to age or physical disabilities, became severely limited since they could not travel far.",1
"In countries with major car manufacturers, such as USA or Germany, a certain degree of car dependency might be positive for the economy at a macroeconomic level, since it demands automobile production, therefore resulting also in job demand and tax revenue. These economic conditions were particularly valid during the 1920s when the number of automobiles, worldwide, had a substantial annual average increase, but also during the post–World War II economic expansion.",1
"Notwithstanding the growing effects provided by the automobile on the economy of some countries, several other auto-dependent countries, deprived from automobile industry and oil resources, have to allocate substantial economic assets, to satisfy its mobility policies, affecting then their commercial balance. This situation is broadly valid in the majority of the European countries, since, disregarding some few exceptions such as Norway, Europe is largely dependent on imports for its fossil fuels. Furthermore, just few European countries, such as Germany or France, have car manufacturers productive enough to satisfy their country's internal demand for cars.",1
"All these factors related to high motorisation rates, affect therefore the economic growth in the majority of the European countries.",1
"As of 2009 the U.S. motor vehicle manufacturing industry employed 880,000 workers, or approximately 6.5% of the U.S. manufacturing workforce. Cycling steadily became more important in Europe over the first half of the 20th century, but it dropped off dramatically in the United States between 1900 and 1910. Automobiles became the dominant means of transportation. Over the 1920s, bicycles gradually became considered children's toys, and by 1940 most bicycles in the US were made for children.",1
"From the early 20th century until after WWII, the roadster constituted most adult bicycles sold in the UK and in many parts of the British Empire. For many years after the advent of the motorcycle and automobile, they remained a primary means of adult transport.",1
"In several countries - both high and low income - bicycles have retained or regained this position. In Denmark, cycling policies were adopted as a direct consequence of the 1973 oil crisis, whereas bike advocacy in the Netherlands started in earnest with a campaign against traffic deaths called ""stop child murder"". Today both countries have high modal shares of cycling while also having high car ownership rates.",1
"The motorcycle made regular medium-distance travel more convenient and affordable and after World War I the automobile too, especially in areas without railways. Because cars did not require rest, were faster than horse-drawn conveyances, and soon had a lower total cost of ownership, more people were routinely able to travel farther than in earlier times. The construction of highways in the 1950s continued this. Some experts suggest that many of these changes began during the earlier Golden age of the bicycle, from 1880 to 1915.",1
"Beginning in the 1940s, most urban environments in the United States lost their streetcars, cable cars, and other forms of light rail, to be replaced by diesel-run motor coaches or buses. Many of these have never returned, but some urban communities eventually installed rapid transit. Another change brought about by the car is that modern urban pedestrians must be more alert than their ancestors. In the past, a pedestrian had to worry about relatively slow-moving streetcars or other obstacles of travel.",1
"With the proliferation of the car, a pedestrian has to anticipate safety risks of automobiles traveling at high speeds because they can cause serious injuries to a human and can be fatal, unlike in previous times when traffic deaths were usually due to horses escaping control. According to many social scientists, the loss of pedestrian-scale villages has also disconnected communities. Many people in developed countries have less contact with their neighbors and rarely walk unless they place a high value on walking.",1
"Following World War II in the United States, government policies and regulations such as the Federal-Aid Highway Act of 1956, low-cost mortgages through the G.I. Bill, and residential redlining combined with white flight to foster the creation of suburbs. Suburban affluence led to a baby boomer generation far removed from the hardships of their parents. Community standards of the past, driven by scarcity and the need to share public resources, gave way to new credos of self-exploration.",1
"As the economy of the 1950s and 1960s boomed, car sales grew steadily, from 6,000,000 units sold per year in the United States to 10,000,000. Married women entered the workforce and two-car households with driveways and garages became commonplace. In the 1970s, however, the comparative economic stagnation then experienced was accompanied by societal self-reflection on the changes the motor car brought. Critics of automotive society found little positive choice in the decision to move to the suburbs; the physical movement was looked upon as flight.",1
"The automotive industry was also under attack from bureaucratic fronts, and new emission and CAFÉ regulations began to hamper Big Three (automobile manufacturers) profit margins as the United States went into a recession. Kenneth R. Schneider in Autokind vs Mankind (1971) called for a war against the automobile, derided it for being a destroyer of cities, and likened its proliferation to a disease. In combination with his second book On the Nature of Cities (1979), he called for a struggle to halt and partially reverse negative developments in transportation, although he was largely ignored at the time.",1
"Renowned social critic Vance Packard in A Nation of Strangers (1972) blamed the geographic mobility enabled by the auto for loneliness and social isolation. Automobile sales peaked in 1973, at 14.6 million units sold, and were not to reach comparable levels for another decade. The 1973 Arab-Israeli War was followed by the OPEC oil embargo, leading to an explosion of prices, long queues at filling stations, and talks of rationing fuel.",1
"While it may appear clear, in retrospect, that the automotive/suburban culture would continue to persist, as it did in the 1950s and 1960s, no such certainty existed at the time when British architect Martin Pawley authored his seminal work, The Private Future (1973). Pawley called the automobile ""the shibboleth of privatisation; the symbol and the actuality of withdrawal from the community"" and perceived that, in spite of its momentary misfortunes, its dominance in North American society would continue.",1
"The car was a private world that allowed for fantasy and escape, and Pawley forecasted that it would grow in size, and in technological capacities. He saw no pathology in consumer behavior grounded in freedom of expression. Improved transport accelerated the outward growth of cities and the development of suburbs beyond an earlier era's streetcar suburbs. Until the advent of the car, factory workers lived either close to the factory or in high-density communities farther away, connected to the factory by streetcar or rail.",1
"The car had a significant effect on the culture of the United States. In American society, the automobile has traditionally played an important role in personal mobility and is often seen as a symbol of independence, individualism and freedom. According to German business magazine Manager Magazin, the United States is considered ""the car country par excellence"", being the ""homeland of drive-in restaurants, car cinemas and Route 66"".As other vehicles had been, cars were incorporated into artworks including music, books and movies. Between 1905 and 1908, more than 120 songs were written in which the automobile was the subject.",1
"Where 19th-century mass media had made heroes of Casey Jones, Allan Pinkerton and other stalwart protectors of public transport, new road movies offered heroes who found freedom and equality, rather than duty and hierarchy, on the open road. George Monbiot writes that widespread car culture has shifted voter's preference to the right-wing of the political spectrum, and thinks that car culture has contributed to an increase in individualism and fewer social interactions between members of different socioeconomic classes.",1
"The American Motor League had promoted the making of more and better cars since the early days of the car, and the American Automobile Association joined the good roads movement begun during the earlier bicycle craze; when manufacturers and petroleum fuel suppliers were well established, they also joined construction contractors in lobbying governments to build public roads.As tourism became motorized, individuals, families and small groups were able to vacation in distant locations such as national parks. Roads including the Blue Ridge Parkway were built specifically to help the urban masses experience natural scenery previously seen only by a few.",1
Cheap restaurants and motels appeared on favorite routes and provided wages for locals who were reluctant to join the trend to rural depopulation.,1
"Road building was sometimes also influenced by Keynesian-style political ideologies. In Europe, massive freeway building programs were initiated by a number of social democratic governments after World War II, in an attempt to create jobs and make the car available to the working classes. From the 1970s, promotion of the automobile increasingly became a trait of some conservatives. Margaret Thatcher mentioned a ""great car economy"" in the paper on Roads for Prosperity.",1
"The rise of car culture during the twentieth century played an important cultural role in cinema, including in road movies and blockbusters. James Bond was seen in his Aston Martin DB5, and James Dean in other powerful automobiles. Some comedies and fantasies such as Go Trabi Go, Herbie, Chitty Chitty Bang Bang, and Cars (film) concentrated on the car as a character. Others such as A Racing Romeo, The Great Race, and Racing Dreams were about automobile racing.",1
"With the advent of car radios, radio programming during rush hour became known as drive time. Music also references impacts such as Big Yellow Taxi.",1
"Over time, the car has evolved beyond being a means of transportation or status symbol and into a subject of interest and a cherished lifestyle amongst many people in the world, who appreciate cars for their craftsmanship, their performance, as well as the vast arrays of activities one can take part in with one's car. People who have a keen interest in cars and/or participate in the car hobby are known as ""Car Enthusiasts"". One major aspect of the hobby is collecting. Cars, especially classic vehicles, are appreciated by their owners as having aesthetic, recreational and historic value.",1
"Such demand generates investment potential and allows some cars to command extraordinarily high prices and become financial instruments in their own right.A second major aspect of the car hobby is vehicle modification, as many car enthusiasts modify their cars to achieve performance improvements or visual enhancements.",1
"Many subcultures exist within this segment of the car hobby, for example, those building their own custom vehicles, primarily appearance-based on original examples or reproductions of pre-1948 US car market designs and similar designs from the World War II era and earlier from elsewhere in the world, are known as hot rodders, while those who believe cars should stay true to their original designs and not be modified are known as ""Purists"".",1
"In addition, motorsport (both professional and amateur) as well as casual driving events, where enthusiasts from around the world gather to drive and display their cars, are important pillars of the car hobby as well. Notable examples of such events are the annual Mille Miglia classic car rally and the Gumball 3000 supercar race. Many car clubs have been set up to facilitate social interactions and companionships amongst those who take pride in owning, maintaining, driving and showing their cars.",1
"Many prestigious social events around the world today are centered around the hobby, a notable example is the Pebble Beach Concours d'Elegance classic car show.",1
"For those aged 5–34 in the United States, motor vehicle crashes are the leading cause of death, claiming the lives of 18,266 Americans each year.It is estimated that motor vehicle collisions caused the death of around 60 million people during the 20th century around the same number of World War II casualties. Just in 2010 alone, 1.23 million people were killed due to traffic collisions.Notwithstanding the high number of fatalities, the trend of motor vehicle collision is showing a decrease. Road toll figures in developed nations show that car collision fatalities have declined since 1980.",1
"Japan is an extreme example, with road deaths decreasing to 5,115 in 2008, which is 25% of the 1970 rate per capita and 17% of the 1970 rate per vehicle distance travelled. In 2008, for the first time, more pedestrians than vehicle occupants were killed in Japan by cars. Besides improving general road conditions like lighting and separated walkways, Japan has been installing intelligent transportation system technology such as stalled-car monitors to avoid crashes. In developing nations, statistics may be grossly inaccurate or hard to get.",1
"Some nations have not significantly reduced the total death rate, which stands at 12,000 in Thailand in 2007, for example. In the United States, twenty-eight states had reductions in the number of automobile crash fatalities between 2005 and 2006. 55% of vehicle occupants 16 years or older in 2006 were not using seat belts when they crashed. Road fatality trends tend to follow Smeed's law, an empirical schema that correlates increased fatality rates per capita with traffic congestion. Motoring offences and crimes related to cars include offences predating the automobile rather than exclusive to it.",1
Many have become more prevalent with the rise of mass motoring. Car bomb Car theft Drive-by shooting DUI Jaywalking Parking violation Speeding Street racing Vehicular homicide,1
"This government support of the automobile through subsidies for infrastructure, the cost of highway patrol enforcement, recovering stolen cars, and many other factors makes public transport a less economically competitive choice for commuters when considering out-of-pocket expenses. Consumers often make choices based on those costs, and underestimate the indirect costs of car ownership, insurance and maintenance. However, globally and in some US cities, tolls and parking fees partially offset these heavy subsidies for driving.",1
"million euros with the share of this cost born by society being between 41% (€4674 per year) and 29% (€5273 per year). This suggests that cars consume ""a large share of disposable income"", creating ""complexities in perceptions of transport costs, the economic viability of alternative transport modes, or the justification of taxes"".",1
"Compared to other popular modes of passenger transportation, especially buses or trains, the car has a relatively high cost per passenger-distance travelled. Motorists in the United Kingdom seem to spend on their cars an average of roughly 1/3 of their average net income, while motorists in Portugal seem to spend 1/2 of their net income. For the average car owner, depreciation constitutes about half the cost of running a car, nevertheless the typical motorist underestimates this fixed cost by a big margin, or even ignores it altogether.In",1
"the United States, out of pocket expenses for car ownership can vary considerably based on the state in which you live. In 2013, annual car ownership costs including repair, insurance, gas and taxes were highest in Georgia ($4,233) and lowest in Oregon ($2,024) with a national average of $3,201. Furthermore, the IRS considers, for tax deduction calculations, that the automobile has a total cost for drivers in the US, of US$0.55/mile, around 0.26 EUR/km. Data provided by the American Automobile Association indicates that the cost of ownership for an automobile in the United States is rising about 2% per year.",1
"2013 data provided by the Canadian Automobile Association concludes that the cost of ownership for a compact car in Canada, including depreciation, insurance, borrowing costs, maintenance, licensing, etc. was CA $9500 per year, or about US$7300.",1
"The Austrian philosopher Ivan Illich, a critic of the modern society habits, was one of the first thinkers to establish the so-called consumer speed concept. He defined the term in his 1974 book Energy and Equity as the distance that an average person commutes each year, divided by the amount of time dedicated to commuting and related activities. He calculated that the average American male spent 1,600 hours per year in car-related activities — about 28% of the time they spend awake — and traveled 7,500 miles (12,100 km) by car each year, giving a consumer speed of about 4.7",1
"mph (7.6 km/h). In comparison, their contemporaries in developing countries spent less than 8% of their time walking. In other words, ""[w]hat distinguishes the traffic in rich countries from the traffic in poor countries is not more mileage per hour of lifetime for the majority, but more hours of compulsory consumption of high doses of energy, packaged and unequally distributed by the transportation industry."" Forum for the Automobile and Society Traffic Volumes & Highway Capacity Manifesto for the Reorganisation of the City after COVID19",1
"may carry pollutants such as fats, oils and greases; solvents, detergents and other chemicals; heavy metal; other solids; and food waste. Possible sources include a wide range of manufacturing industries, mining industries, oil and gas extraction, and service industries. There are several kinds of wastewater which are treated at the appropriate type of treatment plant. Domestic wastewater (also called municipal wastewater or sewage) is processed at a sewage treatment plant. For industrial wastewater, treatment either takes place in a separate industrial wastewater treatment facility, or in a sewage treatment plant (usually after some form of pre-treatment).",1
"The U.S. ""Secondary Treatment Regulation"" is the national standard for municipal sewage treatment plants. Agricultural wastewater treatment Effluent guidelines (U.S. wastewater regulations) Effluent limitation Industrial wastewater treatment Stormwater Surface runoff",1
"Pokorny in the US achieved this as well.Independently, a team under Juda Hirsch Quastel, working at the Rothamsted Experimental Station made the same discovery. Quastel was tasked by the Agricultural Research Council (ARC) to discover methods for improving crop yield. By analyzing soil as a dynamic system, rather than an inert substance, he was able to apply techniques such as perfusion. Quastel was able to quantify the influence of various plant hormones, inhibitors, and other chemicals on the activity of microorganisms in the soil and assess their direct impact on plant growth.",1
"Control is the destruction of unwanted weeds or the damage of them to the point where they are no longer competitive with the crop. Suppression is incomplete control and still provides some economic benefits, such as reduced competition with the crop. Crop safety, for selective herbicides, is the relative absence of damage or stress to the crop. Most selective herbicides cause some visible stress to crop plants. Defoliant, similar to herbicides, but designed to remove foliage (leaves) rather than kill the plant.",1
"The basis of selectivity is based on physical or biological factors. Some biological factors include morphology, physiology, metabolism, and biochemical factors. There are some climatic factors affecting absorption including humidity, light, precipitation, and temperature. Foliar-applied herbicides will enter the leaf more readily at high humidity by lengthening the drying time of the spray droplet and increasing cuticle hydration. Light of high intensity may break down some herbicides and cause the leaf cuticle to thicken, which reduces absorption. Precipitation may wash away or remove some foliar-applied herbicides but it will increase root absorption of soil-applied herbicides.",1
"Drought-stressed plants are less likely to translocate herbicides. As temperature increases, herbicides' performance may decrease. Absorption and translocation may be reduced in very cold weather. Selective herbicides control or suppress certain plants without affecting the growth of other plant species. Selectivity may be due to translocation, differential absorption, or physical (morphological), or physiological differences between plant species. Surfactants alter the physical properties of the spray solution and the overall phytotoxicity of the herbicide, increasing translocation. 2,4-D, mecoprop, and dicamba control many broadleaf weeds but remain ineffective against turf grasses.",1
"Herbicides do not prevent weeds from germinating but they kill weeds as they grow through the herbicide-treated zone by affecting the cell division in the emerging seedling. Dithiopyr and pendimethalin are preemergence herbicides. Weeds that have already emerged before application or activation are not affected by pre-herbicides as their primary growing point escapes the treatment. Postemergence: These herbicides are applied after weed seedlings have emerged through the soil surface. They can be foliar or root absorbed, selective or nonselective, and contact or systemic. Application of these herbicides is avoided during rain since being washed off the soil makes it ineffective.",1
"2,4-D is a selective, systemic, foliar-absorbed postemergence herbicide.",1
"Volatility and photolysis are two common processes that reduce the availability of herbicides. Many soil-applied herbicides are absorbed through plant shoots while they are still underground leading to their death or injury. EPTC and trifluralin are soil-applied herbicides. Foliar applied: These are applied to a portion of the plant above the ground and are absorbed by exposed tissues. These are generally postemergence herbicides and can either be translocated (systemic) throughout the plant or remain at a specific site (contact). External barriers of plants like cuticles, waxes, cell walls etc. affect herbicide absorption and action. Glyphosate, 2,4-D, and dicamba are foliar-applied herbicides.",1
"Residual activity: An herbicide is described as having low residual activity if it is neutralized within a short time of application (within a few weeks or months) – typically this is due to rainfall, or reactions in the soil. A herbicide described as having high residual activity will remain potent for the long term in the soil. For some compounds, the residual activity can leave the ground almost permanently barren. Herbicides are often classified according to their site of action because as a general rule, herbicides within the same site of action class will produce similar symptoms on susceptible plants.",1
"Classification based on the site of action of the herbicide is preferable as herbicide resistance management can be handled more effectively. Classification by mechanism of action (MOA) indicates the first enzyme, protein, or biochemical step affected in the plant following application.",1
"ACCase inhibitors: Acetyl coenzyme A carboxylase (ACCase) is part of the first step of lipid synthesis. Thus, ACCase inhibitors affect cell membrane production in the meristems of the grass plant. The ACCases of grasses are sensitive to these herbicides, whereas the ACCases of dicot plants are not. ALS inhibitors: Acetolactate synthase (ALS; also known as acetohydroxyacid synthase, or AHAS) is part of the first step in the synthesis of the branched-chain amino acids (valine, leucine, and isoleucine). These herbicides slowly starve affected plants of these amino acids, which eventually leads to the inhibition of DNA synthesis.",1
"Therefore, this group of compounds causes electrons to accumulate on chlorophyll molecules. As a consequence, oxidation reactions in excess of those normally tolerated by the cell occur, and the plant dies. The triazine herbicides (including atrazine) and urea derivatives (diuron) are photosystem II inhibitors. Photosystem I inhibitors steal electrons from ferredoxins, specifically the normal pathway through FeS to Fdx to NADP+, leading to direct discharge of electrons on oxygen. As a result, reactive oxygen species are produced and oxidation reactions in excess of those normally tolerated by the cell occur, leading to plant death.",1
"Mesotrione and sulcotrione are herbicides in this class; a drug, nitisinone, was discovered in the course of developing this class of herbicides.",1
"The WSSA and HRAC systems differ in the group designation. Groups in the WSSA and the HRAC systems are designated by numbers and letters, respectively. The goal for adding the “Group” classification and mode of action to the herbicide product label is to provide a simple and practical approach to deliver the information to users. This information will make it easier to develop educational material that is consistent and effective. It should increase user's awareness of herbicide mode of action and provide more accurate recommendations for resistance management.",1
"Detailed investigations on the chemical structure of active ingredients of the registered herbicides showed that some moieties (moiety is a part of a molecule that may include either whole functional groups or parts of functional groups as substructures; a functional group has similar chemical properties whenever it occurs in different compounds) have the same mechanisms of action. According to Forouzesh et al. 2015, these moieties have been assigned to the names of chemical families and active ingredients are then classified within the chemical families accordingly.",1
"A further method of herbicide application developed around 2010, involves ridding the soil of its active weed seed bank rather than just killing the weed. This can successfully treat annual plants but not perennials. Researchers at the Agricultural Research Service found that the application of herbicides to fields late in the weeds' growing season greatly reduces their seed production, and therefore fewer weeds will return the following season.",1
"Herbicide volatilisation or spray drift may result in herbicide affecting neighboring fields or plants, particularly in windy conditions. Sometimes, the wrong field or plants may be sprayed due to error.",1
"Although herbicidal warfare uses chemical substances, its main purpose is to disrupt agricultural food production and/or to destroy plants which provide cover or concealment to the enemy. During the Malayan Emergency (1948–1960), the British military deployed herbicides and defoliants in the Malaysian countryside (including crop fields) in order to deprive Malayan National Liberation Army (MNLA) insurgents of cover, potential sources of food and to flush them out of the jungle.",1
"Chemical manufacturer Monsanto Company agreed to change its advertising after pressure from New York attorney general Dennis Vacco; Vacco complained about misleading claims that its spray-on glyphosate-based herbicides, including Roundup, were safer than table salt and ""practically non-toxic"" to mammals, birds, and fish (though proof that this was ever said is hard to find). Roundup is toxic and has resulted in death after being ingested in quantities ranging from 85 to 200 ml, although it has also been ingested in quantities as large as 500 ml with only mild or moderate symptoms.",1
"The manufacturer of Tordon 101 (Dow AgroSciences, owned by the Dow Chemical Company) has claimed Tordon 101 has no effects on animals and insects, in spite of evidence of strong carcinogenic activity of the active ingredient, picloram, in studies on rats.The risk of Parkinson's disease has been shown to increase with occupational exposure to herbicides and pesticides. The herbicide paraquat is suspected to be one such factor.The",1
"While some studies have shown that atrazine may be a teratogen, causing demasculinization in male frogs, the EPA and its independent Scientific Advisory Panel (SAP) examined all available studies on this topic and concluded that ""atrazine does not adversely affect amphibian gonadal development based on a review of laboratory and field studies.""",1
"This caused incredibly strong selective pressure upon weeds, encouraging mutations conferring glyphosate resistance to persist and spread.However, in 2015, an expansive study showed an increase in herbicide resistance as a result of rotation, and instead recommended mixing multiple herbicides for simultaneous application. As of 2023, the effectiveness of combining herbicides is also questioned, particularly in light of the rise of non-target site resistance.Plants developed resistance to atrazine and to ALS-inhibitors relatively early, but more recently, glyphosate resistance has dramatically risen. Marestail is one weed that has developed glyphosate resistance.",1
"Glyphosate-resistant weeds are present in the vast majority of soybean, cotton and corn farms in some U.S. states. Weeds that can resist multiple other herbicides are spreading. Few new herbicides are near commercialization, and none with a molecular mode of action for which there is no resistance. Because most herbicides could not kill all weeds, farmers rotate crops and herbicides to stop the development of resistant weeds. A 2008–2009 survey of 144 populations of waterhemp in 41 Missouri counties revealed glyphosate resistance in 69%.",1
"Weeds from some 500 sites throughout Iowa in 2011 and 2012 revealed glyphosate resistance in approximately 64% of waterhemp samples. As of 2023, 58 weed species have developed glyphosate resistance. Weeds resistant to multiple herbicides with completely different biological action modes are on the rise. In Missouri, 43% of waterhemp samples were resistant to two different herbicides; 6% resisted three; and 0.5% resisted four. In Iowa 89% of waterhemp samples resist two or more herbicides, 25% resist three, and 10% resist five.As of 2023, Palmer amaranth with resistance to six different herbicide modes of action has emerged.",1
"Annual bluegrass collected from a golf course in the U.S. state of Tennessee was found in 2020 to be resistant to seven herbicides at once. Rigid ryegrass and annual bluegrass share the distinction of the species with confirmed resistance to the largest number of herbicide modes of action, both with confirmed resistance to 12 different modes of action; however, this number references how many forms of herbicide resistance are known to have emerged in the species at some point, not how many have been found simultaneously in a single plant.In",1
"When mutations occur in the genes responsible for the biological mechanisms that herbicides interfere with, these mutations may cause the herbicide mode of action to work less effectively. This is called target-site resistance. Specific mutations that have the most helpful effect for the plant have been shown to occur in separate instances and dominate throughout resistant weed populations. This is an example of convergent evolution. Some mutations conferring herbicide resistance may have fitness costs, reducing the plant's ability to survive in other ways, but over time, the least costly mutations tend to dominate in weed populations.Recently,",1
"incidences of non-target site resistance have increasingly emerged, such as examples where plants are capable of producing enzymes that neutralize herbicides before they can enter the plant's cells – metabolic resistance. This form of resistance is particularly challenging, since plants can develop non-target-site resistance to herbicides their ancestors were never directly exposed to.",1
"Resistance to herbicides can be based on one of the following biochemical mechanisms: Target-site resistance: In target-site resistance, the genetic change that causes the resistance directly alters the chemical mechanism the herbicide targets. This reduces or neutralizes the ability of the herbicide to bind to its target protein. The mutation may relate to an enzyme with a crucial function in a metabolic pathway, or to a component of an electron-transport system. Target-site resistance may also be caused by an over-expression of the target enzyme (via gene amplification or changes in a gene promoter).",1
"Non-target-site resistance: In non-target-site resistance, the genetic change giving resistance is not directly related to the target site, but causes the plant to be less susceptible by some other means. Some mechanisms include metabolic detoxification of the herbicide in the weed, reduced uptake and translocation, sequestration of the herbicide, or reduced penetration of the herbicide into the leaf surface. These mechanisms all cause less of the herbicide's active ingredient to reach the target site in the first place.The",1
"Worldwide experience has been that farmers tend to do little to prevent herbicide resistance developing, and only take action when it is a problem on their own farm or neighbor's. Careful observation is important so that any reduction in herbicide efficacy can be detected. This may indicate evolving resistance. It is vital that resistance is detected at an early stage as if it becomes an acute, whole-farm problem, options are more limited and greater expense is almost inevitable. Table 1 lists factors which enable the risk of resistance to be assessed.",1
"Much will depend on the resistance mechanisms present, and it should not be assumed that these will necessarily be the same in different populations of the same species. These differences are due, at least in part, to the existence of different mutations conferring target site resistance. Consequently, selection for different mutations may result in different patterns of cross-resistance. Enhanced metabolism can affect even closely related herbicides to differing degrees. For example, populations of Alopecurus myosuroides (blackgrass) with an enhanced metabolism mechanism show resistance to pendimethalin but not to trifluralin, despite both being dinitroanilines.",1
"This is due to differences in the vulnerability of these two herbicides to oxidative metabolism. Consequently, care is needed when trying to predict the efficacy of alternative herbicides.",1
"One practical advantage of sequences of two herbicides compared with mixtures is that a better appraisal of the efficacy of each herbicide component is possible, provided that sufficient time elapses between each application. A disadvantage with sequences is that two separate applications have to be made and it is possible that the later application will be less effective on weeds surviving the first application.",1
"Rotation of herbicides from different chemical groups in successive years should reduce selection for resistance. This is a key element in most resistance prevention programmes. The value of this approach depends on the extent of cross-resistance, and whether multiple resistance occurs owing to the presence of several different resistance mechanisms. A practical problem can be the lack of awareness by farmers of the different groups of herbicides that exist. In Australia a scheme has been introduced in which identifying letters are included on the product label as a means of enabling farmers to distinguish products with different modes of action.",1
"Herbicide resistance became a critical problem in Australian agriculture, after many Australian sheep farmers began to exclusively grow wheat in their pastures in the 1970s. Introduced varieties of ryegrass, while good for grazing sheep, compete intensely with wheat. Ryegrasses produce so many seeds that, if left unchecked, they can completely choke a field. Herbicides provided excellent control, while reducing soil disrupting because of less need to plough. Within little more than a decade, ryegrass and other weeds began to develop resistance. In response Australian farmers changed methods.",1
"By 1983, patches of ryegrass had become immune to Hoegrass, a family of herbicides that inhibit an enzyme called acetyl coenzyme A carboxylase.Ryegrass populations were large, and had substantial genetic diversity, because farmers had planted many varieties. Ryegrass is cross-pollinated by wind, so genes shuffle frequently. To control its distribution farmers sprayed inexpensive Hoegrass, creating selection pressure. In addition, farmers sometimes diluted the herbicide in order to save money, which allowed some plants to survive application. When resistance appeared farmers turned to a group of herbicides that block acetolactate synthase.",1
"Once again, ryegrass in Australia evolved a kind of ""cross-resistance"" that allowed it to rapidly break down a variety of herbicides. Four classes of herbicides become ineffective within a few years. In 2013 only two herbicide classes, called Photosystem II and long-chain fatty acid inhibitors, were effective against ryegrass.",1
"Vinegar is effective for 5–20% solutions of acetic acid, with higher concentrations most effective, but it mainly destroys surface growth, so respraying to treat regrowth is needed. Resistant plants generally succumb when weakened by respraying. Steam has been applied commercially, but is now considered uneconomical and inadequate. It controls surface growth but not underground growth and so respraying to treat regrowth of perennials is needed. Flame is considered more effective than steam, but suffers from the same difficulties. D-limonene (citrus oil) is a natural degreasing agent that strips the waxy skin or cuticle from weeds, causing dehydration and ultimately death.",1
Saltwater or salt applied in appropriate strengths to the rootzone will kill most plants.,1
"SRA during the Steam Era Longworth, Jim Australian Railway Historical Society Bulletin, April, 1996 pp99–116 General InformationNational Pesticide Information Center, Information about pesticide-related topics National Agricultural Statistics ServiceRegulatory policyUS EPA UK Pesticides Safety Directorate European Commission pesticide information pmra Pest Management Regulatory Agency of Canada",1
"Sewage can be treated close to where the sewage is created, which may be called a decentralized system or even an on-site system (on-site sewage facility, septic tanks, etc.). Alternatively, sewage can be collected and transported by a network of pipes and pump stations to a municipal treatment plant. This is called a centralized system (see also sewerage and pipes and infrastructure). A large number of sewage treatment technologies have been developed, mostly using biological treatment processes (see list of wastewater treatment technologies).",1
"Very broadly, they can be grouped into high tech (high cost) versus low tech (low cost) options, although some technologies might fall into either category. Other grouping classifications are intensive or mechanized systems (more compact, and frequently employing high tech options) versus extensive or natural or nature-based systems (usually using natural treatment processes and occupying larger areas) systems. This classification may be sometimes oversimplified, because a treatment plant may involve a combination of processes, and the interpretation of the concepts of high tech and low tech, intensive and extensive, mechanized and natural processes may vary from place to place.",1
"Examples for more high-tech, intensive or mechanized, often relatively expensive sewage treatment systems are listed below. Some of them are energy intensive as well. Many of them provide a very high level of treatment. For example, broadly speaking, the activated sludge process achieves a high effluent quality but is relatively expensive and energy intensive.: 239",1
It is a treatment/disposal system that requires a large amount of land per person.,1
"In developing countries, they might be different and the focus might be more on construction and operating costs as well as process simplicity.: 218 Choosing the most suitable treatment process is complicated and requires expert inputs, often in the form of feasibility studies. This is because the main important factors to be considered when evaluating and selecting sewage treatment processes are numerous.",1
"Odors emitted by sewage treatment are typically an indication of an anaerobic or septic condition. Early stages of processing will tend to produce foul-smelling gases, with hydrogen sulfide being most common in generating complaints. Large process plants in urban areas will often treat the odors with carbon reactors, a contact media with bio-slimes, small doses of chlorine, or circulating fluids to biologically capture and metabolize the noxious gases. Other methods of odor control exist, including addition of iron salts, hydrogen peroxide, calcium nitrate, etc. to manage hydrogen sulfide levels.",1
"The energy requirements vary with type of treatment process as well as sewage strength. For example, constructed wetlands and stabilization ponds have low energy requirements. In comparison, the activated sludge process has a high energy consumption because it includes an aeration step. Some sewage treatment plants produce biogas from their sewage sludge treatment process by using a process called anaerobic digestion. This process can produce enough energy to meet most of the energy needs of the sewage treatment plant itself.:",1
This is usually only practical in hilly terrain and in areas where the treatment plant is relatively remote from housing because of the difficulty in managing odors.,1
"In highly regulated developed countries, industrial wastewater usually receives at least pretreatment if not full treatment at the factories themselves to reduce the pollutant load, before discharge to the sewer. The pretreatment has the following two main aims: Firstly, to prevent toxic or inhibitory compounds entering the biological stage of the sewage treatment plant and reduce its efficiency. And secondly to avoid toxic compounds from accumulating in the produced sewage sludge which would reduce its beneficial reuse options. Some industrial wastewater may contain pollutants which cannot be removed by sewage treatment plants.",1
"Also, variable flow of industrial waste associated with production cycles may upset the population dynamics of biological treatment units.",1
Different types of sewage treatment may utilize some or all of the process steps listed below.,1
Preliminary treatment (sometimes called pretreatment) removes coarse materials that can be easily collected from the raw sewage before they damage or clog the pumps and sewage lines of primary treatment clarifiers.,1
"Grit consists of sand, gravel, rocks, and other heavy materials. Preliminary treatment may include a sand or grit removal channel or chamber, where the velocity of the incoming sewage is reduced to allow the settlement of grit. Grit removal is necessary to (1) reduce formation of deposits in primary sedimentation tanks, aeration tanks, anaerobic digesters, pipes, channels, etc. (2) reduce the frequency of tank cleaning caused by excessive accumulation of grit; and (3) protect moving mechanical equipment from abrasion and accompanying abnormal wear.",1
"The removal of grit is essential for equipment with closely machined metal surfaces such as comminutors, fine screens, centrifuges, heat exchangers, and high pressure diaphragm pumps. Grit chambers come in three types: horizontal grit chambers, aerated grit chambers, and vortex grit chambers. Vortex grit chambers include mechanically induced vortex, hydraulically induced vortex, and multi-tray vortex separators. Given that traditionally, grit removal systems have been designed to remove clean inorganic particles that are greater than 0.210 millimetres (0.0083 in), most of the finer grit passes through the grit removal flows under normal conditions.",1
During periods of high flow deposited grit is resuspended and the quantity of grit reaching the treatment plant increases substantially.,1
"Basins can also provide a place to temporarily hold, dilute and distribute batch discharges of toxic or high-strength wastewater which might otherwise inhibit biological secondary treatment (such was wastewater from portable toilets or fecal sludge that is brought to the sewage treatment plant in vacuum trucks). Flow equalization basins require variable discharge control, typically include provisions for bypass and cleaning, and may also include aerators and odor control.",1
"Primary treatment is the ""removal of a portion of the suspended solids and organic matter from the sewage"".: 11 It consists of allowing sewage to pass slowly through a basin where heavy solids can settle to the bottom while oil, grease and lighter solids float to the surface and are skimmed off. These basins are called primary sedimentation tanks or primary clarifiers and typically have a hydraulic retention time (HRT) of 1.5 to 2.5 hours.: 398 The settled and floating materials are removed and the remaining liquid may be discharged or subjected to secondary treatment.",1
"Primary settling tanks are usually equipped with mechanically driven scrapers that continually drive the collected sludge towards a hopper in the base of the tank where it is pumped to sludge treatment facilities.: 9–11 Sewage treatment plants that are connected to a combined sewer system sometimes have a bypass arrangement after the primary treatment unit. This means that during very heavy rainfall events, the secondary and tertiary treatment systems can be bypassed to protect them from hydraulic overloading, and the mixture of sewage and storm-water receives primary treatment only.Primary",1
"sedimentation tanks remove about 50–70% of the suspended solids, and 25–40% of the biological oxygen demand (BOD).: 396",1
"The biological floc or biofilm and remaining fine solids form a sludge which can be settled and separated. After separation, a liquid remains that is almost free of solids, and with a greatly reduced concentration of pollutants.Secondary treatment can reduce organic matter (measured as biological oxygen demand) from sewage, using aerobic or anaerobic processes. The organisms involved in these processes are sensitive to the presence of toxic materials, although these are not expected to be present at high concentrations in typical municipal sewage.",1
"This can be, depending on the wastewater, organic matter (from the sewage itself), sulfide, or an added donor like methanol. The sludge in the anoxic tanks (denitrification tanks) must be mixed well (mixture of recirculated mixed liquor, return activated sludge, and raw influent) e.g. by using submersible mixers in order to achieve the desired denitrification. Over time, different treatment configurations for activated sludge processes have evolved to achieve high levels of nitrogen removal. An initial scheme was called the Ludzack–Ettinger Process. It could not achieve a high level of denitrification.:",1
"616 The Modified Ludzak–Ettinger Process (MLE) came later and was an improvement on the original concept. It recycles mixed liquor from the discharge end of the aeration tank to the head of the anoxic tank. This provides nitrate for the facultative bacteria.: 616 There are other process configurations, such as variations of the Bardenpho process.: 160 They might differ in the placement of anoxic tanks, e.g. before and after the aeration tanks.",1
"In this process, specific bacteria, called polyphosphate-accumulating organisms (PAOs), are selectively enriched and accumulate large quantities of phosphorus within their cells (up to 20 percent of their mass).: 148–155 Phosphorus removal can also be achieved by chemical precipitation, usually with salts of iron (e.g. ferric chloride) or aluminum (e.g. alum), or lime.: 18 This may lead to a higher sludge production as hydroxides precipitate and the added chemicals can be expensive. Chemical phosphorus removal requires significantly smaller equipment footprint than biological removal, is easier to operate and is often more reliable than biological phosphorus removal.",1
"The report also found that ""globally, 594 million people have sewer connections that don't receive sufficient treatment. Many more are connected to wastewater treatment plants that do not provide effective treatment or comply with effluent requirements."".: 55",1
"in 2020 showed that there is still too much uncollected household wastewater: Only 66% of all household wastewater flows were collected at treatment facilities in 2020 (this is determined from data from 128 countries).: 17 Based on data from 42 countries in 2015, the report stated that ""32 per cent of all wastewater flows generated from point sources received at least some treatment"".: 17 For sewage that has indeed been collected at centralized sewage treatment plants, about 79% went on to be safely treated in 2020.:",1
"18 The history of sewage treatment had the following developments: It began with land application (sewage farms) in the 1840s in England, followed by chemical treatment and sedimentation of sewage in tanks, then biological treatment the late 19th century, which led to the development of the activated sludge process starting in 1912. In most countries, sewage collection and treatment are subject to local and national regulations and standards.",1
"These are acids or bases that have pH levels of less than or equal to 2, or greater than or equal to 12.5. An example is battery acid.With the increase of worldwide technology, there are more substances that are considered toxic and harmful to human health. Technology growth at this rate is extremely daunting for civilization and can eventually lead to more harm/negative outcomes. Some of this technology includes cell phones and computers. Such items have been given the name e-waste or EEE, which stands for Electrical and Electronic Equipment.",1
"The EPA requires that toxic waste be handled with special precautions, and be disposed of in designated facilities around the country. Also, many US cities have collection days where household toxic waste is gathered. Some materials that may not be accepted at regular landfills are ammunition, commercially generated waste, explosives/shock sensitive items, hypodermic needles/syringes, medical waste, radioactive materials, and smoke detectors. Toxic wastes often contain carcinogens, and exposure to these by some route, such as leakage or evaporation from the storage, causes cancer to appear at increased frequency in exposed individuals.",1
"For example, a cluster of the rare blood cancer polycythemia vera was found around a toxic waste dump site in northeast Pennsylvania in 2008.The Human & Ecological Risk Assessment Journal conducted a study that focused on the health of individuals living near municipal landfills to see if it would be as harmful as living near hazardous landfills. They conducted a 7-year study that specifically tested for 18 types of cancers to see if the participants had higher rates than those that don't live around landfills.",1
"In the United States today millions of Americans live near a toxic waste site that is in a radius of three miles of where they currently reside. For example, In February 2022 it was found that ""Black Americans are 75 percent more likely to live near waste-producing facilities."" Residents that live in or near communities that are 1.8 miles around a Superfund or hazardous site have a ""high risk for life-long and long-term mental health and physical health challenges, including cancer, birth defects, and developmental disabilities.""",1
"If adults are exposed occupationally, they can have higher rates of hypertension than the average person. Men can result in low sperm count and females can result in miscarriages. In order to further quantify the burden of diseases caused by toxic wastes TSIP, Toxic Sites Identification Program, "" identifies active and abandoned hazardous waste sites resulting from both formal and informal industrial activities in LMICs"". As an investigation begins a key pollutant is sought out and identified.",1
"For example, ""Heavy metals are the most commonly occurring key pollutant, with ingestion of contaminated soils being the most commonly occurring route of exposure listed in the TSIP database."" Argentina, Mexico, and Uruguay were chosen since they had more available data after meeting certain criteria.",1
"When this method seemed unavailable and an area was suspected of having to lead contamination, the blood of individuals was tested to show the amount the people who were exposed to lead. The exposure data were collected from a total of 129 hazardous waste sites distributed across Argentina (n = 23), Mexico (n = 62), and Uruguay (n = 44). In Figs. 1 and 2 the sites of geographical distributions are shown. An estimated population of 316,703 individuals were at risk of exposure (mean = 2455; median = 250 per site), which is approximately 0.19%",1
"of the total population of all three countries. There was an estimation of 80,021 individuals who were women of childbearing age (15–49 years of age), and 122,084 individuals who were younger than 18 years of age.",1
"In recent years in the region of Campania, Italy there has been a rise in illegal dumping and burning of toxic and solid waste. In response to this, there has been a rise of dangerous chemical molecules like dioxins that are carcinogenic, which implies that they have the potential to cause cancer, that is appearing in humans and animals. For example, there has been a recent increase in sheep that have been born in contaminated areas that have, ""higher rates of chromosome fragility, higher mortality, and a higher incidence of abnormal fetal development when compared with sheep raised in non-contaminated areas.""",1
To assess the causal relations between cancer mortality and congenital malformations in humans coming from illegal dumping a map was drawn using the geographical locations of the sites. As one can see most of these sites are located in Campania where Naples and Caserta are based. The spread of dioxin through food consumption is primarily due to the animal products from the animals that were raised in the geographical locations where dioxins were the highest. Researchers tested mammalian milk from these areas and saw that the levels of dioxin were over the suggested amount.,1
"This was greatly seen as an issue because humans have the highest capability to concentrate the dioxin in their fat tissues. To test this, 94 women in Campania who were breastfeeding had samples of their breast milk tested and it was found that every woman had dioxin in their breast milk. A correlation was also discovered that the older you were the more dioxin was in your breast milk. One of the biggest problems with today's toxic material is how to dispose of it properly.",1
"Toxic waste in the form of petroleum oil can either spill into the oceans from pipe leaks or large ships, but it can also enter the oceans from everyday citizens dumping car oil into the rainstorm sewer systems. Disposal is the placement of waste into or on the land. Disposal facilities are usually designed to permanently contain waste and prevent the release of harmful pollutants to the environment.The most common hazardous waste disposal practice is placement in a land disposal unit such as a landfill, surface impoundment, waste pile, land treatment unit, or injection well.",1
"Land disposal is subject to requirements under EPA's Land Disposal Restrictions Program. Injection wells are regulated under the federal Underground Injection Control program.Organic wastes can be destroyed by incineration at high temperatures. However, if the waste contains heavy metals or radioactive isotopes, these must be separated and stored, as they cannot be destroyed. The method of storage will seek to immobilize the toxic components of the waste, possibly through storage in sealed containers, inclusion in a stable medium such as glass or a cement mixture, or burial under an impermeable clay cap.",1
"The RCRA governs the generation, transportation, treatment, storage, and disposal of hazardous waste. The Toxic Substances Control Act (TSCA), also enacted in 1976, authorizes the EPA to collect information on all new and existing chemical substances, as well as to control any substances that were determined to cause unreasonable risk to public health or the environment. The Superfund law, passed in 1980, created a cleanup program for abandoned or uncontrolled hazardous waste sites.There has been a long ongoing battle between communities and environmentalists versus governments and corporations about how strictly and how fairly the regulations and laws are written and enforced.",1
"Warren County citizens argued that the toxic waste landfill regulations were based on the fundamental assumption that the EPA's conceptual dry-tomb landfill would contain the toxic waste. This assumption informed the siting of toxic waste landfills and waivers to regulations that were included in EPA's Federal Register. For example, in 1978, the base of a major toxic waste landfill could be no closer than five feet from groundwater, but this regulation and others could be waived.",1
Citizens argued that the waivers to the siting regulations were discriminatory mechanisms facilitating the shift from scientific to political considerations concerning the siting decision and that in the South this would mean a discriminatory proliferation of dangerous waste management facilities in poor black and other minority communities. They also argued that the scientific consensus was that permanent containment could not be assured.,1
"issue of handling toxic waste has become a global problem as international trade has arisen out of the increasing toxic byproducts produced with the transfer of them to less developed countries. In 1995, the United Nations Commission on Human Rights began to notice the illicit dumping of toxic waste and assigned a Special Rapporteur to examine the human rights aspect to this issue (Commission resolution 1995/81).",1
"In September 2011, the Human Rights Council decided to strengthen the mandate to include the entire life-cycle of hazardous products from manufacturing to the final destination (aka cradle to grave), as opposed to only movement and dumping of hazardous waste. The title of the Special Rapporteur has been changed to ""Special Rapporteur on the implications for human rights of the environmentally sound management and disposal of hazardous substances and wastes"" (Human Rights Council 18/11).",1
"""Toxic waste"" is often utilized in science fiction as a plot device that causes organisms or characters to undergo mutation. Examples of works that feature toxic waste in such a manner include the films Mutant, C.H.U.D., Impulse (all 1984), and Teenage Mutant Ninja Turtles (1990). Several films produced by Troma Entertainment involve mutation via toxic or radioactive waste, including The Toxic Avenger (1984) and Class of Nuke 'Em High (1986).",1
"To some extent, how much light reflects for a given amount of particulates is dependent upon properties of the particles like their shape, color, and reflectivity. For this reason (and the reason that heavier particles settle quickly and do not contribute to a turbidity reading), a correlation between turbidity and total suspended solids (TSS) is somewhat unusual for each location or situation.Turbidity in lakes, reservoirs, channels, and the ocean can be measured using a Secchi disk.",1
The European turbidity standard is 4 NTU.,1
"5 NTU over background (when background is 50 NTU or less), or 10 percent increase when background is over 50 NTU.",1
"Various stages of solid/liquid separation processes recycle as much sodium hydroxide as possible from the residue back into the Bayer Process, in order to reduce production costs and make the process as efficient as possible. This also lowers the final alkalinity of the residue, making it easier and safer to handle and store. Red mud is composed of a mixture of solid and metallic oxides. The red colour arises from iron oxides, which can comprise up to 60% of the mass. The mud is highly basic with a pH ranging from 10 to 13.",1
"In addition to iron, the other dominant components include silica, unleached residual aluminium compounds, and titanium oxide.The main constituents of the residue after the extraction of the aluminium component are insoluble metallic oxides. The percentage of these oxides produced by a particular alumina refinery will depend on the quality and nature of the bauxite ore and the extraction conditions.",1
"The table below shows the composition ranges for common chemical constituents, but the values vary widely: Mineralogically expressed the components present are: In general, the composition of the residue reflects that of the non-aluminium components, with the exception of part of the silicon component: crystalline silica (quartz) will not react but some of the silica present, often termed, reactive silica, will react under the extraction conditions and form sodium aluminium silicate as well as other related compounds.",1
"Discharge of red mud can be hazardous environmentally because of its alkalinity and species components. Until 1972, Italian company Montedison was discharging red mud off the coast of Corsica. The case is important in international law governing the Mediterranean sea.In October 2010, approximately one million cubic meters of red mud slurry from an alumina plant near Kolontár in Hungary was accidentally released into the surrounding countryside in the Ajka alumina plant accident, killing ten people and contaminating a large area.",1
"In other cases, impoundments were constructed with dams or levees, while for some operations valleys were dammed and the residue deposited in these holding areas.It was once common practice for the red mud to be discharged into rivers, estuaries, or the sea via pipelines or barges; in other instances the residue was shipped out to sea and disposed of in deep ocean trenches many kilometres offshore. From 2016, all disposal into the sea, estuaries and rivers was stopped.As residue storage space ran out and concern increased over wet storage, since the mid-1980s dry stacking has been increasingly adopted.",1
"2015, a major initiative was launched in Europe with funds from the European Union to address the valorization of red mud. Some 15 Ph.D. students were recruited as part the European Training Network (ETN) for Zero-Waste Valorisation of Bauxite Residue. The key focus will be the recovery of iron, aluminium, titanium and rare-earth elements (including scandium) while valorising the residue into building materials. A European Innovation Partnership has been formed to explore options for using by-products from the aluminium industry, BRAVO (Bauxite Residue and Aluminium Valorisation Operations).",1
"This sought to bring together industry with researchers and stakeholders to explore the best available technologies to recover critical raw materials but has not proceeded. Additionally, EU funding of approximately Euro 11.5 million has been allocated to a four year programme starting in May 2018 looking at uses of bauxite residue with other wastes, RemovAL. A particular focus of this project is the installation of pilot plants to evaluate some of the interesting technologies from previous laboratory studies.",1
"As part of the H2020 project RemovAl, it is planned to erect a house in the Aspra Spitia area of Greece that will be made entirely out of materials from bauxite residue. Other EU funded projects that have involved bauxite residue and waste recovery have been ENEXAL (ENergy-EXergy of ALuminium industry) [2010–2014], EURARE (European Rare earth resources) [2013–2017] and three more recent projects are ENSUREAL (ENsuring SUstainable ALumina production) [2017–2021], SIDEREWIN (Sustainable Electro-winning of Iron) [2017–2022] and SCALE (SCandium – ALuminium in Europe) [2016–2020] a 7 million Euro project to look at the recovery of scandium from bauxite residue.",1
"In ReActiv modification will be made to both the alumina production and the cement production side of the chain, in order to link them through the new ReActiv technologies. The latter will modify the properties of the industrial residue, transforming it into a reactive material (with pozzolanic or hydraulic activity) suitable for new, low CO2 footprint, cement products. In this manner ReActiv proposes a win-win scenario for both industrial sectors (reducing wastes and CO2 emissions respectively).",1
"Fluorchemie GmbH have developed a new flame-retardant additive from bauxite residue, the product is termed MKRS (modified re-carbonised red mud) with the trademark ALFERROCK(R) and has potential applicability in a wide range of polymers (PCT WO2014/000014). One of its particular benefits is the ability to operate over a much broader temperature range, 220 – 350 °C, that alternative zero halogen inorganic flame retardants such as aluminium hydroxide, boehmite or magnesium hydroxide.",1
"The high death rates from cancers pointed towards the presence of illegal and improper hazardous waste disposal by various organized crime groups including the Camorra. The 2004 Lancet Oncology article noted, ""Today, the difference between lawful management of waste and illegal manipulation with regard to their compliance with health regulations is very narrow, and the health risks are rising...",1
"some media outlets report France and Germany as waste sources, the EU has remained silent as to the sources of the waste in its criticism and demands of Italy. By February 1994, several regional landfills in Campania had become overfilled, and Prime Minister Carlo Azeglio Ciampi declared a state of emergency and created the Committee for the Waste Emergency in Campania (Commissariato di Governo per l'emergenza rifiuti in Campania).By December 1999, all regional landfills had reached capacity.",1
"""the situation worsened during this period as the Camorra diversified their illegal waste disposal strategy: 1) transporting and dumping hazardous waste in the countryside by truck; 2) dumping waste in illegal caves or holes; 3) mixing toxic waste with textiles to avoid explosions and then burning it; and 4) mixing toxic with urban waste for disposal in landfills and incinerators.""A Camorra member, Nunzio Perella was arrested in 1992, and began collaborating with authorities; he had stated ""the rubbish is gold.""",1
"The boss of the Casalesi clan, Gaetano Vassallo, admitted to systematically working for 20 years to bribe local politicians and officials to gain their acquiescence to dumping toxic waste. Giorgio Napolitano, President of Italian Republic, said in June 2008: It is certain, not only to citizens but to the government as well, that the systematic transfer of toxic waste from industries in Northern Italy to Campania, was committed by the Camorra. The triangle of death and the waste management crisis are primarily a result of government failure to control illegal waste dumping.",1
"It is hypothesized that industrial slurry originating from Porto Marghera (industrial docklands near Venice) was disguised as compost and spread on fields in the Acerra countryside by the Casalesi clan, often with help from the landowners.In one case, a company had its assets seized during a 2006 investigation in which it was alleged that the company had illegally disposed of waste from industries in the regions of Veneto and Tuscany in the territories of Bacoli, Giugliano and Qualiano. Approximately one million tonnes of toxic waste are said to have been disposed of, earning €27 million.",1
"The company was already the subject of a 2003 investigation. In another case, a tank full of toxic substances was found buried in an illegal dump, in Marigliano.The illegal burning of waste, for example to recover copper from wiring, is known to release dioxins into the atmosphere. Such fires are easily hidden among legitimate incineration resulting from the more general waste disposal problem, and the illegal burning of hazardous materials was particularly noted during 2007 and 2008.",1
"Between 2007 and 2008, the waste commissioner Guido Bertolaso, (the head of the civil protection department), planned to open a landfill but this was opposed by residents of Chiaiano. There was similar resistance in Pianosa to reopening a closed landfill proposed by government commissioner Giovanni De Gennaro. Some of the protests turned violent, and in May 2008, it became a penal felony to protest in the vicinity of landfills, incinerators or any plant related to waste management. It is alleged that there was collusion between local political interests and organised crime over building interests.By",1
"July 17, 2008, Berlusconi declared that the emergency had ended.The incinerator of Acerra has also received backlash in the local area. In 2009, the Acerra incineration facility was completed at a cost of over €350 million. The incinerator burns 600,000 tons of waste per year to produce refuse-derived fuel. The energy produced from the facility is enough to power 200,000 households per year.",1
"In 2007, research conducted by the World Health Organization, Italian Istituto Superiore di Sanità, Consiglio Nazionale delle Ricerche and Campania Region collected data on cancer and congenital abnormalities in 196 municipalities covering the period between 1994 and 2002 found abnormally high disease incidence. These abnormal patterns may correlate to areas where there are uncontrolled waste sites. However, this work also highlighted the difficulty in determining causality and in establishing a link between increased death and malformation rates and waste disposal.",1
"The government blames the Mafia's illegal garbage disposal racket.In March 2008, dioxin were found in buffalo milk from farms in Caserta. While only 2.8% of farms in Campania were affected, the sale of dairy products from Campania collapsed in both domestic and global markets.A chain reaction followed, in which several countries including Japan, China, Russia and Germany took various measures ranging from the mere raising of the attention threshold to the suspension of imports.",1
"On 19 April, China definitively removed the ban on mozzarella, originally activated on 28 March 2008, and tests held in December 2013 in Germany on behalf of four Italian consumer associations have highlighted dioxin and heavy metal levels at least five times lower than the legal limit.",1
"Cancer Alley Changzhou Foreign Languages School controversy Smokey Mountain and the Payatas dumpsite Valley of the Drums La Terra dei fuochi, website showing claims on illegal waste disposal in Campania La Terra dei fuochi, website on ""triangle of poisons"" Giugliano-Qualiano-Villaricca (in English) Kathryn Senior and Alfredo Mazza, ""Italian 'Triangle of death' linked to waste crisis"", The Lancet Oncology, Volume 5, Issue 9, September 2004, pages 525–527. (in Italian) Translation by The Lancet Oncology from the site of Centro Nazionale di Epidemiologia, Sorveglianza e Promozione della Salute (in English) Fabrizio Bianchi et al.,",1
"""Italian 'Triangle of death'"", The Lancet Oncology, Volume 12, Issue 5, December 2004, page 710. (in Italian) Trattamento dei rifiuti in Campania: impatto sulla salute umana, report by World Health Organization, Italian Health Institute, it:Consiglio Nazionale delle Ricerche e Regione Campania (Italia). Report: Terra bruciata, TV 2008-03-09, and how finished this story in: Come è andata a finire?.",1
"Repubblica Radio TV: Morire di diossina in Campania, del 2007-12-28: [1], [2], [3] La 7: Il cancro di Napoli, del 2007-12-12; Allarme cibo avvelenato, Exit del 2007-12-18; Il posto dei rifiuti, del 2007-09-22 Tg1: interview of Roberto Saviano at 2008-03-01 (evening edition at 8:00 p.m.) Sat 2000: interview of Antonio Marfella, oncologist at Formato famiglia, 2007-12-20",1
"Bacteria that survive treatment have an even higher potential for regrowth, as they benefit from the death of other organisms in two different ways (i) nutrients essential for bacterial growth are released in the form of dissolved organic matter and, (ii) there is a decrease in the number of predators that would otherwise eat them. Overall, bacterial regrowth has been observed after 18 hrs to 7 days of applying different treatments.Therefore, the scientific evidence currently available supports the idea that it is not an issue of “IF regrowth” but “WHEN regrowth”. Timescales are very important when considering regrowth.",1
The SAGD process of heavy oil or bitumen production is an enhancement on the steam injection techniques originally developed to produce heavy oil from the Kern River Oil Field of California. The key to all steam flooding processes is to deliver heat to the producing formation to reduce the viscosity of the heavy oil and enable it to move toward the producing well.,1
"The cyclic steam stimulation (CSS) process developed for the California heavy oil fields was able to produce oil from some portions of the Alberta oil sands, such as the Cold Lake oil sands, but did not work as well to produce bitumen from heavier and deeper deposits in the Athabasca oil sands and Peace River oil sands, where the majority of Alberta's oil sands reserves lie. To produce these much larger reserves, the SAGD process was developed, primarily by Dr. Roger Butler of Imperial Oil with the assistance of the Alberta Oil Sands Technology and Research Authority and industry partners.",1
"The basis of the SAGD process is that thermal communication is established with the reservoir so that the injected steam forms a ""steam chamber"". The heat from the steam reduces the viscosity of the heavy crude oil or bitumen which allows it to flow down into the lower wellbore. The steam and associated gas rise because of their low density compared to the heavy crude oil below, ensuring that steam is not produced at the lower production well, tend to rise in the steam chamber, filling the void space left by the oil.",1
"The higher the liquid level above the producer the lower the temperature and higher is the sub-cool. However, real life reservoirs are invariably heterogeneous therefore it becomes extremely difficult to achieve a uniform sub-cool along the entire horizontal length of a well. As a consequence many operators, when faced with uneven stunted steam chamber development, allow a small quantity of steam to enter into the producer to keep the bitumen in the entire wellbore hot hence keeping its viscosity low with the added benefit of transferring heat to colder parts of the reservoir along the wellbore.",1
"Another drawback of very high sub-cool is the possibility of steam pressure eventually not being enough to sustain steam chamber development above the injector, sometimes resulting in collapsed steam chambers where condensed steam floods the injector and precludes further development of the chamber. Continuous operation of the injection and production wells at approximately reservoir pressure eliminates the instability problems that plague all high-pressure and cyclic steam processes and SAGD produces a smooth, even production that can be as high as 70% to 80% of oil in place in suitable reservoirs.",1
"The process is relatively insensitive to shale streaks and other vertical barriers to steam and fluid flow because, as the rock is heated, differential thermal expansion allows steam and fluids to gravity flow through to the production well. This allows recovery rates of 60% to 70% of oil in place, even in formations with many thin shale barriers. Thermally, SAGD is generally twice as efficient as the older CSS process, and it results in far fewer wells being damaged by the high pressures associated with CSS.",1
"Combined with the higher oil recovery rates achieved, this means that SAGD is much more economic than cyclic steam processes where the reservoir is reasonably thick. The gravity drainage idea was originally conceived by Dr. Roger Butler, an engineer for Imperial Oil in the 1970s In 1975 Imperial Oil transferred Butler from Sarnia, Ontario to Calgary, Alberta to head their heavy oil research effort. He tested the concept with Imperial Oil in 1980, in a pilot at Cold Lake which featured one of the first horizontal wells in the industry, with vertical injectors.",1
One of the main targets of AOSTRA finding of suitable technologies for that part of the Athabasca oil sands that could not be recovered using conventional surface mining technologies.,1
"In 1984, AOSTRA initiated the Underground Test Facility in the Athabasca oil sands, located between the MacKay Rivers and the Devon River west of the Syncrude plant as an in-situ SAGD bitumen recovery facility. It was here that their first test of twin (horizontal) SAGD wells took place, proving the feasibility of the concept, briefly achieving positive cash flow in 1992 at a production rate of about 2,000 barrels per day (320 m3/d) from three well pairs.",1
"The Foster Creek plant in Alberta Canada, built in 1996 and operated by Cenovus Energy, was the first commercial Steam-assisted gravity drainage (SAGD) project and by 2010 Foster Creek ""became the largest commercial SAGD project in Alberta to reach royalty payout status. ""The original UTF SAGD wells were drilled horizontally from a tunnel in the limestone underburden, accessed with vertical mine shafts. The concept coincided with development of directional drilling techniques that allowed companies to drill horizontal wells accurately, cheaply and efficiently, to the point that it became hard to justify drilling a conventional vertical well any more.",1
"With the low cost of drilling horizontal well pairs, and the very high recovery rates of the SAGD process (up to 60% of the oil in place), SAGD is economically attractive to oil companies. At Foster Creek Cenovus has employed its patented 'wedge well' technology to recover residual resources bypassed by regular SAGD operations, this improves the total recovery rate of the operation.",1
"The 'wedge well' technology works by accessing the residual bitumen that is bypassed in regular SAGD operations by drilling an infill well between two established operating SAGD well pairs once the SAGD steam chambers have matured to the point where they have merged and are in fluid communication and then what is left to recover in that reservoir area between the operating SAGD well pairs is a 'wedge' of residual, bypassed oil.",1
"Wedge well technology has been shown to improve overall recovery rates by 5%-10% at a reduced capital cost as less steam is required once the steam chambers mature to the point where they are in fluid communication and typically at this stage in the recovery process, also commonly known as the 'blow down' phase, the injected steam is replaced with a non-condensable gas such as methane, further reducing production costs. This technology was not at-first commercially viable. It became so during the increased oil prices during the 2000s.",1
"While traditional drilling methods were prevalent up until the 1990s, high crude prices of the 21st Century are encouraging more unconventional methods (such as SAGD) to extract crude oil. The Canadian oil sands have many SAGD projects in progress, since this region is home of one of the largest deposits of bitumen in the world (Canada and Venezuela have the world's largest deposits).",1
"The SAGD process allowed the Alberta Energy Resources Conservation Board (ERCB) to increase its proven oil reserves to 179 billion barrels, which raised Canada's oil reserves to the third highest in the world after Venezuela and Saudi Arabia and approximately quadrupled North American oil reserves. As of 2011, the oil sands reserves stand at around 169 billion barrels.",1
"Other sources of generating heat are under consideration, notably gasification of the heavy fractions of the produced bitumen to produce syngas, using the nearby (and massive) deposits of coal, or even building nuclear reactors to produce the heat.",1
"Canadian Natural Resources employs cyclic steam or ""huff and puff"" technology to develop bitumen resources. This technology requires one well bore and the production consists of the injection to fracture and heat the formation prior to the production phases. First steam is injected above the formation fracture point for several weeks or months, mobilizing cold bitumen, the well is then shut in for several weeks or months to allow the steam to soak into the formation. Then the flow on the injection well is reversed producing oil through the same injection well bore.",1
"The injection and production phases together comprise one cycle. Steam is re-injected to begin a new cycle when oil production rates fall below a critical threshold due to the cooling of the reservoir. Cyclic steam stimulation also has a number of CSS Follow-up or Enhancement Processes, including Pressure Up and Blow Down (PUBD), Mixed Well Steam Drive and Drainage (MWSDD), Vapor Extraction (Vapex), Liquid Addition to Steam for Enhanced Recovery of Bitumen (LASER) and HPCSS Assisted SAGD and Hybrid Process.",1
"""Roughly 35 per cent of all in situ production in the Alberta oil sands uses a technique called high pressure cyclic steam stimulation (HPCSS), which cycles between two phases: first, steam is injected into an underground oil sands deposit to fracture and heat the formation to soften the bitumen just like CSS does, excepting at even higher pressures; then, the cycle switches to production where the resulting hot mixture of bitumen and steam (called a ""bitumen emulsion"") is pumped up to the surface through the same well, again just like CSS, until the resulting pressure drop slows production to an uneconomical",1
"Alternative enhanced oil recovery mechanisms include VAPEX (Vapor Assisted Petroleum Extraction), Electro-Thermal Dynamic Stripping Process (ET-DSP), and ISC (for In Situ Combustion). VAPEX, a ""gravity-drainage process that uses vapourized solvents rather than steam to displace or produce heavy oil and reduce its viscosity, was also invented by Butler.ET-DSP is a patented process that uses electricity to heat oil sands deposits to mobilize bitumen allowing production using simple vertical wells. ISC uses oxygen to generate heat that diminishes oil viscosity; alongside carbon dioxide generated by heavy crude oil displace oil toward production wells.",1
"eMSAGP is a MEG Energy patented process wherein MEG, in partnership with Cenovus, developed a modified recovery process dubbed “enhanced Modified Steam and Gas Push” (eMSAGP), a modification of SAGP designed to improve the thermal efficiency of SAGD by utilizing additional producers located midway between adjacent SAGD well pairs, at the elevation of the SAGD producers. These additional producers, commonly referred to as “infill” wells, are an integral part of the eMSAGP recovery system.",1
Enhanced oil recovery Heavy crude oil Oil sands Oil shale Mazut SAGD process with a focus on Reverse Emulsions Description of SAGD and SAGD history Example Supplier of SAGD components Key Supplier of SAGD components Archived 2016-01-25 at the Wayback Machine Key Supplier of SAGD boilers,1
"jurisdiction or jurisdiction cannot be determined, the United States refers cases to flag states, in accordance with MARPOL. These procedures require substantial coordination between the Coast Guard, the State Department, and other flag states, and the response rate from flag states has been poor.: 19–21 Different regulations apply to vessels, depending on the individual state. In the United States, several federal agencies have some jurisdiction over ships in U.S. waters, but no one agency is responsible for or coordinates all of the relevant government functions. The U.S.",1
"For example, the National Oceanic and Atmospheric Administration (NOAA, Department of Commerce) works with the Coast Guard and EPA to report on the effects of marine debris. The Animal and Plant Health Inspection Service (APHIS) is responsible for ensuring quarantine inspection and disposal of food-contaminated garbage. In some cases, states and localities have responsibilities as well.",1
"The Vessel Incidental Discharge Act (VIDA), approved in 2018, requires EPA to develop new performance standards for vessel discharges, and generally requires that the new standards be at least as stringent as the 2013 VGP. On October 26, 2020 EPA published proposed VIDA implementation regulations. Until this proposal is finalized, the existing EPA discharge permits and Coast Guard regulations remain in effect.",1
"Commercial vessels discharging sewage, except fishing vessels, are subject to the VGP or SVGP requirements. Recreational vessels are exempt from the permit requirements, but vessel operators must implement Best Management Practices to control their discharges.",1
"Section 312 of the CWA prohibits the dumping of untreated or inadequately treated sewage from vessels into the navigable waters of the United States (defined as within 3 miles (4.8 km) of shore). It is implemented jointly by EPA and the Coast Guard. Under commercial and recreational vessels with installed toilets are required to have marine sanitation devices (MSDs), which are designed to prevent the discharge of untreated sewage. EPA is responsible for developing performance standards for MSDs, and the Coast Guard is responsible for MSD design and operation regulations and for certifying MSD compliance with the EPA rules.",1
"The regulations, which have not been revised since 1976, do not require ship operators to sample, monitor, or report on their effluent discharges. Critics point out a number of deficiencies with this regulatory structure as it affects large vessels. First, the MSD regulations only cover discharges of bacterial contaminants and suspended solids, while the NPDES permit program for other point sources typically regulates many more pollutants such as chemicals, pesticides, heavy metals, oil, and grease that may be released by large vessels as well as land-based sources.",1
"Second, sources subject to NPDES permits must comply with sampling, monitoring, recordkeeping, and reporting requirements, which do not exist in the MSD rules. In addition, the Coast Guard, responsible for inspecting vessels for compliance with the MSD rules, has been heavily criticized for poor enforcement of Section 312 requirements. In its 2000 report, the Government Accountability Office (GAO) said that Coast Guard inspectors ""rarely have time during scheduled ship examinations to inspect sewage treatment equipment or filter systems to see if they are working properly and filtering out potentially harmful contaminants."":",1
"However, its requirements are minimal, even compared with U.S. rules for MSDs. Annex IV requires that vessels be equipped with a certified sewage treatment system or holding tank, but it prescribes no specific performance standards. Within three miles (5 km) of shore, Annex IV requires that sewage discharges be treated by a certified MSD prior to discharge. Between three and 12 miles (19 km) from shore, sewage discharges must be treated by no less than maceration or chlorination; sewage discharges beyond 12 miles (19 km) from shore are unrestricted.",1
"AWTs are believed to be very effective in removing pathogens, oxygen demanding substances, suspended solids, oil and grease, and particulate metals from sewage, but only moderately effective in removing dissolved metals and nutrients (ammonia, nitrogen and phosphorus).",1
"Section 312 has another means of addressing sewage discharges, through establishment of no-discharge zones (NDZs) for vessel sewage. A state may completely prohibit the discharge of both treated and untreated sewage from all vessels with installed toilets into some or all waters over which it has jurisdiction (up to 3 miles (4.8 km) from land). To create a no-discharge zone to protect waters from sewage discharges by vessels, the state must apply to EPA under one of three categories.",1
"Ship discharges of solid waste are governed by two laws. Title I of the Marine Protection, Research, and Sanctuaries Act (MPRSA) applies to cruise ships and other vessels and makes it illegal to transport garbage from the United States for the purpose of dumping it into ocean waters without a permit or to dump any material transported from a location outside the United States into U.S. territorial seas or the contiguous zone (within 12 nautical miles (22 km) from shore) or ocean waters.",1
"APPS prohibits the discharge of all garbage within 3 nautical miles (5.6 km) of shore, certain types of garbage within 12 nautical miles (22 km) offshore, and plastic anywhere. It applies to all vessels, whether seagoing or not, regardless of flag, operating in U.S. navigable waters and the Exclusive Economic Zone (EEZ). It is administered by the Coast Guard, which carries out inspection programs to insure the adequacy of port facilities to receive offloaded solid waste.",1
"The Resource Conservation and Recovery Act (RCRA) is the primary federal law that governs hazardous waste management through a ""cradle-to-grave"" program that controls hazardous waste from the point of generation until ultimate disposal. The act imposes management requirements on generators, transporters, and persons who treat or dispose of hazardous waste. Under this act, a waste is hazardous if it is ignitable, corrosive, reactive, or toxic, or appears on a list of about 100 industrial process waste streams and more than 500 discarded commercial products and chemicals.",1
"Treatment, storage, and disposal facilities are required to have permits and comply with operating standards and other EPA regulations. The owner or operator of a ship may be a generator and/or a transporter of hazardous waste, and thus subject to RCRA rules. Issues that the ship industry may face relating to RCRA include ensuring that hazardous waste is identified at the point at which it is considered generated; ensuring that parties are properly identified as generators, storers, treaters, or disposers; and determining the applicability of RCRA requirements to each.",1
"RCRA rules that cover small-quantity generators (those that generate more than 100 kilograms but less than 1,000 kilograms of hazardous waste per month) are less stringent than those for large-quantity generators (generating more than 1,000 kilograms per month), and it is unclear whether ships are classified as large or small generators of hazardous waste. Moreover, some ship companies argue that they generate less than 100 kilograms per month and therefore should be classified in a third category, as ""conditionally exempt small-quantity generators,"" a categorization that allows for less rigorous requirements for notification, recordkeeping, and the like.",1
"jurisdiction. To implement APPS, the Coast Guard has promulgated regulations prohibiting the discharge of oil or oily mixtures into the sea within 12 nautical miles (22 km) of the nearest land, except under limited conditions. However, because many ships are foreign registered and because APPS only applies to foreign ships within U.S. navigable waters, the APPS regulations have limited applicability to ship operations.",1
"Congress amended the CWA in 1996 to require development of uniform national discharge standards (""UNDS"") for military vessels. The standards are being developed jointly by EPA and DOD. Initial regulations were published in 1999, to identify and characterize a wide variety of discharge types from ships and boats. A final rule setting specific standards for 11 discharge types was published in 2017. A final rule covering 11 additional discharge categories was published in 2020. The majority of vessels covered belong to the U.S.",1
"Not all substances present in coal will burn, and hence the non-combustible material is present in more concentrated amounts in coal ash than in coal itself. Substances commonly found in coal ash include arsenic, barium, beryllium, boron, cadmium, nickel, lead, mercury, molybdenum, selenium and thallium. Elevated levels of radioactivity may also be present. Many of these substances, especially heavy metals, can have negative effects on humans when ingested. Because of biomagnification, the concentration of unwanted chemicals in animals can increase up a food chain (similarly to mercury in tuna).",1
"Coal ash, a product of combustion, concentrates these elements and can contaminate groundwater or surface waters if there are leaks from an ash pond.",1
"Ash ponds are not allowed in the Netherlands, as they are a type of landfill. Instead, all coal ash is recycled in the Netherlands.",1
In 2021 inspections were criticized and said to be insufficient.: 75,1
"In the United States, coal ash is a major component of the nation's industrial waste stream. As of 2012 approximately 60 percent of US coal ash was disposed in surface impoundments and landfills. The US had 310 active on-site landfills in 2012, averaging more than 120 acres in size with an average depth of over 40 feet, and more than 735 active on-site surface impoundments, averaging more than 50 acres in size with an average depth of 20 feet. In 2017, 38.2 million short tons (34.7×10^6 t) of fly ash, and 9.7 million short tons (8.8×10^6",1
"In 1980 the U.S. Congress defined coal ash as a ""special waste"" that would not be regulated under the stringent hazardous waste permitting requirements of the Resource Conservation and Recovery Act (RCRA). Congress also directed EPA to study the coal ash problem and decide whether further regulation would be appropriate. In 2000, EPA stated that coal fly ash did not need to be regulated as a hazardous waste.Following a 2008 failure that caused the Tennessee Valley Authority's Kingston Fossil Plant coal fly ash slurry spill, EPA began developing regulations that would apply to all ash ponds in the US.",1
"EPA published a Coal Combustion Residuals (CCR) regulation in 2015. The agency continued to classify coal ash as non-hazardous (thereby avoiding strict permitting requirements under RCRA Subtitle C), but with new restrictions: Existing ash ponds that are contaminating groundwater must stop receiving CCR, and close or retrofit with a liner. Existing ash ponds and landfills must comply with structural and location restrictions, where applicable, or close. A pond no longer receiving CCR is still subject to all regulations unless it is dewatered and covered by 2018. New ponds and landfills must include a geomembrane liner over a layer of compacted soil.Some",1
"January 11, 2022 EPA announced an enforcement action involving ash ponds at certain coal-fired plants in Indiana, Ohio, Iowa and New York. The agency's proposal would deny the plants' requests for extensions beyond the 2021 deadline and would require them to close their ash ponds ahead of their proposed schedules. EPA sent warning letters to four additional plants. EPA's action is subject to a 30-day public comment period. Remediation options include ""capping, dewatering and/or stabilizing, consolidating into a new landfill, disposing off site, converting to wetlands, or any combination of these options.""There",1
"The aid agencies later hired foreign experts who recommended treatment plants that were inappropriate to the conditions, were regularly breaking down, or were not removing the arsenic.According to a British Geological Survey study in 1998 on shallow tube-wells in 61 of the 64 districts in Bangladesh, 46 percent of the samples were above 0.01 mg/L and 27 percent were above 0.050 mg/L. Based on the estimated 1999 population of Bangladesh, the study suggested that 28–35 million people may have been exposed to arsenic levels above 0.05",1
"Nepal is subject to a serious problem with arsenic contamination. The problem is most severe in the Terai region, the worst being near Nawalparasi District, where 26 percent of shallow wells failed to meet WHO standard of 10 ppb. A study by Japan International Cooperation Agency and the Environment in the Kathmandu Valley showed that 72% of deep wells failed to meet the WHO standard, and 12% failed to meet the Nepali standard of 50 ppb.",1
"This amendment created the ""costs and benefits rule"" to determine whether the cost of implementing new MCLs outweighs the health benefits. To maximize the costs and benefits of setting new MLCs, the EPA began allowing more affordable technology to be substituted that did not fully meet MLC standards because it was more affordable. The EPA studied the pros and cons of lowering the arsenic MCL for years in the late 1980s and 1990s. No action was taken until January 2001, when the Clinton administration in its final weeks promulgated a new standard of 0.01",1
"Fallon, Nevada has long been known to have groundwater with relatively high arsenic concentrations (in excess of 0.08 mg/L). Even some surface waters, such as the Verde River in Arizona, sometimes exceed 0.01 mg/L arsenic, especially during low-flow periods when the river flow is dominated by groundwater discharge.A study conducted in a contiguous six-county area of southeastern Michigan investigated the relationship between moderate arsenic levels and 23 disease outcomes. Disease outcomes included several types of cancer, diseases of the circulatory and respiratory system, diabetes mellitus, and kidney and liver diseases.",1
"The SAR Project was selected by the Blacksmith Institute – New York & Green Cross- Switzerland as one of the ""12 Cases of Cleanup & Success"" in the World's Worst Polluted Places Report 2009. (Refer: www.worstpolluted.org). Currently, large scale SAR plants are being installed in US, Malaysia, Cambodia, and Vietnam.",1
"AMRIT uses an adsorbent based on a simple method to maintain the metastable 2-line ferrihydrite (named as CM2LF) phase at room temperature, by confining it in biopolymeric cages. It can handle concentrations of arsenic and colloidal iron reaching up to 100-800 µg/L and 50 mg/L, respectively and brings the output concentration below the permissible limit set by EPA of 10 µg/L and 200 µg/L, respectively. The arsenic adsorption capacity of the composite is 1.4 to 7.6 times better than the available compositions, in field conditions.",1
"The role of ANC chair involves strategic co-ordination of board activities, and chairing the bi-monthly company meetings attended by representatives of the membership organisations. The position is currently held by Paul Shields, Dan Saunders is the Immediate Past Chair. The Association's President is also a member of the board, usually a more senior experienced acoustician holding a more overarching ambassadorial role. Graham Parry is the current president. The Association of Noise Consultants UK Institute of Acoustics",1
"Awaaz Foundation once again petitioned the Court to have these places notified as silence zones. On 6 August 2009, the principal secretary of the Home Department, Government of Maharashtra in an affidavit told the court that about 1,313 religious places had been identified in the city of Mumbai and the BMC would put up Silence zone boards within three months. Finally on 20 Aug 2009 principal secretary (appeals and security) Government of Maharashtra Mr.",1
"Firecracker packaging did not disclose details of noise levels or chemical content or even the year of manufacture; the Petroleum and Explosives Safety Organisation (PESO) who is the Authority to check firecrackers at the stage of manufacture and the Arms and Explosives Department of the Mumbai Police who license firecracker vendors did not take action for many years following complaints of violations. In 2012, Awaaz Foundation, under Right to Information, obtained an Order to disclose details of all firecrackers tested by PESO on their website. Diwali 2012 was the quietest Diwali in recent years In 2013.",1
"the Mumbai Police undertook an awareness and enforcement campaign for the 10pm deadline on bursting crackers during the Diwali Festival. The Firecracker Distributors' Association of Mumbai and Thane also cooperated in this effort. Diwali 2013 was the quietest in a decade.Awaaz Foundation also has organised volunteers groups, offered them support and education to all those who faced noise related problems, independently monitored Ambient noise level using sound level meter. and interacted with the authorities to ensure their support and co operation.",1
"Excessive noise from loudspeakers, construction, traffic and firecrackers have been separately taken up by Foundation at various times and with various authorities; educational programs and publications for schools, colleges, citizens groups and the authorities empowered to implement the laws have been supported and implemented.Awaaz Foundation encouraged citizen participation to implement noise rules by creating awareness about a free downloadable application onto phones to measure decibel levels. Awaaz requested citizens to complain to the Mumbai Police website with a copy to them for followup and received numerous complaints in the festival season 2012.",1
"The citizens' noise map was sent to the Chief Minister of Maharashtra and spurred a decision of the Government to conduct a formal noise map of Mumbai.Awaaz Foundation has conducted numerous awareness campaigns including #GetWellSoonMumbai, a social media campaign on Facebook, #TellTheDriver not to honk in partnership with the Thane, Navi Mumbai and Mumbai Traffic Police, #HornFllu in partnership with the Indian Medical Association, Noise Annoys in partnership with the Times of India #YourAwaazAgainstNoise, #GodsAgainstNoise.",1
"In 2015, community leaders carried out awareness drives to reduce noise from Mahim Fair and Eid e Milan through public Statements and grass root level campaignsAwaaz Foundation measured noise at the Shiv Sena Party's annual Dasara Rally in 2010, 2011, 2012 2013, 2014 and 2015 and presented their findings to the Police and Bombay High Court. Based on these readings the police filed cases against Rally organizers.Following final hearings of Awaaz Foundation's PIL, clubbed with nine other PILs by the Bombay High Court in August 2016, a comprehensive final Order was passed.",1
"The issue was brought to attention at any national or international forum for the first time through a side event The effect of coastal sand mining on biodiversity at the Convention on Biological Diversity Conference of Parties 11 by Awaaz Foundation and Bombay Natural History Society(BNHS) in October 2012. In August 2013, the National Green Tribunal banned sand mining in rivers across India. However, illegal sand mining on the coast around Mumbai continued even after the Order.The",1
"term sand mafia has been referred to by the Indian media while referring to those supporting or engaged in illegal sand mining (mainly politicians) who threaten, attack and kill Government and Police officers, activists or any other person who attempts to stop the illegal activity. MITRA (Movement against Intimidation, Threat and Revenge against Activists), a network of NGOs to protect activists in Maharashtra was set up after an attack by the sand mafia on Awaaz Foundation Convenor Sumaira Abdulali in 2004.",1
"This was the first publicly reported attack by the sand mafia but over the years there have been numerous others including a second attack on Sumaira Abdulali and a team of journalists, the murder of a Police Officer in Madhya Pradesh, murder of activists in Tamil Nadu and UP, and the suspension of IAS Durga Shakti Nagpal.",1
"Awaaz Foundation wrote to the Prime Minister of India protesting Durga Nagpal's transfer and demanded an investigation into the links between the transfer, the murder of activist Pale Ram Chauhan in the same area a few days later, and the politically led sand mafia of the region. An investigation was conducted by the MoEF and the presence of the sand mafia was confirmed.",1
"Report of MoEF on sand miningThe State Government of Maharashtra first took serious note of illegal coastal sand mining in 2004 following an incident of assault at Kihim Beach on Sumaira Abdulali (Convenor of Awaaz Foundation) by the son and employees of a local Member of the Legislative Assembly who are part of an extensive politically controlled sand mafia in Maharashtra. After that, Awaaz Foundation filed a public interest litigation (PIL) in the Bombay High Court seeking a ban on mining activities along the Konkan coast.",1
"Thereafter, the Bombay High Court has completely banned all sand mining activity in the State of Maharashtra and the Government has been forced to notify a completely new Policy on sand mining after considering the IIT Bombay Report.Sumaira Abdulali of Awaaz foundation raised some specific queries under the Right to Information Act regarding number of licences issued to barges carrying sand from Raigad district to Mumbai and Navi Mumbai along with the name of barges owners, conditions for operations as well as the number of inspections deployed to check if any contraband material was being smuggled into the jetty.",1
"The MMB did not respond for several months, then foundation filed these queries with the Maharashtra State Information Commission. Thereafter, the concerned agencies responded that neither The Maharashtra Maritime Board (MMB) nor Directorate-General of Shipping (DGS) nor The Indian Coast Guard maintain any records of the number of barges that move in and out of the inland waters on a day -to -day basis. The new sand mining policy stipulates that the barges should be registered and the list should be updated with the local Tehsildar.",1
"The Maharashtra Maritime Board (MMB) will Provide No Objection Certificates to the sand barges that pass through the sea channel after the letters of approval from the district collector. Awaaz Foundation inspected numerous illegal sand mining sites in the coastal areas near Mumbai including Thane, Vaitarna, Bankot Creeks, Kihim and Awas beaches and sent their findings to the MoEF, Government of Maharashtra, police and local authorities. They were instrumental in bringing public awareness about illegal sand mining and political links to this activity. Awaaz Foundation published a Report ' The links between politicians and sand mining in and around Mumbai.",1
"Awaaz Foundation is advocating inclusion of coastal sand mining on the Agenda of the next Convention of Biodiversity Conference of Parties 12 in 2014 by writing to the Indian Government, who is its International custodian until October 2014.In 2016, Awaaz Foundation once again represented to the United Nations that the ill effects of sand mining should form part of the global agenda of the United Nations Environment Programme during a meeting with Mr Erik Solheim, chief of UNEP.",1
"They also pressed for mainstreaming of alternative methods of building and road construction using recycled debris and plastics, which have been successful in pilot and small projects.In August 2016 a number of people lost their lives when a bridge was swept away at Mahad. The bridge was located near a sand mining site where Sumaira Abdulali had been attacked in 2010 during a sand mining site inspection. Sand mining equipment was found abandoned in the creek.",1
"Awaaz Foundation demanded an enquiry into the link between the collapse and nearby illegal sand mining, but Home Minister to the Government of Maharashtra Deepak Kesarkar, without carrying out any enquiry, stated that there was no link. In 2006, India applied to the UNESCO MAB for the Western Ghats to be listed as a protected World Heritage Site. The Western Ghats is very important Tropical Rainforest of India. During the monsoon season between June and September, the unbroken Western Ghats chain acts as a barrier to the moisture laden clouds.",1
"The range starts near the border of Gujarat and Maharashtra, south of the River Tapti, and runs approximately 1,600 kilometres (990 mi) through the states of Maharashtra, Goa, Karnataka, Tamil Nadu and Kerala ending at Kanyakumari, at the southern tip of India, one of three Biodiversity hotspots in the country.The National Mineral Policy of India, 2008 rules that any abandoned mine ""should be made richer than what it was before"" through refilling the craters and reforestation, but most miners leave their mines in a state of utter decay and toxicity.",1
"According to the data available with the ministry's Indian Bureau of Mines, there are 297 abandoned mines across the country and most of them are yet to be ""rehabilitated"". To protect large-scale destruction of flora and fauna around Western Ghats. Awaaz Foundation is advocating a zero-mining policy. Awaaz Foundation successfully filed public interest litigation to declare the Sawantwadi–Dodamarg wildlife corridor as an eco sensitive area.",1
"ministry of environment and forests of Government of India appointed two high levels Committees to recommend the type of development which should take place in the Western Ghats. Initially, the MoEF appointed the Western Ghat Ecology Expert Panel headed by ecologist Dr. Madhav Gadgil but suppressed its Report which recommended that the entire Western Ghats were eco sensitive to varying degrees. Awaaz Foundation and other concerned citizens filed Right to Information applications which resulted in the Report being made public over 6 months after it was finalised.",1
"Amid growing demand for implementation of the Western Ghat Ecology Expert Panel, the Government appointed another Committee chaired by Dr. Krishnaswamy Kasturirangan to assess the recommendations of the Western Ghat Ecology Expert Panel Report. Dr. Kasturirangan Report too, was neither accepted nor declined for several months. Meanwhile, Awaaz Foundation's litigation for declaration of the Sawantwadi-Dodamarg wildlife corridor as eco sensitive was heard by the Bombay High Court on 28 September 2013 and the Government ordered to notify it as eco sensitive before 31 December 2013.",1
of India,1
"Final oil separation, or fractionating, separates the oil into three different oil grades: Light viscosity lubricants suitable for general lubricant applications, low viscosity lubricants for automotive and industrial applications, and high viscosity lubricants for heavy-duty applications. The oil that is produced in this step is referred to as re-refined base oil (RRBL). The final step is blending additives into these three grades of oil products to produce final products with the right detergent and anti-friction qualities. Then each product is tested again for quality and purity before being released for sale to the public.",1
"The sludge (""residue"") associated with engine oil recycling, which collects at the bottom of re-refining vacuum distillation towers, is known by various names, including ""re-refined engine oil bottoms"" (abbreviated ""REOB"" or ""REOBs"").A report from the U.S. Federal Highway Administration (FHWA) states that: The oil in a car engine... contains a variety of additives to enhance the vehicle’s performance. These include polymers, viscosity modifiers, heat stabilizers, additional lubricants, and wear additives. The REOB contains all the additives that were in the waste oil as well as the wear metals from the engine (mainly iron and copper).",1
"These additives include zinc dialkyldithiophosphate, which contains zinc, sulfur, and phosphorus; calcium phenate, which contains calcium; and molybdenum disulfide, which contains molybdenum and sulfur.Some producers of asphalt for paving have—openly or secretly—incorporated REOBs into their asphalt, creating some controversy and concern in the traffic engineering community, with some experts suggesting it reduces the durability of the resulting pavement. Vegetable oil recycling Vehicle recycling Recycleoil.org – American Petroleum Institute Energy Efficiency and Recycling at the American Petroleum Institute",1
"The NOAA was created in 1970 after an oil spill 30 miles of the coast of California released 235,000 gallons of crude oil into the ocean. As time passes and technology advances, the NOAA has added sanctuaries all over the US. Three sites followed from 1992, with Congress designating Stellwagen Bank National Marine Sanctuary in Massachusetts and Monterey Bay National Marine Sanctuary in California. Title I of the MPRSA prohibits all ocean dumping, except that allowed by permits issued by the EPA Administrator pursuant to Section 102 of the MPRSA, in any ocean waters under U.S. jurisdiction, by any U.S.",1
"vessel, or by any vessel sailing from a U.S. port. EPA designates sites for ocean dumping and specifies in each permit where the material is to be disposed.In 1973, the EPA permitted two interim chemical disposal sites in the Gulf of Mexico, as described in the report, Assessing Potential Ocean Pollutants, published by the National Academy of Sciences (NAS, 1975) https://books.google.com/books/about/Assessing_Potential_Ocean_Pollutants.html?id=eicQOgkswusC. At Site A, uncontained wastes were discharged through a submerged pipe into the turbulent wake of a barge. At Site B, waste materials were placed in barrels before discharge.",1
"Chemical wastes discharged at these sites reportedly had various concentrations of chlorinated hydrocarbons, calcium and sodium metals, formaldehyde, cyanide and other metals (i.e. antimony, mercury, arsenic, zinc, manganese, and iron). Seven permits issued by the EPA in 1973 for the period of May 1 to November 1 allowed for the disposal of 84,500 tons of uncontained waste at Site A and 208,500 waste barrels at Site B, of which 55,000 barrels contained chlorinated hydrocarbons. By July 1973, four companies with plants at 7 locations were using Sites A and B (NAS, 1975).",1
"basic objective of the permit program is to ""prevent or strictly limit the dumping into ocean waters of any material that would adversely affect human health, welfare, or amenities, or the marine environment, ecosystems, or economic potentialities."" The Secretary of the Army (through the Corps of Engineers) is authorized to issue permits for dredged material disposal, and EPA is authorized to designate appropriate dump sites. Dumping restrictions were enacted for both U.S. flag vessels and materials transported from a location outside the U.S. With respect to the latter category, dumping was prohibited within the U.S. territorial sea and the U.S.",1
"contiguous zone. A specific dumping prohibition was included for radiological, chemical and biological warfare agents, high-level radioactive waste and medical wastes. Restrictions have since been placed on dumping activities in the New York Bight Apex, and sewage sludge dumping at the ""106-Mile Site"" offshore of New Jersey ended in 1992.In order for anyone to dump on US waters, they must follow certain laws. Public Law 97-424, enacted in 1983, placed a 2-year prohibition on ocean dumping of any low-level radioactive waste.",1
"Public Law 100-688 terminated the dumping of sewage sludge and waste from industrial companies (commencing with the 270th day after November 18, 1988) under certain conditions. After December 31, 1991, it was prohibited to dump any type of sewage sludge and industrial waste. This law gives EPA the authority to issue emergency permits for the dumping of industrial waste into ocean waters if an unacceptable human health risk exists and no other alternative is available. Statutes authorizing appropriations to implement Title I were enacted annually through 1977 and, thereafter, in 1980, 1981, and 1988.",1
"Statutes providing authority for appropriations were enacted in 1972, 1975, 1976, 1977, 1980, 1986 and 1988. Public Law 100-627 authorized appropriations of $13.5 million for Title II for Fiscal Year 1989, and $14.5 million for Fiscal Year 1990. Title III allows the Secretary of Commerce to designate discrete areas as National Marine Sanctuaries after conferring with the heads of involved federal agencies and state and local governments, as appropriate. The establishment of these sanctuaries is important in helping to promote comprehensive management of their special conservation, recreational, ecological, historical, research, educational, or aesthetic resources.",1
A statement of the research needs and priorities within the context of a 10-year goal. 4. An assessment of how the plan will incorporate existing research and management in the region 5. A description and schedule of the research objectives for the region during the 4-year period covered by the plan.,1
"In 1977, Congress amended the Act to require that dumping of municipal sewage sludge or industrial wastes, which unreasonably degrade the environment, to cease by December 1981. Because that deadline was not achieved, amendments were passed in 1988 that extended the deadline to December 1991. In 1986 amendments, Congress directed that ocean disposal of all wastes end at the traditional 12-mile site off the New York/New Jersey coast and that they be moved to a new site 106 miles offshore.",1
"Congress amended the Act again in 1992, giving permission to states to adopt ocean dumping standards more stringent than federal standards and to require that permits conform with long-term management plans for designated dumpsites. This amendment was put into place to ensure that permitted activities are consistent with expected uses of the site. The violation of a permit or permit requirement carries a civil penalty of not more than $75,000 per violation that is assessed by the EPA.",1
"During this convention, more than 85 countries agreed in the prohibition of dumping in the ocean the next elements: mercury, cadmium and other substances such as DDT and PCBs, solid wastes and persistent plastics, oil, high-level radioactive wastes, and chemical and biological warfare agents; and requires special permits for other heavy metals, cyanides and fluorides, and medium- and low-level radioactive wastes.",1
"In just the first decade of the century, more plastic has been created than all the plastic in history up until the year of 2000 and a majority of that plastic is not recycled. There is an estimated 15 to 51 trillion pieces of plastic amongst all of the world's oceans stretching from the top of ocean to the seafloor. Oceans are Earth's deepest and most extensive basins with average depths of the abyssal plains being about 4 km beneath sea level. Gravity will naturally move and transfer materials from land to the ocean, with the ocean becoming the end-repository.",1
"Even remote island atolls can have beaches loaded with plastic from a faraway source. At the ocean surface, plastic debris is concentrated within circular structures of large areal extent, called ocean gyres. Ocean gyres form within all oceans, due to alternating patterns of zonal winds that drive equatorward interior transport in the subtropics, and poleward interior transport in subpolar oceans. Ocean currents concentrate plastic waste within the gyres. Plastics have been increasingly manufactured because of their flexible, molding and durable qualities, which provides plastic with a myriad of useful applications.",1
"Plastics are remarkably resistant to natural weathering processes that break down many other materials at the Earth's surface. Ocean processes, including storms, wave action, ocean currents, hydration, and surface exposure to the atmospheric weathering processes (e.g. oxidation) and ultraviolet radiation, tend to break plastic particles into ever-decreasing sizes (resulting in microplastics), rather than organically digest or chemically alter plastic substances. Estimates of the total number and weight of plastic across five ocean gyre plastic concentration zones are of the order of 5.25 trillion particles weighing almost 300,000 tons.",1
"The most eye-catching evidence of the ocean plastic problem are the garbage patches that accumulate in gyre regions. A gyre is a circular ocean current formed by the Earth's wind patterns and the forces created by the rotation of the planet. There are five main ocean gyres: the North and South Pacific Subtropical Gyres, the North and South Atlantic Subtropical Gyres, and the Indian Ocean Subtropical Gyre. There are significant garbage patches in each of these.Larger",1
"plastic waste (macroplastics) can be ingested by marine species, filling their stomachs and leading them to believe they are full when in fact they have taken in nothing of nutritional value. This can bring seabirds, whales, fish, and turtles to die of starvation with plastic-filled stomachs. Marine species can also be suffocated or entangled in plastic garbage.Macroplastic waste can break can weather into smaller fragments of plastic debris, known as microplastics when they are smaller than 5mm in size. Sunlight exposure, temperature, humidity, waves, and wind begin to break the plastic down into pieces smaller than five millimeters long.",1
"Plastics can also be broken down by smaller organisms who will eat plastic debris, breaking it down into small pieces, and either excrete these microplastics or spit them out. In lab tests, it was found that amphipods of the species Orchestia gammarellus could quickly devour pieces of plastic bags, shredding a single bag into 1.75 million microscopic fragments. Although the plastic is broken down, it is still a man-made material that does not biodegrade. It is estimated that approximately 90% of the plastics in the pelagic marine environment are microplastics.",1
"There are also primary sources of microplastics, such as microbeads and nurdles. These microplastics are frequently consumed by marine organisms at the base of the food chain, like plankton and fish larvae, which leads to a concentration of ingested plastic up the food chain. Plastics are produced with toxic chemicals, so these toxic substances enter the marine food chain, including the fish that some humans eat. Plastic waste entering the seas is increasing each year with much of the plastic entering the seas is in particles smaller than 5 millimetres.",1
"Ocean Conservancy reported that China, Indonesia, Philippines, Thailand, and Vietnam dump more plastic in the sea than all other countries combined.One study estimated that there are more than 5 trillion plastic pieces (defined into the four classes of small microplastics, large microplastics, meso- and macroplastics) afloat at sea. In 2020, new measurements found more than 10 times as much plastic in the Atlantic Ocean than previously estimated to be there.In",1
"plastic litter enters the ocean largely through storm-water runoff, flowing into watercourses or directly discharged into coastal waters. Plastic in the ocean has been shown to follow ocean currents which eventually form into what is known as Great Garbage Patches. The impact of microplastic and macroplastic into the ocean is not subjected to infiltration directly by dumping of plastic into marine ecosystems, but through polluted rivers that lead or create passageways to oceans across the globe. Rivers can either act as a source or sink depending on the context.",1
"1994 study of the seabed using trawl nets in the north-western Mediterranean around the coasts of Spain, France, and Italy reported mean concentrations of debris of 1,935 items per square kilometre. Plastic debris accounted for 77%, of which 93% was plastic bags.",1
"Approximately half of the plastic material introduced to the marine environment is buoyant, but fouling by organisms can cause plastic debris to sink to the sea floor, where it may interfere with sediment-dwelling species and sedimental gas exchange processes. Several factors contribute to microplastic's buoyancy, including the density of the plastic it is composed of as well as the size and shape of the microplastic fragments themselves. Microplastics can also form a buoyant biofilm layer on the ocean's surface.",1
"Microplastics are also found within the many other types of marine particles such as dead biological material (tissue and shells) and some soil particles (blown in by wind and carried to the ocean by rivers). Population density and proximity to urban centers have been considered the main factors that influence the abundance of microplastics in the environment. A greater concentration of microplastics have been associated with rainfall events. The runoff after rainfall on land, where plastic production and degradation rate of plastic debris is higher, could deliver these microplastics into the aquatic environment.",1
"Australia's national science agency CSIRO estimated that 14 million metric tons of microplastics are already on the ocean floor in 2020. This represents an increase from a 2015 estimate that the world's oceans contain 93–236 thousand metric tons of microplastics and a 2018 estimate of 270 thousand tons.The Ocean Conservancy has reported that China, Indonesia, Philippines, Thailand, and Vietnam dump more plastic in the sea than all other countries combined.A",1
"study of the distribution of eastern Pacific Ocean surface plastic debris (not specifically microplastic, although, as previously mentioned, most is likely microplastic) helps to illustrate the rising concentration of plastics in the ocean. By using data on surface plastic concentration (pieces of plastic per km2) from 1972 to 1985 (n=60) and 2002–2012 (n=457) within the same plastic accumulation zone, the study found the mean plastic concentration increase between the two sets of data, including a 10-fold increase of 18,160 to 189,800 pieces of plastic per km2.Arctic Ocean microplastics come mainly from Atlantic sources, especially Europe and North America.",1
"can concentrate in the gills and intestines of marine life and can interfere with their feedings habits, typically resulting in death. Microplastics have been shown to induce a lethargic swimming and feeding behavior in fish, mussels and nematodes, under severe overload situations. Microplastic size is an important feature for the production of toxic effects on the different organisms, however, the tissue structure and anatomy of each organism play an important role in the severity of the damage that these particles can produce.",1
"Bioaccumulation of microplastics can have a huge effect on the food web, thus altering ecosystems and contributing to loss of biodiversity. Once ingested, microplastics will either be egested or retained by an organism. If a predator consumes an organism that has retained microplastic, the predator will be indirectly consuming this plastic as part of its diet, in a process referred to as ""trophic transfer'. Retention of plastics can be influenced by food availability and shape but will be governed by the size of the plastic.",1
"Ingested microplastics will typically be passed along the intestinal tract, then will either be adsorbed across the gut lining, become entrapped in the gut (i.e., intestinal blockage causing retention of plastic), or become incorporated into the animal's feces and egested.The ingestion of plastic by marine organisms has now been established at full ocean depth. Microplastic was found in the stomachs of hadal amphipods sampled from the Japan, Izu-Bonin, Mariana, Kermadec, New Hebrides and the Peru-Chile trenches. The amphipods from the Mariana Trench were sampled at 10,890 m and all contained microfibres.According",1
"to one recent research estimate, a person who consumes seafood will ingest 11 000 bits of microplastics per year. Even very minute microplastics have been discovered in human blood.",1
"Research performed by MBARI in 2013 off the west coast of North America and around Hawaii found that out of all the debris observed from 22 years of VARS database video footage, one-third of the items was plastic bags. This debris was most common below 2000 m depth. A recent study that collected organisms and sediments in the Abyssopelagic Zone of the Western Pacific Ocean extracted materials from samples and discovered that poly(propylene-ethylene) copolymer (40.0%) and polyethylene terephthalate (27.5%) were the most commonly detected polymers.Another",1
"study was conducted by collecting deep-sea sediment and coral specimens between 2011 and 2012 in the Mediterranean Sea, Southwest Indian Ocean, and Northeast Atlantic Ocean. Of the 12 coral and sediment samples taken, all were found with an abundance of microplastics. Rayon is not a plastic but was included in the study due to being a common synthetic material. It was found in all samples and comprised 56.9% of materials found, followed by polyester (53.4%), plastics (34.1%) and acrylic (12.4%).",1
"This study found that the amount of microplastics, in the form of microfibres, was comparable to that found in intertidal or subtidal sediments. A 2017 study had a similar finding – by surveying the Rockall Trough in the Northeast Atlantic Ocean at a depth of more than 2200 meters, microplastic fibers were identified at a concentration of 70.8 particles per cubic meter. This is comparable to amounts reported in surface waters.",1
"This study also looked at micropollution ingested by benthic invertebrates Ophiomusium lymani, Hymenaster pellucidus and Colus jeffreysianus and found that of the 66 organisms studied, 48% had ingested microplastics in quantities also comparable to coastal species. A recent review of 112 studies found the highest plastic ingestion in organisms collected in the Mediterranean and Northeast Indian Ocean with significant differences among plastic types ingested by different groups of animals, including differences in colour and the type of prevalent polymers. Overall, clear fibre microplastics are likely the most predominant types ingested by marine megafauna around the globe.In",1
"2020 scientists created what may be the first scientific estimate of how much microplastic currently resides in Earth's seafloor, after investigating six areas of ~3 km depth ~300 km off the Australian coast. They found the highly variable microplastic counts to be proportionate to plastic on the surface and the angle of the seafloor slope.",1
"By averaging the microplastic mass per cm3, they estimated that Earth's seafloor contains ~14 million tons of microplastic – about double the amount they estimated based on data from earlier studies – despite calling both estimates ""conservative"" as coastal areas are known to contain much more microplastic. These estimates are about one to two times the amount of plastic thought to currently enter the oceans annually.Two billion people worldwide lack adequate garbage collection facilities to capture harmful plastics. Improved wastewater treatment and stormwater management in many poor nations would prevent part of the 1.5",1
"These toxins are believed to bring harm to the marine life living in the area. Bisphenol A (BPA) is a famous example of a plasticizer produced in high volumes for food packing from where it can leach into food, leading to human exposure. As an estrogen and glucocorticoid receptor agonist, BPA is interfering with the endocrine system and is associated with increased fat in rodents.Researchers collected seawater samples worldwide, and found that all samples contained polystyrene derivatives. Polystyrene is a plastic found in styrofoam and many household and consumer goods.",1
"The scientists then simulated the decomposition of polystyrene in the open ocean. The results of this simulation showed that polystyrene, which begins breaking down at temperatures of 86° and higher, breaks down into harmful chemicals, such as Bisphenol A (BPA, which can cause reproductive harm in animals), styrene monomer (a suspected carcinogen), and styrene trimer (a by-product of polystyrene).Plasticizers in microplastics have been linked to abnormal growth and reproductive problems in multiple animal models due to endocrine disruption. Microplastics have also been postulated to cause GI irritation, alteration of the microbiome, disturbance of energy and lipid metabolism, and oxidative stress.Organic",1
"In samples taken from the North Pacific Gyre in 1999, the mass of plastic exceeded that of zooplankton (the dominant animal life in the area) by a factor of six.Midway Atoll, in common with all the Hawaiian Islands, receives substantial amounts of debris from the garbage patch. Ninety percent plastic, this debris accumulates on the beaches of Midway where it becomes a hazard to the bird population of the island.",1
"Over nine years, global research documenting this phenomenon ballooned from 46 (2011) to 853 (2019) publications.",1
"Concern among experts has grown since the 2000s that some organisms have adapted to live on floating plastic debris, allowing them to disperse with ocean currents and thus potentially become invasive species in distant ecosystems. Research in 2014 in the waters around Australia confirmed a wealth of such colonists, even on tiny flakes, and also found thriving ocean bacteria eating into the plastic to form pits and grooves. These researchers showed that ""plastic biodegradation is occurring at the sea surface"" through the action of bacteria, and noted that this is congruent with a new body of research on such bacteria.",1
"Their finding is also congruent with the other major research undertaken in 2014, which sought to answer the riddle of the overall lack of build up of floating plastic in the oceans, despite ongoing high levels of dumping. Plastics were found as microfibres in core samples drilled from sediments at the bottom of the deep ocean. The cause of such widespread deep sea deposition has yet to be determined. The hydrophobic nature of plastic surfaces stimulates rapid formation of biofilms, which support a wide range of metabolic activities, and drive succession of other micro- and macro-organisms.",1
"These pieces eventually become so small that even microorganisms can ingest and metabolize them, converting the plastics into carbon dioxide. In some instances, these microplastics are absorbed directly into a microorganism's biomolecules. However, before reaching this state, any number of organisms could potentially interact with these plastics.",1
"Larger plastics (called ""macroplastics"") such as plastic shopping bags can clog the digestive tracts of larger animals when consumed by them and can cause starvation through restricting the movement of food, or by filling the stomach and tricking the animal into thinking it is full. Microplastics on the other hand harm smaller marine life. For example, pelagic plastic pieces in the center of our ocean's gyres outnumber live marine plankton, and are passed up the food chain to reach all marine life.Fishing",1
"Some marine species, such as sea turtles, have been found to contain large proportions of plastics in their stomach. When this occurs, the animal typically starves, because the plastic blocks the animal's digestive tract. Sometimes marine mammals are entangled in plastic products such as nets, which can harm or kill them.",1
"Cetaceans have been sighted within the patch, which poses entanglement and ingestion risks to animals using the Great Pacific garbage patch as a migration corridor or core habitat.",1
"of these long-lasting pieces end up in the stomachs of marine birds and animals, including sea turtles, and black-footed albatross. This results in obstruction of digestive pathways, which leads to reduced appetite or even starvation. In a 2008 Pacific Gyre voyage, Algalita Marine Research Foundation researchers began finding that fish are ingesting plastic fragments and debris. Of the 672 fish caught during that voyage, 35% had ingested plastic pieces.With the increased amount of plastic in the ocean, living organisms are now at a greater risk of harm from plastic consumption and entanglement.",1
"Approximately 23% of aquatic mammals, and 36% of seabirds have experienced the detriments of plastic presence in the ocean. Since as much as 70% of the trash is estimated to be on the ocean floor, and microplastics are only millimeters wide, sealife at nearly every level of the food chain is affected. Animals who feed off of the bottom of the ocean risk sweeping microplastics into their systems while gathering food. Smaller marine life such as mussels and worms sometimes mistake plastic for their prey.Larger",1
"Plastic can cause blockage of intestines as well as tearing of interior stomach and intestinal lining of marine life, ultimately leading to starvation and death.Some long-lasting plastics end up in the stomachs of marine animals. Plastic attracts seabirds and fish. When marine life consumes plastic allowing it to enter the food chain, this can lead to greater problems when species that have consumed plastic are then eaten by other predators. Multiple studies have found plastics and microplastics in the stomach contents of marine animals.The",1
"ingestion of large amounts of plastic debris, such as fish nets and ropes, can lead to marine animal's deaths via gastric impaction.",1
"They can mistake plastics for food and consume them accidentally when feeding on prey organisms that are gathered near plastics. Plastics can also enter their system if their prey already had synthetic plastic particles in their digestive tract via bioaccumulation. Large amounts of plastics have been found in the stomachs of beached whales. Plastic debris started appearing in the stomach of the sperm whale since the 1970s, and has been noted to be the cause of death of several whales.",1
"of the tiniest bits of plastic are being consumed by small fish, in a part of the pelagic zone in the ocean called the Mesopelagic zone, which is 200 to 1000 metres below the ocean surface, and completely dark. Not much is known about these fish, other than that there are many of them. They hide in the darkness of the ocean, avoiding predators and then swimming to the ocean's surface at night to feed. Plastics found in the stomachs of these fish were collected during Malaspina's circumnavigation, a research project that studies the impact of global change on the oceans.A",1
"study conducted by Scripps Institution of Oceanography showed that the average plastic content in the stomachs of 141 mesopelagic fish over 27 different species was 9.2%. Their estimate for the ingestion rate of plastic debris by these fish in the North Pacific was between 12,000 and 24,000 tonnes per year. The most popular mesopelagic fish is the lantern fish. It resides in the central ocean gyres, a large system of rotating ocean currents.",1
"Since lantern fish serve as a primary food source for the fish that consumers purchase, including tuna and swordfish, the plastics they ingest become part of the food chain. The lantern fish is one of the main bait fish in the ocean, and it eats large amounts of plastic fragments, which in turn will not make them nutritious enough for other fish to consume.Another study found bits of plastic outnumber baby fish by seven to one in nursery waters off Hawaii. After dissecting hundreds of larval fish, the researchers discovered that many fish species ingested plastic particles.",1
"Plastics were also found in flying fish, which are eaten by top predators such as tunas and most Hawaiian seabirds.Deep sea animals have been found with plastics in their stomachs. In 2020, deep sea species Eurythenes plasticus was discovered, with one of the samples already having plastics in its gut; it was named to highlight the impacts of plastic pollution.It was found in 2016–2017 that more than 35% of south Pacific Lanternfish had consumed plastic particles. When ingested by the fish, the chemical compounds found in these plastics cannot be digested.",1
"This can affect humans, as the Lanternfish is a food source for both salmon and tuna. Fish and whales may also mistake the plastic as a food source.",1
"is a type of fibrotic disease initially found in one species of bird in 2023. After the initial observation that many of the beaches in New Zealand had high concentrations of plastic pellets, further studies found that different species of prion ingest the plastic debris. Hungry prions mistook these pellets for food, and these particles were found intact within the birds' gizzards and proventriculi.",1
"Pecking marks similar to those made by northern fulmars in cuttlebones have been found in plastic debris, such as styrofoam, on the beaches on the Dutch coast, showing that this species of bird also mistake plastic debris for food.Of the 1.5 million Laysan albatrosses that inhabit Midway Atoll, nearly all are likely to have plastic in their gastrointestinal tract. Approximately one-third of their chicks die, and many of those deaths are from plastic unwittingly fed to them by their parents.",1
"Twenty tons of plastic debris washes up on Midway every year with five tons ending up in the bellies of albatross chicks. These seabirds choose red, pink, brown, and blue plastic pieces because of similarities to their natural food sources. As a result of plastic ingestion, the digestive tract can be blocked resulting in starvation. The windpipe can also be blocked, which results in suffocation. The debris can also accumulate in the animal's gut, and give them a false sense of fullness which would also result in starvation.",1
"On the shore, thousands of birds corpses can be seen with plastic remaining where the stomach once was. The durability of the plastics is visible among the remains. In some instances, the plastic piles are still present while the bird's corpse has decayed.Similar to humans, animals exposed to plasticizers can experience developmental defects. Specifically, sheep have been found to have lower birth weights when prenatally exposed to bisphenol A. Exposure to BPA can shorten the distance between the eyes of a tadpole. It can also stall development in frogs and can result in a decrease in body length.",1
"In different species of fish, exposure can stall egg hatching and result in a decrease in body weight, tail length, and body length. A study found that in 1960 less than 5% of seabirds were found to have consumed waste material, while as of August 2015 that figure climbed to about 90%. It is predicted that by 2050, 99% of seabirds will have consumed such materials. Scientists studying the stomach contents of Laysan Albatross chicks report a 40% mortality rate before fledging. When the stomach contents were analyzed following necropsies, they were found to contain plastic waste.",1
"In addition, as coral gets trapped in different types of fishing gear, this causes coral to develop stress as they are not in a favorable condition, which causes coral to break and die off. According to multiple research studies, Tubastraea micranthus is a type of coral species that appears to be the most impacted by fishing gear in the ocean because of its branches and its ability to grow on top of fishing gear such as nets, ropes, and lines.Phytoplankton In 2019 and 2020 there were week-long studies done in Australia along the Georges River to measure the number of microplastics.",1
"many different species of phytoplankton are being exposed to microplastics in the Georges River, not only does this impact the lives of the phytoplankton themselves, but also affects other animals in their food chain. Phytoplankton are primary producers; therefore, when microplastics are ingested, other living organisms in the environment that feed on phytoplankton also ingest microplastics.Fin Whales In the Mediterranean Sea, studies have been performed to determine how the number of microplastics on the surface level of the ocean has affected fin whale populations.",1
"results of the studies indicated that there were high levels of microplastics within the surface level of the Mediterranean Sea which is the fin whales' habitat and serves as the location of their food source mainly during the summer months. The results indicate that when fin whales search for food to eat on the surface level of the ocean, they often accidentally consume microplastics. These microplastics have many toxins and chemicals that could harm the fin whale if they consume them as these toxins are then stored in the tissues of the fin whale for long periods of time.",1
"A study from 2019 indicates that the large amounts of plastic in the Great Pacific garbage patch could affect the behavior and distribution of some marine animals, as they can act as fish aggregating devices (FAD). FADs can attract feeding cetaceans, thus increasing the risk of being entangled or ingesting additional plastic. Nanoplastics can penetrate the intestine tissue in aquatic creatures and can end up in the human food chain by inhalation (breathing) or ingestion (eating), particularly through shellfish and crustaceans. Ingestion of plastics has been associated with a variety of reproductive, carcinogenic, and mutagenic effects.",1
"Many ideas exist for cleaning up plastic in the oceans including trapping plastic particles at river mouths before entering the ocean, and cleaning up the ocean gyres.",1
"A fleet of 30 vessels, including a 32-metre (105-foot) mothership, took part in a month-long voyage to determine how much plastic is present using trawls and aerial surveys.The organization ""everwave"" uses special rubbish collection boats in rivers and estuaries to prevent rubbish from entering the world's oceans.There is also Ocean Plastic Utilisation Ships System R&D project (OPUSS). The main objective of this project is to make the ocean cleaning process commercially realistic in time, environmentally efficient and viable in general.",1
"The central idea of the OPUSS project lies in developing new circular logistic scheme of the ocean cleanup, as existing reverse logistics supply chains are not able to capture the specifics of the plastic waste collection out on the ocean. The main target of a project is cleaning the ocean with optimal results in terms of logistics and construction costs, as well as with minimal operating costs.",1
The company is led by a team of engineers from the university of Warwick.Other companies working on a system for converting plastic waste to fuel include GRT Group and OMV.,1
"The development of such a treaty is underway as of March 2022 and is expected to conclude by the end of 2024.In the EU it is estimated that banning the intentional addition of microplastics to cosmetics, detergents, paints, polish and coatings, among others, would reduce emissions of microplastics by about 400,000 tonnes over 20 years.The trade in plastic waste from industrialized countries to developing countries has been identified as the main cause of marine litter because countries importing the waste plastics often lack the capacity to process all the material.",1
"Therefore, the United Nations has imposed a ban on waste plastic trade unless it meets certain criteria. The global plastic waste trade when it comes into effect in January 2021.",1
"2006, Ken Weiss published an article in the Los Angeles Times which was the first to make the public aware about the effects that the Garbage Patch in the Pacific Ocean. Later in 2009, a group of researchers decided to go out into the Pacific Ocean to prove if the Garbage Patch was real or a myth. After days out on the sea, the research group came across hundreds of plastic pieces in the ocean that were seen as a soup of microplastics rather than large pieces of plastics as expected.The",1
"Dunning, Brian (16 December 2008). ""Skeptoid #132: The Sargasso Sea and the Pacific Garbage Patch"". Skeptoid.",1
"In 2010, large-scale burn pit operations in Iraq and Afghanistan, allegedly operated by the U.S. military or its contractors such as KBR, were reported to have allowed the operation of the burn pits for long periods, burning many tons of assorted waste. Active duty personnel reported respiratory difficulties and headaches in some cases, while some veterans made disability claims based on respiratory system symptoms allegedly derived from the burn pits.",1
"Joint Base Balad (JBB), the largest U.S. base in Iraq had a burn pit operation as late as the summer of 2008, burning 147 tons of waste per day when the Army Times published a major story about it and related health concerns. The burn pit at JBB was 10-acres and the waste produced by each person assigned to JBB is estimated to be between 3.6 and 4.5 kilograms (7.9 and 9.9 lb) of waste per day.",1
"Another called it “pollen dust.” The color of the smoke could be blue and black, or yellow and orange, but was usually black.",1
"Burn pits operate at lower temperatures which causes more incomplete combustion, which results in greater amounts of aerosolized toxic by-products. In November 2009, the Veteran's Administration (VA) and the National Academy of Sciences Institute of Medicine (IOM) began an 18-month study to determine the long-term health effects of exposure to the burn pits in Iraq and Afghanistan.",1
"The VA and the Department of Defense (DoD), the Board on the Health of Select Populations of the Institute of Medicine formed the Committee on Long-term Health Consequences of Exposure to Burn Pits in Iraq and Afghanistan which held its first meeting February 23/24, 2010 in Washington, D.C. In 2011, the Institute of Medicine reviewed the scientific literature related to the possibility of adverse long-term health effects of open burn pits. The report, Long-Term Health Consequences of Exposure to Burn Pits in Iraq and Afghanistan noted U.S.",1
"If there is sufficient evidence of a connection between exposure to burn pits and subsequent illness and disability, it might serve as the basis for congressional enactment of a ""presumption of service connection"" similar to that in place for exposure to Agent Orange. Currently, there has been research in the following areas to determine exposure to burn pit and health effects: Reproductive Health Outcomes: There is some research to suggest that toxins from burn pits can have adverse birth outcomes (low birth weight, preterm delivery, and increased risk of birth defects).",1
"Additionally, there is growing evidence to suggest a reduction in sperm quality associated with burn pits. Autoimmune Disorders A study found no elevated occurrence of rheumatoid arthritis and lupus among veterans deployed within 3 miles of burn pits. Cancers: It is believed one veteran's fatal pancreatic cancer is associated with burn pit exposure. Another veteran is believed to have brain cancer from the exposure. One study using Burn Pits 360's registry, there is a higher rate of proportionate cancer mortality among deceased veterans.",1
"High Blood Pressure: A study from the Veterans Affairs Airborne Hazards and Open Burn Pit Registry, one-third those exposed to burn pits were diagnosed with high blood pressure. Respiratory Disorders: The Veterans Affairs Airborne Hazards and Open Burn Pit Registry, 30% of participates have been diagnosed with chronic obstructive pulmonary disease, emphysema, and chronic bronchitis.But according to the Army, proper waste management practices have reduced the spread of infectious diseases that contributed significantly to mortality and morbidity in military populations.",1
"Report on Data from the Airborne Hazards and Open Burn Pit (AH&OBP) Registry, June 2015 - Between April 25, 2014, and December 31, 2014, nearly thirty thousand Veterans and Active Duty Servicemembers filled out the registry survey. This report highlights health conditions and physical limitations experienced by burn pit registry participants. The most common doctor-diagnosed health problems reported were insomnia and neurological problems. Other commonly diagnosed health problems reported include allergies, high blood pressure, and lung disease like emphysema, chronic bronchitis, and asthma.",1
"It is important to remember that Registry findings alone can't tell if exposure to burn pits, dust storms, or other hazards caused these health conditions.2. Report on Data from the Airborne Hazards and Open Burn Pit (AH&OBP) Registry, April 2015As of December 31, 2019, 186,051 veterans and active duty members have completed the questionnaire since June 2014.",1
"US Army veteran and University of Pennsylvania graduate student Chad Baer has vocally asserted that claims of inclusive results are due to faulty research design. Baer was selected as a SVA/VFW Legislative Fellow in 2019, and traveled to Capitol Hill to advocate for a predictive analytics model. Baer has asserted that technological advances have made longitudinal studies of all veterans feasible, except that this is not possible so long as the Department of Defense refuses to give VA researchers more complete data.",1
"The data in question would be the personnel data that would allow the VA to establish ""clusters"", based on items such as physical location, job specialties, or other relevant data points. A Minnesota mother, Amie Muller, was a victim of the exposure and her senator, Amy Klobuchar (MN-DFL), carried a bill called the “Helping Vets Exposed to Burn Pits Act” that was passed and signed into law by President Donald Trump (as H.R. 5895) on September 21, 2018. Through 2019, it will provide $5 million for burn pit research, education and evaluation of the exposure of other U.S.",1
"service members and veterans to burn pits and toxic airborne chemicals.Congressional action taken includes: 2009 – HR 2419, Military Personnel War Zone Toxic Exposure Prevention Act 2013 – President Obama signed the National Burn Pit Registry into law as part of the Dignified Burial and Veterans' Benefit Improvement Act of 2012. 2018 – President Trump signed the Helping Vets Exposed to Burn Pits Act.",1
"2022 – President Biden signed the Promise to Address Comprehensive Toxics (PACT) Act Combustion Incineration Waste Incineration Directive Waste management Department of Veterans Affairs, Public Health, VA's Airborne Hazards and Open Burn Pit Registry webpage VA Airborne Hazards and Open Burn Pit Registry Video ""Report: Army making toxic mess in war zones"" article by Kelly Kennedy in Military Times Oct 3, 2008 David E. Mosher, Beth E. Lachman, Michael D. Greenberg, Tiffany Nichols, Brian Rosen, Henry H.",1
Military Burn Pits in Iraq and Afghanistan Al-Jazeera interview with U.S. veteran and experts (1 August 2017): [1],1
The main purpose of a windbreak or a shelterbelt is to protect areas from wind causing erosion on the bare soil of croplands. Windbreaks can also serve as an area that separates fields and protects them from spray drift of pesticides. Buffer strips are very important in helping to provide habitat for many species of wildlife in the open farm lands by causing an edge effect. With much of the land open on farms having an edge allows a safe-haven for animals to move between different ecosystems.,1
"Buffers are also helpful in conserving biodiversity especially to that of rare or endangered species through the incorporation of native grasses into their seeding by the landowner. Native grasses are especially important to pheasants, quail, chukar and songbirds because they provide the foods they need as well as the shelter from predators. Since most buffer strip areas have limited disturbance from farming it allows for a shelter to hide year round for many of the species including insects, birds, and mammals.",1
"& Isenhart, T. (1997). ""Riparian Buffers for Agricultural Land."" Agroforestry Notes, No. 3, January 1997. National Agroforestry Center, USDA Forest Service, Lincoln, NE. NRCS. ""National Conservation Practice Standards."" Archived 2011-06-11 at the Wayback Machine National Handbook of Conservation Practices. Accessed 2009-05-24. NRCS. Web Soil Survey NRCS. Planting materials USDA. Grassed Wasterways Perspective Minn. DNR Buffer Strips",1
"All types of organizations are invited to participate in PDP and commit to reducing their plastic footprint. The Plastic Disclosure Project (PDP) is an initiative that aims to track and reduce plastic waste generated by companies and institutions. Lush (company) was the first participant to disclose its plastic waste data in 2011, followed by UC Berkeley, the first university to join in 2012. The project is managed by Campus Recycling and Refuse Services, along with the Office of Sustainability, with plans to assign interns to monitor plastic waste leaving the campus.",1
"Brazilian firefighters are trained for NBC situations. During the 2016 Summer Olympics, police forces like the GATE from Minas Gerais, the Federal Police, and the National Public Security Force were prepared.In the military, there is CBRN equipment and personnel in all branches of the Armed Forces.",1
"The Brazilian Army has two specific teams: the 1st Chemical, Biological, Radiological and Nuclear Defense Battalion, which is based in Rio de Janeiro and is responsible for decontaminating military equipment, weapons, and personnel, and the Chemical, Biological, Radiological and Nuclear Defense Company, based at Goiânia and part of the Brazilian Special Operations Command, that makes the decontamination and defense in CBRN situations. The Brazilian Presidential Guard and Army Police also have CBRN units.The",1
"Brazilian Marine Corps has the CDefNBQR (Nuclear, Biological, Chemical and Radiological Defense Center) that controls the ARAMAR Nuclear, Biological, Chemical and Radiological Defense Battalion, at Iperó, São Paulo, conceived to provide physical security and to perform CBRN emergencies control actions at the Centro Experimental Aramar, responsible for developing Brazilian Navy nuclear researches; the Itaguaí Nuclear, Biological, Chemical and Radiological Defense Battalion, at Itaguaí, Rio de Janeiro, which is to be the host of the first Brazilian Navy nuclear-powered submarine; and the Nuclear, Biological, Chemical and Radiological Defense Company, at Duque de Caxias, Rio de Janeiro.",1
"The Canadian Joint Incident Response Unit is a Canadian Forces unit, under the direction of the Canadian Special Operations Forces Command, charged with supporting ""the Government of Canada in order to prevent, control and mitigate CBRN threats to Canada, Canadians and Canadian interests.""All members of the Canadian Armed Forces are trained in CBRNE defense and maintain minimum standards, tested at least every three years. At the provincial level, cities are provided opportunities for emergency services with CBRN training. In Ontario, emergency services in Windsor, Peterborough, Toronto, and Ottawa have obtained CBRN standing at NFPA Standard 472 Awareness Level 3.",1
"In mid-July 2016, the European Parliament negotiated a new draft counterterrorism directive aimed at protecting Europe's people from biological, chemical and other attacks. The timeline of the directive is illustrated in the following table: The directive would criminalize: Certain acts related to preparing for a terrorist attack, such as traveling abroad to meet with a terrorist group Training to make explosives, firearms, and other dangerous substances Public incitement or praise for terrorism and financing of terrorismThe directive also includes text to help victims of terror attacks.",1
"Hong Kong has had CBRN response capabilities since the early 1990s and advanced training from 1998. The Standing CBRN Planning Group (known as the SRPG) plans for all CBRN incidents in Hong Kong. The SRPG was set up with the support of the Secretary for Security by the Senior Bomb Disposal Officer in Hong Kong, Dominic Brittain. It consists of representatives from 9 government departments who plan the response to CBRN threats. These departments include Police EOD, Fire Services, the Hospital Authority and the Department of Health, amongst others.",1
"The operational arm of the SRPG is the CBRN Incident Advisory Group (RIAG) form in the initial stages of a CBRN incident using telephone conferencing. RIAG consists of five experts who assist with the technical response to the incident by providing real-time advice and support to the departments involved. The Hong Kong capability is well rehearsed, with regular departmental exercises conducted and a full-scale CBRN exercise conducted every year.",1
"The Indian Army ordered 16 CBRN monitoring vehicles, of which the first 8 were inducted in December 2010. It was developed by the Defence Research and Development Organization (DRDO) and manufactured by Ordnance Factories Board.",1
"The Indonesian Army has a CBRN defense unit which is the Kompi Zeni Nuklir, Biologi dan Kimia (abbreviated ""Kompi Zeni Nubika Pusat Zeni TNI AD"") translated as Army Engineers Nuclear, Biological, and Chemical Company. The unit was founded on 22 April 1986 under the command of the Indonesian Army Corps of Engineers. The unit is also in cooperation with the Ministry of Health, the Indonesian Nuclear power regulator agency, the Veterinary Research Agency, and the National Nuclear Power Agency. This unit is the one and only unit that can handle CBRN Defense Capability within the Armed Forces.",1
The Indonesian National Police special unit the Mobile Brigade Corps (Brimob) has a CBR unit under the Gegana detachment. It was formed in December 2009. This unit acts as first responders to bomb and terrorist threats in the public.,1
"The Irish Defence Forces have CBRNE training and equipment capabilities – in particular the Ordnance Corps (Explosive Ordnance Disposal/EOD teams), Engineer Corps and Army Ranger Wing (ARW) – and will aid the civil authority if requested. The Irish Army runs CBRNE defense courses has detection equipment, and decontamination equipment and is reported to have purchased 10,000 protective CBRN/NBC suits, enough for all of its personnel. All Army Reserve personnel undergo CBRN warfare defense training.The Irish national police force, the Garda Síochána, has a number of nationwide CBRN response teams.",1
"The teams are based regionally (in six regions; Dublin, Eastern, Northern, Southern, South-Eastern & Western) and began operating in 2004 with 100 trained officers (170 responders trained throughout the country as of 2009). There is a requirement for members to be re-certified within 18 months of training. CBRN response teams are trained by the Garda Tactical Training Unit, and supported nationally by the Emergency Response Unit (ERU). Other emergency services also have limited CBRN expertise, such as the Health Service Executive (HSE) and Dublin Fire Brigade (DFB), which have a Hazardous Materials (Haz-Mat) and Chemical Incident Unit.",1
"The Malaysian Army formed a CBRN unit, Peperangan Nuklear, Biologi dan Kimia 3 Divisyen (English: Chemical, Biological and Nuclear Warfare Division 3; PNBK 3D) in April 2002.The Royal Malaysia Police has CBRN providers. The Pasukan Gerakan Khas (PGK) has two special operations detachments with HAZMAT expertise - 69 Commandos and Special Actions Unit. The Federal Reserve Unit (FRU) also has a CBRN unit. Both PGK and FRU teams handle CBRN calls before an army PNBK unit responds.",1
All members of the NZDF are trained in CBRN drills for deployment.,1
RNZN personnel conduct training with the NZ Army and RNZAF for any deployment or training.,1
The RNZAF conducted regular yearly training for all its personnel given the higher probability of airfields being the target of an enemy CBRN attack. RNZAF Security Forces personnel conduct all CBRN training for the RNZAF and complete CBRN courses at the Defence CBRN Centre in the United Kingdom.,1
The Spanish Army 1st CBRN Regiment 'Valencia' was formed in March 2005. Training in the defense against CBRN agents as part of combat support is the main aim of exercise 'Grifo' (Griffin) – the most important of this type that the Army undertakes. The National Police and the Spanish Civil Guard have their own CBRN units. The Military Emergencies Unit and emergency services have CBRN training.,1
"The Swedish Armed Forces has the National CBRN Defence Centre (designated SkyddC) localized in Umeå as its main CBRN protection forces. It consists of one company (1st CBRN-company) as the standing force, however, SkyddC is also responsible for training conscripts, training 60 in 2022-2023.",1
CBRN defense units in Turkey are the mainly CBRN Defense Battalion (Kimyasal Biyolojik Radyolojik Nükleer (KBRN) Savunma Tabur) of Turkish Armed Forces including CBRN Defense Special Response Unit (KBRN Savunma Özel Müdahale Birliği) and CBRN School and Training Center Command (KBRN Okul ve Eğitim Merkezi) Gendarmerie General Command has also unit within self Gendarmerie Search and Rescue Battalion Command has CBRN units. Ministry of the Interior's associated Disaster and Emergency Management Presidency AFAD Works in coordination with law enforcement units to intervene in the events of any CBRN accident.,1
"Apart from these, Turkey mostly makes its own CBRN protective clothing and equipment. Mechanical and Chemical Industry Corporation's Maksam factory mainly covers the needs of respirators for NATO and neighboring countries. Main products such as SR6 and SR6M NBC Respirator licensed United Kingdom production. MAKSAM Panoramic Mask MKE NEFES (breath) CBRN Gas Mask SR10 and SR10 ST Masks",1
"The Marine Corps runs a CBRN School to train Marine CBRN Defense Officers and Marine CBRN Defense Specialists at Fort Leonard Wood, Missouri. See also: Chemical Biological Incident Response Force (USMC CBIRF) The USN requires all personnel to take a web-based CBRNE training annually to get a basic understanding of facts and procedures related to responding to a CBRNE incident.",1
"The Nuclear, Biological and Chemical Protection Troops (NBC Protection Troops) of the Russian Federation are special forces designed to conduct the most complex set of measures aimed at reducing the loss of associations and formations of the Ground Forces and ensuring their combat tasks assigned during operations in conditions of radioactive, chemical and biological contamination, as well as at enhancing their survivability and protection against high-precision and other weapons.The Russian government vaccinated around half a million reindeer against anthrax in 2015. Around 1.5 million reindeer carcasses in Russian permafrost are at risk of melting due to global warming in the Arctic.",1
"A company is currently producing the capsules in a factory in Russia. Numbers vary, but news reports and market forecast reports place the market for CBRN products in 2013 and 2014 between US$8.7–8.8 billion. The market for CBRN products is expected to grow to over US$13 billion by 2023.",1
"Biological and Chemical Defence Review Committee (Canada) Biosecurity Bioterrorism Hazmat suit HazMat team List of CBRN warfare forces Overpressure (CBRN protection) NBC suit Poison gas in World War I Weapons of mass destruction Featured video of Singapore Army's Chemical, Biological and Radiological Defence Group on YouTube NCT CBRNe Asia 2013: Malaysian Army Demonstration on YouTube",1
"Many plants such as mustard plants, alpine pennycress, hemp, and pigweed have proven to be successful at hyperaccumulating contaminants at toxic waste sites. Not all plants are able to accumulate heavy metals or organics pollutants due to differences in the physiology of the plant. Even cultivars within the same species have varying abilities to accumulate pollutants.",1
"with plant-based systems of remediation, it is not possible to completely prevent the leaching of contaminants into the groundwater (without the complete removal of the contaminated ground, which in itself does not resolve the problem of contamination) the survival of the plants is affected by the toxicity of the contaminated land and the general condition of the soil bio-accumulation of contaminants, especially metals, into the plants can affect consumer products like food and cosmetics, and requires the safe disposal of the affected plant material when taking up heavy metals, sometimes the metal is bound to the soil organic matter, which makes",1
"After harvest, a lower level of the contaminant will remain in the soil, so the growth/harvest cycle must usually be repeated through several crops to achieve a significant cleanup. After the process, the soil is remediated.Of course many pollutants kill plants, so phytoremediation is not a panacea. For example, chromium is toxic to most higher plants at concentrations above 100 μM·kg−1 dry weight.Mining of these extracted metals through phytomining is a conceivable way of recovering the material. Hyperaccumulating plants are often metallophyte.",1
"Induced or assisted phytoextraction is a process where a conditioning fluid containing a chelator or another agent is added to soil to increase metal solubility or mobilization so that the plants can absorb them more easily. While such additives can increase metal uptake by plants, they can also lead to large amounts of available metals in the soil beyond what the plants are able to translocate, causing potential leaching into the subsoil or groundwater.Examples of plants that are known to accumulate the following contaminants: Arsenic, using the sunflower (Helianthus annuus), or the Chinese Brake fern (Pteris vittata).",1
"Caesium-137 and strontium-90 were removed from a pond using sunflowers after the Chernobyl accident. Mercury, selenium and organic pollutants such as polychlorinated biphenyls (PCBs) have been removed from soils by transgenic plants containing genes for bacterial enzymes. Thallium is sequestered by some plants.",1
"Phytostabilization reduces the mobility of substances in the environment, for example, by limiting the leaching of substances from the soil. It focuses on the long term stabilization and containment of the pollutant. The plant immobilizes the pollutants by binding them to soil particles making them less available for plant or human uptake. Unlike phytoextraction, phytostabilization focuses mainly on sequestering pollutants in soil near the roots but not in plant tissues. Pollutants become less bioavailable, resulting in reduced exposure. The plants can also excrete a substance that produces a chemical reaction, converting the heavy metal pollutant into a less toxic form.",1
"Stabilization results in reduced erosion, runoff, leaching, in addition to reducing the bioavailability of the contaminant. An example application of phytostabilization is using a vegetative cap to stabilize and contain mine tailings. Some soil amendments decrease radiosource mobility – while at some concentrations the same amendments will increase mobility. Vidal et al. 2000 find the root mats of meadow grasses are effective at demobilising radiosource materials especially with certain combinations of other agricultural practices. Vidal also find that the particular grass mix makes a significant difference.",1
"Whereas in the human liver enzymes such as cytochrome P450s are responsible for the initial reactions, in plants enzymes such as peroxidases, phenoloxidases, esterases and nitroreductases carry out the same role.In the second stage of phytotransformation, known as Phase II metabolism, plant biomolecules such as glucose and amino acids are added to the polarized xenobiotic to further increase the polarity (known as conjugation). This is again similar to the processes occurring in the human liver where glucuronidation (addition of glucose molecules by the UGT class of enzymes, e.g. UGT1A1) and glutathione addition reactions occur on reactive centres of the xenobiotic.Phase",1
"I and II reactions serve to increase the polarity and reduce the toxicity of the compounds, although many exceptions to the rule are seen. The increased polarity also allows for easy transport of the xenobiotic along aqueous channels.In the final stage of phytotransformation (Phase III metabolism), a sequestration of the xenobiotic occurs within the plant. The xenobiotics polymerize in a lignin-like manner and develop a complex structure that is sequestered in the plant. This ensures that the xenobiotic is safely stored, and does not affect the functioning of the plant.",1
"However, preliminary studies have shown that these plants can be toxic to small animals (such as snails), and, hence, plants involved in phytotransformation may need to be maintained in a closed enclosure.Hence, the plants reduce toxicity (with exceptions) and sequester the xenobiotics in phytotransformation. Trinitrotoluene phytotransformation has been extensively researched and a transformation pathway has been proposed.",1
"Phytostimulation (or rhizodegradation) is the enhancement of soil microbial activity for the degradation of organic contaminants, typically by organisms that associate with roots. This process occurs within the rhizosphere, which is the layer of soil that surrounds the roots. Plants release carbohydrates and acids that stimulate microorganism activity which results in the biodegradation of the organic contaminants. This means that the microorganisms are able to digest and break down the toxic substances into harmless form. Phytostimulation has been shown to be effective in degrading petroleum hydrocarbons, PCBs, and PAHs.",1
"Phytostimulation can also involve aquatic plants supporting active populations of microbial degraders, as in the stimulation of atrazine degradation by hornwort.",1
Poplar trees are one of the most successful plants for removing VOCs through this process due to its high transpiration rate.,1
"A plant is said to be a hyperaccumulator if it can concentrate the pollutants in a minimum percentage which varies according to the pollutant involved (for example: more than 1000 mg/kg of dry weight for nickel, copper, cobalt, chromium or lead; or more than 10,000 mg/kg for zinc or manganese). This capacity for accumulation is due to hypertolerance, or phytotolerance: the result of adaptative evolution from the plants to hostile environments through many generations.",1
"A number of interactions may be affected by metal hyperaccumulation, including protection, interferences with neighbour plants of different species, mutualism (including mycorrhizae, pollen and seed dispersal), commensalism, and biofilm.",1
"To ease field implementation of phytoscreening, standard methods have been developed to extract a section of the tree trunk for later laboratory analysis, often by using an increment borer. Phytoscreening may lead to more optimized site investigations and reduce contaminated site cleanup costs. Bioaugmentation Biodegradation Bioremediation Constructed wetland Mycorrhizal bioremediation Mycoremediation Phytotreatment ""Phytoremediation Website"" — Includes reviews, conference announcements, lists of companies doing phytoremediation, and bibliographies. Archived 2010-10-17 at the Wayback Machine ""An Overview of Phytoremediation of Lead and Mercury"" June 6 2000. The Hazardous Waste Clean-Up Information Web Site.",1
"Vassil AD, Kapulnik Y, Raskin I, Salt DE (June 1998), ""The Role of EDTA in Lead Transport and Accumulation by Indian Mustard"", Plant Physiol., 117 (2): 447–53, doi:10.1104/pp.117.2.447, PMC 34964, PMID 9625697. Salt, D. E.; Smith, R. D.; Raskin, I. (1998). ""Phytoremediation"". Annual Review of Plant Physiology and Plant Molecular Biology. 49: 643–668. doi:10.1146/annurev.arplant.49.1.643. PMID 15012249. S2CID 241195507. Wang, X. J.; Li, F. Y.; Okazaki, M.; Sugisaki, M. (2003). ""Phytoremediation of contaminated soil"". Annual Report CESS. 3: 114–123. Ancona, V; Barra Caracciolo, A; Grenni, P; Di Lenola, M; Campanale, C; Calabrese, A; Uricchio, VF; Mascolo, G; Massacci, A (2017).",1
"do not easily break down or degrade, which made them attractive for industries. PCB mixtures are resistant to acids, bases, oxidation, hydrolysis, and temperature change. They can generate extremely toxic dibenzodioxins and dibenzofurans through partial oxidation. Intentional degradation as a treatment of unwanted PCBs generally requires high heat or catalysis (see Methods of destruction below). PCBs readily penetrate skin, PVC (polyvinyl chloride), and latex (natural rubber). PCB-resistant materials include Viton, polyethylene, polyvinyl acetate (PVA), polytetrafluoroethylene (PTFE), butyl rubber, nitrile rubber, and Neoprene.",1
"In terms of their structure and toxicity, PCBs fall into two distinct categories, referred to as coplanar or non-ortho-substituted arene substitution patterns and noncoplanar or ortho-substituted congeners. Coplanar or non-ortho The coplanar group members have a fairly rigid structure, with their two phenyl rings in the same plane. It renders their structure similar to polychlorinated dibenzo-p-dioxins (PCDDs) and polychlorinated dibenzofurans, and allows them to act like PCDDs, as an agonist of the aryl hydrocarbon receptor (AhR) in organisms.",1
"Because of their lower overt toxicity, they have typically been of lesser concern to regulatory bodies.Di-ortho-substituted, non-coplanar PCBs interfere with intracellular signal transduction dependent on calcium which may lead to neurotoxicity. ortho-PCBs can disrupt thyroid hormone transport by binding to transthyretin. Commercial PCB mixtures were marketed under the following names:",1
"The only North American producer, Monsanto Company, marketed PCBs under the trade name Aroclor from 1930 to 1977. These were sold under trade names followed by a four-digit number. In general, the first two digits refer to the product series as designated by Monsanto (e.g. 1200 or 1100 series); the second two numbers indicate the percentage of chlorine by mass in the mixture. Thus, Aroclor 1260 is a 1200 series product and contains 60% chlorine by mass.",1
"It is a myth that the first two digits referred to the number of carbon atoms; the number of carbon atoms do not change in PCBs. The 1100 series was a crude PCB material which was distilled to create the 1200 series PCB product.The exception to the naming system is Aroclor 1016 which was produced by distilling 1242 to remove the highly chlorinated congeners to make a more biodegradable product. ""1016"" was given to this product during Monsanto's research stage for tracking purposes but the name stuck after it was commercialized.",1
"Another estimate put the total global production of PCBs on the order of 1.5 million tonnes. The United States was the single largest producer with over 600,000 tonnes produced between 1930 and 1977. The European region follows with nearly 450,000 tonnes through 1984. It is unlikely that a full inventory of global PCB production will ever be accurately tallied, as there were factories in Poland, East Germany, and Austria that produced unknown amounts of PCBs. There are still 21,500 tons of PCBs stored in the easternmost regions of Slovakia.",1
"A small volume of PCBs has been detected throughout the earth's atmosphere. The atmosphere serves as the primary route for global transport of PCBs, particularly for those congeners with one to four chlorine atoms.In the atmosphere, PCBs may be degraded by hydroxyl radicals, or directly by photolysis of carbon–chlorine bonds (even if this is a less important process).Atmospheric concentrations of PCBs tend to be lowest in rural areas, where they are typically in the picogram per cubic meter range, higher in suburban and urban areas, and highest in city centres, where they can reach 1 ng/m3 or more.",1
"In the biosphere, PCBs can be degraded by the sun, bacteria or eukaryotes, but the speed of the reaction depends on both the number and the disposition of chlorine atoms in the molecule: less substituted, meta- or para-substituted PCBs undergo biodegradation faster than more substituted congeners.In bacteria, PCBs may be dechlorinated through reductive dechlorination, or oxidized by dioxygenase enzyme. In eukaryotes, PCBs may be oxidized by the cytochrome P450 enzyme. Like many lipophilic toxins, PCBs undergo biomagnification and bioaccumulation primarily due to the fact that they are easily retained within organisms.Plastic",1
"PCB concentrations within an organism also change depending upon which trophic level they occupy. When an organism occupies a high trophic level, like orcas or humans, they will accumulate more PCBs than an organism that occupies a low trophic level, like phytoplankton. If enough organisms with a trophic level are killed due to the accumulation of toxins, like PCB, a trophic cascade can occur. PCBs can cause harm to human health or even death when eaten. PCBs can be transported by birds from aquatic sources onto land via feces and carcasses.",1
"PCBs containing ortho–meta and meta–para protons can be metabolized by either enzyme, making them the most likely to leave the organism. However, some metabolites of PCBs containing ortho–meta protons have increased steric hindrance from the oxygen, causing increased stability and an increased chance of accumulation.",1
"Metabolism is also dependent on the species of organism; different organisms have slightly different P450 enzymes that metabolize certain PCBs better than others. Looking at the PCB metabolism in the liver of four sea turtle species (green, olive ridley, loggerhead and hawksbill), green and hawksbill sea turtles have noticeably higher hydroxylation rates of PCB 52 than olive ridley or loggerhead sea turtles. This is because the green and hawksbill sea turtles have higher P450 2-like protein expression. This protein adds three hydroxyl groups to PCB 52, making it more polar and water-soluble.",1
"P450 3-like protein expression that is thought to be linked to PCB 77 metabolism, something that was not measured in this study.",1
"The excretion rate of PCBs matched with the perch's natural bioenergetics, where most of their consumption, respiration and growth rates occur during the late spring and summer. Since the perch is performing more functions in the warmer months, it naturally has a faster metabolism and has less PCB accumulation. However, multiple cold-water periods mixed with toxic PCBs with coplanar chlorine molecules can be detrimental to perch health.",1
"Enantiomers of chiral compounds have similar chemical and physical properties, but can be metabolized by the body differently. This was looked at in bowhead whales (Balaena mysticetus) for two main reasons: they are large animals with slow metabolisms (meaning PCBs will accumulate in fatty tissue) and few studies have measured chiral PCBs in cetaceans. They found that the average PCB concentrations in the blubber were approximately four times higher than the liver; however, this result is most likely age- and sex-dependent.",1
"As reproductively active females transferred PCBs and other poisonous substances to the fetus, the PCB concentrations in the blubber were significantly lower than males of the same body length (less than 13 meters). The toxicity of PCBs varies considerably among congeners. The coplanar PCBs, known as nonortho PCBs because they are not substituted at the ring positions ortho to (next to) the other ring, (such as PCBs 77, 126 and 169), tend to have dioxin-like properties, and generally are among the most toxic congeners.",1
"High exposure to PCBs can cause birth defects, developmental delays, and liver changes.""",1
Human infants are exposed to PCBs through breast milk or by intrauterine exposure through transplacental transfer of PCBs and are at the top of the food chain.: 249ff Workers recycling old equipment in the electronics recycling industry can also be exposed to PCBs.,1
"Other symptoms included fatigue, headaches, coughs, and unusual skin sores. Additionally, in children, there were reports of poor cognitive development. Women exposed to PCBs before or during pregnancy can give birth to children with lowered cognitive ability, immune compromise, and motor control problems.There is evidence that crash dieters that have been exposed to PCBs have an elevated risk of health complications. Stored PCBs in the adipose tissue become mobilized into the blood when individuals begin to crash diet.PCBs have shown toxic and mutagenic effects by interfering with hormones in the body.",1
"PCBs, depending on the specific congener, have been shown to both inhibit and imitate estradiol, the main sex hormone in females. Imitation of the estrogen compound can feed estrogen-dependent breast cancer cells, and possibly cause other cancers, such as uterine or cervical. Inhibition of estradiol can lead to serious developmental problems for both males and females, including sexual, skeletal, and mental development issues. In a cross-sectional study, PCBs were found to be negatively associated with testosterone levels in adolescent boys.High",1
"PCB levels in adults have been shown to result in reduced levels of the thyroid hormone triiodothyronine, which affects almost every physiological process in the body, including growth and development, metabolism, body temperature, and heart rate. It also resulted in reduced immunity and increased thyroid disorders.",1
"Animals that eat PCB-contaminated food, even for short periods of time, suffer liver damage and may die. In 1968 in Japan, 400,000 birds died after eating poultry feed that was contaminated with PCBs. Animals that ingest smaller amounts of PCBs in food over several weeks or months develop various health effects, including anemia; acne-like skin conditions (chloracne); liver, stomach, and thyroid gland injuries (including hepatocarcinoma), and thymocyte apoptosis. Other effects of PCBs in animals include changes in the immune system, behavioral alterations, and impaired reproduction. PCBs that have dioxin-like activity are known to cause a variety of teratogenic effects in animals.",1
Exposure to PCBs causes hearing loss and symptoms similar to hypothyroidism in rats.,1
"In 2013, the International Agency for Research on Cancer (IARC) classified dioxin-like PCBs as human carcinogens. According to the U.S. EPA, PCBs have been shown to cause cancer in animals and evidence supports a cancer-causing effect in humans. Per the EPA, studies have found increases in malignant melanoma and rare liver cancers in PCB workers.In 2013, the IARC determined that the evidence for PCBs causing non-Hodgkin lymphoma is ""limited"" and ""not consistent"". In contrast an association between elevated blood levels of PCBs and non-Hodgkin lymphoma had been previously accepted.",1
"2003, Monsanto and Solutia Inc., a Monsanto corporate spin-off, reached a $700 million settlement with the residents of West Anniston, Alabama, who had been affected by the manufacturing and dumping of PCBs. In a trial lasting six weeks, the jury found that ""Monsanto had engaged in outrageous behavior, and held the corporations and its corporate successors liable on all six counts it considered – including negligence, nuisance, wantonness and suppression of the truth.[i",1
"dont think that's a real charge]""In 2014, the Los Angeles Superior Court found that Monsanto was not liable for cancers claimed to be from PCBs permeating the food supply of three plaintiffs who had developed non-Hodgkin's lymphoma. After a four-week trial, the jury found that Monsanto's production and sale of PCBs between 1935 and 1977 were not substantial causes of the cancer.In 2015, the cities of Spokane, San Diego, and San Jose initiated lawsuits against Monsanto to recover cleanup costs for PCB contaminated sites, alleging that Monsanto continued to sell PCBs without adequate warnings after they knew of their toxicity.",1
"In March 2018 Ohio Attorney General Mike DeWine also filed a lawsuit against Monsanto over health issues posed by PCBs.On November 21, 2019, a federal judge denied a bid by Monsanto to dismiss a lawsuit filed by LA County calling the company to clean up cancer-causing PCBs from Los Angeles County waterways and storm sewer pipelines. The lawsuit calls for Monsanto to pay for cleanup of PCBs from dozens of waterways, including the LA River, San Gabriel River and the Dominguez Watershed.In",1
"Years later in 1876, German chemist Oscar Döbner (Doebner) synthesized the first PCB in a laboratory. Since then, large amounts of PCBs were released into the environment, to the extent that there are even measurable amounts of PCBs in feathers of birds currently held in museums before the production of PCBs peaked.In 1935, Monsanto Chemical Company (now Solutia Inc) took over commercial production of PCBs from Swann Chemical Company which had begun in 1929. PCBs, originally termed ""chlorinated diphenyls"", were commercially produced as mixtures of isomers at different degrees of chlorination.",1
"Public health Service official described the wife and child of a worker from the Monsanto Industrial Chemical Company who exhibited blackheads and pustules on their skin. The official attributed these symptoms to contact with the worker's clothing after he returned from work. In 1937, a conference about the hazards was organized at Harvard School of Public Health, and a number of publications referring to the toxicity of various chlorinated hydrocarbons were published before 1940.In 1947, Robert Brown reminded chemists that Arochlors were ""objectionably toxic"": ""Thus the maximum permissible concentration for an 8-hr. day is 1 mg. per cu.m. [1.0",1
"There have been allegations that Industrial Bio-Test Laboratories engaged in data falsification in testing relating to PCBs. In 2003, Monsanto and Solutia Inc., a Monsanto corporate spinoff, reached a US$700 million settlement with the residents of West Anniston, Alabama who had been affected by the manufacturing and dumping of PCBs. In a trial lasting six weeks, the jury found that ""Monsanto had engaged in outrageous behavior, and held the corporations and its corporate successors liable on all six counts it considered – including negligence, nuisance, wantonness and suppression of the truth.""Existing",1
"PCBs entered the human food supply by animals grazing on contaminated pastures near the factory, especially in local veal mostly eaten by farmers' families. The exposed population showed an elevated risk of Non-Hodgkin lymphoma, but not for other specific cancers.",1
"The chemical plant Chemko in Strážske (east Slovakia) was an important producer of polychlorinated biphenyls for the former communist bloc (Comecon) until 1984. Chemko contaminated a large part of east Slovakia, especially the sediments of the Laborec river and reservoir Zemplínska šírava.",1
"Several cetacean species have very high mean blubber PCB concentrations likely to cause population declines and suppress population recovery. Striped dolphins, bottlenose dolphins and orcas were found to have mean levels that markedly exceeded all known marine mammal PCB toxicity thresholds. The western Mediterranean Sea and the south-west Iberian Peninsula were identified as ""hotspots"".",1
"Monsanto was the only company that manufactured PCBs in the US. Its production was entirely halted in 1977. (Kimbrough, 1987, 1995) On November 25, 2020, U.S. District Judge Fernando M. Olguin rejected a proposed $650 million settlement from Bayer, the company which acquired Monsanto in 2018, and allowed Monsanto-related lawsuits involving PCB to proceed.",1
"In 1976, environmentalists found PCBs in the sludge at Waukegan Harbor, the southwest end of Lake Michigan. They were able to trace the source of the PCBs back to the Outboard Marine Corporation that was producing boat motors next to the harbor. By 1982, the Outboard Marine Corporation was court-ordered to release quantitative data referring to their PCB waste released. The data stated that from 1954 they released 100,000 tons of PCB into the environment, and that the sludge contained PCBs in concentrations as high as 50%.In",1
"1989, during construction near the Zilwaukee bridge, workers uncovered an uncharted landfill containing PCB-contaminated waste which required $100,000 to clean up.Much of the Great Lakes area were still heavily polluted with PCBs in 1988, despite extensive remediation work.",1
"Because of public opposition to the incinerator, however, the State of Indiana passed a number of laws that delayed and blocked its construction. The parties to the consent decree began to explore alternative remedies in 1994 for six of the main PCB contaminated sites in the consent decree. Hundreds of sites remain unaddressed as of 2014. Monroe County will never be PCB-free, as noted in a 2014 Indiana University program about the local contamination.On February 15, 2008, Monroe County approved a plan to clean up the three remaining contaminated sites in the City of Bloomington, at a cost of $9.6",1
"million to CBS Corp., the successor of Westinghouse. In 1999, Viacom bought CBS, so they are current responsible party for the PCB sites.",1
"Fish and waterfowl who live in and around the river contain significant levels of PCBs and are not safe to eat. EPA designated the Pittsfield plant and several miles of the river as a Superfund site in 1997, and ordered GE to remediate the site. EPA and GE began a cleanup of the area in 1999.New Bedford Harbor, which is a listed Superfund site, contained some of the highest sediment concentrations of PCBs in the marine environment. Cleanup of the area began in 1994 and is mostly complete as of 2020.Investigations",1
"into historic waste dumping in the Bliss Corner neighborhood have revealed the existence of PCBs, among other hazardous materials, buried into soil and waste material.",1
"In 1982, Martha C. Rose Chemical Inc. began processing and disposing of materials contaminated with PCBs in Holden, Missouri, a small rural community about 40 miles (64 km) east of Kansas City. From 1982 until 1986, nearly 750 companies, including General Motors Corp., Commonwealth Edison, Illinois Power Co. and West Texas Utilities, sent millions of pounds of PCB contaminated materials to Holden for disposal. Instead, according to prosecutors, the company began storing the contaminated materials while falsifying its reports to the EPA to show they had been removed.",1
"Most of the surface debris, including close to 13 million pounds of contaminated equipment, carcasses and tanks of contaminated oil, had to be removed. Walter C. Carolan, owner of Rose Chemical, and five others pleaded guilty in 1989 to committing fraud or falsifying documents. Carolan and two other executives served sentences of less than 18 months; the others received fines and were placed on probation. Cleanup costs at the site are estimated at $35 million.",1
"In 1981, a transformer explosion in the basement spewed PCBs throughout the entire 18-story building. The contamination was so severe that cleanup efforts kept the building closed for 13 years.",1
"One of the largest deliberate PCB spills in American history occurred in the summer of 1978 when 31,000 gallons (117 m^3) of PCB-contaminated oil were illegally sprayed by the Ward PCB Transformer Company in 3-foot (0.91 m) swaths along the roadsides of some 240 miles (390 km) of North Carolina highway shoulders in 14 counties and at the Fort Bragg Army Base. The crime, known as ""the midnight dumpings"", occurred over nearly 2 weeks, as drivers of a black-painted tanker truck drove down one side of rural Piedmont highways spraying PCB-laden waste and then up the other side the following night.Under",1
"Governor James B. Hunt, Jr., state officials then erected large, yellow warning signs along the contaminated highways that read: ""CAUTION: PCB Chemical Spills Along Highway Shoulders"". The illegal dumping is believed to have been motivated by the passing of the Toxic Substances Control Act (TSCA), which became effective on August 2, 1978, and increased the expense of chemical waste disposal. Within a couple of weeks of the crime, Robert Burns and his sons, Timothy and Randall, were arrested for dumping the PCBs along the roadsides. Burns was a business partner of Robert ""Buck"" Ward, Jr.,",1
"of the Ward PCB Transformer Company, in Raleigh. Burns and sons pleaded guilty to state and Federal criminal charges; Burns received a three to five-year prison sentence. Ward was acquitted of state charges in the dumping, but was sentenced to 18 months prison time for violation of TSCA.Cleanup and disposal of the roadside PCBs generated controversy, as the Governor's plan to pick up the roadside PCBs and to bury them in a landfill in rural Warren County were strongly opposed in 1982 by local residents.",1
"Spokane utilities will spend $300 million to prevent PCBs from entering the river in anticipation of a 2017 federal deadline to do so. In August 2015 Spokane joined other U.S cities like San Diego and San Jose, California, and Westport, Massachusetts, in seeking damages from Monsanto.",1
"From 1954 until 1971, the Fox River in Appleton, Wisconsin, had PCBs deposited into it from Appleton Paper/NCR, P.H. Gladfelter, Georgia-Pacific and other notable local paper manufacturing facilities. The Wisconsin DNR estimates that after wastewater treatment the PCB discharges to the Fox River due to production losses ranged from 81,000 kg to 138,000 kg. (178,572 lbs. to 304,235 lbs). The production of Carbon Copy Paper and its byproducts led to the discharge into the river. Fox River clean up is ongoing.",1
"Polychlorinated biphenyls have been discovered in organisms living in the Mariana trench in the Pacific Ocean. Levels were as high as 1,900 nanograms per gram of amphipod tissue in the organisms analyzed.",1
"In 1981, the UK banned closed uses of PCBs in new equipment, and nearly all UK PCB synthesis ceased; closed uses in existing equipment containing in excess of 5 litres of PCBs were not stopped until December 2000.",1
"PCBs are fairly chemically unreactive, this property being attractive for its application as an inert material. They resist oxidation. Many chemical compounds are available to destroy or reduce the PCBs. Commonly, PCBs are degraded by basic mixtures of glycols, which displace some or all chloride. Also effective are reductants such as sodium or sodium naphthalene. Vitamin B12 has also shown promise.",1
"This allows for U. rigida to uptake large amounts of PCB from the sediment with concentrations of PCB in U. rigida reaching 1580 μg kg−1 within 24 hours of the bloom. Live tissue tended to take up higher concentrations of PCB than dead tissue, but this is not to say that dead tissue did not still take up large amounts of PCB as well. For a complete list of the 209 PCB congeners, see PCB congener list. Note that biphenyl, while not technically a PCB congener because of its lack of chlorine substituents, is still typically included in the literature.",1
"Bay mud Organochlorine compound Polybrominated biphenyl Zodiac, a novel by Neal Stephenson which involves PCBs and their impact on the environment. ATSDR Toxicological Profile U.S. Department of Health and Human Services IARC PCB Monograph PCBs – US EPA National Toxicology Program technical reports searched for ""PCB"" Polychlorinated Byphenyls: Human Health Aspects by the WHO Current Intelligence Bulletin 7: Polychlorinated (PCBs)—NIOSH/CDC (1975) It's Your Health – PCBs (Health Canada)",1
"Space debris began to accumulate in Earth orbit immediately with the first launch of an artificial satellite Sputnik 1 into orbit in October 1957. But even before that humans might have produced ejecta that became space debris, as in the August 1957 Pascal B test. Going back even earlier, there was natural ejecta from Earth in orbit. After the launch of Sputnik, the North American Aerospace Defense Command (NORAD) began compiling a database (the Space Object Catalog) of all known rocket launches and objects reaching orbit: satellites, protective shields and upper-stages of launch vehicles.",1
"NASA later published modified versions of the database in two-line element set, and beginning in the early 1980s the CelesTrak bulletin board system re-published them. The trackers (NORAD) who fed the database were aware of other objects in orbit, many of which were the result of in-orbit explosions. Some were deliberately caused during the 1960s anti-satellite weapon (ASAT) testing, and others were the result of rocket stages blowing up in orbit as leftover propellant expanded and ruptured their tanks. To improve tracking, NORAD employee John Gabbard kept a more detailed database of as many objects as he could identify.Studying",1
"In addition to approaches to debris reduction where time and natural gravitational/atmospheric effects help to clear space debris, or a variety of technological approaches that have been proposed (with most not implemented) to reduce space debris, a number of scholars have observed that institutional factors – political, legal, economic, and cultural ""rules of the game"" – are the greatest impediment to the cleanup of near-Earth space.",1
"By 2014, there was little commercial incentive to reduce space debris, since the cost of dealing with it is not assigned to the entity producing it, but rather falls on all users of the space environment, and rely on human society as a whole that benefits from space technologies and knowledge. A number of suggestions for improving institutions so as to increase the incentives to reduce space debris have been made. These include government mandates to create incentives, as well as companies coming to see economic benefit to reducing debris more aggressively than existing government standard practices.",1
In 1979 NASA founded the Orbital Debris Program to research mitigation measures for space debris in Earth orbit.,1
"During the 1980s, NASA and other U.S. groups attempted to limit the growth of debris. One trial solution was implemented by McDonnell Douglas in 1981 for the Delta launch vehicle by having the booster move away from its payload and vent any propellant remaining in its tanks. This eliminated one source for pressure buildup in the tanks which had previously caused them to explode and create additional orbital debris. Other countries were slower to adopt this measure and, due especially to a number of launches by the Soviet Union, the problem grew throughout the decade.A",1
"new battery of studies followed as NASA, NORAD, and others attempted to better understand the orbital environment, with each adjusting the number of pieces of debris in the critical-mass zone upward. Although in 1981 (when Schefter's article was published) the number of objects was estimated at 5,000, new detectors in the Ground-based Electro-Optical Deep Space Surveillance system found new objects. By the late 1990s, it was thought that most of the 28,000 launched objects had already decayed and about 8,500 remained in orbit.",1
"By 2005 this was adjusted upward to 13,000 objects, and a 2006 study increased the number to 19,000 as a result of an ASAT and a satellite collision. In 2011, NASA said that 22,000 objects were being tracked.A 2006 NASA model suggested that if no new launches took place the environment would retain the then-known population until about 2055, when it would increase on its own. Richard Crowther of Britain's Defence Evaluation and Research Agency said in 2002 that he believed the cascade would begin about 2015.",1
"National Research Council warned NASA that the amount of orbiting space debris was at a critical level. According to some computer models, the amount of space debris ""has reached a tipping point, with enough currently in orbit to continually collide and create even more debris, raising the risk of spacecraft failures."" The report called for international regulations limiting debris and research of disposal methods.",1
"By mid-1994 there had been 68 breakups or debris ""anomalous events"" involving satellites launched by the former Soviet Union/Russia and 18 similar events had been discovered involving rocket bodies and other propulsion-related operational debris. As of 2009, 19,000 debris over 5 cm (2 in) were tracked by United States Space Surveillance Network. As of July 2013, estimates of more than 170 million debris smaller than 1 cm (0.4 in), about 670,000 debris 1–10 cm, and approximately 29,000 larger pieces of debris are in orbit. As of July 2016, nearly 18,000 artificial objects are orbiting above Earth, including 1,419 operational satellites.",1
"As of October 2019, nearly 20,000 artificial objects in orbit above the Earth, including 2,218 operational satellites.",1
"As of January 2019 there were estimated to be over 128 million pieces of debris smaller than 1 cm (0.39 in), and approximately 900,000 pieces between 1 and 10 cm. The count of large debris (defined as 10 cm across or larger) was 34,000 in 2019, and at least 37,000 by June 2023. The technical measurement cut-off is c. 3 mm (0.12 in).As of 2020, there were 8,000 metric tons of debris in orbit, a figure that is expected to increase.",1
"Traditionally, the most populated LEO orbits have been a number of sun-synchronous satellites that keep a constant angle between the Sun and the orbital plane, making Earth observation easier with consistent sun angle and lighting. Sun-synchronous orbits are polar, meaning they cross over the polar regions. LEO satellites orbit in many planes, typically up to 15 times a day, causing frequent approaches between objects. The density of satellites – both active and derelict – is much higher in LEO.Orbits",1
"are affected by gravitational perturbations (which in LEO include unevenness of the Earth's gravitational field due to variations in the density of the planet), and collisions can occur from any direction. The average impact speed of collisions in Low Earth Orbit is 10 km/s with maximums reaching above 14 km/s due to orbital eccentricity. The 2009 satellite collision occurred at a closing speed of 11.7 km/s (26,000 mph), creating over 2,000 large debris fragments. These debris cross many other orbits and increase debris collision risk.",1
The upper atmosphere is not a fixed density at any particular orbital altitude; it varies as a result of atmospheric tides and expands or contracts over longer time periods as a result of space weather. These longer-term effects can increase drag at lower altitudes; the 1990s expansion was a factor in reduced debris density. Another factor was fewer launches by Russia; the Soviet Union made most of their launches in the 1970s and 1980s.: 7,1
"Although velocities are low between GEO objects, when a satellite becomes derelict (such as Telstar 401) it assumes a geosynchronous orbit; its orbital inclination increases about .8° and its speed increases about 160 km/h (99 mph) per year. Impact velocity peaks at about 1.5 km/s (0.93 mi/s). Orbital perturbations cause longitude drift of the inoperable spacecraft and precession of the orbital plane. Close approaches (within 50 meters) are estimated at one per year. The collision debris pose less short-term risk than from an LEO collision, but the satellite would likely become inoperable.",1
"Large objects, such as solar-power satellites, are especially vulnerable to collisions.Although the ITU now requires proof a satellite can be moved out of its orbital slot at the end of its lifespan, studies suggest this is insufficient. Since GEO orbit is too distant to accurately measure objects under 1 m (3 ft 3 in), the nature of the problem is not well known. Satellites could be moved to empty spots in GEO, requiring less maneuvering and making it easier to predict future motion.",1
"Satellites or boosters in other orbits, especially stranded in geostationary transfer orbit, are an additional concern due to their typically high crossing velocity. Despite efforts to reduce risk, spacecraft collisions have occurred. The European Space Agency telecom satellite Olympus-1 was struck by a meteoroid on 11 August 1993 and eventually moved to a graveyard orbit. On 29 March 2006, the Russian Express-AM11 communications satellite was struck by an unknown object and rendered inoperable; its engineers had enough contact time with the satellite to send it into a graveyard orbit.",1
"In 1958, the United States of America had launched Vanguard I into a medium Earth orbit (MEO). As of October 2009, it, the upper stage of Vanguard 1's launch rocket and associated piece of debris, are the oldest surviving artificial space objects still in orbit and are expected to be until after the year 2250. As of May 2022, the Union of Concerned Scientists listed 5,465 operational satellites from a known population of 27,000 pieces of orbital debris tracked by NORAD.Occasionally",1
"In February 2015, for example, the USAF Defense Meteorological Satellite Program Flight 13 (DMSP-F13) exploded on orbit, creating at least 149 debris objects, which were expected to remain in orbit for decades. Later that same year, NOAA-16 which had been decommissioned after an anomaly in June 2014, broke apart on orbit into at least 275 pieces. For older programs, such as the Soviet-era Meteor 2 and Kosmos satellites, design flaws resulted in numerous break-ups – at least 68 by 1994 – following decommissioning, resulting in more debris.In",1
"addition to the accidental creation of debris, some has been made intentionally through the deliberate destruction of satellites. This has been done as a test of anti-satellite or anti-ballistic missile technology, or to prevent a sensitive satellite from being examined by a foreign power. The United States has conducted over 30 anti-satellite weapons tests (ASATs), the Soviet Union/Russia has performed at least 27, China has performed 10 and India has performed at least one.",1
"The most recent ASATs were the Chinese interception of FY-1C, Russian trials of its PL-19 Nudol, the American interception of USA-193 and India's interception of an unstated live satellite.",1
"Space debris includes a glove lost by astronaut Ed White on the first American space-walk (EVA), a camera lost by Michael Collins near Gemini 10, a thermal blanket lost during STS-88, garbage bags jettisoned by Soviet cosmonauts during Mir's 15-year life, a wrench, and a toothbrush. Sunita Williams of STS-116 lost a camera during an EVA. During an STS-120 EVA to reinforce a torn solar panel, a pair of pliers was lost, and in an STS-126 EVA, Heidemarie Stefanyshyn-Piper lost a briefcase-sized tool bag.",1
"Rocket upper stages which end up in orbit are a significant source of space debris. In characterizing the problem of space debris, it was learned that much debris was due to rocket upper stages (e.g. the Inertial Upper Stage) which end up in orbit, and break up due to decomposition of unvented unburned fuel. The first such instance involved the launch of the Transit-4a satellite in 1961. Two hours after insertion the Ablestar upper stage exploded. But even boosters that don't break apart can be a problem as a major known impact event involved an (intact) Ariane booster.:",1
"Although the explosion was captured on film by astronomers, due to the orbit path the debris cloud has been difficult to measure with radar. By 21 February 2007, over 1,000 fragments were identified. A 14 February 2007 breakup was recorded by Celestrak. Another Briz-M broke up on 16 October 2012 after a failed 6 August Proton-M launch. The amount and size of the debris was unknown.",1
"Starting in 1981, depletion burns – to get rid of excess propellant – became standard and no Delta Rocket Bodies launched after 1981 experience severe fragmentations afterward, but some of those launched prior to 1981 continued to explode. In 1991, the Delta 1975-052B fragmented, 16 years after launch, demonstrating the resilience of the propellent.",1
"A past debris source was the testing of anti-satellite weapons (ASATs) by the U.S. and Soviet Union during the 1960s and 1970s. North American Aerospace Defense Command (NORAD) files only contained data for Soviet tests, and debris from U.S. tests were only identified later. By the time the debris problem was understood, widespread ASAT testing had ended; the U.S. Program 437 was shut down in 1975.The U.S. restarted their ASAT programs in the 1980s with the Vought ASM-135 ASAT.",1
"A 1985 test destroyed a 1-tonne (2,200 lb) satellite orbiting at 525 km (326 mi), creating thousands of debris larger than 1 cm (0.39 in). Due to the altitude, atmospheric drag decayed the orbit of most debris within a decade. A de facto moratorium followed the test. China's government was condemned for the military implications and the amount of debris from the 2007 anti-satellite missile test, the largest single space debris incident in history (creating over 2,300 pieces golf-ball size or larger, over 35,000 1 cm (0.4 in) or larger, and one million pieces 1 mm (0.04 in) or larger).",1
"launched an SM-3 missile from the USS Lake Erie to destroy a defective U.S. spy satellite thought to be carrying 450 kg (1,000 lb) of toxic hydrazine propellant. The event occurred at about 250 km (155 mi), and the resulting debris has a perigee of 250 km (155 mi) or lower. The missile was aimed to minimize the amount of debris, which (according to Pentagon Strategic Command chief Kevin Chilton) had decayed by early 2009.On 27 March 2019, Indian Prime Minister Narendra Modi announced that India shot down one of its own LEO satellites with a ground-based missile.",1
"vulnerability of satellites to debris and the possibility of attacking LEO satellites to create debris clouds has triggered speculation that it is possible for countries unable to make a precision attack. An attack on a satellite of 10 t (22,000 lb) or more would heavily damage the LEO environment.",1
"Space junk can be a hazard to active satellites and spacecraft. It has been theorized that Earth orbit could even become impassable if the risk of collision grows too high.However, since the risk to spacecraft increases with exposure to high debris densities, it is more accurate to say that LEO would be rendered unusable by orbiting craft. The threat to craft passing through LEO to reach a higher orbit would be much lower owing to the very short time span of the crossing.",1
"Although spacecraft are typically protected by Whipple shields, solar panels, which are exposed to the Sun, wear from low-mass impacts. Even small impacts can produce a cloud of plasma which is an electrical risk to the panels.Satellites are believed to have been destroyed by micrometeorites and (small) orbital debris (MMOD). The earliest suspected loss was of Kosmos 1275, which disappeared on 24 July 1981 (a month after launch). Kosmos contained no volatile fuel, therefore, there appeared to be nothing internal to the satellite which could have caused the destructive explosion which took place.",1
"However, the case has not been proven and another hypothesis forwarded is that the battery exploded. Tracking showed it broke up, into 300 new objects.Many impacts have been confirmed since. For example, on 24 July 1996, the French microsatellite Cerise was hit by fragments of an Ariane-1 H-10 upper-stage booster which exploded in November 1986.: 2 On 29 March 2006, the Russian Ekspress AM11 communications satellite was struck by an unknown object and rendered inoperable.",1
"first major satellite collision occurred on 10 February 2009. The 950 kg (2,090 lb) derelict satellite Kosmos 2251 and the operational 560 kg (1,230 lb) Iridium 33 collided, 500 mi (800 km) over northern Siberia. The relative speed of impact was about 11.7 km/s (7.3 mi/s), or about 42,120 km/h (26,170 mph). Both satellites were destroyed, creating thousands of pieces of new smaller debris, with legal and political liability issues unresolved even years later.",1
"On 22 January 2013, BLITS (a Russian laser-ranging satellite) was struck by debris suspected to be from the 2007 Chinese anti-satellite missile test, changing both its orbit and rotation rate.Satellites sometimes perform Collision Avoidance Maneuvers and satellite operators may monitor space debris as part of maneuver planning. For example, in January 2017, the European Space Agency made the decision to alter orbit of one of its three Swarm mission spacecraft, based on data from the US Joint Space Operations Center, to lower the risk of collision from Cosmos-375, a derelict Russian satellite.",1
"Crewed flights are naturally particularly sensitive to the hazards that could be presented by space debris conjunctions in the orbital path of the spacecraft. Examples of occasional avoidance maneuvers, or longer-term space debris wear, have occurred in Space Shuttle missions, the MIR space station, and the International Space Station.",1
"A NASA 2005 study concluded that debris accounted for approximately half of the overall risk to the Shuttle. Executive-level decision to proceed was required if the catastrophic impact was likelier than 1 in 200. On a normal (low-orbit) mission to the ISS, the risk was approximately 1 in 300, but the Hubble telescope repair mission was flown at the higher orbital altitude of 560 km (350 mi) where the risk was initially calculated at a 1-in-185 (due in part to the 2009 satellite collision).",1
"A re-analysis with better debris numbers reduced the estimated risk to 1 in 221, and the mission went ahead.Debris incidents continued on later Shuttle missions. During STS-115 in 2006 a fragment of circuit board bored a small hole through the radiator panels in Atlantis's cargo bay. On STS-118 in 2007 debris blew a bullet-like hole through Endeavour's radiator panel.",1
"Impact wear was notable on Mir, the Soviet space station since it remained in space for long periods with its original solar module panels.",1
"The ISS also uses Whipple shielding to protect its interior from minor debris. However, exterior portions (notably its solar panels) cannot be protected easily. In 1989, the ISS panels were predicted to degrade approximately 0.23% in four years due to the ""sandblasting"" effect of impacts with small orbital debris. An avoidance maneuver is typically performed for the ISS if ""there is a greater than one-in-10,000 chance of a debris strike"". As of January 2014, there have been sixteen maneuvers in the fifteen years the ISS had been in orbit.",1
"By 2019, over 1,400 meteoroid and orbital debris (MMOD) impacts had been recorded on the ISS.As another method to reduce the risk to humans on board, ISS operational management asked the crew to shelter in the Soyuz on three occasions due to late debris-proximity warnings. In addition to the sixteen thruster firings and three Soyuz-capsule shelter orders, one attempted maneuver was not completed due to not having the several days' warning necessary to upload the maneuver timeline to the station's computer. A March 2009 event involved debris believed to be a 10 cm (3.9 in) piece of the Kosmos 1275 satellite.",1
"In 2013, the ISS operations management did not make a maneuver to avoid any debris, after making a record four debris maneuvers the previous year.",1
"growth in the number of objects as a result of the late-1990s studies sparked debate in the space community on the nature of the problem and the earlier dire warnings. According to Kessler's 1991 derivation and 2001 updates, the LEO environment in the 1,000 km (620 mi) altitude range should be cascading. However, only one major satellite collision incident occurred: the 2009 satellite collision between Iridium 33 and Cosmos 2251. The lack of obvious short-term cascading has led to speculation that the original estimates overstated the problem.",1
"According to Kessler in 2010 however, a cascade may not be obvious until it is well advanced, which might take years.",1
"Radar and optical detectors such as lidar are the main tools for tracking space debris. Although objects under 10 cm (4 in) have reduced orbital stability, debris as small as 1 cm can be tracked, however determining orbits to allow re-acquisition is difficult. Most debris remain unobserved. The NASA Orbital Debris Observatory tracked space debris with a 3 m (10 ft) liquid mirror transit telescope. FM Radio waves can detect debris, after reflecting off them onto a receiver. Optical tracking may be a useful early-warning system on spacecraft.The U.S.",1
"A debris cloud resulting from a single event is studied with scatter plots known as Gabbard diagrams, where the perigee and apogee of fragments are plotted with respect to their orbital period. Gabbard diagrams of the early debris cloud prior to the effects of perturbations, if the data were available, are reconstructed. They often include data on newly observed, as yet uncatalogued fragments. Gabbard diagrams can provide important insights into the features of the fragmentation, the direction and point of impact.",1
"An average of about one tracked object per day has been dropping out of orbit for the past 50 years, averaging almost three objects per day at solar maximum (due to the heating and expansion of the Earth's atmosphere), but one about every three days at solar minimum, usually five and a half years later. In addition to natural atmospheric effects, corporations, academics and government agencies have proposed plans and technology to deal with space debris, but as of November 2014, most of these are theoretical, and there is no extant business plan for debris reduction.A",1
"number of scholars have also observed that institutional factors – political, legal, economic, and cultural ""rules of the game"" – are the greatest impediment to the cleanup of near-Earth space. There is little commercial incentive to act, since costs are not assigned to polluters, though a number of technological solutions have been suggested. However, effects to date are limited. In the US, governmental bodies have been accused of backsliding on previous commitments to limit debris growth, ""let alone tackling the more complex issues of removing orbital debris.""",1
"The different methods for removal of space debris have been evaluated by the Space Generation Advisory Council, including French astrophysicist Fatoumata Kébé.",1
"There is no international treaty minimizing space debris. However, the United Nations Committee on the Peaceful Uses of Outer Space (COPUOS) published voluntary guidelines in 2007, using a variety of earlier national regulatory attempts at developing standards for debris mitigation. As of 2008, the committee was discussing international ""rules of the road"" to prevent collisions between satellites. By 2013, a number of national legal regimes existed, typically instantiated in the launch licenses that are required for a launch in all spacefaring nations.The U.S. issued a set of standard practices for civilian (NASA) and military (DoD and USAF) orbital-debris mitigation in 2001.",1
"The standard envisioned disposal for final mission orbits in one of three ways: 1) atmospheric reentry where even with ""conservative projections for solar activity, atmospheric drag will limit the lifetime to no longer than 25 years after completion of mission;"" 2) maneuver to a ""storage orbit:"" move the spacecraft to one of four very broad parking orbit ranges (2,000–19,700 km (1,200–12,200 mi), 20,700–35,300 km (12,900–21,900 mi), above 36,100 km (22,400 mi), or out of Earth orbit completely and into any heliocentric orbit; 3) ""Direct retrieval: Retrieve the structure and remove it from orbit as soon as practicable after completion of mission.""",1
"The standard articulated in option 1, which is the standard applicable to most satellites and derelict upper stages launched, has come to be known as the ""25-year rule"". The US updated the Orbital Debris Mitigation Standard Practices (ODMSP) in December 2019, but made no change to the 25-year rule even though ""[m]any in the space community believe that the timeframe should be less than 25 years."" There is no consensus however on what any new timeframe might be.In",1
"2002, the European Space Agency (ESA) worked with an international group to promulgate a similar set of standards, also with a ""25-year rule"" applying to most Earth-orbit satellites and upper stages. Space agencies in Europe began to develop technical guidelines in the mid-1990s, and ASI, UKSA, CNES, DLR and ESA signed a ""European Code of Conduct"" in 2006, which was a predecessor standard to the ISO international standard work that would begin the following year. In 2008, ESA further developed ""its own ""Requirements on Space Debris Mitigation for Agency Projects"" which ""came into force on 1 April 2008.""Germany",1
"and France have posted bonds to safeguard the property from debris damage. The ""direct retrieval"" option (option no. 3 in the US ""standard practices"" above) has rarely been done by any spacefaring nation (exception, USAF X-37) or commercial actor since the earliest days of spaceflight due to the cost and complexity of achieving direct retrieval, but the ESA has scheduled a 2025 demonstration mission (Clearspace-1) to do this with a single small 100 kg (220 lb) derelict upper stage at a projected cost of €120 million not including the launch costs.By",1
"2006, the Indian Space Research Organization (ISRO) had developed a number of technical means of debris mitigation (upper stage passivation, propellant reserves for movement to graveyard orbits, etc.) for ISRO launch vehicles and satellites, and was actively contributing to inter-agency debris coordination and the efforts of the UN COPUOS committee.In 2007, the ISO began preparing an international standard for space-debris mitigation. By 2010, ISO had published ""a comprehensive set of space system engineering standards aimed at mitigating space debris. [with primary requirements] defined in the top-level standard, ISO 24113."" By 2017, the standards were nearly complete.",1
Krag of the European Space Agency states that as of 2017 there is no binding international regulatory framework with no progress occurring at the respective UN body in Vienna.,1
"Rockets are the only source of direct anthropogenic emissions into the stratosphere and emit ozone depleting substances such as nitrous oxide, hydrogen chloride and aluminium oxide; these substances can destroy 105 ozone molecules before depleting. Each launch showers an area concentrated within a kilometre with toxins, heavy metals, and acids. This results in localised regional acid rain, plant death, fish kills, and failed seed germination. Furthermore, studies on trace elements concentration in alligators, near NASA launch activities in Florida (USA), showed that over 50% of alligators had ""greater than toxic levels"" of trace elements in their liver.",1
"Similarly, research in Kazakhstan, Russia and China has found that unsymmetrical dimethylhydrazine (UDMH) has carcinogenic, mutagenic, convulsant, teratogenic, embryotoxic and DNA damaging effects on rodents living near the Baikonur Cosmodrome, Kazakhstan. It is unknown, however, at what trace concentrations these toxic effects manifest in humans or how it may bioaccumulate up the food chain. A lack of adequate resourcing to maintain safe, non-toxic environments makes these areas sacrifice zones and spaces of waste. The relative remoteness of these spaces makes them attractive launch sites, yet this ""periphery"" remain central to both their human and non-human inhabitants, who become ""sacrificial"".",1
"is an argument that as well as viewing space as an environment space should also be viewed as a commons. If space is viewed as a commons then its resources need to be managed for the common good of all people. If not, then this poses a risk of injustice. By managing space as a resource that all nations have access to, and none can claim sovereignity over, outer space can be also understood as an example of a global commons. However, legally defining space as a common is challenging, as the idea of global commons is a social construct.",1
"Many space treaties include various phrases describing and defining the usage of outer space, including phrases such as ""for the benefit of all people"" and ""shall be the providence of all mankind"". However, none of these treaties provides an adequate framework for handling resources or resolving issues.Governance frameworks for outer space have a very narrow and utilitarian view of outer space that looks at what they can gain from exploration.",1
"Other satellites (such as many CubeSats) in low orbits below approximately 400 km (250 mi) orbital altitude depend on the energy-absorbing effects of the upper atmosphere to reliably deorbit a spacecraft within weeks or months. Increasingly, spent upper stages in higher orbits – orbits for which low-delta-v deorbit is not possible, or not planned for – and architectures that support satellite passivation, at end of life are passivated at end of life. This removes any internal energy contained in the vehicle at the end of its mission or useful life.",1
"While this does not remove the debris of the now derelict rocket stage or satellite itself, it does substantially reduce the likelihood of the spacecraft destructing and creating many smaller pieces of space debris, a phenomenon that was common in many of the early generations of US and Soviet spacecraft. Upper stage passivation (e.g. of Delta boosters) by releasing residual propellants reduces debris from orbital explosions; however even as late as 2011, not all upper stages implement this practice.",1
"Although the ITU requires geostationary satellites to move to a graveyard orbit at the end of their lives, the selected orbital areas do not sufficiently protect GEO lanes from debris. Rocket stages (or satellites) with enough propellant may make a direct, controlled de-orbit, or if this would require too much propellant, a satellite may be brought to an orbit where atmospheric drag would cause it to eventually de-orbit.",1
"This was done with the French Spot-1 satellite, reducing its atmospheric re-entry time from a projected 200 years to about 15 by lowering its altitude from 830 km (516 mi) to about 550 km (342 mi).The Iridium constellation – 95 communication satellites launched during the five-year period between 1997 and 2002 – provides a set of data points on the limits of self-removal.",1
"The satellite operator – Iridium Communications – remained operational over the two-decade life of the satellites (albeit with a company name change through a corporate bankruptcy during the period) and, by December 2019, had ""completed disposal of the last of its 65 working legacy satellites."" However, this process left 30 satellites with a combined mass of (20,400 kg (45,000 lb), or nearly a third of the mass of this constellation) in LEO orbits at approximately 700 km (430 mi) altitude, where self-decay is quite slow.",1
"Of these satellites, 29 simply failed during their time in orbit and were thus unable to self-deorbit, while one – Iridium 33 – was involved in the 2009 satellite collision with the derelict Russian military satellite Kosmos-2251. No contingency plan was laid for the removal of satellites that were unable to remove themselves.",1
"In 2019, the Iridium CEO, Matt Desch, said that Iridium would be willing to pay an active-debris-removal company to deorbit its remaining first-generation satellites if it were possible for an unrealistically low cost, say ""US$10,000 per deorbit, but [he] acknowledged that price would likely be far below what a debris-removal company could realistically offer. 'You know at what point [it's] a no-brainer, but [I] expect the cost is really in the millions or tens of millions, at which price I know it doesn't make sense.'""Passive methods of increasing the orbital decay rate of spacecraft debris have been proposed.",1
"To date in 2019, removal costs and legal questions about ownership and the authority to remove defunct satellites have stymied national or international action. Current space law retains ownership of all satellites with their original operators, even debris or spacecraft which are defunct or threaten active missions. Multiple companies made plans in the late 2010s to conduct external removal on their satellites in mid-LEO orbits.",1
"For example, OneWeb planned to utilize onboard self-removal as ""plan A"" for satellite deorbiting at the end of life, but if a satellite were unable to remove itself within one year of end of life, OneWeb would implement ""plan B"" and dispatch a reusable (multi-transport mission) space tug to attach to the satellite at an already built-in capture target via a grappling fixture, to be towed to a lower orbit and released for re-entry.",1
"A well-studied solution uses a remotely controlled vehicle to rendezvous with, capture, and return debris to a central station. One such system is Space Infrastructure Servicing, a commercially developed refueling depot and service spacecraft for communications satellites in geosynchronous orbit originally scheduled for a 2015 launch. The SIS would be able to ""push dead satellites into graveyard orbits."" The Advanced Common Evolved Stage family of upper stages is being designed with a high leftover-propellant margin (for derelict capture and de-orbit) and in-space refueling capability for the high delta-v required to de-orbit heavy objects from geosynchronous orbit.",1
"A tug-like satellite to drag debris to a safe altitude for it to burn up in the atmosphere has been researched. When debris is identified the satellite creates a difference in potential between the debris and itself, then using its thrusters to move itself and the debris to a safer orbit. A variation of this approach is for the remotely controlled vehicle to rendezvous with debris, capture it temporarily to attach a smaller de-orbit satellite and drag the debris with a tether to the desired location.",1
"The ""mothership"" would then tow the debris-smallsat combination for atmospheric entry or move it to a graveyard orbit. One such system is the proposed Busek ORbital DEbris Remover (ORDER), which would carry over 40 SUL (satellite on umbilical line) de-orbit satellites and propellant sufficient for their removal.On 7 January 2010 Star, Inc. reported that it received a contract from the Space and Naval Warfare Systems Command for a feasibility study of the ElectroDynamic Debris Eliminator (EDDE) propellantless spacecraft for space-debris removal.",1
"In February 2012 the Swiss Space Center at École Polytechnique Fédérale de Lausanne announced the Clean Space One project, a nanosatellite demonstration project for matching orbit with a defunct Swiss nanosatellite, capturing it and de-orbiting together. The mission has seen several evolutions to reach a pac-man inspired capture model. In 2013, Space Sweeper with Sling-Sat (4S), a grappling satellite which captures and ejects debris was studied. In 2022, a Chinese satellite, SJ-21, grabbed an unused satellite and ""threw"" it into an orbit with a lower risk for it to collide.In",1
"December 2019, the European Space Agency awarded the first contract to clean up space debris. The €120 million mission dubbed ClearSpace-1 (a spinoff from the EPFL project) is slated to launch in 2025. It aims to remove a 100 kg VEga Secondary Payload Adapter (Vespa) left by Vega flight VV02 in an 800 km (500 mi) orbit in 2013. A ""chaser"" will grab the junk with four robotic arms and drag it down to Earth's atmosphere where both will burn up.",1
"The 2003 Space Shuttle Columbia disaster postponed the project and according to Nicholas Johnson, chief scientist and program manager for NASA's Orbital Debris Program Office, ""There are lots of little gotchas in the Orion final report. There's a reason why it's been sitting on the shelf for more than a decade.""The momentum of the laser-beam photons could directly impart a thrust on the debris sufficient to move small debris into new orbits out of the way of working satellites.",1
"NASA research in 2011 indicates that firing a laser beam at a piece of space junk could impart an impulse of 1 mm (0.039 in) per second, and keeping the laser on the debris for a few hours per day could alter its course by 200 m (660 ft) per day. One drawback is the potential for material degradation; the energy may break up the debris, adding to the problem. A similar proposal places the laser on a satellite in Sun-synchronous orbit, using a pulsed beam to push satellites into lower orbits to accelerate their reentry.",1
"On 28 February 2014, Japan's Japan Aerospace Exploration Agency (JAXA) launched a test ""space net"" satellite. The launch was an operational test only. In December 2016 the country sent a space junk collector via Kounotori 6 to the ISS by which JAXA scientists experiment to pull junk out of orbit using a tether. The system failed to extend a 700-meter tether from a space station resupply vehicle that was returning to Earth. On 6 February the mission was declared a failure and leading researcher Koichi Inoue told reporters that they ""believe the tether did not get released"".Since",1
"2012, the European Space Agency has been working on the design of a mission to remove large space debris from orbit. The mission, e.Deorbit, is scheduled for launch during 2023 with an objective to remove debris heavier than 4,000 kilograms (8,800 lb) from LEO. Several capture techniques are being studied, including a net, a harpoon and a combination robot arm and clamping mechanism.",1
"The RemoveDEBRIS mission plan is to test the efficacy of several ADR technologies on mock targets in low Earth orbit. In order to complete its planned experiments the platform is equipped with a net, a harpoon, a laser ranging instrument, a dragsail, and two CubeSats (miniature research satellites). The mission was launched on 2 April 2018.",1
"Metal processing technologies to melt space debris and transform it into other useful form factors are developed by CisLunar Industries. Their system uses electromagnetic heating to melt metal and shape it into metal wire, sheet metal, and metal fuel.",1
"With the rapid development of the computer and digitalization industries, more countries and companies have engaged in space activities since the turn of the 20th century. The tragedy of the commons is an economic theory referring to a situation where maximizing self-interest through using a shared resource can finally lead to the resource degradation shared by all. Based on the theory, individuals' rational action in space will finally lead to an irrational collective result: orbits are crowded with debris. As a common-pool resource, the Earth's orbits, especially LEO and GEO that accommodate most satellites, are nonexcludable and rivalry.",1
"To address the tragedy and ensure space sustainability, many technical approaches have been developed. And in terms of governance mechanisms, the top-down centralized one is less suitable to tackle the complex debris problem due to the increasing number of space actors. Instead, much evidence has proved that polycentric form of governance developed by Elinor Ostrom can work in space.In the process of promoting the polycentric network, there are some existing barriers needed to be dealt with.",1
"As orbital debris is a global problem affecting both spacefaring and non-spacefaring nations, it is necessary to be handled in a worldwide context. Because of the complexity and dynamics of object movements like spacecraft, debris, meteorites, etc., many countries and regions including the United States, Europe, Russia and China have developed their space situational awareness (SSA) to avoid potential threats in space or plan actions in advance. To a certain extent, SSA plays a role in tracking space debris. In order to build a powerful SSA system, there are two prerequisites: international cooperation and exchange of information and data.",1
"However, limitations still exist in spite of the substantially improving data quality over the past decades. Some space powers are not willing to share the information that they have collected, and those, such as the U.S., that have shared the data keep parts of it secret. Instead of joining in a coordinated way, a great deal of SSA programs and national databases run parallel to each other with some overlaps, hindering the formation of a collaborative monitoring system.Some private actors are also trying to establish SSA systems. For example, the Space Data Association (SDA) formed in 2009 is a non-governmental entity.",1
"It currently consists of 21 global satellite operators and 4 executive members: Eutelsat, Inmarsat, Intelsat and SES. SDA is a non-profit platform, aiming to avoid radio interference and space collisions through pooling data from operators independently. Researchers suggest that it is essential to establish an international center for exchanging information on space debris because SSA networks do not completely equal debris tracking systems – the former ones focus more on active and threatening objects in space. And in terms of debris populations and defunct satellites, not very much operators have provided data.In",1
"a polycentric governance network, a resource that cannot be holistically monitored is less possible to be well managed. Both insufficient transnational cooperation and information sharing bring resistance to addressing the debris problem. There is still a long way to go before building a global network that covers complete data and has strong interconnection and interoperability.",1
"With the commercialization of satellites and space, the private sector is getting more interested in space activities. For example, SpaceX is planning to create a network of around 12,000 small satellites that can transmit high-speed internet to any place in the world. The proportion of commercial spacecraft has increased from 4.6% in the 1980s to 55.6% in the 2010s. Despite the high participation rate of commercial entities, UN COPUOS once deliberately excluded them from having a voice in discussions unless being formally invited by a member state.",1
Ostrom said that the involvement of all relevant stakeholders in the rule-design and implementation process is one of the critical elements of successful governance. The exclusion of private actors largely reduces the effectiveness of the committee's role in making collective-choice arrangements that reflect the interests of all space users.The limited engagement of private actors slows down the process of addressing space debris to some degree. Ties existing between dissimilar stakeholders in the governance network offer access to diverse resources. Different competence among stakeholders can help allocate the tasks more reasonably.,1
"In that case, the expertise and experience of private operators are critical to help the world achieve space sustainability. The complementary strengths of different stakeholders enable the governance network to be more adaptable to changes and reach common goals more effectively. In recent years, many private actors have seen commercial opportunities of eliminating space debris. It is estimated that by 2022 the global market for debris monitoring and removal will generate a revenue of around $2.9 billion. For example, Astroscale has contracted with European and Japanese space agencies to develop the capacity of removing orbital debris.",1
"Despite that, they are still in small quantity compared to the number of those who have placed satellites in space. Privateer Space, a Hawaiian-based startup company started by American engineer Alex Fielding, space environmentalist Dr. Moriba Jah, and Apple co-founder Steve Wozniak, announced plans in September 2021 to launch hundreds of satellites into orbit in order to study space debris. However, the company stated it is in ""stealth mode"" and no such satellites have been launched.Fortunately,",1
"the current space exploration is not completely driven by competition, and there still exists a chance for dialogues and cooperation among all stakeholders in both developed and developing countries, to reach an agreement on tackling space debris and assure an equitable and orderly exploration. Besides private actors, network governance does not necessarily exclude the states from playing a role. Instead, the different functions of states might promote the governance process.",1
"To improve the polycentric governance network of space debris, researchers suggest: encourage data-sharing among different national and organizational databases at the political level; develop shared standards for data collection systems to improve interoperability; enhance the participation of private actors through involving them in national and international discussions. The issue of space debris has been raised as a mitigation challenge for missions around the Moon with the danger of increasing space debris around it.In",1
"2022, several elements of space debris were found on Mars, Perseverance's backshell was found on the surface of Jezero Crater, and a piece of a thermal blanket that may have come from the descent stage of the rover.It is thought that on 4 March 2022, for the first time, human space debris – most likely a spent rocket body, Long March 3C third stage from the 2014 Chang'e 5 T1 mission – unintentionally hit the lunar surface, creating an unexpected double crater.",1
"Until the End of the World (1991) is a French sci-fi drama set under the backdrop of an out-of-control Indian nuclear satellite, predicted to re-enter the atmosphere, threatening vast populated areas of the Earth.Gravity, a 2013 survival film directed by Alfonso Cuaron, is about a disaster on a space mission caused by Kessler syndrome.In season 1 of Love, Death & Robots (2019), episode 11, ""Helping Hand"", revolves around an astronaut being struck by a screw from space debris which knocks her off a satellite in orbit.Manga",1
and anime Planetes tells a story about a crew of Space Debris station that collects and disposes space debris.,1
"A spherical untamped critical mass is about 11 kg (24.2 lbs), 10.2 cm (4"") in diameter. Using appropriate triggers, neutron reflectors, implosion geometry and tampers, the critical mass can be less than half of that. The fission of one atom of 239Pu generates 207.1 MeV = 3.318 × 10−11 J, i.e. 19.98 TJ/mol = 83.61 TJ/kg, or about 23 gigawatt hours/kg. Plutonium is made from uranium-238. 239Pu is normally created in nuclear reactors by transmutation of individual atoms of one of the isotopes of uranium present in the fuel rods.",1
"Occasionally, when an atom of 238U is exposed to neutron radiation, its nucleus will capture a neutron, changing it to 239U. This happens more easily with lower kinetic energy (as 238U fission activation is 6.6MeV). The 239U then rapidly undergoes two β− decays — an emission of an electron and an anti-neutrino ( ν ¯ e {\displaystyle {\bar {\nu }}_{e}} ), leaving a proton — the first β− decay transforming the 239U into neptunium-239, and the second β− decay transforming the 239Np into 239Pu: U 92 238 + n 0 1 ⟶ U 92 239 → 23.5",1
"min β − Np 93 239 → 2.356 d β − Pu 94 239 {\displaystyle {\ce {{}^{238}_{92}U + {}^{1}_{0}n -> {}^{239}_{92}U ->[\beta^-][23.5\ {\ce {min}}] {}^{239}_{93}Np ->[\beta^-][2.356\ {\ce {d}}] {}^{239}_{94}Pu}}} Fission activity is relatively rare, so even after significant exposure, the 239Pu is still mixed with a great deal of 238U (and possibly other isotopes of uranium), oxygen, other components of the original material, and fission products. Only if the fuel has been exposed for a few days in the reactor, can the 239Pu be chemically separated from the rest of the material to yield high-purity 239Pu metal.",1
"239Pu has a higher probability for fission than 235U and a larger number of neutrons produced per fission event, so it has a smaller critical mass. Pure 239Pu also has a reasonably low rate of neutron emission due to spontaneous fission (10 fission/s·kg), making it feasible to assemble a mass that is highly supercritical before a detonation chain reaction begins. In practice, however, reactor-bred plutonium will invariably contain a certain amount of 240Pu due to the tendency of 239Pu to absorb an additional neutron during production.",1
"Moreover, 239Pu and 240Pu cannot be chemically distinguished, so expensive and difficult isotope separation would be necessary to separate them. Weapons-grade plutonium is defined as containing no more than 7% 240Pu; this is achieved by only exposing 238U to neutron sources for short periods of time to minimize the 240Pu produced.",1
"(In fact, the RBMK was built by the Soviet Union during the Cold War, so despite their ostensibly peaceful purpose, it is likely that plutonium production was a design criterion.) By contrast, the Canadian CANDU heavy-water moderated natural-uranium fueled reactor can also be refueled while operating, but it normally consumes most of the 239Pu it produces in situ; thus, it is not only inherently less proliferative than most reactors, but can even be operated as an ""actinide incinerator"".",1
"The American IFR (Integral Fast Reactor) can also be operated in an ""incineration mode"", having some advantages in not accumulating the plutonium-242 isotope or the long-lived actinides, which cannot be easily burned except in a fast reactor. Also IFR fuel has a high proportion of burnable isotopes, while in CANDU an inert material is needed to dilute the fuel; this means the IFR can burn a higher fraction of its fuel before needing reprocessing.",1
"Both plutonium-239 and uranium-235 are obtained from Natural uranium, which primarily consists of uranium-238 but contains traces of other isotopes of uranium such as uranium-235. The process of enriching uranium, i.e. increasing the ratio of 235U to 238U to weapons grade, is generally a more lengthy and costly process than the production of plutonium-239 from 238U and subsequent reprocessing.",1
"Such low irradiation times limit the amount of additional neutron capture and therefore buildup of alternate isotope products such as 240Pu in the rod, and also by consequence is considerably more expensive to produce, needing far more rods irradiated and processed for a given amount of plutonium. Plutonium-240, in addition to being a neutron emitter after fission, is a gamma emitter, and so is responsible for a large fraction of the radiation from stored nuclear weapons.",1
"Such fuel is called MOX (mixed oxide) fuel, as it contains a mixture of uranium dioxide (UO2) and plutonium dioxide (PuO2). The addition of plutonium-239 reduces the need to enrich the uranium in the fuel. Plutonium-239 emits alpha particles to become uranium-235. As an alpha emitter, plutonium-239 is not particularly dangerous as an external radiation source, but if it is ingested or breathed in as dust it is very dangerous and carcinogenic. It has been estimated that a pound (454 grams) of plutonium inhaled as plutonium oxide dust could give cancer to two million people.",1
"Teller-Ulam design NLM Hazardous Substances Databank – Plutonium, Radioactive Table of nuclides with 239Pu data at Kaye and Laby Online Half-life of Plutonium-239 Archived 2011-08-15 at the Wayback Machine",1
"In areas where humans rely on fishing or aquafarming for nourishment, decreased populations of fish and shellfish can lead to undernourishment and associated diseases.",1
"Like prairie filter strips, forested riparian buffers are filter strips that are not planted, but rather, are populated by indigenous trees and other flora. They are better able to support local terrestrial fauna. As opposed to undisturbed land, riparian buffers support a significantly greater number of avian and arthropod species. However, they are not able to support as large of a number of species as undisturbed land.",1
"(2003) found that vegetated filter strips were effective in reducing the concentration of phosphorus, with results ranging from 61% to 89% for 2m-wide filter strips and 15m-wide filter strips respectively. This indicates that filter strips are effective at even small widths. Filter strips have also been shown to be very effective in sediment trapping. A study of sediment removal found that prairie filter strips had a 96% sediment trapping efficiency over a 4-year period.",1
"On 11 August 2013, the Greenpeace ship Arctic Sunrise left the Norwegian port of Kirkenes to begin a month-long expedition in the Arctic to protest against oil exploration in Arctic waters. The Arctic Sunrise sailed into the Barents Sea and was then refused permission three times by the Russian authorities to enter the Northern Sea Route although the refusal is in violation of international law including the right to freedom of navigation. On 23 August, Greenpeace ignored Russia's ban to protest state oil company Rosneft's operations in the Arctic and entered the international waters of the Kara Sea.",1
"The two activists were removed from the platform and held on board the coastguard vessel, although it was unclear whether or not they had been placed under arrest.On 19 September 2013, the day after the Prirazlomnaya protest, the Russian authorities forcibly took control of the Arctic Sunrise, which was boarded from a helicopter by fifteen Federal Security Service officers in balaclavas, armed with guns and knives.",1
"At the time of the boarding, the Arctic Sunrise was in Russia's Exclusive Economic Zone but not within the safety zone around the oil rig, and permission was not sought to board it from the Arctic Sunrise's flag state, the Netherlands. The captain was separated from the crew and brutally beaten, while other crew members and activists were held in the mess room. It has been alleged that crew members and activists were brutally beaten, punched, and kicked during the forced boarding.The Arctic Sunrise was towed to the port of Murmansk.",1
"All of the 30 people on board were taken to a detention facility where they were brutally beaten and interrogated. In early October, the Leninsky District Court in Murmansk issued a warrant to arrest all 30 people. 22 were put in custody for two months pending an investigation and the other eight were detained for three days pending a new hearing. They were under investigation for piracy, which in Russia carries a maximum jail sentence of 15 years.",1
"On 23 October the charge of piracy was dropped and replaced by a charge for aggravated hooliganism with a maximum sentence of seven years. After they were transferred to Saint Petersburg on 12 November, the Kalininsky and Primorsky district courts released most of the people on bail, and the Murmansk Regional Court rejected an appeal against the arrests on 21 November.According",1
"to Phil Radford, executive director of Greenpeace in the United States at the time, the reaction of the Russian coast guard and courts had been the ""stiffest response that Greenpeace has encountered from a government since the bombing of the Rainbow Warrior in 1985."" The detainees were christened the ""Arctic 30"" by Greenpeace and the press. They included:",1
"US: Captain Peter Henry Willcox Argentina: Second mate Miguel Hernán Pérez Orsi Australia: Radio operator Colin Russell Brazil: Deckhand Ana Paula Alminhana Maciel Canada: Bosun Alexandre Paul, first mate Paul D Ruzycki Denmark: Third mate Anne Mie Roer Jensen France: Deckhand Francesco Pisanu Italy: Deckhand Cristian D'Alessandro Netherlands: Chief engineer Mannes Ubels New Zealand: Boat mechanic Jonathan Beauchamp, electrician David John Haussmann Turkey: Volunteer assistant cook Gizem Akhan UK: Communications officer Alexandra Hazel Harris, 2nd engineer Iain Rogers Ukraine: Cook Ruslan Yakushev",1
"Argentina: Activist Camila Speziale Finland: Activist Sini Saarela Netherlands: Campaigner Faiza Oulahsen Poland: Activist Tomasz Dziemianczuk Russia: Spokesman Roman Dolgov, Dr Yekaterina Zaspa, press officer Andrei Allahverdov Sweden: Campaigner Dima Litvinov Switzerland: Activist Marco Weber UK: logistics co-ordinator Frank Hewetson, activist Anthony Perrett, activist Philip Ball",1
"UK: Videographer and journalist Kieron Bryan Russia: Photographer Denis Sinyakov One of the jailed people was the award-winning Russian photographer Denis Sinyakov, whose jailing led to protests by the Russian Union of Journalists and the international group Reporters Without Borders. According to Alexei Simonov, head of Glasnost Defense Foundation, a Moscow-based rights group, Sinyakov had only been covering the actions of Greenpeace activists in the Barents Sea and had nothing to do with the group's agenda: ""The authorities violated all norms and laws by keeping Sinyakov in prison ...",1
"I must say it again and again that Russian justice system is designed by the Kremlin not to look for real culprits to be punished but to punish and scare those who don't suit the authorities."" Sinyakov posted on his Facebook account an image of a hooded Russian coast guardsman pointing a handgun at the boat. When the first two activists were detained, Sinyakov wrote: ""I call upon you to join the struggle for freeing these activists, who sincerely see Arctic exploration as malignant."" Sinyakov was subsequently detained.",1
"The top trans-Atlantic security and rights group, the Organization for Security and Cooperation in Europe, also demanded Sinyakov's immediate release. Several Russian media outlets, including the lenta.ru site and a private but Kremlin-friendly national TV station, NTV, took all pictures off their web sites in a show of solidarity with the jailed photographer. In Paris, a few dozen Greenpeace activists protested in front of the Russian Embassy on 27 September 2013, waving banners with images of the incarcerated activists and the word ""FREE"" written over them.",1
"Prior to 22 November 2013, the Russian court had released all but one of the Greenpeace campaigners against bail (paid by Greenpeace) with the condition the campaigners could not leave Russia.As flag state for the Arctic Sunrise, the Netherlands asked for immediate release of the ship and shipmates to Dutch authorities. The Dutch government argued that since the ship was outside Russian territorial waters and outside the 500-metre (1,600 ft) safety zone around the oil rig, it was in open sea, and hence outside Russian sovereign rights and jurisdiction.",1
"According to nautical law, any actions against a ship in open sea can only be conducted after agreement with the flag state. Hence, the Dutch took the position that the capture of the Arctic Sunrise by Russia had not been legal. After Russia did not release the ship, the Netherlands filed a formal case with the International Tribunal for the Law of the Sea on 21 October 2013 to order Russia to release the Greenpeace ship and the activists who had been on board.New",1
"Zealand Prime Minister John Key raised the issue with Russian President Vladimir Putin, but said the Russian judicial process would need to run its course.Eleven Nobel prize-winners wrote to Vladimir Putin asking the Russian president to drop charges against the Greenpeace activists and journalists.Six men broke into the Greenpeace office in Murmansk and stole materials.",1
"On 22 November 2013, the International Tribunal for the Law of the Sea ruled that the campaigners and the ship should be immediately released, and should be allowed to leave the country, against a bail of 3.5 Million Euro.On 14 August 2015, the international Permanent Court of Arbitration unanimously ruled that Russia had acted in breach of the UN Convention on the Law of the Sea and had to compensate the Dutch government (flag state of the ship) for damages to the ship.",1
"The tribunal ruled that the actions of Greenpeace could not be labelled as piracy or hooliganism; reasons Russia had given for capturing the ship. Russia, a partner of the permanent court of arbitration, responded by stating it does not recognize the authority of the court in this case.",1
"According to Greenpeace, charges of piracy against peaceful activists have no merit in international law. Greenpeace rejected the suggestion of illegal drugs on the Arctic Sunrise. Certain pharmaceutical drugs are kept in a safe. The Russian authorities broke the safe after they took the vessel.Phil Radford, executive director of Greenpeace USA, argued that the arrest of the Arctic 30 had been the stiffest response that Greenpeace has encountered from a government since the bombing of the Rainbow Warrior by the French secret service in 1985.Greenpeace",1
"activists have continued to call for governments to save the arctic, the original motivation for the protest.According to Dutch Greenpeace members, the condition of the Greenpeace ship worsened during its stay in Murmansk, as the Russian officials did not take proper care of the vessel.",1
"11 Nobel peace laureates wrote to Putin, calling on him to drop the ""excessive"" charges of piracy: South African Bishop Desmond Tutu Northern Irish peace campaigner Betty Williams Former President of Costa Rica, Oscar Arias Sanchez US peace campaigner Jody Williams Liberian peace campaigner Leymah Gbowee Yemeni peace campaigner Tawakkol Karman Guatemalan social reformist Rigoberta Menchú Tum Northern Irish peace activist Mairead Maguire Iranian lawyer and former judge Shirin Ebadi Former President of East Timor Jose Ramos Horta Argentine community organiser Adolfo Perez Esquivel<German chancellor Angela Merkel expressed concerns about the arrest of the Greenpeace activists to Vladimir Putin, and urged",1
"a swift resolution of the case.William Hague, the foreign secretary UK, negotiated with Russian ministers over the fate of the six British nationals involved.According to Julia Marton-Lefèvre, the International Union for Conservation of Nature oil and gas exploring in the Arctic would have drastic consequences and the world should find low-carbon sources of energy.Damon Albarn of Blur showed a poster of Frank Hewetson during the band's concert in Santiago, Chile, on 7 November 2013, asking for him to be freed.",1
"In December 2013, the 30 activists were all released from prison as part of a general amnesty, purportedly in celebration of the 20th anniversary of Russia's post-Soviet constitution. Arctic Refuge drilling controversy Climate change in the Arctic Green imperialism Save the Arctic, a Greenpeace campaign Sinking of the Rainbow Warrior Arctic 30: watch Russian forces seize Greenpeace ship – video The Arctic Sunrise Case (Kingdom of the Netherlands v. Russian Federation) in the International Tribunal for the Law of the Sea Arctic Sunrise Arbitration (Netherlands v. Russia)",1
"Antibiotics Estrogens and hormones Anti-inflammatories and analgesics Antiepileptics Lipid regulators Antihypertensives Contrast media Antidepressants Antiulcer drugs and Antihistamines The chemical structure of pharmaceuticals affects the type of hydro-geochemical processes that mainly impacts on their fate in groundwater and it is strictly associated with their chemical properties. Therefore, a classification of pharmaceuticals based on chemical classes is a valid alternative to the purpose of understanding the role of molecular structures in determining the kind of physical and geochemical processes affecting their mobility in porous media.",1
"Lipophilicity, often measured through the so-called octanol-water partition coefficient (typically addressed as K O W {\displaystyle K_{OW}} )Large K O W {\displaystyle K_{OW}} values outline the non polar character of the chemical species, which shows instead particular affinity to dissolve into organic solvents. Therefore, lipophilic pharmaceuticals are markedly subjected to the risk to bioaccumulate and biomagnificate in the environment, consistent with their preferential partition with the organic tissues of living organisms.",1
"Affinity of sorption onto the soilsThis feature is expressed in terms of the so-called organic carbon-water partition coefficient, that is usually referred to as K O C {\displaystyle K_{OC}} and is an intrinsic property of the molecule. Acidic characterMolecules behaviour in relation to aqueous dissociation reactions is typically related to their acid dissociation constants, that are typically outlined in terms of their P k a {\displaystyle Pk_{a}} coefficients.",1
"Affinity to redox reactions, even in the context of bacterially-mediated metabolic pathwaysThe molecular structure of xenobiotics typically outlines the existence of several possible reaction pathways, which are embedded in complex reaction networks and are typically referred to as transformation processes. With reference to organic compounds, such as pharmaceuticals, innumerable kinds of chemical reactions exist, most of them involving common chemical mechanisms, such as functional groups elimination, addition and substitution. These processes often involve further redox reactions accomplished on the substrates, which are here represented by pharmaceutical solutes and, eventually, their transformation products and metabolites.",1
"These processes can be then classified as either biotic or abiotic, depending on the presence or absence of bacterial communities acting as reaction mediators. In the former case, these transformation pathways are typically addressed as biodegradation or biotransformation in the hydrogeochemical literature, depending on the extent of cleavage of the parent molecule into highly oxidized, innocuous species. The fate of pharmaceuticals in groundwater is governed by different processes. The reference theoretical framework is that of reactive solute transport in porous media at the continuum scale, that is typically interpreted through the advective-dispersive-reactive equation (ADRE).",1
"With reference to the saturated region of the aquifer, the ADRE is written as: ∂ ∂ t ( ϕ C W ( x , t ) ) = − ∇ ( ϕ C W ( x , t ) v ( x , t ) ) ⏟ advection + ∇ ( ϕ D ( x , t ) ∇ C W ( x , t ) ) ⏟ hydrodynamic dispersion + R ⏟ accumulation {\displaystyle {\frac {\partial }{\partial t}}(\phi C_{W}({\boldsymbol {x}},t))=-\underbrace {\nabla (\phi C_{W}({\boldsymbol {x}},t){\boldsymbol {v}}({\boldsymbol {x}},t))} _{\text{advection}}+\underbrace {\nabla (\phi {\boldsymbol {D}}({\boldsymbol {x}},t)\nabla C_{W}({\boldsymbol {x}},t))} _{\text{hydrodynamic dispersion}}+\underbrace {R} _{\text{accumulation}}} Where ϕ",1
"{\displaystyle \phi } represents the effective porosity of the medium, x {\displaystyle {\boldsymbol {x}}} and t {\displaystyle t} represent - respectively - the spatial coordinates vector and the time coordinate. ∇ {\displaystyle \nabla } represents the divergence operator, except for when it applies to C W {\displaystyle C_{W}} , where the nabla symbol stands for gradient of C W {\displaystyle C_{W}} .",1
"Lastly, the storage term R {\displaystyle R} includes the accumulation or removal contribution due to all possible reactive processes in the system, i.e., adsorption, dissolution / precipitation, acid dissociation and other transformation reactions, such as biodegradation.The main hydrological transport processes driving pharmaceuticals and organic contaminants migration in aquifer systems are: Advection Hydrodynamic dispersionThe most influential geochemical processes, also referred to as reactive processes and whose effect is embedded in the term R {\displaystyle R} of the ADRE, include: Adsorption onto soil Dissolution and precipitation Acid dissociation and aqueous complexation Biodegradation, biotransformation and other transformation pathways",1
"Advective transport accounts for the contribution of solute mass transfer across the system that originates from bulk flow motion. At the continuum scale of analysis, the system is interpreted as a continuous medium rather than a collection of solid particles (grains) and empty spaces (pores) through which the fluid can flow. In this context, an average flow velocity can be typically estimated, which arises upscaling the pore scale velocities. Here, the fluid flow conditions ensure the validity of the Darcy's law, which governs the system evolution in terms of average fluid velocity, typically referred to as seepage or advective velocity.",1
Dissolved pharmaceuticals in groundwater are transferred within the domain along with the mean fluid flow and in agreement with the physical principles governing any other solute migration across the system.,1
"Hydrodynamic dispersion identifies a process that arises as summation of two separate effects. First, it is associated with molecular diffusion, a phenomenon that is appreciated at the macroscale as consequence of microscale Brownian motions. Secondly, it includes a contribution (called mechanical dispersion) arising as an effect of upscaling the fluid-dynamic transport problem from the pore to the continuum scale of investigation, due to the upscaling of local dishomogeneous velocities. The latter contribution is therefore not related to the occurrence of any physical process at the pore scale, but it is only a fictitious consequence of the modelling scale choice.",1
Hydrodynamic dispersion is then embedded in the advective-dispersive-reactive equation (ADRE) assuming a Fickian closure model. Dispersion is felt at the macroscale as responsible of a spread effect of the contaminant plume around its center of mass.,1
"Sorption identifies a heterogeneous reaction that is often driven by instantaneous thermochemical equilibrium. It describes the process for which a certain mass of solute dissolved in the aqueous phase adheres to a solid phase (such as the organic fraction of soil in the case of organic compounds), being therefore removed from the liquid phase. In hydrogeochemistry, this phenomenon has been proved to cause a delayed effect in solute mobility with respect to the case in which solely advection and dispersion occur in the aquifer.",1
"For pharmaceuticals, it can be typically interpreted using a linear adsorption model at equilibrium, which is fully appliable at low concentrations ranges. The latter model relies upon assessment of a linear partition coefficient, usually denoted as k d {\displaystyle k_{d}} , that depends - for organic compounds - on both organic carbon-water partition coefficient K O C {\displaystyle K_{OC}} and organic carbon fraction f O C {\displaystyle f_{OC}} into soil. While the former term is an intrinsic chemical property of the molecule, the latter one instead depends on the soil moisture of the analyzed aquifer.Sorption",1
"Anionic forms are instead insensitive to sorptive mechanisms, while cations can undergo adsorption only in very particular conditions.",1
"Dissolution represents the heterogeneous reaction during which a solid compound, such as an organic salt in the case of pharmaceuticals, gets dissolved into the aqueous phase. Here, the original salt appears in the form of both aqueous cations and anions, depending on the stoichiometry of the dissolution reaction. Precipitation represents the reverse reaction. This process is typically accomplished at thermochemical equilibrium, but in some applications of hydrogeochemical modelling it might be required to consider its kinetics. As an example for the case of pharmaceuticals, the non-steroidal anti-inflammatory drug diclofenac, which is commercialised as sodium diclofenac, undergoes this process in groundwater environments.",1
"Pharmaceuticals can undergo biotransformation or transformation processes in groundwater systems.Aquifers are indeed rich reserves in terms of minerals and other dissolved chemical species, such as organic matter, dissolved oxygen, nitrates, ferrous and manganese compounds, sulfates, etc., as well as dissolved cations, such as calcium, magnesium and sodium ones. All of these compounds interact through complex reaction networks embedding reactive processes of different nature, such as carbonates precipitation / dissolution, acid–base reactions, sorption and redox reactions.",1
"With reference to the latter kind of processes, several pathways are typically possible in aquifers because the environment is often rich in both reducing (like organic matter) and oxidizing agents (like dissolved oxygen, nitrates, ferrous and Manganese oxides, sulfates etc.). Pharmaceuticals can act as substrates as well in this scenario, i.e., they can represent either the reducing, or the oxidizing agent in the context of redox processes. In fact, most chemical reactions involving organic molecules are typically accomplished upon gain or loss of electrons, so that the oxidation state of the molecule changes along the reactive pathway.",1
"Therefore, recognizing the correct molecular mechanisms through which a chemical reaction progresses is fundamental to the purpose of modelling the reaction rates correctly (for example, it is often possible to identify a rate limiting step within multistep reactions and relate the rate of reaction progress to that particular step). Modelling these reactions typically follows the classic kinetic laws, except for the case in which reactions involving the contaminant are accomplished in the context of bacterial metabolism.",1
"For example, the Monod and Michaelis-Menten equations are suitable options in case of biotic transformation processes involving organic compounds (such as pharmaceuticals) as substrates.Despite most hydrogeochemical literature addresses these processes through linear biodegradation models, several studies have been carried out since the second decade of the twenty-first century, as the former ones are typically too simplified to ensure reliable predictions of pharmaceuticals fate in groundwater and might bias risk estimates in the context of risk mitigation applications for the environment.",1
"Some people might expect that green spaces are extravagant and excessively difficult to maintain, but high-performing green spaces can provide tangible economic, ecological, and social benefits. For example: Urban forestry in an urban environment can supplement stormwater management and reduce associated energy usage costs and runoff. Bioretention systems can be applied to the creation of a green transportation system.As a result, high-performing green spaces work to create a balance between built and natural environments.",1
"A higher abundance of green space in communities or neighbourhoods, for example, has been observed to promote participation in physical activities among elderly men, while more green space around one's house is associated with improved mental health.",1
"Chinese literary gardens are an example of a sustainable lawn that showcased natural beauty in suburban areas. These gardens, dating back to the Shang Dynasty (1600–1046 BC), were designed to allow native plant species to thrive in their natural conditions and appear untouched by humans. This created ecological havens within the city.",1
"Greece was an early adopter of the concept of green Infrastructure with the invention of Greek agora. Agoras were meeting spaces that were built for social conversations and allowed Greeks to converse in public. Many were built across Greece, and some incorporated nature as a design aspect, giving nature a space among the public.",1
"They often incorporated design elements blending urbanism and nature, forming a relationship that showcased how the French grew alongside nature and often made it a key aspect of their expansion.In 18th Century France, Citizens were able to request to have old and battered city walls destroyed to make room for new gardens, vegetation sites, and green walkways. This opened up new areas to the city landscape and incorporated greenery into the new areas where the walls were torn down.",1
"In 1847, a speech by George Perkins Marsh called attention to negative human impacts such as deforestation. Marsh later wrote Man and Nature in 1864 based on his idea for conserving forests. Around the same time, Henry David Thoreau’s Walden of 1860 discussed preservation of nature and applied these ideas to urban planning saying, “I think every town should have a park,” and stated the “importance of preserving some portions of nature herself unimpaired.”",1
"One of Howard's concepts was of the ""marriage of town and country"" to promote sustainable relationships between human society and nature through the planning of garden cities.The US government became more involved in conservation and land preservation in the late 1800s. This was seen in the 1864 legislation to preserve the Yosemite Valley as a California public park, and 8 years later, the United States’ first national park.",1
"In attempts to reduce the amount of rainwater that enters the combined sewer systems, agencies such as the Milwaukee Metropolitan Sewerage District amended regulations that require downspout disconnection at residential areas.",1
"Bioswales are stormwater runoff systems providing an alternative to traditional storm sewers. Much like rain gardens, bioswales are vegetated or mulched channels commonly placed in long narrow spaces in urban areas. They absorb flows or carry stormwater runoff from heavy rains into sewer channels or directly to surface waters. Vegetated bioswales infiltrate, slow down, and filter stormwater flows that are most beneficial along streets and parking lots.",1
"The Trust for Public Land has completed 183 green school yards across the 5 boroughs in New York. Existing asphalt school yards are converted to a more vibrant and exciting place while also incorporating infrastructure to capture and store rainwater: rain garden, rain barrel, tree groves with pervious pavers, and an artificial field with a turf base. The children are engaged in the design process, lending to a sense of ownership and encourages children to take better care of their school yard. Success in New York has allowed other cities like Philadelphia and Oakland to also convert to green school yards.",1
"In the United Kingdom, Green Infrastructure planning is increasingly recognised as a valuable approach for spatial planning and is now seen in national, regional and local planning and policy documents and strategies, for example in the Milton Keynes and South Midlands Growth area.In 2009, guidance on green infrastructure planning was published by Natural England. This guidance promotes the importance of green infrastructure in 'place-making', i.e. in recognizing and maintaining the character of a particular location, especially where new developments are planned.In",1
"2012, the Greater London Authority published the All London Green Grid Supplementary Planning Guidance (ALGG SPG) which proposes an integrated network of green and open spaces together with the Blue Ribbon Network of rivers and waterways. The ALGG SPG aims to promote the concept of green infrastructure, and increase its delivery by boroughs, developers, and communities, to benefit areas such as sustainable travel, flood management, healthy living and the economic and social uplift these support.Green Infrastructure is being promoted as an effective and efficient response to projected climate change.Green Infrastructure may include geodiversity objectives.",1
"green infrastructure is yet to become a mainstream practice, many US cities have initiated its implementation to comply with their MS4 permit requirements. For example, the City of Philadelphia has installed or supported a variety of retrofit projects in neighborhoods throughout the city. Installed improvements include: permeable pavements in parks, basketball courts and parking lots rain gardens and bioretention systems at schools and other public facilities constructed wetlands for management of stormwater runoff.Some of these facilities reduce the volume of runoff entering the city's aging combined sewer system, and thereby reduce the extent of system overflows during rainstorms.Another U.S.",1
"A valuable new tool not only for making land conservation decisions today, but for building a broader and better informed public consensus for sustainable growth and land preservation decisions into the future. The program was established in 2001 with the objective to ""preserve an extensive intertwined network of lands vital to the long-term protection of the State's natural resources, in concert with other Smart Growth initiatives.""In April 2011, EPA announced the Strategic Agenda to Protect Waters and Build More Livable Communities through Green Infrastructure and the selection of the first ten communities to be green infrastructure partners.",1
"The communities selected were: Austin, Texas; Chelsea, Massachusetts; the Northeast Ohio Regional Sewer District (Cleveland, Ohio); the City and County of Denver, Colorado; Jacksonville, Florida; Kansas City, Missouri; Los Angeles, California; Puyallup, Washington; Onondaga County and the City of Syracuse, New York; and Washington, D.C.The Federal Emergency Management Agency (FEMA) is also promoting green infrastructure as a means of managing urban flooding (also known as localized flooding).",1
"Since 2009, two editions of the ABC (Active, Beautiful, Clean) Waters Design Guidelines have been published by the Public Utilities Board, Singapore. The latest version (2011) contains planning and design considerations for the holistic integration of drains, canals and reservoirs with the surrounding environment. The Public Utilities Board encourages the various stakeholders — landowners, private developers to incorporate ABC Waters design features into their developments, and the community to embrace these infrastructures for recreational & educational purposes.",1
"A 2012 paper by the Overseas Development Institute reviewed evidence of the economic impacts of green infrastructure in fragile states. Upfront construction costs for GI were up to 8% higher than non-green infrastructure projects. Climate Finance was not adequately captured by Fragile states for GI investments, and governance issues may further hinder capability to take full advantage.GI Investments needed strong government participation as well as institutional capacities and capabilities that fragile states may not possess.",1
"Potential poverty reduction includes improved agricultural yields and higher rural electrification rates, benefits that can be transmitted to other sectors of the economy not directly linked to the GI investment.Whilst there are examples of GI investments creating new jobs in a number of sectors, it is unclear what the employment opportunities advantages are in respect to traditional infrastructure investments. The correct market conditions (i.e. labour regulations or energy demand) are also required in order to maximise employment creation opportunities. Such factors that may not be fully exploited by fragile state governments lacking the capacity to do so.",1
"GI investments have a number of co-benefits including increased energy security and improved health outcomes, whilst a potential reduction of a country's vulnerability to the negative effects of climate change being arguably the most important co-benefit for such investments in a fragile state context.There is some evidence that GI options are taken into consideration during project appraisal. Engagement mostly occurs in projects specifically designed with green goals, hence there is no data showing decision making that leads to a shift towards any green alternative.",1
"Comparisons of costs, co-benefits, poverty reduction benefits or employment creation benefits between the two typologies are also not evident.Currently, an international standard for green infrastructure is developed: SuRe – The Standard for Sustainable and Resilient Infrastructure is a global voluntary standard which integrates key criteria of sustainability and resilience into infrastructure development and upgrade. SuRe is developed by the Swiss Global Infrastructure Basel Foundation and the French bank Natixis as part of a multi-stakeholder process and will be compliant with ISEAL guidelines.",1
"The foundation has also developed the SuRe SmartScan, a simplified version of the SuRe Standard which serves as a self-assessment tool for infrastructure project developers. It provides them with a comprehensive and time-efficient analysis of the various themes covered by the SuRe Standard, offering a solid foundation for projects that are planning to become certified by the SuRe Standard in the future. Upon completion of the SmartScan, project developers receive a spider diagram evaluation, which indicates their project's performance in the different themes and benchmarks the performances with other SmartScan assessed projects.",1
"In addition to referencing Chinese culture, the system is capable of significantly reducing nutrient loads from influent waters, which are provided by a nearby wastewater recycling facility.",1
"Farmers claimed that flooding of their farmlands was caused by suburban development upstream. The flooding was a result of funneled runoff directed into storm drains by impervious cove, which ran unmitigated and unabsorbed into their farmlands downstream. The farmers were awarded an undisclosed amount of money in the tens of millions as compensation. Low density and highly paved residential communities redirect stormwater from impervious surfaces and pipes to stream at velocities much greater than predevelopment rates. Not only are these practices environmentally damaging, they can be costly and inefficient to maintain.",1
"In response, the city of Surrey opted to employ a green infrastructure strategy and chose a 250-hectare site called East Clayton as a demonstration project. The approach reduced the stormwater flowing downstream and allows for infiltration of rainwater closer if not at its point of origin. In result, the stormwater system at East Clayton had the ability to hold one inch of rainfall per day, accounting for 90% of the annual rainfall. The incorporation of green infrastructure at Surrey, British Columbia was able to create a sustainable environment that diminishes runoff and to save around $12,000 per household.",1
"Contaminants include PCBs, coal tar wastes, heavy metals, and volatile organics. On March 2, 2010, EPA added the canal to its Superfund National Priorities List (NPL). Placing the canal on the list allows the agency to further investigate contamination at the site and develop an approach to address the contamination. After the NPL designation, several firms tried to redesign the area surrounding the canal to meet EPA's principles. One of the proposals was the Gowanus Canal Sponge Park, suggested by Susannah Drake of DLANDstudio, an architecture and landscape architecture firm based in Brooklyn.",1
"Another strategy was to restore the native ecology of the corridor, giving special attention to the ecotones that bisect the site. The design proposed retrofitting historic buildings with stormwater management techniques, such as rainwater collection systems, which allows historic buildings to be preserved. This project received the Award of Excellence from the ASLA in 2013. A geographic information system (GIS) is a computer system for that allows users to capture, store, display, and analyze all kinds of spatial data on Earth. GIS can gather multiple layers of information on one single map regarding streets, buildings, soil types, vegetation, and more.",1
"An example of how this might work is found in Oregon's Energy Efficiency Construction Credits. In Eugene, Oregon, a new biofuel station built on an abandoned gas station site included a green roof, bioswales and rain gardens. In this case, nearly $250,000 worth of tax credits reduced income and sales tax for the private company that built and operated the project. The U.S. Department of Treasury administers the multibillion-dollar New Markets Tax Credit Program, which encourages private investment for a range of project types (typically real estate or business development projects) in distressed areas.",1
Awards are allocated to non-profit and private entities based on their proposals for distributing these tax benefits.,1
"Native trees, shrubs, and herbaceous perennials of the wetland and riparian zones being the most useful for runoff detoxification.As a result, high performing green spaces work to create a balance between built and natural environments.",1
"The new greenery will increase property values by $390 million over 45 years, also boosting the property taxes the city takes in.A green infrastructure plan in New York City is expected to cost $1.5 billion less than a comparable grey infrastructure approach. Also, the green stormwater management systems alone will save $1 billion, at a cost of about $0.15 less per gallon. The sustainability benefits in New York City range from $139–418 million over the 20 year life of the project. This green plan estimates that “every fully vegetated acre of green infrastructure would provide total annual benefits of $8.522",1
"PaveShare – Permeable Paver Design Green Infrastructure Case Studies The Conservation Fund Save the Rain – Onondaga County, NY Maryland's Green Infrastructure- Maryland Department of Natural Resources Sonoran Desert Conservation Plan – Pima County, Arizona The Center for Green Infrastructure Design – The Center for Green Infrastructure Design Green Infrastructure Wiki Low Impact Development – The Low Impact Development Center (US) Green Infrastructure Resource Center – American Society of Landscape Architects Gowanus Sponge Park – ASLA award winner project Global Infrastructure Basel Foundation (GIB)",1
[3] Badal gives go ahead to NEER project for Budha Nullha | LivePunjab - Express India [4] Green bridge tech helps restore nullah - Times Of India [5] India Together: Cost-effective technology stalled by Pune government - 31 May 2010 [6],1
"From 1965 to 1967, the Soviet Yuzhnoye Design Office developed two satellite ELINT systems: Tselina-O for broad observations and Tselina-D for detailed observations. The ELINT payloads (satellites) for Tselina were first tested under the Kosmos designation in 1962–65. The Soviet Ministry of Defence could not convince the different parts of the Soviet military to decide between the two, so both systems were brought into service. The first production Tselina-O was launched in 1970. The Tselina-D took longer to enter service, due to delays with the satellite development and problems with the mass budget. The full Tselina system became operational in 1976.",1
"Continued improvements in the satellite systems led to Tselina-O being abandoned in 1984, with all of the capabilities of the two satellite systems being combined into Tselina-D. Kosmos-1408 was part of the Tselina-D system. It had a mass of around 1,750 kg (3,860 lb), and a radius of around 2.5 m (8 ft 2 in). It is thought to have replaced Kosmos-1378 in the Tselina system, since it was launched into a similar orbital plane.Kosmos-1408 was launched on a Tsyklon-3 launch vehicle on 16 September 1982, from Site 32/2, at the Plesetsk Cosmodrome.",1
"It was placed in low Earth orbit, with a perigee of 645 km (401 mi), an apogee of 679 km (422 mi), and an inclination of 82.5°. Its orbital period was 97.8 minutes.The satellite had an expected lifespan of around six months, but it operated for around two years. The satellite could not be de-orbited after finishing operations because it did not have a propulsion system. Its orbit subsequently slowly decayed due to the small natural drag of the thermosphere. On 15 November 2021, at around 02:50 UTC, the satellite was destroyed as part of an anti-satellite weapons test by Russia.",1
"The direct-ascent anti-satellite A-235 ""Nudol"" anti-ballistic missile was launched from Plesetsk Cosmodrome at around 02:45 UTC. The system had been undergoing testing since 2014, but this was the first satellite it destroyed. The Outer Space Treaty, which Russia has ratified, bans some types of military activities in space, but not anti-satellite missiles using conventional warheads.The destruction of the satellite and missile produced a cloud of space debris that threatened the International Space Station.",1
"The seven crew members aboard the ISS (four American, two Russian, one German) were told to put on their spacesuits and take shelter in the crew capsules so they could quickly return to Earth if debris struck the station. The satellite had been in orbit at an altitude ~50 kilometers (~30 miles) above the ISS orbital altitude, with the debris intersecting the orbit of the ISS every 93 minutes.The crew sheltered for only the second and third passes through the debris field, based on an assessment of the debris risk.",1
"There is no evidence that any debris hit the station, but the risk of a potential impact was thought to be increased by a factor of five for the following weeks and months, and the longer term risk was doubled. In June 2022 the ISS had to manoeuvre to avoid a piece of debris from the satellite. The debris can also pose a risk to other low Earth orbit satellites, and several SpaceX Starlink satellites underwent maneuvers to reduce the risk of collision with the debris. On 18 January 2022 there was a near miss (separated by only 14.5",1
"metres (48 ft)) between a piece of debris and the Tsinghua Science Satellite.On 15 November, the US State Department reported that it had identified about 1,500 pieces of debris that can be tracked by ground-based radar, and hundreds of thousands more that are more difficult to track. The same day, breakup of the satellite was independently confirmed by Numerica Corporation and Slingshot Aerospace. By 16 November 2021, the debris was orbiting at altitudes between 440 and 520 km (270 and 320 mi); by 17 November 2021 this range increased to 300 to 1,100 km (190 to 680 mi).On",1
"18 November 2021, LeoLabs, a commercial tracking company, detected around 300 pieces and also estimated that there were around 1,500 ground-trackable pieces in total. They found this lower than expected, compared to other anti-satellite tests, meaning that the pieces are expected to have higher masses so will stay in orbit for longer, and that the lower-than-expected number of debris pieces might be because the event was not a hypervelocity collision. By 21 December, LeoLabs was tracking around 500 pieces of debris, including several large items that are thought to be the solar panels, antennas and booms from the satellite.The",1
"low altitude of the satellite means the debris swarm is expected to be short-lived. As of February 2023 only 300 of the initial 1,790 pieces of debris (17 %) were still in orbit. Increasing solar activity during solar cycle 25 is causing the debris to decay at a faster rate than usual.",1
"The US State Department accused Russia of having targeted Kosmos 1408 during an anti-satellite weapon test, using a ground-based missile against their own defunct satellite, saying that it was ""dangerous and irresponsible"". On 15 November the Russian foreign minister, Sergei Lavrov, stated that there was no risk to the ISS or other peaceful uses of space. On 16 November, Sergei Shoigu, the Russian minister of defence, acknowledged that the destruction of the satellite was due to a Russian missile test, but argued that it posed no threat to any space activities.NASA",1
"administrator Bill Nelson stated that: ""With its long and storied history in human spaceflight, it is unthinkable that Russia would endanger not only the American and international partner astronauts on the ISS, but also their own cosmonauts"", and the ""actions are reckless and dangerous, threatening as well [sic] the Chinese space station"".The Secure World Foundation, a U.S. think tank, called upon the United States, Russia, China, and India to declare unilateral moratoriums on further testing of their antisatellite weapons.",1
1985 ASM-135 ASAT test – United States first anti-satellite missile test 2007 Chinese anti-satellite missile test Gravity – 2013 science fiction movie in which a Russian satellite shoot-down creates a catastrophic Kessler syndrome–inciting debris swarm Kessler syndrome – hypothetical runaway debris cascade making low Earth orbit inaccessible for centuries Mission Shakti – 2019 Indian anti-satellite missile test Operation Burnt Frost – 2008 United States anti-satellite missile test,1
The rate of NO concentration increase is given by d [ N O ] d t = k 1 f [ N 2 ] [ O ] + k 2 f [ N ] [ O 2 ] + k 3 f [ N ] [ O H ] − k 1 b [ N O ] [ N ] − k 2 b [ N O ] [ O ] − k 3 b [ N O ] [ H ] {\displaystyle {\frac {d[\mathrm {NO} ]}{dt}}=k_{1f}[\mathrm {N} _{2}][\mathrm {O} ]+k_{2f}[\mathrm {N} ][\mathrm {O} _{2}]+k_{3f}[\mathrm {N} ][\mathrm {OH} ]-k_{1b}[\mathrm {NO} ][\mathrm,1
"{N} ]-k_{2b}[\mathrm {NO} ][\mathrm {O} ]-k_{3b}[\mathrm {NO} ][\mathrm {H} ]} Similarly, the rate of N concentration increase is d [ N ] d t = k 1 f [ N 2 ] [ O ] − k 2 f [ N ] [ O 2 ] − k 3 f [ N ] [ O H ] − k 1 b [ N O ] [ N ] + k 2 b [ N O ] [ O ] + k 3 b [ N O ] [ H ] {\displaystyle {\frac {d[\mathrm {N} ]}{dt}}=k_{1f}[\mathrm {N} _{2}][\mathrm {O} ]-k_{2f}[\mathrm {N} ][\mathrm",1
{O} _{2}]-k_{3f}[\mathrm {N} ][\mathrm {OH} ]-k_{1b}[\mathrm {NO} ][\mathrm {N} ]+k_{2b}[\mathrm {NO} ][\mathrm {O} ]+k_{3b}[\mathrm {NO} ][\mathrm {H} ]},1
"If a treatability study shows no degradation (or an extended lab period before significant degradation is achieved) in contamination contained in the groundwater, then inoculation with strains known to be capable of degrading the contaminants may be helpful. This process increases the reactive enzyme concentration within the bioremediation system and subsequently may increase contaminant degradation rates over the nonaugmented rates, at least initially after inoculation.",1
Certain types of permeable reactive barriers utilize biological organisms in order to remediate groundwater.,1
Chemical oxidation has proven to be an effective technique for dense non-aqueous phase liquid or DNAPL when it is present.,1
Some permeable reactive barriers utilize chemical processes to achieve groundwater remediation.,1
"MTBE is manufactured via the chemical reaction of methanol and isobutylene. Methanol is primarily derived from natural gas, where steam reforming converts the various light hydrocarbons in natural gas (primarily methane) into carbon monoxide and hydrogen. The resulting gases then further react in the presence of a catalyst to form methanol. Isobutylene can be produced through a variety of methods. n-butane can be isomerized into isobutane which can be dehydrogenated to isobutylene. In the Halcon process, t-Butyl hydroperoxide derived from isobutane oxygenation is reacted with propylene to produce propylene oxide and t-butanol. The t-butanol can be dehydrated to isobutylene.",1
It is one of a group of chemicals commonly known as oxygenates because they raise the oxygen content of gasoline.,1
"Other oxygenates are available as additives for gasoline including ethanol and other ethers such as ETBE. Ethanol has been advertised as a safe alternative by agricultural and other interest groups in the U.S. and Europe. In 2003, California was the first U.S. state to start replacing MTBE with ethanol. An alternative to ethanol is ETBE, which is manufactured from ethanol and isobutene. Its performance as an additive is similar to MTBE, but due to the higher price of ethanol compared to methanol, it is more expensive. Higher quality gasoline is also an alternative, so that additives such as MTBE are unnecessary.",1
"This provision was first proposed in 2003 and had been thought by some to be a priority of Tom DeLay and Rep. Joe Barton, then chairman of the Energy and Commerce Committee. This bill did include a provision that gave MTBE makers, including some major oil companies, $2 billion in transition assistance while MTBE was phased out over the following nine years. Due to opposition in the Senate, the conference report dropped all MTBE provisions. The final bill was signed into law by President George W. Bush.",1
"1986 Boliden discontinued all operations at the San Francisco site in May 1986. All buildings at the site, with the exception of Building 1, the Office Building, Building 2, the Laboratory; and Buildings 11-12, the Melt Shop, and Mechanical Processing area, were demolished and the business was moved to our current location in Gilroy, CA. Trelleborg, (the parent company of Boliden), later spun off the smelting operations under the name Boliden but retained Metech as a recycling and processing operation. In 2002 Viking Investment and Asset Management, based in Johannesburg, South Africa, bought Metech.",1
"2005 In 2005 Metech was acquired by MTI Corp and relocated the corporate offices from Mapleville, RI to Worcester, Mass. The company designed a processing line to include shredders and downstream separation equipment. At this time, Metech also discontinued receiving precious-metals-containing hazardous waste and scaled back its other local precious metals refining businesses that were not adding value to the company’s focus on integrated electronics recycling. 2007 In 2007 Metech was acquired by “Centillion Environment and Recycling Ltd” of Singapore. In 2008 Centillion purchases “Guaranteed Recycling Xperts” (GRX) with locations in Denver, CO, Salt Lake City, UT and Omaha, NE.",1
"2009 2009 Centillion merges Metech and GRX under the Metech Recycling banner. In 2012 Centillion was renamed Metech International 2016 In 2016 the Worcester facility was relocated once more to its current location in nearby Clinton, MA. At this time, corporate operations were permanently transferred to the Gilroy, CA facility. 2018 In 2018 Metech Recycling was purchased from METech International Pte by First America Management Group and taken Private. 2021 The METech Creedmoor location relocates to Roxboro, NC.",1
"METech continues to operate with a strong national footprint serving industries across the United States in industries such as medical, military, government, education, manufacturing and many more. IT Asset Management Data security Data erasure Computer Recycling Electronic waste Electronic devices Grossman, Elizabeth (2006). High Tech Trash- Digital Devices, Hidden Toxics, and Human Health. Island Press. ISBN 1-55963-554-1. Metech Recycling, Inc.:Home Audit: Government could do more in e-waste arena; Utah steps up http://yosemite.epa.gov/opa/admpress.nsf/0/54fcf812f3cb2972852579260068d977?OpenDocument",1
"Established: 1977 Number of sites: ~350 different site locations Numbers of users: >37,000",1
"The National Atmospheric Deposition Program, or NADP, was initiated by the State Agricultural Experiment Station in 1977 to monitor the effects of atmospheric deposition on crops, rangelands, forests, surface waters, and other natural and cultural resources. The initial goal was to provide regional data for the deposition of acids, nutrients, and base cations (including temporal trends/amounts and geographic distributions).In 1978, the first NADP sites began collecting weekly precipitation samples. In the early 1980s, the National Acid Precipitation Assessment Program (NAPAP). was established, and began to work in collaboration with NADP in order to sustain a long term, quality-assured precipitation monitoring network.",1
"This unification brought on a major expansion as well as newfound federal agency support. Today, the NADP National Trends Network (NTN) has more than 250 sites. In response to emerging issues, the NADP established an additional two networks in the 1990s: The Atmospheric Integrated Research Monitoring Network (AIRMoN), which collected daily samples at five sites, and the Mercury Deposition Network (MDN), which has more than 80 sites (six of which are located in Canada). The MDN collects wet deposition data for both total and methyl mercury in precipitation.In",1
"2009, the Atmospheric Mercury Network (AMNet) was formed as a fourth network, and as a subset of some MDN sites. The network uses continuous automatic measurement systems to monitor gaseous and particulate concentrations of atmospheric mercury. The Ammonia Monitoring Network (AMoN) was added as a fifth network in October 2010, and it currently has more than 100 sites. AMoN monitors ammonia gas concentrations across the United States to provide consistent and lasting data The Mercury Litterfall Network (MLN) was approved as the sixth network in 2021 with 22 sites.",1
MLN provides estimates of mercury dry deposition in forested landscapes using passive collectors.,1
"To reflect the federal NAPAP role in the NADP, the network name was changed to NADP National Trends Network (NTN)",1
"The organizational structure of the NADP follows the State Agricultural Experiment Station Guidelines for Multi-State Research Activities (SAESD, 2006)1. This framework allows any individual or institution to participate in any segment of NADP, whether it be the monitoring or the research aspect of atmospheric deposition. NADP is managed by two groups. The first being Program Management, which is largely a volunteer group made up of site sponsors and supervisors, policy experts from several agencies (at the federal, state, and local levels), scientists and research specialists, and anyone with an interest in atmospheric deposition.",1
"Program Management is organized through an Executive Committee, Technical Subcommittees, several advisory subcommittees, science subcommittees, and ad hoc groups. The second group is Program Operations, which is managed by a professional staff housed at the Wisconsin State Laboratory of Hygiene at the University of Wisconsin-Madison. The Program Office oversees day to day tasks, including coordinating with the Executive Committee, the individual monitoring networks, the analytical laboratories, the External Quality Assurance Program, and the Network Equipment Depot.",1
"The NADP is governed by an elected and rotating Executive Committee (8 members). Currently, there are two standing Subcommittees, three standing Advisory Committees, and four Science Committees (highlighted below) that contribute continuous, scheduled suggestions to the Executive Committee. Ad hoc groups and the Program Office also supply crucial input to the Executive Committee. The Executive Committee (EC) is responsible for considering and, if approved, executing decisions which are often based on the suggestions made by the subcommittees, advisory committees, science committees, and ad hoc groups.",1
"In addition, the EC is accountable for financial decisions and securing a balanced, stable, and ongoing program. There are eight voting members, as well as numerous non-voting members, that make decisions and appoint responsibilities to the subcommittees. The two standing Technical Subcommittees, Education and Outreach Subcommittee (EOS) (formally the Ecological Response and Outreach Subcommittee) and Network Operations Subcommittee (NOS), provide the technical support necessary to promote the goals of NADP. EOS maintains a platform to coordinate outreach and education activities among the network and scientific subcommittees.",1
"With approval and recommendation from the Executive Committee, EOS will provide guidance for outreach efforts and educational materials to the Program Office. EOS will provide a forum to enable communication of outreach and education needs, goals and activities of the subcommittees and networks. The goal is to enhance efficiency in messaging and reaching new audiences. The NOS focuses more on equipment, research, sampling methods, collection sites, and the evaluation of the issues that arise from these components. The three advisory subcommittees include the Budget Advisory Committee (BAC), Quality Assurance Advisory Group (QAAG), and Data Management Advisory Group (DMAG).",1
"The role of the BAC is to advise the EC with suggestions pertaining to the budget, and to outline financial planning for current and future years. The QAAG is in charge of ensuring quality management in all aspects of NADP, including the Program Office, networks, and laboratories. To do so, they provide recommendations for manuals and procedures to the EC. The DMAG counsels the EC in data management by reviewing data reports and formats in order to ensure that they are in line with the correct protocols. The science committees do not directly advise NADP networks, but they are closely affiliated.",1
"A fourth Science Committee, the Mercury in the Environment and Links to Deposition Science Committee was formed in 2020 to improve our understanding of atmospherically-derived mercury sources, pathways, processes, and effects on the environment. All NADP operations are administered at the NADP Program Office, which is currently located at the Wisconsin State Laboratory of Hygiene at the University of Wisconsin–Madison. The five main functions of the Program Office are network administration, management, meetings and trainings, data and publications, and quality assurance and management.",1
"Network administration involves overseeing the endeavors of all five networks, managing sample analysis, and coordinating data storage and user availability. These functions are executed from the two analytical laboratories housed at WSLH: The Central Analytical Lab, which analyses samples from the NTN, AMoN, and AIRMoN networks, and the Mercury (Hg) Analytical Laboratory (HAL). The HAL was previously housed at Eurofins Frontier Global Sciences, Inc. in Bothell, Washington. In addition, the Network Equipment Depot, located at the WSLH, provides spare parts for NADP field equipment and troubleshoots site operation problems.",1
"The CAL also measures orthophosphate, but only for quality assurance as an indicator of sample contamination.",1
"The MDN measures total mercury concentrations on a weekly basis (methyl mercury is measured monthly at some sites), which provides wet deposition data for surface waters and other waterways. The goal is to deliver accurate information that allows researchers to evaluate the linkage between mercury and health, which is strengthened by its large spatial and temporal footprint.",1
The MLN can provide an important component of mercury dry deposition to a forested landscape. The importance of litterfall mercury data for quantifying atmospheric mercury deposition to forests was demonstrated with studies at NADP sites in the eastern USA from 2007-2009 and 2007 to 2014.,1
Brochures Annual Data Summaries Quality Assurance Reports CLAD Science Committee Reports TDep Science Committee Reports AMSC Study Plan MELD Science Committee Reports,1
"Accurate and consistent measurement of gases and deposition at every monitoring site is of the utmost importance to the NADP. This is accomplished, in part, by ensuring that all sites adhere to specific standard operating procedures. This provides consistent methodology at all sites within the networks. The SOPs can be viewed here: http://nadp.slh.wisc.edu/siteops/",1
"In the United Kingdom, brownfield land and previously developed land (PDL) have the same definition under the National Planning Policy Framework (NPPF). The government of the United Kingdom refers to them both as: ""Land which is or was occupied by a permanent structure, including the curtilage of the developed land (although it should not be assumed that the whole of the curtilage should be developed) and any associated fixed surface infrastructure.""They",1
"exclude land that: ""is or has been occupied by agricultural or forestry buildings; has been developed for minerals extraction or waste disposal by landfill purposes where provision for restoration has been made through development control procedures; land in built-up areas such as private residential gardens, parks, recreation grounds and allotments; and land that was previously developed but where the remains of the permanent structure or fixed surface structure have blended into the landscape in the process of time.""",1
"Generally, post industrial brownfield sites exist in a city's or town's industrial section, on locations with abandoned factories or commercial buildings, or other previously polluting operations like steel mills, refineries or landfills.Small brownfields also may be found in older residential neighborhoods, as for example dry cleaning establishments or gas stations produced high levels of subsurface contaminants. Typical contaminants found on contaminated brownfield land include hydrocarbon spillages, solvents, pesticides, heavy metals such as lead (e.g., paints), tributyl tins, and asbestos. Old maps may assist in identifying areas to be tested.",1
"Canada has an estimated 200,000 ""contaminated sites"" across the nation. As of 2016 Canada had about 23,078 federally recognized contamination sites, from abandoned mines, to airports, lighthouse stations, and military bases, which are classified into N 1,2,or 3, depending on a score of contamination, with 5,300 active contaminated sites, 2,300 suspected sites and 15,000 listed as closed because remediated or no action was necessary.The provincial governments have primary responsibility for brownfields.",1
"The provinces' legal mechanisms for managing risk are limited, as there are no tools such as ""No Further Action"" letters to give property owners finality and certainty in the cleanup and reuse process. Yet, Canada has cleaned up sites and attracted investment to contaminated lands such as the Moncton rail yards. A strip of the Texaco lands in Mississauga is slated to be part of the Waterfront Trail. However, Imperial Oil has no plans to sell the 75-acre (30 ha) property which has been vacant since the 1980s.",1
"Port Hope has the largest volume of historic low-level radioactive wastes in Canada, resulting from ""radium and uranium processing in Port Hope between 1933 and 1988 by the former Crown corporation Eldorado Nuclear Limited and its private sector predecessors. By 2010 it was projected that it would cost well over a billion dollars for the soil remediation project, it was the largest such cleanup in Canadian history. The effort is projected to be complete in 2022.",1
"4–5 Under the Shared-Responsibility Contaminated Sites Policy Framework (2005), the government may provide funding for the remediation of nonfederal sites, if the contamination is related to federal government activities or national security. See Natural Resources Canada (2012)",1
"While Denmark lacks the large land base which creates the magnitude of brownfield issues facing countries such as Germany and the U.S., brownfield sites in areas critical to the local economies of Denmark's cities require sophisticated solutions and careful interaction with affected communities. Examples include the cleanup and redevelopment of former and current ship building facilities along Copenhagen's historic waterfront. Laws in Denmark require a higher degree of coordination of planning and reuse than is found in many other countries.",1
"In France, brownfields are called friches industrielles and the Ministère de l'Écologie, du Développement Durable et de l'Énergie (MEDDE) maintains a database of polluted sites named BASOL, with ""more than 4000 sites"". of about 300,000 to 400,000 potentially polluted sites total (around 100,000 ha), in a historical inventory named BASIAS, maintained by the Agence de l'Environnement et de la Maitrise de l'Energie (ADEME).",1
"In 2018, the Campaign to Protect Rural England (CPRE) reported that the 17,656 sites (covering over 28,000 hectares of land) identified by English local planning authorities on their Brownfield Land Registers would provide enough land for a minimum of 1 million homes, which could rise to over 1.1 million once all registers are published. The registers contain land that is available for redevelopment so is a small subset of all land that would be considered brownfield.",1
"There is also brownfield capacity in areas in which the green belt is in danger, for example in Northwest England , where local authorities have identified enough brownfield land to provide for 12 years of housing demand.",1
"Michigan State University, in collaboration with DaimlerChrysler and NextEnergy, has small plots of soybean, corn, canola, and switchgrass growing in a former industrial dump site in Oakland County, Michigan. The intent is to see if the plants can serve two purposes simultaneously: assist with phytoremediation, and contribute to the economical production of biodiesel and/or ethanol fuel.The regeneration of brownfields in the United Kingdom and in other European countries has gained prominence due to greenfield land restrictions as well as their potential to promote the urban renaissance.",1
"states and localities have spent considerable money assessing the contamination on local brownfield sites, to quantify the cleanup costs in an effort to move the redevelopment process forward. Therefore, federal and state programs have been developed to help developers interested in cleaning up brownfield sites and restoring them to practical uses.In the process of cleaning contaminated brownfield sites, previously unknown underground storage tanks, buried drums or buried railroad tank cars containing wastes are sometimes encountered. Unexpected circumstances increase the cost for study and clean-up. As a result, the cleanup work may be delayed or stopped entirely.",1
"To avoid unexpected contamination and increased costs, many developers insist that a site be thoroughly investigated (via a Phase II Site Investigation or Remedial Investigation) prior to commencing remedial cleanup activities.",1
"As of 2006 the Atlantic Station project in Atlanta, was the largest brownfield redevelopment in the United States. Dayton, like many other cities in the region, is developing Tech Town in order to attract technology-based firms to Dayton and revitalize the downtown area. In Homestead, Pennsylvania, the site once occupied by Carnegie Steel has been converted into a successful commercial center, The Waterfront.Pittsburgh, Pennsylvania, has successfully converted numerous former steel mill sites into high-end residential, shopping, and offices.",1
"Examples of brownfield redevelopment in Pittsburgh include: In Pittsburgh's Squirrel Hill neighborhood, a former slag dump for steel mills was turned into a $243 million residential development called Summerset at Frick Park. In Pittsburgh's South Side neighborhood, a former LTV Steel mill site was transformed into Southside Works, a mixed-use development that includes high-end entertainment, retail, offices, and housing. In the Hazelwood (Pittsburgh) neighborhood, a former Jones and Laughlin steel mill site was transformed into a $104 million office park called Pittsburgh Technology Center.",1
"In Herr's Island, a 17-hectare (42-acre) island on the western bank of the Allegheny River, a former rail stop for livestock and meatpacking was transformed into Washington's Landing, a waterfront center for commerce, manufacturing, recreation and upscale housing",1
"It can also provide tax incentives for cleanup that is not paid for outright; specifically, cleanup costs are fully tax-deductible in the year they are incurred. Many of the most important provisions on liability relief are contained in state codes that can differ significantly from state to state.",1
United States EPA Brownfields Homepage Parents Demand Curbs on Schools Built on Contaminated Land Photographies of French Brownfields. Photographies of German Brownfields. National Brownfields Conference cosponsored by the U.S. EPA and ICMA From Industrial Wasteland to Community Park From Brownfield to Greenfield: A New Working Landscape for Wellesley College Wrenched from its Toxic Past The Brownfields Center at Carnegie Mellon University Browninfo Methodology and Software for Development of Interactive Brownfield Databases Brownfield Land at Curlie,1
"Chapter-1 PriliminaryShort Title; Extent; Application and; Definitions. (Reg 1–2) Chapter-IIReturns, Notices and Plans. (Reg 3–9) Chapter-III : Inspectors, Management and DutiesQualifications; Appointment; General Management and; Duties of Pe ns Employed in Mines for various functions.",1
"(Reg 10–23) Chapter-IV : Drilling and WorkoverReg 24- Derricks; 25- Derrick platforms and floors; 26- Ladders; 27- Safety belts and life lines; 28- Emergency escape device; 29- Weight indicator; 30- Escape exits; 31- Guardrails, handrails and covers; 32- Draw-works; 33- Cathead and cat line; 34- Tongs; 35- Safety chains or wire lines; 36- Casing lines; 37- Rigging equipment for material handling; 38- Storage of materials; 39- Construction and loading of pipe-racks; 40- Rigging-up and rig dismantling; 41- Mud tanks and mud pumps; 42- Blowout preventer assembly; 43- Control system for blowout preventers; 44- Testing of blowout preventer assembly; 45- Precautions against",1
"blowout; 46- Precautions after a blowout has occurred; 47- Drilling workover and other operations; 48- Precautions during drill stem test. Chapter-V: ProductionWell completion, Testing and Activation (Reg 49–50) Group Gathering Station and Emergency Plan (Reg 51-51A) Precautions during acidizing operations; fractu operations and; loading and unloading of petroleum tankers. (Reg 52–54) Storage Tank; Well servicing operations; Artificial lifting of oil; Temporary closure of producing well and; Plugging requirements of abandoned wells (Reg 55–59) Chapter-V: ProductionApplication (Reg-60) Chapter-VI : Transport and pipelinesApproval and design of the route and design of pipeline, their laying and, Emergency procedure.",1
"Discharge in relation to oil or to an oily mixture means any discharge or escape howsoever caused Heavy diesel oil means marine diesel oil, other than those distillates of which more than fifty percent by volume distils at a temperature not exceeding 340 °C / 644 °F when tested by American Society for Testing and Materials standard method D158-53 Mile means a nautical mile of 6,080 feet (1,850 m) Oil means persistent oils, such as crude oil, fuel oil, heavy diesel oil, and lubricating oil.",1
"far east as the lower exit of the Lachine Canal Montreal in the Province of Quebec, Canada. Secretary means the Secretary of the United States Army",1
"Adriatic Zones - Within the Adriatic Sea the prohibited zones off the coasts of Italy and Yugoslavia respectively shall each extend for a distance of 50 miles (80 km) from land, excepting only the island of Vis.",1
North Sea Zones - The North Sea zone shall extend for a distance of 100 miles (160 km) from the coasts of the following countries: Belgium Denmark Federal Republic of Germany Netherlands United Kingdom of Great Britain and Northern Ireland but not beyond the point where the limit of a 100 miles (160 km) zone off the west coast of Jutland intersects the limit of the 50 miles (80 km) zone off the coast of Norway.,1
"Atlantic Zones - Atlantic zone shall be within a line drawn from a point on the Greenwich meridian 100 miles (160 km) in a north-north-easterly direction from the Shetland Islands; thence northwards along the Greenwich meridian to latitude 64° north; thence westwards along the 64th parallel to longitude 10° west (64°00′00″N 10°00′00″W); thence to latitude 60° north, longitude 14° west (60°00′00″N 14°00′00″W); thence to latitude 54° 30' north, longitude 30° west (54°30′00″N 30°00′00″W); thence to latitude 44° 20' north, longitude 30° west (44°20′00″N 30°00′00″W); thence to latitude 48° north, longitude 14° west (48°00′00″N 14°00′00″W); thence eastwards along the 48th parallel to",1
"a point of intersection with the 50 miles (80 km) zone off the coast of France. Australian Zone - Australian Zone shall extend for a distance of 150 miles (240 km) from the coasts of Australia, except off the north and west coasts of the Australian mainland between the point opposite Thursday Island and the point on the west coast at 20° south latitude (20°00′00″S 119°40′00″E).",1
"""Automatic Identification System Vessel Tracking"". VesselFinder.com.",1
"Greywater usually contains some traces of human waste and is therefore not free of pathogens. The excreta come from washing the anal area in the bath and shower or from the laundry (washing underwear and diapers). The quality of greywater can deteriorate rapidly during storage because it is often warm and contains some nutrients and organic matter (e.g. dead skin cells), as well as pathogens. Stored greywater also leads to odour nuisances for the same reason.",1
"The main advantage of keeping greywater separate from toilet wastewater is that the pathogen load is greatly reduced, and the greywater is therefore easier to treat and reuse.When greywater is mixed with toilet wastewater, it is called sewage or blackwater and should be treated in sewage treatment plants or an onsite sewage facility, which is often a septic system. Greywater from kitchen sinks contains fats, oils and grease, and high loads of organic matter. It should undergo preliminary treatment to remove these substances before discharge into a greywater tank.",1
"However, the California Plumbing Code, derived from the UPC, permits it.",1
"Laws governing oil spills in the United States began in 1851 with the Limitation of Liability Act. This statue, in an attempt to protect the shipping industry, stated that vessel owners were liable for incident-related costs up to the post-incident value of their vessel. The shortcomings of this law were revealed in 1967 with the release of over 100,000 tons of crude oil into the English Channel from the Torrey Canyon. Of the $8 million of cleanup-related costs, the owners of the Torrey Canyon were held liable for only $50—the value of the only remaining Torrey Canyon lifeboat.",1
"Soon afterward, in June 1989, three smaller spills occurred within coastal waters of the United States. This was timely evidence that oil spills were not uncommon.Alaska Governor Steve Cowper authorized the creation of the Alaska Oil Spill Commission in 1989 to examine the causes of the Exxon Valdez oil spill and issue recommendations on potential policy changes. Cowper appointed Walter B. Parker, a longtime transportation consultant and public official, as the chairman of the commission. Under Parker, the Commission issued 52 recommendations for improvements to industry, state, and federal regulations.",1
"November 19, 1989: the bill was passed by the Senate, with revisions. The bill was sent back to the House of Representatives for approval of the changes added by the Senate. However, the House of Representatives did not agree to the revisions. August 2, 1990: a conference committee was created, including members of both the House of Representatives and Senate, in order to resolve differences and propose a final bill for approval. Initially, the Senate agreed to the committee's final proposed report. August 4, 1990: both chambers of Congress had passed the bill in identical form.",1
"In some instances, claims for removal cost reimbursement can be initially brought to the Oil Spill Liability Trust Fund thus sidestepping the responsible party. For example, claimants advised by the EPA, governors of affected states, and American claimants for incidents involving foreign vessels or facilities may initially present their claims to the Oil Spill Liability Trust Fund. When claims for removal cost reimbursement are brought to the fund, the claimant must prove that removal costs were sustained from activities required to avoid or alleviate effects of the incident and that such actions were approved or directed by the federal on-scene coordinator.In",1
"Not just the oil industry, but also the vessel owners and operators would be held liable for an oil spill, facing a significant increase in financial responsibility. The OPA's liability increase for vessel owners raised fears and concerns from the vast majority of the shipping industry. Vessel owners objected that additional oil spill penalties imposed by the states are free from OPA limitations of the Limitation of Liability Act of 1851.",1
"Ultimately, the threat of unlimited liability under the OPA and other state statutes has led countless oil shipping companies to reduce oil trade to and from the ports of the United States.However, there were positive reactions from the oil industries despite the newly enforced codes and regulations. In 1990, the oil industry united to form the Marine Spill Response Corporation (MRSC), a non-profit corporation whose expenses would be compensated by the oil producers and transporters. The major MRSC responsibility was to develop new response plans for oil spills cleanups and for the OPA-required remediation.",1
"Shipping companies like the Exxon Shipping reacted positively to OPA's efforts to reduce their risk of liability for oil spill disasters. To help ensure OPA compliance, Exxon Shipping compiled all state and federal regulations to which they must abide. Several independent and non-U.S. companies and operators, however, may avoid operations in the United States ports due to the OPA liability. Though the majority of elicited reactions and criticism from the enactment of OPA has been negative, it has nevertheless led to founding and designing safer requirements for ships and global oil trade.",1
"Lastly, OPA has the ability to directly impact the domestic oil production industry due to the rigorous offshore facility provisions. Financial responsibility: The U.S. Coast Guard is responsible for the implementation of the vessel provisions mandated by the Oil Pollutions Act. According to OPA, vessel owners need evidence of financial liability that covers complete responsibility of a disaster if their vessel weighs more than 300 gross tons.",1
"The majority of charterers refuse to pay more for higher grade vessels despite the liability and compensation regulations enforced by OPA. The new and safer double hull tanker vessels are approximately 15-20% more costly to operate. In 1992, approximately 60% of global vessels was at least fifteen years old or older. The major oil companies are still delaying the fleet replacement requirement of retiring single hull vessels mandated by OPA. For example, Exxon and Texaco have delayed the replacement of their single hull vessels for new double-hulled ships. However, companies like Chevron and Mobil have ordered two new double hull tankers.",1
"As a result of major companies withdrawing their plans to drill, many smaller, independent producers had entered to make a profit. By October 1993, 93% of all oil and natural gas exploration and drilling were from independents producers. Of these new exploration projects, approximately 85% of drilling operations were in the Gulf of Mexico. The independent oil producers generated nearly 40% of the crude oil in the United States and 60% of domestic natural gas.",1
Oily mixture means a mixture with any oil content. Discharge in relation to instantaneous rate of discharge of oil content means the rate of discharge of oil in liters per hour at any instant divided by the speed of the ship in knots at the same instant. Discharge of oil or oily mixture from a ship is prohibited unless I.) ship is proceeding en route II.) the instantaneous rate of discharge of oil content does not exceed 60 litres (13 imp gal; 16 US gal) per 1 mile (1.6,1
"km) Discharge of oil or oily mixture from a ship, other than tankers is prohibited unless I.) oil content of the discharge is less than one hundred parts per one million parts of the mixture II.) oil content of the discharge is made as far as practicable from the nearest land Discharge of oil or oily mixture from tankers is prohibited unless I.) Discharges from machinery space bilges shall be governed by the above provisions for ships other than tankers II.) Total quantity of oil discharge on a ballast voyage does not exceed 1/15000 of the total cargo carrying capacity III.)",1
Tanker is more than 50 miles (80 km) from the nearest land Nearest land means more than 50 miles (80 km) from a coastline Secretary means the Secretary of the department which governs the operations of the United States Coast Guard,1
"In cases where no building contract has previously been placed, the keel is laid or the tanker is at a similar stage of construction, after June 30, 1972United States tankers are required to have on board a certificate of compliance attesting to the construction of the nautical vessel in accordance with annex C to the convention as specified by tank arrangement and limitation of tank size.",1
"Australian Zone - northeastern coast of Australia or Queensland designated by a line drawn from a point on the coast of Australia in latitude 11 degrees south, longitude 142 degrees 08 minutes east (11°00′00″S 142°08′00″E) to a point in latitude 10 degrees 35 minutes south, longitude 141 degrees 55 minutes east (10°35′00″S 141°55′00″E). Great Barrier Reef - Coral reef protection zone of the Earth's largest coral reef system.",1
"thence to a point latitude 10 degrees 00 minutes south, longitude 142 degrees 00 minutes east (10°00′00″S 142°00′00″E) thence to a point latitude 9 degrees 10 minutes south, longitude 143 degrees 52 minutes east (9°10′00″S 143°52′00″E) thence to a point latitude 9 degrees 00 minutes south, longitude 144 degrees 30 minutes east (9°00′00″S 144°30′00″E) thence to a point latitude 13 degrees 00 minutes south, longitude 144 degrees 00 minutes east (13°00′00″S 144°00′00″E) thence to a point latitude 15 degrees 00 minutes south, longitude 146 degrees 00 minutes east (15°00′00″S 146°00′00″E) thence to a point latitude 18 degrees 00 minutes south, longitude",1
"147 degrees 00 minutes east (18°00′00″S 147°00′00″E) thence to a point latitude 21 degrees 00 minutes south, longitude 153 degrees 00 minutes east (21°00′00″S 153°00′00″E) thence to a point on the coast of Australia in latitude 24 degrees 42 minutes south, longitude 153 degrees 15 minutes east (24°42′00″S 153°15′00″E)",1
"Maritime Administration - U.S. Department of Commerce. December 1976. OCLC 822729563. ""Automatic Identification System Marine Tracking"". MarineTraffic.com. ""Automatic Identification System Vessel Tracking"". VesselFinder.com.",1
"The process of loosening the chaff from the grain so as to remove it is called ""threshing"" – traditionally done by milling or pounding. Separating remaining loose chaff from the grain is called ""winnowing"" – traditionally done by repeatedly tossing the grain up into a light wind, which gradually blows the lighter chaff away. This method typically uses a broad, plate-shaped basket or similar receptacle to hold and collect the winnowed grain as it falls back down.Domesticated grains such as durum and common wheat have been bred to have chaff that is easily removed.",1
"In 2000, the Institute hosted its first international conference: The Atlantic Coast Contaminant Workshop ACCW 2000, Endocrine Disruptors in the Marine Environment: Impacts on Marine Wildlife and Human Health, uniting international wildlife and human health scientists. Shortly thereafter, the Institute launched a coastal monitoring program, a lecture series, and education programs. In 2000, Shaw Institute began long-term research focused on marine sentinel species to characterize the extent of contamination of the northwest Atlantic marine ecosystem from Maine to New York, funded by the National Oceanic and Atmospheric Administration (NOAA).",1
"This work has shown that levels of toxic chemicals, such as polychlorinated biphenyls (PCBs), in northwest Atlantic harbor seals are among the highest in the world.In 2002, the Institute convened the Gulf of Maine Forum: Protecting Our Coastal and Offshore Waters in Blue Hill in conjunction with the Gulf of Maine Council on the Marine Environment, representing New England states and Canadian provinces. A year later, the Shaw Institute begins its student internships program for scientific research and monitoring. In 2004, the Ocean Environment Lecture Series is launched, attracting international experts in a variety of fields.",1
"That same year, the long-term Blue Hill Bay Monitoring Project, the first bay-wide health assessment of its kind, is established to produce a ten-year baseline dataset on conditions and issues of concern. In 2014, the project expands geographically to include Penobscot Bay and targets research on microplastics, invasive species, and seafood contamination. In 2012, the Institute pioneered microplastics research in Blue Hill Bay, Maine. Alarming findings about the presence of microplastics in coastal waters prompted concern for human health (via seafood consumption).",1
"In 2013, Shaw was lead investigator of a study that tested a group of firefighters in San Francisco and found that their blood contains high levels of flame retardants and cancer-causing chemicals such as dioxins and furans, produced by the burning of flame-retarded household materials. Based on these findings, in 2014, the Institute announced plans for a long-term study of chemical exposure and cancer risk in U.S. firefighters named the National Fire Fighter Cancer Biomarker Study, funded in part by IAFF and IAB.",1
"Starting in 2017, the Institute began a multi-year project and partnership with researchers from Sweden, Greenland and Iceland to assess the converging impacts of climate change and flame retardant chemicals on marine mammals from the US Atlantic, Baltic, and Arctic seas. In 2012, Shaw Institute conducted the first microplastics study of its kind in the Gulf of Maine. Using new collection methods, they detected an average of 17 microplastic fragments per liter in local seawater samples. These high results prompted the institute to monitor input sites including stream and river mouths around Blue Hill Bay.",1
"2018, in partnership with Bigelow Laboratory for Ocean Sciences, Shaw Institute scientists lead a 2018 study on the uptake and expulsion of microplastic fibers by blue mussels (Mytilus edulis) in the Gulf of Maine. In 2019, the Shaw Institute partnered with the international Plastics Health Coalition in order to advance understanding of the damaging effects of microplastics in the human body and to promote plastic reduction on a global scale. Official website",1
"Ocean Recovery Alliance is also a founding member of the Ocean Conservancy’s “Trash Free Seas Alliance” which was announced at the Clinton Global Initiative in 2011.On June 21, 2012, Ocean Recovery Alliance hosted a side event Plasticity Forum Rio, at the RIO+20 Earth Summit.The Tsunami Debris Tracking Project was the first project to place satellite tracking buoys to follow some of the debris flow in the south west part of the plume that was generated from the 2011 Tohoku earthquake and tsunami.Together",1
"September 2012, Ocean Recovery Alliance organized Kids Ocean Day HK.To celebrate World Oceans Day each June 8, Ocean Recovery Alliance encourages the Oceanic Big 5 to organize ocean cleanups to give back to the environment they rely on for recreation. The Oceanic Big 5 are the top sport users of our ocean; surfers, sailors, swimmers, divers and paddlers.Ocean Recovery Alliance offers educational Junk Trips for companies or schools.",1
Ocean Recovery Alliance Plastic Disclosure Project Plasticity Forum Kids Ocean Day HK 2012 Video Project Kaisei,1
"Estrogens accumulate in body fat and tissue, and because of the cycle of the food chain, the artificial estrogens/EDCs bioaccumulate as they rise up the different levels of the food chain. EDCs are present in the environment, whether naturally or artificially. Although the EDCs from birth control are obviously causing a great effect on the humans, it turns out that, in the United States, the estrogens given to livestock are even more prevalent.",1
"There are also humans. The chemicals that alter gender are constantly produced and excreted by a human being on a normal everyday basis. Along with this, pregnant women contain greater amounts of the chemicals thus releasing greater amounts of it with every excretion. Because of this, one can see that the source of gender-altering pollutants is not natural, but due to man-made chemicals that, globally, are being released. Chemicals such as EDCs and artificial estrogens are in constant circulation around the planet through a variety of mediums.",1
"Therefore, the tainted source is recycled through a community, exposing more people and releasing more chemicals along the way.",1
"Studies have been conducted on animals, but the observed trends are also associated with effects noticed in humans. Scientists observing EDCs in women's blood found that these chemicals mimic human hormones and trigger changes in the sex-determining process of unborn children. Some scientists suggest that this hormonal influence on the sex-determining process has led to a decrease in the male/female ratio. Other effects directly influencing the sex of an individual include a decrease in number and quality of sperm and increased deficiency in a male's reproductive system.Specifically",1
"During this period, exposure to an EDC such as oestrogen causes a reduction in Sertoli cells produced. The reduction of Sertoli cells causes a decrease in the production of sperm thus rendering the male reproductive system less effective. EDCs have also been linked to early puberty, infertility, and developmental defects. Not only have these effects been found in human subjects, but aquatic life has also been studied as these animals are in direct contact with EDCs as a part of their lifestyle. Populations of fish have been largely affected by EDC's prevalence in their native ecosystems.",1
"A study published in 2008 in Japan examined the effects of EDCs from personal care products on a local river biome. The effect of triclosan indicated the inhibition of growth of multiple species including algae, protozoa, crustaceans, bacteria, and amphibians. Further evidence of EDC presence is revealed by surveys of freshwater, estuarine, and marine ecosystems that also pose great consequences to the health of fish. Estrogen and androgen mimickers create endocrine imbalances in fish populations that rely on hormone communication for reproduction and maturation.",1
"Rodricks, a co-founder and Principal of ENVIRON International, prepared a chapter on exposure science appearing in the third edition of the National Academies of Science’s Reference Manual on Scientific Evidence. He has also written for the International Journal of Toxicology.",1
"In Cologne, Germany, the proposed construction of the Cologne Central Mosque encountered strong criticism from some area residents; a ban on broadcasting the call to prayer over loudspeakers outside the building was among the first stipulations that the mosque's supporters had to agree to when seeking a building permit.",1
"As a direct response to this incident, Indonesia's Ministry of Religious Affairs issued a circular on Adhan or the Islamic call to prayer, with guidelines on when and how it ought to be broadcast by mosques. The issue continues to divide as of March 2022 when the Ministry issued even stricter guidelines, which included restricting sound levels to 100 decibels and any pre-call to prayer sermons to 10 minutes duration, down from the previous 15.",1
"On 5 May 2020 Waltham Forest council, London, gave eight mosques permission to publicly broadcast its call to prayer during Ramadan. On 14 May 2020 Newham Council followed suit, granting permission to nineteen mosques within the London borough to publicly broadcast its call to prayer during Ramadan. Many residents in the area of Newham, in dispute of the decision, wrote to the Mayor's office occupied by Rokshana Fiaz.",1
"On the 20 May 2020 residents concerned with the public broadcast to prayer received a response back from the Mayor in which she stated: ""I am sorry if you were offended by the call to prayer, but the Council does not propose to take any further action or correspond further on this matter."" Harrow Council proposed a planning application to allow Harrow Central Mosque to publicly broadcast its prayer call every Friday at 6 pm for three months.On 31 May 2020, Maidenhead Mosque was given permission by Maidenhead council to publicly broadcast its call to prayer on a one-off occasion.",1
"In 2004, the Al-Islah Mosque in Hamtramck, Michigan, US, attracted national attention when it requested permission to broadcast its call to prayer. This upset many of the non-Muslim residents of the area, which has a large and long-established Polish Catholic population. Proponents pointed out that the city was already subject to loud bell ringing from the local church, while opponents argued that the church bells served a nonreligious purpose. Later that year, the city amended its noise regulations to limit the volume of all religious sounds.",1
"A comprehensive set of analyses of wood ash composition from many tree species has been carried out by Emil Wolff, among others. Several factors have a major impact on the composition: Fine ash: Some studies include the solids escaping via the flue during combustion, while others do not. Temperature of combustion. Ash content yield decreases with increasing combustion temperature which produces two direct effects:Dissociation: Conversion of carbonates, sulfides, etc., to oxides results in no carbon, sulfur, carbonates, or sulfides. Some metallic oxides (e.g.",1
"Type, age, and growing environment of the wood stock affect the composition of the wood (e.g. hardwood and softwood), and thus the ash. Hardwoods usually produce more ash than softwoods with bark and leaves producing more than internal parts of the trunk.",1
"According to one research on the average the burning of wood results in about 6–10% ashes. The residue ash of 0.43 and 1.82 percent of the original mass of burned wood (assuming dry basis, meaning that H2O is driven off) is produced for certain woods if it is pyrolized until all volatiles disappear and it is burned at 350 °C (662 °F) for 8 hours. Also the conditions of the combustion affect the composition and amount of the residue ash, thus higher temperature will reduce the ash yield.",1
"Typically, wood ash contains the following major elements: Carbon (C) — 5–30%. Calcium (Ca) — 7–33% Potassium (K) — 3–10% Magnesium (Mg) — 1–2% Manganese (Mn) — 0.3–1.3% Phosphorus (P) — 0.3–1.4% Sodium (Na) — 0.2–0.5%.",1
"of wood ash contains calcium carbonate (CaCO3) as its major component, representing 25% or even 45% of total ash weight. At 600 °C (1,112 °F) CaCO3 and K2CO3 were identified in one case. Less than 10% is potash, and less than 1% is phosphate.",1
"There are trace elements of iron (Fe), manganese (Mn), zinc (Zn), copper (Cu) and some heavy metals. Their concentrations in ash vary due combustion temperature. Decomposition of carbonates and the volatilization of potassium (K), sulfur (S), and trace amounts of copper (Cu) and boron (B) may result from increased temperature. The study has found that at raised temperature K, S, B, sodium (Na) and copper (Cu) decreased, whereas Mg, P, Mn, Al, Fe, and Si did not change relative to calcium (Ca). All of these trace elements are, however, present in the form of oxides at higher temperature of combustion.",1
Some elements in wood ash (all fractions given in mass of elements per mass of ash) include:: 304 Fe 1.6-55 ‰ Si 6-170 ‰ Al 1.2-45 ‰ Mn 1-20 ‰ As 0.6-50 ppm Cd 0.18-60 ppm Pb 2-500 ppm Cr 12-280 ppm Ni 10-140 ppm V 1.8-120 ppm,1
"One study has determined that a slowly burning wood (100–200 °C (212–392 °F) ) emissions typically include 16 alkenes, 5 alkadienes, 5 alkynes and several alkanes and arenes in proportions. Ethene, acetylene and benzene were a major part at efficient combustion. Proportion of C3-C7 alkenes were found to be higher for smouldering. Benzene and 1,3-butadiene constituted ~10–20% and ~1–2% by mass of total non-methane hydrocarbons.",1
"However it was not until the invention of the Leblanc process that high quality sodium hydroxide could be mass produced, rendering obsolete the earlier forms of soap using crude wood or plant ash. This was a revolutionary discovery that facilitated the modern soapmaking industry.",1
The ectomycorrhizal fungi Suillus granulatus and Paxillus involutus can release elements from wood ash.,1
"In present day, the amount of wood ash content in bread flour, as measured by the Chopin alveograph, is strictly regulated by France. Ash burner (traditional occupation) Bottom ash Charcoal Fly ash Ashery – A location or factory producing lye from wood ash",1
"A 1973 report cites a university study of fifty cases of people complaining about a ""low throbbing background noise"" that others were unable to hear. The sound, always peaking between 30 and 40 Hz, was found to only be heard during cool weather with a light breeze, and often early in the morning. These noises were often confined to a 10-kilometre (6 mi) wide area.",1
"A study into the Taos Hum in the early 1990s in Taos, New Mexico indicated that at least two percent could hear it; each hearer at a different frequency between 32 Hz and 80 Hz, modulated from 0.5 to 2 Hz. Similar results have been found in an earlier British study. It seems possible for hearers to move away from it, with one hearer of the Taos Hum reporting its range was 30 miles (48 km). There are approximately equal percentages of male and female hearers. Age does appear to be a factor, with middle-aged people more likely to hear it.",1
"In 2006, Tom Moir, then of Massey University in Auckland, New Zealand, made several recordings that appeared to be the Auckland Hum. His previous research using simulated sounds had indicated that the hum was around 56 hertz.",1
"In late 2011, residents of Windsor, Ontario (south of Detroit, Michigan), began reporting a low droning vibration, sometimes loud enough to be irritating (one evening in 2012 saw 22,000 reports to officials). It was estimated that the sound was emanating from Zug Island, a heavily industrialized section of River Rouge on the north bank of the Detroit River (which separates Windsor and Detroit). Canadian officials requested US assistance in determining the source, but local authorities were stymied by official refusals to allow access to the island. A steel mill operated by U.S.",1
"Steel was the possible cause, but officials stated that no new equipment had been installed or activated around the time that the noise became noticeable. When the blast furnaces were deactivated in April 2020, the noise went away as well.",1
"In 2021, hums were reported in Frankfurt and Darmstadt, in Germany.In 2022, hums were reported in St. Louis County, Missouri and surrounding areas. There is skepticism as to whether the hum exists as a physical sound. In 2009, the head of audiology at Addenbrooke's Hospital in Cambridge, David Baguley, said he believed people's problems with the hum were based on the physical world about one-third of the time, and stemmed from people focusing too keenly on innocuous background sounds the other two-thirds of the time.",1
"His research focuses on using psychology and relaxation techniques to minimise distress, which can lead to a quieting or even removal of the noise.Geoff Leventhall, a noise and vibration expert, has suggested cognitive behavioral therapy (CBT) may be effective in helping those affected, saying that ""It's a question of whether you tense up to the noise or are relaxed about it. The CBT was shown to work, by helping people to take a different attitude to it.""",1
"Steel plant there ceased operations in April 2020.One hum in Myrtle Beach, South Carolina, was suspected of originating at a Santee Cooper substation almost 2 miles away from the home of a couple who first reported it. The substation is home to the state's largest transformer. One local couple sued the power company for the disruption the hum was causing them. The hum was louder inside their house than out, in part, they believed, because their house vibrated in resonance to the 60 Hz hum.",1
"David Deming observes that the difficulty of locating a source of the hum could be attributed to its broadcast from moving aircraft in this fashion, although he notes that there have never been any reports of the Hum around the US Navy's stationary broadcast stations at Cutler, Maine, and Jim Creek, Washington.Deming considers it significant that the Hum ""avoids publicity"", often subsiding in response to an increase in local press coverage, and speculates that this may be a sign that the source is anthropogenic in nature.",1
"Human ears generate their own noises, called spontaneous otoacoustic emissions (SOAE). Various studies have shown that 38–60% of adults with normal hearing have them, although the majority are unaware of these sounds. The people who do hear these sounds typically hear a faint hissing (cicada-like sound), buzzing or ringing, especially if they are otherwise in complete silence.Researchers who looked at the Taos Hum considered otoacoustic emissions as a possibility.",1
"One of the many possible causes of the West Seattle Hum considered was that it was related to the midshipman fish, also known as a toadfish. A previous hum in Sausalito, California, also on the west coast of the United States, was determined to be the mating call of the male midshipman. However, in that case the hum was resonating through houseboat hulls and affecting the people living on those boats.",1
"In the West Seattle case, the University of Washington researcher determined that it would be impossible for any resonating hum, transmitted via tanker or boat hulls, to be transmitted very far inland, certainly not far enough to account for the reports.The Scottish Association for Marine Science hypothesised that the nocturnal humming sound heard in Hythe, Hampshire, in the UK could be produced by a similar ""sonic"" fish. The council believed this to be unlikely, since such fish are not commonly found in inshore waters of the UK.",1
"As of February 2014, although the source had still not been located, the Hythe hum had been recorded. The Taos Hum has been featured on the TV show Unsolved Mysteries, and in LiveScience's ""Top Ten Unexplained Phenomena"", where it took tenth place. BBC Radio 4 featured an investigation of the Hum phenomena in their Punt PI fact-based comedy programme. In October 2022, the Norwegian state broadcaster NRK covered the Hum in its Oppdatert podcast.In a 1998 episode of The X-Files titled ""Drive"", Agent Mulder speculates that extremely low frequency (ELF) radio waves ""may be behind the so-called Taos Hum"".In",1
"a 2018 episode of the police procedural series Criminal Minds, characters are made to commit violent acts as a result of mania caused by the Hum. The story editors described the episode as having ""an X-Files feel"".The Windsor Hum is the subject of the song ""The Hum"" by Canadian musician Dan Griffin. Exploding head syndrome Infrasound List of unexplained sounds Skyquake Deming, D. (2004). The Hum: An Anomalous Sound Heard Throughout the World Fox, Barry (December 9, 1989). ""Low-frequency 'hum' may permeate the environment"". New Scientist. p. 27. Leventhall, H. G. (2004). ""Low frequency noise and annoyance"". Noise & Health.",1
The World Hum Map and Database,1
"""The anchovy catch fell from 204,000 tons in 1984 to 200 tons in 1993; sprat from 24,600 tons in 1984 to 12,000 tons in 1993; horse mackerel from 4,000 tons in 1984 to zero in 1993."" Now that the jellyfish have exhausted the zooplankton, including fish larvae, their numbers have fallen dramatically, yet they continue to maintain a stranglehold on the ecosystem. Invasive species can take over once occupied areas, facilitate the spread of new diseases, introduce new genetic material, alter underwater seascapes, and jeopardize the ability of native species to obtain food.",1
Invasive species are responsible for about $138 billion annually in lost revenue and management costs in the US alone.,1
"Dust can also be attributed to a global transport from the Gobi and Taklamakan deserts across Korea, Japan, and the Northern Pacific to the Hawaiian Islands.Since 1970, dust outbreaks have worsened due to periods of drought in Africa. There is a large variability in dust transport to the Caribbean and Florida from year to year; however, the flux is greater during positive phases of the North Atlantic Oscillation. The USGS links dust events to a decline in the health of coral reefs across the Caribbean and Florida, primarily since the 1970s.Climate",1
"change is raising ocean temperatures and raising levels of carbon dioxide in the atmosphere. These rising levels of carbon dioxide are acidifying the oceans. This, in turn, is altering aquatic ecosystems and modifying fish distributions, with impacts on the sustainability of fisheries and the livelihoods of the communities that depend on them. Healthy ocean ecosystems are also important for the mitigation of climate change.",1
"Some of the potential toxic metals include copper, zinc, cadmium, lead as well as rare earth elements such as lanthanum and yttrium. Following the release of toxins there is an increase of noise, light, sediment le dan plumes and elements that have the potential to impact the ecosystems.Deep sea minerals (DSM) can be extremely beneficial, it can cause wealth, raising living standards as well as economic opportunities for both current and future generations. In addition, if the wealth is poorly managed it can have the potential to cause great economic and social damage .",1
The instability of price and production levels of minerals can cause an external economic shock leading to a significant backlash on the domestic economy.,1
"The World Resources Institute has identified 375 hypoxic coastal zones around the world, concentrated in coastal areas in Western Europe, the Eastern and Southern coasts of the US, and East Asia, particularly in Japan. In the ocean, there are frequent red tide algae blooms that kill fish and marine mammals and cause respiratory problems in humans and some domestic animals when the blooms reach close to shore. In addition to land runoff, atmospheric anthropogenic fixed nitrogen can enter the open ocean.",1
"Apart from plastics, there are particular problems with other toxic pollutants that either do not break down or only very slowly in the marine environment. Examples of persistent toxicants are PCBs, DDT, TBT, pesticides, furans, dioxins, phenols, and radioactive waste. Heavy metals are metallic chemical elements that have a relatively high density and are toxic or poisonous at low concentrations. Examples are mercury, lead, copper and cadmium. Some toxicants can accumulate in the tissues of many species of aquatic life in a process called bioaccumulation.",1
"Due to their high position in the food chain and the subsequent accumulation of heavy metals from their diet, mercury levels can be high in larger species such as bluefin and albacore. As a result, in March 2004 the United States FDA issued guidelines recommending that pregnant women, nursing mothers and children limit their intake of tuna and other types of predatory fish. Some shellfish and crabs can survive polluted environments, accumulating heavy metals or toxins in their tissues. For example, mitten crabs have a remarkable ability to survive in highly modified aquatic habitats, including polluted waters.",1
"The Ocean Conservancy reported that China, Indonesia, Philippines, Thailand, and Vietnam dump more plastic in the sea than all other countries combined. Through more sustainable packing this could lead to; eliminating toxic constituents, using fewer materials, making more readily available recyclable plastic. However, awareness can only take these initiatives so far. The most abundant plastic is PET (Polyethylene terephthalate) and is the most resistant to biodegradables. Researchers have been making great strides in combating this problem. In one way has been by adding a special polymer called a tetrablock copolymer.",1
"The London Convention applied only to waste dumped from ships, and thus did nothing to regulate waste discharged as liquids from pipelines.",1
"Disturbing the peace by playing loud music in the night is a criminal offense, typically a misdemeanor. The exact definition of what constitutes a loud music violation varies by location, either at a certain volume (measured in decibels) or the distance from the source at which the music can be heard. The time of day is also often a factor in the law, with the restrictions in some places applying only to specified nighttime hours (e.g. 11 PM-7 AM). The amount of effort put forth by law enforcement members in dealing with loud music also varies by location.",1
"The most common punishment for a conviction is a fine or some other small sanction. But on rare occasions, loud music may be grounds for imprisonment. In May 2008, a United Kingdom woman was sentenced to 90 days in jail for violating a court order not to play music that disturbed her neighbours eleven times.Police have also at times discovered other crimes, such as illegal drug usage, when investigating loud music complaints.Since mass transit agencies are frequently government-operated and/or subsidized, these rules can be legally enforced, and violation may result in prosecution.",1
"In 2014, software engineer Michael Dunn was convicted of first-degree murder after fatally shooting 17-year-old Jordan Davis in an altercation over the loud music Davis was playing. In many settings, loud music is not tolerated by property owners, and may be grounds for certain civil actions, such as eviction from rented property. Property owners at locations where patrons visit temporarily, such as hotels, campgrounds, or businesses, may order those who play loud music to leave the property.",1
"David Grissom declared that “loud music is a forty-dollar fine,” the lead single from the 2008 album Loud Music, specifically citing experiences in municipalities such as Tulsa, Oklahoma, Amarillo, Texas and San Francisco, California.",1
"Music played at 85 decibels, or level of sounds, for prolonged periods of times can cause hearing damage, for instance, sound levels at some rock concerts can reach 110-120 A-weighted decibels, and at those levels, the maximum daily limit set by most standards and regulations can be reached in less than one minute of exposure.Continual exposure to loud music can also lead to tinnitus.It is predicted that exposure to loud music will cause as many as 50 million Americans to suffer hearing loss by 2050.",1
"A study conducted by French scientists showed that loud music leads to more alcohol consumption in less time. For three Saturday evenings researchers observed customers of two bars situated in a medium-sized city in the west of France. Participants included forty males aged between 18 and 25, who were unaware that they were subjects of a research. The study featured only those who ordered a glass of draft beer (25 cl. or 8 oz.).",1
"The lead researcher, Nicolas Guéguen, said that each year more than 70,000 people in France die from an increased level of alcohol consumption, which also leads to fatal car accidents. Loud music has in some instances provoked lethal responses. In 2023, a Bronx woman allegedly stabbed her neighbor over the loud music that was disturbing her. Earmuff Earplug Hearing impairment Heavy metal music Hip hop music Loudest band in the world Loud Records Music torture Noise induced hearing loss Noise regulation Sound Sound power level Soundproofing Tinnitus",1
"The MRL is usually determined by repeated (on the order of 10) field trials, where the crop has been treated according to good agricultural practice (GAP) and an appropriate pre harvest interval or withholding period has elapsed. For many pesticides this is set at the Limit of determination (LOD) – since only major pesticides have been evaluated and understanding of acceptable daily intake (ADI) is incomplete (i.e. producers or public bodies have not submitted MRL data – often because these were not required in the past).",1
"A swap test can eliminate this gap. MRL's for ornamental produce can sometimes result in a conflicting outcome because of the absence of pre harvest intervals (PHI) or withholding periods for ornamentals, specifically in crops where harvesting is continuous, like roses. This happens when a grower is following the label recommendations and the produce is sampled shortly after.",1
"Three key points are taken into consideration regarding MRL values in the EU regulation: 1) the amounts of residues found in food must be safe for consumers and must be as low as possible, 2) the European Commission fixes MRLs for all food and animal feed, and 3) the MRLs for all crops and all pesticides can be found in the MRL database on the Commission website. Detection limits Pesticides QuEChERS - method for testing pesticide residues Maximum Contaminant Level FAO (2016).",1
"Submission and evaluation of pesticide residues data for the estimation of maximum residue levels in food and feed, Rome: Food and Agriculture Organization of the United Nations OECD (2014). MRL Calculator: Users Guide and White Paper, Series on Pesticides and Biocides, No. 56. Paris: OECD Publishing. doi:10.1787/9789264221567-en. ISBN 9789264221567. FAO/WHO, Codex Alimentarius: MRL database Code of Federal Regulations, Part 180—Tolerances and exemptions for pesticide chemical residues in food",1
"The threat posed to birds, fish, shellfish and crustaceans from spilled oil was known in England in the 1920s, largely through observations made in Yorkshire. The subject was also explored in a scientific paper produced by the National Academy of Sciences in the US in 1974 which considered impacts to fish, crustaceans and molluscs. The paper was limited to 100 copies and was described as a draft document, not to be cited.In general, spilled oil can affect animals and plants in two ways: dirесt from the oil and from the response or cleanup process.",1
"Animals who rely on scent to find their babies or mothers cannot do so due to the strong scent of the oil. This causes a baby to be rejected and abandoned, leaving the babies to starve and eventually die. Oil can impair a bird's ability to fly, preventing it from foraging or escaping from predators. As they preen, birds may ingest the oil coating their feathers, irritating the digestive tract, altering liver function, and causing kidney damage. Together with their diminished foraging capacity, this can rapidly result in dehydration and metabolic imbalance.",1
"Some birds exposed to petroleum also experience changes in their hormonal balance, including changes in their luteinizing protein. The majority of birds affected by oil spills die from complications without human intervention. Some studies have suggested that less than one percent of oil-soaked birds survive, even after cleaning, although the survival rate can also exceed ninety percent, as in the case of the MV Treasure oil spill. Oil spills and oil dumping events have been impacting sea birds since at least the 1920s and was understood to be a global problem in the 1930s.Heavily",1
"furred marine mammals exposed to oil spills are affected in similar ways. Oil coats the fur of sea otters and seals, reducing its insulating effect, and leading to fluctuations in body temperature and hypothermia. Oil can also blind an animal, leaving it defenseless. The ingestion of oil causes dehydration and impairs the digestive process. Animals can be poisoned, and may die from oil entering the lungs or liver.",1
"The majority of oil from an oil spill remains in the environment, hence a spill from an operation in the ocean is different from an operation on tundra or wetland. Wetlands are considered one of the most sensitive habitats to oil spills and the most difficult to clean. Oil spills can be caused by human error, natural disasters, technical failures or deliberate releases. It is estimated that 30-50% of all oil spills are directly or indirectly caused by human error, with approximately 20-40% of oil spills being attributed to equipment failure or malfunction.",1
"Causes of oil spills are further distinguished between deliberate releases, such as operational discharges or acts of war and accidental releases. Accidental oil spills are in the focus of the literature, although some of the largest oil spills ever recorded, the Gulf War Oil Spill (sea based) and Kuwaiti Oil Fires (land based) were deliberate acts of war. The academic study of sources and causes of oil spills identifies vulnerable points in oil transportation infrastructure and calculates the likelihood of oil spills happening. This can then guide prevention efforts and regulation policies",1
"Around 40-50% of all oil released into the oceans stems from natural seeps from seafloor rocks. This corresponds to approximately 600,000 tons annually on a global level. While natural seeps are the single largest source of oil spills, they are considered less problematic because ecosystems have adapted to such regular releases. For instance, on sites of natural oil seeps, ocean bacteria have evolved to digest oil molecules.",1
"There has been a steady decrease of operational discharges of oil, with an additional decrease of around 50% since the 1990s.As of 2007, accidental oil tank vessel spills accounted for approximately 8-13% of all oil spilled into the oceans. The main causes of oil tank vessel spills were collision (29%), grounding (22%), mishandling (14%) and sinking (12%), among others. Oil tanker spills are considered a major ecological threat due to the large amount of oil spilled per accident and the fact that major sea traffic routes are close to Large Marine Ecosystems.",1
"Around 90% of the world's oil transportation is through oil tankers, and the absolute amount of seaborne oil trade is steadily increasing. However, there has been a reduction of the number of spills from oil tankers and of the amount of oil released per oil tanker spill. In 1992, MARPOL was amended and made it mandatory for large tankers (5,000 dwt and more) to be fitted with double hulls. This is considered to be a major reason for the reduction of oil tanker spills, alongside other innovations such as GPS, sectioning of vessels and sea lanes in narrow straits.",1
This ambiguous development results in no clear trend regarding the frequency of offshore oil platform spills.,1
"This conversion allows sensitivity indexing to become more adaptable and in 1995 by the US National Oceanic and Atmospheric Administration (NOAA) worked on the tool allowing ESI to extended maps to lakes, rivers, and estuary shoreline types. ESI maps have since become integral to collecting, synthesizing, and producing data which have previously never been accessible in digital formats. Especially in the United States, the tool has made impressive advancements in developing tidal bay protection strategies, collecting seasonal information and generally in the modelling of sensitive areas.",1
"Together with Geographic Information System Mapping (GIS), ESI integrates their techniques to successfully geographically reference the three different types of resources.",1
"Shoreline type mapping codes a large range of ecological settings including estuarine, lacustrine, and riverine environments. Floating oil slicks put the shoreline at particular risk when they eventually come ashore, covering the substrate with oil. The differing substrates between shoreline types vary in their response to oiling, and influence the type of cleanup that will be required to effectively decontaminate the shoreline. Hence ESI shoreline ranking helps committees identify which clean-up techniques are approved or detrimental the natural environment.",1
"The exposure the shoreline has to wave energy and tides, substrate type, and slope of the shoreline are also taken into account—in addition to biological productivity and sensitivity. Mangroves and marshes tend to have higher ESI rankings due to the potentially long-lasting and damaging effects of both oil contamination and cleanup actions. Impermeable and exposed surfaces with high wave action are ranked lower due to the reflecting waves keeping oil from coming onshore, and the speed at which natural processes will remove the oil.",1
"Within the biological resources, the ESI maps protected areas as well as those with bio-diverse importance. These are usually identified through the UNEP-WCMC Integrated Biodiversity Assessment Tool. There are varying types of coastal habitats and ecosystems and thus also many endangered species that need to be considered when looking at affected areas post oil spills. The habitats of plants and animals that may be at risk from oil spills are referred to as ""elements"" and are divided by functional group. Further classification divides each element into species groups with similar life histories and behaviors relative to their vulnerability to oil spills.",1
"There are eight element groups: birds, reptiles, amphibians, fish, invertebrates, habitats and plants, wetlands, and marine mammals and terrestrial mammals. Element groups are further divided into sub-groups, for example, the ‘marine mammals’ element group is divided into dolphins, manatees, pinnipeds (seals, sea lions & walruses), polar bears, sea otters and whales. Necessary when ranking and selecting species is their vulnerability to the oil spills themselves. This not only includes their reactions to such events but also their fragility, the scale of large clusters of animals, whether special life stages occur ashore, and whether any present species is threatened, endangered or rare.",1
"The way in which the biological resources are mapped is through symbols representing the species, and polygons and lines to map out the special extent of the species. The symbols also have the ability to identify the most vulnerable of a species life stages, such as the molting, nesting, hatching or migration patterns. This allows for more accurate response plans during those given periods. There is also a division for sub-tidal habitats which are equally important to coastal biodiversity including kelp, coral reefs and sea beds which are not commonly mapped within the shoreline ESI type.",1
"Crude oil and refined fuel spills from tanker ship accidents have damaged vulnerable ecosystems in Alaska, the Gulf of Mexico, the Galapagos Islands, France, the Sundarbans, Ogoniland, and many other places. The quantity of oil spilled during accidents has ranged from a few hundred tons to several hundred thousand tons (e.g., Deepwater Horizon Oil Spill, Atlantic Empress, Amoco Cadiz), but volume is a limited measure of damage or impact.",1
"spills at sea are generally much more damaging than those on land, since they can spread for hundreds of nautical miles in a thin oil slick which can cover beaches with a thin coating of oil. These can kill seabirds, mammals, shellfish and other organisms they coat. Oil spills on land are more readily containable if a makeshift earth dam can be rapidly bulldozed around the spill site before most of the oil escapes, and land animals can avoid the oil more easily.",1
"The British possessed almost 71,000 air-dropped bombs of 250 kilograms in weight, each of which was filled with tabun. These had been seized from German ammunition dumps during the final months of World War II. A total of 250,000 tons of German chemical weapons had been discovered, the majority of which were destroyed because they comprised warfare agents which the allies already possessed in great abundance e.g. mustard gas at sites such as RAF Bowes Moor. However, the stocks of tabun and sarin were considered more valuable because the allies did not possess nerve agent technology at that time.",1
"As a result, captured stocks of German nerve agents were divided between Britain and the United States after discussion, with the Americans taking the sarin. The British transferred their 14,000 tons of ordnance containing tabun in October 1945, via Hamburg and Newport, to temporary storage at the RAF strategic reserve ammunition store at Llanberis. Longer term facilities were prepared at RAF Llandwrog where the bombs were to be stored in stacks, out in the open, on the runways of the disused airfield. The intention was that any leaks of nerve agent would be dispersed by the prevailing winds.",1
"This was not the case with the 250 kilogram tabun bombs at RAF Landwrog. Not only had the bombs been left with fuzes inserted for a considerable amount of time (possibly years), but they were also left exposed to the elements creating a corrosion risk, together with the inevitable temperature fluctuations which resulted from changing weather. None of these factors was accepted practice regarding the safe, long-term storage of bomb fuzes or explosive ordnance in general. At a rate of 500 bombs a week they were defuzed and individually coated in a waxy preservative to seal them.",1
"Seventy-two irreparable devices were neutralised on-site by being drained into individual pits filled with caustic soda crystals. Despite being given a preservative covering the bombs continued to suffer in the damp Welsh climate and in 1951 twenty-one Bellman hangars were erected on the site to store the bombs. Finally in June 1954 it was decided to dispose of the entire stock because by then it was recognised that not only did the weapons have no military value but they had actually become a liability, which could only become worse as time passed.",1
"Operation Sandcastle was divided into two sections, a sea voyage to Cairnryan and then a transfer to suitable hulks there for later sinking north-west of Ireland beyond the continental shelf. It was intended to process 16,000 bombs in the first attempt in mid-1955. The work began with the construction of a road between Llandwrog and the nearby port of Fort Belan where six tank landing craft were assembled. Loading trials in June indicated only 400 bombs could be loaded on each craft, fewer than hoped.",1
"It was then decided to remove the tail-fins from the bombs to reduce their length, and to pack them in new boxes. This work increased each craft's load to 800 bombs and by mid-July all 16,000 devices had been safely carried to Cairnryan. The SS Empire Claire was the first scuttling ship. Its loading began in late June, and by 23 July all 16,000 bombs were aboard, although an ill-considered loading plan had given it a noticeable list to starboard.",1
"The three scuttling charges of TNT were positioned to ensure its sinking would be steady and flat, and the nine-man crew embarked. Departure was delayed by industrial action on the Firth of Clyde preventing the departure of the ocean-going tugboat Forester. On 25 July 1955 the SS Empire Claire, SS Forester, and navy escorts Mull and Sir Walter Campbell left Cairnryan. The Empire Claire soon broke down and was taken under tow.",1
"MV Vogtland was scuttled on 30 May 1956 at the same site, taking 28,737 bombs with it, and on 21 July 1956 the SS Kotka was sunk (at 56°31′00″N 12°05′00″W) with 26,000 bombs, 330 tons of arsenic compounds, and three tons of toxic seed dressings. Bowles, R. (15 December 2008). ""Standard Reply to Enquiries Re Sea Dumping of Munitions"" (PDF). Ministry of Defence (United Kingdom). Archived from the original on 18 October 2012. Retrieved 13 May 2018.{{cite web}}: CS1 maint: bot: original URL status unknown (link) Defence Science and Technology Laboratory (2 August 2006). ""Sarin Gas Letter"" (PDF).",1
"Archived from the original (PDF) on 9 November 2012. Bless 'em all - aspects of the war in North West Wales, Reg Chambers Jones, Bridge Books, ISBN 1-872424-48-1 The Tale of Tabun - Nazi chemical weapons in North Wales, Roy Sloan, Carrge Gwalch, ISBN 0-86381-465-4",1
"The Ganga Action Plan launched in 1986 by the Government of India has not achieved any success despite expenditure of over five billion rupees. The government claims that the schemes under the Ganga Action Plan have been successful, but actual measurements and scientific data tell a different story. The failure of the GAP is evident but corrective action is lacking.",1
"If sufficient data is generated, minimum significant differences (MSDs) are calculated using power analyses and applied to toxicity tests to determine the difference between statistical difference and ecological relevance. The function of the toxicity portion of the triad approach is to allow you to estimate the effects in the field. While laboratory based experiments simplify a complex and dynamic environment, toxicity results allow the potential for field extrapolation. This creates a link of exposure and effect and allows the determination of an exposure-response relationship.",1
When combined with the other two components of the Sediment Quality Triad it allows for a holistic understanding between cause and effect.,1
"Bioaccumulation should be considered during the utilization of the triad approach depending on the study goals. It preparation for measuring bioaccumulation, it must be specified if the test will serve to assess secondary poisoning or biomagnification (Chapman, 1997). Bioaccumulation analysis should be conducted appropriately based on the contaminants of concern (for example, metals do not biomagnify). This can be done with field-collected, caged organisms, or laboratory exposed organisms (Chapman, 1997). While the bioaccumulation portion is recommended, it is not required.",1
"However, it serves an important role with the purpose of quantifying effects due to trophic transfer of contaminants through consumption of contaminated prey.",1
"The SQT incorporates three lines of evidence (LOE) to provide direct assessment of sediment quality. The chemistry, toxicity, and benthic components of the triad each provide a LOE, which is then integrated into a Weight of evidence.",1
"The chemistry component incorporates both bioavailability and potential effects on benthic community. The potential of sediment toxicity for a given site is based on a linear regression model (LRM). A chemical score index (CSI) of the contaminant describes the magnitude of exposure relative to benthic community disturbance. An optimal set of index-specific thresholds are selected for the chemistry component by statistically comparing several candidates to evaluate which set exhibited greatest overall agreement (Bay and Weisberg, 2012). The magnitude of sediment toxicity is determined by multiple toxicity tests conducted in the lab to complement chemistry component.",1
"Toxicity LOE are determined by the mean of toxicity category score from all relevant tests. Development of LOE for benthic component is based on community metrics and abundance. Several indices such as benthic response index (BRI), benthic biotic integrity (IBI), and relative biotic index (RBI) are utilized to assess biological response of the benthic community. The median score of all individual indices will establish benthic LOE. Each component of the triad is assigned a response category: minimal, low, moderate, or high disturbance relative to background conditions.",1
"Individual LOEs are ranked into categories by comparing test results of each component to established thresholds (Bay and Weisberg, 2012). Integration of benthos and toxicity LOE classify the severity and effects of contamination. LOE of chemistry and toxicity are combined to assign the potential of chemically-mediated effects. A site is assigned an impact category by integrating the severity of effect and the potential of chemically mediated effects. The conditions of individual sites of concern are assigned an impact category between 1 and 5 (with 1 being unimpacted and 5 being clearly impacted by contamination).",1
"The SQT triad can also classify impact as inconclusive in cases when LOE between components are in disagreement or additional information is required (Bay and Weisberg, 2012).",1
"SQT measurements are scaled proportionately by relative impact and visually represented on triaxial graphs. Evaluation of sediment integrity and interrelationships between components can be determined by the size and morphology of the triangle. The magnitude of the triangle is indicative of the relative impact of contamination. Equilateral triangles imply agreement among components. (USEPA, 1994)",1
"A decision matrix can be employed such that all three measures be analyzed simultaneously, and a deduction of possible ecological impacts be made (USEPA 1994)Other advantages of the SQT include information on the potential bioaccumulation and biomagnifcation effects of contaminants, and its flexibility in application, resulting from its design as a framework rather than a formula or standard method. By using multiple lines of evidence, there are a host of ways to manipulate and interpret SQT data (Bay and Weisberg 2012). It has been accepted on an international scale as the most comprehensive approach to assessing sediment (Chapman and McDonald 2005).",1
"Stemming from the National Pollutant Discharge Elimination System (NPDES) EPA permitting guidelines, point and nonpoint discharges may adversely affect sediment quality. As per state regulatory criteria, information on point and nonpoint source contamination, and its effects on sediment quality may be required for assessment of compliance. For example, Washington State Sediment Management Standards, Part IV, mandates sediment control standards which allow for establishment of discharge sediment monitoring requirements, and criteria for creation and maintenance of sediment impact zones (WADOE 2013). In this instance, the SQT could be particularly useful encompassing multiple relevant analyses simultaneously.",1
"The main objective of the space weather segment (SWE) is to detect and forecast of space weather events, avoid adverse effect on European space assets and ground-based infrastructure. To achieve that, the segment will focus on delivery of real-time space weather information, forecasts and warnings, supported by a data archive, applications and services. Assets currently available for the segment consist of multiple ground-based and spaceborne sensors monitoring the Sun, solar wind and Earth's magnetosphere, ionosphere and thermosphere. These include the PROBA2 satellite and the Kanzelhoehe Solar Observatory.",1
"The segment is jointly coordinated by the SWE Data Centre located at the ESTRACK Redu Station and the SSA Space Weather Coordination Centre (SSCC), both in Belgium. The near-Earth object segment aims to deliver monitoring and warning of potential Earth impactors and tracking of newly discovered objects. The segment's current assets consist of a mixture of professional and amateur telescopes, including the OGS Telescope, that are supported by tracking databases. The plans are to create a fully integrated system supporting alerts for civil authorities, including the NEOSTEL flyeye telescope due for completion in 2020.",1
"The segment is operated by the SSA NEO Coordination Centre located at the ESA Centre for Earth Observation, Italy. The SST segment's primary goal is the detection, cataloguing and orbit prediction of objects orbiting the Earth. It is part of an effort to avoid collisions between orbiting satellites and debris, provide safe reentries, detect on-orbit explosions, assist missions at launch, deployment and end-of-life and overall reduce cost of space access. The segment currently relies on existing European radar and optical systems. Some of its assets are existing radio and optical telescopes, with now serving a secondary role for tracking space debris.The",1
radar-based SST assets are split into two categories: surveillance and tracking systems.,1
"Observatorio Astronómico de Mallorca Starbrook and Starbrook north located at RAF Troodos Fabra-ROA telescope (TFRM) at Serra del Montsec ZimSMART robotic telescope Tracking Satellite laser ranging station Graz at Lustbühel Observatory Matera Laser Ranging Observatory (MLRO) in Italy OGS Telescope at the Teide Observatory TAROT and TAROT-South robotic telescope at the La Silla Observatory ZIMLAT telescope at the Zimmerwald Observatory ESA Flyeye Telescope at Sicily, Italy As part of the SSA Programme new, dedicated surveillance radar supported by optical sensors systems will be developed.",1
The segment is coordinated by the Space Surveillance Test & Validation (SSTC) Centre located at the ESAC in Spain.Close approaches of Near-Earth objects and near earth asteroids are reported by ESA through the space situational awareness center. Kessler syndrome Space surveillance United States Space Surveillance Network Official Website Space Surveillance and Tracking Centre,1
"a mixture of low and high permeability materials) can result in less gas flow across some zones. In some situations, such as enhancement of monitored natural attenuation, a passive SVE system that relies on barometric pumping may be employed. SVE has several advantages as a vadose zone remediation technology. The system can be implemented with standard wells and off-the-shelf equipment (blowers, instrumentation, vapor treatment, etc.). SVE can also be implemented with a minimum of site disturbance, primarily involving well installation and minimal aboveground equipment.",1
"Depending on the nature of the contamination and the subsurface geology, SVE has the potential to treat large soil volumes at reasonable costs. The soil gas (vapor) that is extracted by the SVE system generally requires treatment prior to discharge back into the environment. The aboveground treatment is primarily for a gas stream, although condensation of liquid must be managed (and in some cases may specifically be desired). A variety of treatment techniques are available for aboveground treatment and include thermal destruction (e.g., direct flame thermal oxidation, catalytic oxidizers), adsorption (e.g.,",1
"granular activated carbon, zeolites, polymers), biofiltration, non-thermal plasma destruction, photolytic/photocatalytic destruction, membrane separation, gas absorption, and vapor condensation. The most commonly applied aboveground treatment technologies are thermal oxidation and granular activated carbon adsorption. The selection of a particular aboveground treatment technology depends on the contaminant, concentrations in the offgas, throughput, and economic considerations. The effectiveness of SVE, that is, the rate and degree of mass removal, depends on a number of factors that influence the transfer of contaminant mass into the gas phase. The effectiveness of SVE is a function of the contaminant properties (e.g.,",1
"Guidance from the Pacific Northwest National Laboratory (PNNL) supplements these documents by discussing specific actions and decisions related to SVE optimization, transition, and/or closure. Design and operation of a SVE system is relatively straightforward, with the major uncertainties having to do with subsurface geology/formation characteristics and the location of contamination. As time goes on, it is typical for a SVE system to exhibit a diminishing rate of contaminant extraction due to mass transfer limitations or removal of contaminant mass.",1
"Performance assessment is a key aspect to provide input for decisions about whether the system should be optimized, terminated, or transitioned to another technology to replace or augment SVE. Assessment of rebound and mass flux provide approaches to evaluate system performance and obtain information on which to base decisions. Several technologies are related to soil vapor extraction. As noted above, various soil-heating remediation technologies (e.g., electrical resistive heating, in situ vitrification) require a soil gas collection component, which may take the form of SVE and/or a surface barrier (i.e., hood).",1
"The NOx reduction reaction takes place as the gases pass through the catalyst chamber. Before entering the catalyst chamber ammonia, or other reductant (such as urea), is injected and mixed with the gases.",1
The chemical equation for a stoichiometric reaction using either anhydrous or aqueous ammonia for a selective catalytic reduction process is: 2 NO + 2 NH 3 + 1 2 O 2 ⟶ 2 N 2 + 3 H 2 O {\displaystyle {\ce {2 NO + 2 NH3 + 1/2 O2 -> 2 N2 + 3 H2O}}} NO 2 + 2 NH 3 + 1 2 O 2 ⟶ 3 2 N 2 + 3 H 2 O {\displaystyle {\ce {NO2 + 2 NH3 + 1/2 O2 -> 3/2 N2 + 3 H2O}}} NO + NO 2 + 2 NH 3 ⟶,1
2 N 2 + 3 H 2 O {\displaystyle {\ce {NO + NO2 + 2 NH3 -> 2 N2 + 3 H2O}}} With several secondary reactions: 1 8 S 8 + O 2 ⟶ SO 2 {\displaystyle {\ce {1/8 S8 + O2 -> SO2}}} SO 2 + 1 2 O 2 ⟶ SO 3 {\displaystyle {\ce {SO2 + 1/2 O2 -> SO3}}} SO 3 + H 2 O ⟶ H 2 SO 4 {\displaystyle {\ce {SO3 + H2O -> H2SO4}}} 2 NH 3 + H 2 SO 4 ⟶ ( NH 4 ) 2 SO 4 {\displaystyle {\ce {2 NH3 +,1
"H2SO4 -> (NH4)2SO4}}} NH 3 + H 2 SO 4 ⟶ NH 4 HSO 4 {\displaystyle {\ce {NH3 + H2SO4 -> NH4HSO4}}} With urea, the reactions are: 3 NO + CO ( NH 2 ) 2 ⟶ 5 2 N 2 + 2 H 2 O + CO 2 {\displaystyle {\ce {3 NO + CO(NH2)2 -> 5/2 N2 + 2 H2O + CO2}}} 3 NO 2 + 2 CO ( NH 2 ) 2 ⟶ 7 2 N 2 + 4 H 2 O + 2 CO 2 {\displaystyle {\ce {3 NO2 + 2 CO(NH2)2 -> 7/2 N2 + 4 H2O",1
"+ 2 CO2}}} As with ammonia, several secondary reactions also occur in the presence of sulfur: CO ( NH 2 ) 2 + H 2 SO 4 + H 2 O ⟶ ( NH 4 ) 2 SO 4 + CO 2 {\displaystyle {\ce {CO(NH2)2 + H2SO4 + H2O -> (NH4)2SO4 + CO2}}} CO ( NH 2 ) 2 + 2 H 2 SO 4 + H 2 O ⟶ 2 NH 4 HSO 4 + CO 2 {\displaystyle {\ce {CO(NH2)2 + 2 H2SO4 + H2O -> 2 NH4HSO4 + CO2}}} The ideal reaction has an optimal temperature range between 630",1
"They also have a high catalysing potential to oxidize SO2 into SO3, which can be extremely damaging due to its acidic properties.Zeolite catalysts have the potential to operate at substantially higher temperature than base metal catalysts; they can withstand prolonged operation at temperatures of 900 K (627 °C) and transient conditions of up to 1120 K (847 °C). Zeolites also have a lower potential for SO2 oxidation and thus decrease the related corrosion risks.Iron-",1
"These poisons are alkali metals, alkaline earth metals, halogens, phosphorus, sulfur, arsenic, antimony, chromium, heavy metals (copper, cadmium, mercury, thallium, and lead), and many heavy metal compounds (e.g. oxides and halides). Most SCRs require tuning to properly perform. Part of tuning involves ensuring a proper distribution of ammonia in the gas stream and uniform gas velocity through the catalyst. Without tuning, SCRs can exhibit inefficient NOx reduction along with excessive ammonia slip due to not utilizing the catalyst surface area effectively. Another facet of tuning involves determining the proper ammonia flow for all process conditions.",1
"Ammonia flow is in general controlled based on NOx measurements taken from the gas stream or preexisting performance curves from an engine manufacturer (in the case of gas turbines and reciprocating engines). Typically, all future operating conditions must be known beforehand to properly design and tune an SCR system. Ammonia slip is an industry term for ammonia passing through the SCR unreacted. This occurs when ammonia is injected in excess, temperatures are too low for ammonia to react, or the catalyst has been poisoned.",1
"SCR catalysts have a typical operational lifetime of about 16,000 – 40,000 hours (1.8 – 4.5 years) in coal-fired power plants, depending on the flue gas composition, and up to 80,000 hours (9 years) in cleaner gas-fired power plants. Poisons, sulfur compounds, and fly ash can all be removed by installing scrubbers before the SCR system to increase the life of the catalyst, though in most power plants and marine engines, scrubbers are installed after the system to maximize the SCR system's effectiveness.",1
"After a brief transition period, ULSD fuel became common at fuel pumps in the United States and Canada. The 2007 EPA regulations were meant to be an interim solution to allow manufacturers time to prepare for the more stringent 2010 EPA regulations, which reduced NOx levels even further.",1
"The areas are saturated with unexploded shells (including many gas shells), grenades, and rusting ammunition. Soils were heavily polluted by lead, mercury, chlorine, arsenic, various dangerous gases, acids, and human and animal remains. The area was also littered with ammunition depots and chemical plants. Each year, numerous unexploded shells are recovered from former WWI battlefields in what is known as the Iron harvest. According to the Sécurité Civile, the French agency in charge of the land management of Zone Rouge, 300 to 700 more years at this current rate will be needed to clean the area completely.",1
"Some experiments conducted in 2005–06 discovered up to 300 shells per hectare (120 per acre) in the top 15 cm (5.9 in) of soil in the worst areas.Areas where 99% of all plants still die remain off limits (for example, two small pieces of land close to Ypres and the Woëvre), as arsenic constitutes up to 175,907 mg (175.9g) /kg of soil samples because arsenical shells were destroyed in the 1920s. French villages destroyed in the First World War Involuntary park Iron harvest No man's land Smith, Corinna Haven & Hill, Caroline R.",1
"Rising Above the Ruins in France: An Account of the Progress Made Since the Armistice in the Devastated Regions in Re-establishing Industrial Activities and the Normal Life of the People. New York: GP Putnam's Sons, 1920: 6. De Sousa David, La Reconstruction et sa Mémoire dans les villages de la Somme 1918–1932, Editions La vague verte, 2002, 212 pages Bonnard Jean-Yves, La reconstitution des terres de l'Oise après la Grande Guerre: les bases d'une nouvelle géographie du foncier, in Annales Historiques Compiégnoises 113–114, pp. 25–36, 2009. Parent G.-H., 2004.",1
"Trois études sur la Zone Rouge de Verdun, une zone totalement sinistrée I.L'herpétofaune – II.La diversité floristique – III.Les sites d'intérêt botanique et zoologique à protéger prioritairement. Ferrantia, 288 pages Bausinger, Tobias; Bonnaire, Eric; & Preuß, Johannes,. Exposure assessment of a burning ground for chemical ammunition on the Great War battlefields of Verdun, Science of the Total Environment 382:2–3, pp. 259–271, 2007. Map of the Western Front in 1918 (in English) Déminage à Douaumont (in French and English) National Geographic: France’s Zone Rouge is a Lingering Reminder of World War I (in English)",1
"Space domain awareness accomplishes the following: Predicting when and where a decaying space object will re-enter the Earth's atmosphere; Preventing a returning space object, which to radar looks like a missile, from triggering a false alarm in missile-attack warning sensors; Charting the present position of space objects and plot their anticipated orbital paths; Detecting new man-made objects in space; Producing a running catalogue of man-made space objects; Determining which country owns a re-entering space object; Informing countries whether or not objects may interfere with satellites and International Space Station orbits; Providing data for future anti-satellite weapons systems.",1
States Space Surveillance,1
"Two waste products, dust and chips, form at the working surface during woodworking operations such as sawing, milling and sanding. These operations both shatter lignified wood cells and break out whole cells and groups of cells. Shattering of wood cells creates dust, while breaking out of whole groups of wood cells creates chips. The more cell-shattering that occurs, the finer the dust particles that are produced. For example, sawing and milling are mixed cell shattering and chip forming processes, whereas sanding is almost exclusively cell shattering.",1
"Miklós Nyiszli, reports in Auschwitz: A Doctor's Eyewitness Account that the subaltern medical staff, who served Dr. Josef Mengele, subsisted on ""bread made from wild chestnuts sprinkled with sawdust"". Airborne sawdust and sawdust accumulations present a number of health and safety hazards. Wood dust becomes a potential health problem when, for example, the wood particles, from processes such as sanding, become airborne and are inhaled. Wood dust is a known human carcinogen. Certain woods and their dust contain toxins that can produce severe allergic reactions.Breathing airborne wood dust may cause allergic respiratory symptoms, mucosal and non-allergic respiratory symptoms, and cancer.",1
"In the US, lists of carcinogenic factors are published by the American Conference of Governmental Industrial Hygienists (ACGIH), the Occupational Safety and Health Administration (OSHA), and the National Institute for Occupational Safety and Health (NIOSH). All these organisations recognize wood dust as carcinogenic in relation to the nasal cavities and paranasal sinuses. People can be exposed to wood dust in the workplace by breathing it in, skin contact, or eye contact.",1
Sawdust is flammable and accumulations provide a ready source of fuel. Airborne sawdust can be ignited by sparks or even heat accumulation and result in dust fire or explosions.,1
"Wood flour is finely pulverized wood that has a consistency fairly equal to sand or sawdust, but can vary considerably, with particles ranging in dimensions from a fine powder to roughly that of a grain of rice. Most wood flour manufacturers are able to create batches of wood flour that have the same consistency throughout. All high quality wood flour is made from hardwoods because of its durability and strength. Very low grade wood flour is occasionally made from sapless softwoods such as pine or fir.",1
Large quantities of wood flour are frequently to be found in the waste from woodworking and furniture companies. An adaptive reuse to which this material can be directed is composting. Wood flour can be subject to dust explosions if not cared for and disposed of properly.,1
"As with all airborne particulates, wood dust particle sizes are classified with regard to effect on the human respiratory system. For this classification, the unit for measurement of particle sizes is the micrometre or micron (μm), where 1 micrometre = 1 micron. Particles below 50 μm are not normally visible to the naked human eye. Particles of concern for human respiratory health are those <100 μm (where the symbol < means ‘less than’).",1
"Zhang (2004) has defined the size of indoor particulates according to respiratory fraction: Particles which precipitate in the vicinity of the mouth and eyes, and get into the organism, are defined as the inhalable fraction, that is total dust. Smaller fractions, penetrating into the non-cartilage respiratory tract, are defined as respirable dust. Dust emitted in the wood industry is characterized by the dimensional disintegration of particles up to 5 μm, and that is why they precipitate mostly in the nasal cavity, increasing the risk of cancer of the upper respiratory tract.",1
The highest exposure levels were estimated to occur in the construction sector and furniture industry.,1
Festool is one manufacturer of portable power tools using LVHV ventilation integrated into the tool design.,1
"Mercury is a highly toxic element commonly found in coal and municipal waste. Wet scrubbers are only effective for removal of soluble mercury species, such as oxidized mercury, Hg2+. Mercury vapor in its elemental form, Hg0, is insoluble in the scrubber slurry and not removed. Therefore, an additional process of Hg0 conversion is required to complete mercury capture. Usually halogens are added to the flue gas for this purpose.",1
"The type of coal burned as well as the presence of a selective catalytic reduction unit both affect the ratio of elemental to oxidized mercury in the flue gas and thus the degree to which the mercury is removed. In July 2015, one study found that some mercury scrubbers installed on coal power plants inadvertently capture PAH (polycyclic aromatic hydrocarbons) emissions as well. One side effect of scrubbing is that the process only moves the unwanted substance from the exhaust gases into a liquid solution, solid paste or powder form.",1
"This must be disposed of safely, if it can not be reused. For example, mercury removal results in a waste product that either needs further processing to extract the raw mercury, or must be buried in a special hazardous wastes landfill that prevents the mercury from seeping out into the environment. There are issues with that, as it is extremely dangerous to the environment, and many factories cannot process them or have it moved to a landfill.",1
"In 2007 and 2010 respectively, bars in the Swedish cities of Båstad and Visby, popular party destinations for the wealthy youth, banned the spraying of champagne. The ban referred to champagne spraying possibly violating the law’s requirement on servers of alcohol to maintain good order. The ban caused some people to sink the champagne instead, while others chose to buy more expensive champagne.According to Marie Söderqvist, CEO of the analysis company United Minds and author of the book Status – vägen till lycka (Eng.",1
"Status – the road to happiness), sinking is not just a protest against the ban on spraying champagne: ""One gives the finger to everything – bans, global justice, saving the planet and equality."" Sinking has been the subject of articles by national newspapers like Aftonbladet and Dagens Nyheter, but it is unclear how much sinking actually occurs. In a survey among barkeepers in Båstad, Stockholm, and Visby, one of them said they get ""approximately one serious sinking request per night,"" while others claimed sinking was a myth.Sinking",1
"has also been the theme of a music video by Kakan och Julia featured on Swedish Public Television.Variants of the phenomenon have reportedly taken place, such as hamburger dumping (purchasing a large number of hamburgers at a fast food restaurant, and throwing all but one into the trash). Conspicuous consumption",1
"Coinage of the term ""smog"" has been attributed to Henry Antoine Des Voeux in his 1905 paper, ""Fog and Smoke"" for a meeting of the Public Health Congress. The 26 July 1905 edition of the London newspaper Daily Graphic quoted Des Voeux, ""He said it required no science to see that there was something produced in great cities which was not found in the country, and that was smoky fog, or what was known as 'smog'."": 1 The following day the newspaper stated that ""Dr. Des Voeux did a public service in coining a new word for the London fog.""",1
"However, the term appeared twenty-five years earlier than Voeux's paper, in the Santa Cruz & Monterey Illustrated Handbook published in 1880 and also appears in print in a column quoting from the book in the 3 July 1880, Santa Cruz Weekly Sentinel. On 17 December 1881, in the publication Sporting Times, the author claims to have invented the word: ""The 'Smog' – a word I have invented, combined of smoke and fog, to designate the London atmosphere...""",1
"Especially during autumn and winter when coal-fired heating ramps up, the amount of produced smoke at times forces some Chinese cities to close down roads, schools or airports. One prominent example for this was China's Northeastern city of Harbin in 2013.",1
"The nitrogen oxides and volatile organic compounds can undergo a series of chemical reactions with sunlight, heat, ammonia, moisture, and other compounds to form the noxious vapors, ground level ozone, and particles that comprise smog. Photochemical smog, often referred to as ""summer smog"", is the chemical reaction of sunlight, nitrogen oxides and volatile organic compounds in the atmosphere, which leaves airborne particles and ground-level ozone. Photochemical smog depends on primary pollutants as well as the formation of secondary pollutants. These primary pollutants include nitrogen oxides, particularly nitric oxide (NO) and nitrogen dioxide (NO2), and volatile organic compounds.",1
"During the morning rush hour, a high concentration of nitric oxide and hydrocarbons are emitted to the atmosphere, mostly via on-road traffic but also from industrial sources. Some hydrocarbons are rapidly oxidized by OH· and form peroxy radicals, which convert nitric oxide (NO) to nitrogen dioxide (NO2). (1) R ⋅ + O 2 + M ⟶ RO 2 ⋅ + M {\displaystyle {\ce {R{.}+ O2 + M -> RO2{.}+ M}}} (2) RO 2 ⋅ + NO ⟶ NO 2 + RO ⋅ {\displaystyle {\ce {RO2{.}+ NO -> NO2 + RO{.}}}}",1
(3) HO 2 ⋅ + NO ⟶ NO 2 + OH ⋅ {\displaystyle {\ce {HO2{.}+ NO -> NO2 + OH{.}}}},1
"Nitrogen dioxide (NO2) and nitric oxide (NO) further react with ozone (O3) in a series of chemical reactions: (4) NO 2 + hv ⟶ O ( 3 P ) + NO {\displaystyle {\ce {NO2 + hv -> O(^3P) + NO}}} , λ < 400 n m {\displaystyle \lambda <400nm} (5) O ( 3 P ) + O 2 + M ⟶ O 3 + M ( heat ) {\displaystyle {\ce {O(^3P) + O2 + M-> O3 + M(heat)}}} (6) O 3 + NO ⟶ NO 2 + O 2 {\displaystyle {\ce {O3 + NO -> NO2 + O2}}} This series of",1
"equations is referred to as the photostationary state (PSS). However, because of the presence of Reaction 2 and 3, NOx and ozone are not in a perfectly steady state. By replacing Reaction 6 with Reaction 2 and Reaction 3, the O3 molecule is no longer destroyed. Therefore, the concentration of ozone keeps increasing throughout the day. This mechanism can escalate the formation of ozone in smog. Other reactions such as the photooxidation of formaldehyde (HCHO), a common secondary pollutant, can also contribute to the increased concentration of ozone and NO2.",1
"An erupting volcano can emit high levels of sulfur dioxide along with a large quantity of particulates matter; two key components to the creation of smog. However, the smog created as a result of a volcanic eruption is often known as vog to distinguish it as a natural occurrence. The chemical reactions that form smog following a volcanic eruption are different than the reactions that form photochemical smog. The term smog encompasses the effect when a large number of gas-phase molecules and particulate matter are emitted to the atmosphere, creating a visible haze.",1
The event causing a large number of emissions can vary but still result in the formation of smog.,1
"Plants are another natural source of hydrocarbons that could undergo reactions in the atmosphere and produce smog. Globally both plants and soil contribute a substantial amount to the production of hydrocarbons, mainly by producing isoprene and terpenes. Hydrocarbons released by plants can often be more reactive than man-made hydrocarbons. For example when plants release isoprene, the isoprene reacts very quickly in the atmosphere with hydroxyl radicals. These reactions produce hydroperoxides which increase ozone formation. Smog is a serious problem in many cities and continues to harm human health.",1
"Ground-level ozone, sulfur dioxide, nitrogen dioxide and carbon monoxide are especially harmful for senior citizens, children, and people with heart and lung conditions such as emphysema, bronchitis, and asthma. It can inflame breathing passages, decrease the lungs' working capacity, cause shortness of breath, pain when inhaling deeply, wheezing, and coughing. It can cause eye and nose irritation and it dries out the protective membranes of the nose and throat and interferes with the body's ability to fight infection, increasing susceptibility to illness. Hospital admissions and respiratory deaths often increase during periods when ozone levels are high.There",1
"In 2016, the Ontario Medical Association announced that smog is responsible for an estimated 9,500 premature deaths in the province each year.A 20-year American Cancer Society study found that cumulative exposure also increases the likelihood of premature death from respiratory disease, implying the 8-hour standard may be insufficient.",1
"A study examining 806 women who had babies with birth defects between 1997 and 2006, and 849 women who had healthy babies, found that smog in the San Joaquin Valley area of California was linked to two types of neural tube defects: spina bifida (a condition involving, among other manifestations, certain malformations of the spinal column), and anencephaly (the underdevelopment or absence of part or all of the brain, which if not fatal usually results in profound impairment). An emerging cohort study in China linked early-life smog exposure to an increased risk for adverse pregnancy outcomes, in particular oxidative stress.",1
"It was after this that the great clean-up of London began. One by one, historical buildings which, during the previous two centuries had gradually completely blackened externally, had their stone facades cleaned and restored to their original appearance. Victorian buildings whose appearance changed dramatically after cleaning included the British Museum of Natural History. A more recent example was the Palace of Westminster, which was cleaned in the 1980s.",1
"In December 2005, schools and public offices had to close in Tehran and 1,600 people were taken to hospital, in a severe smog blamed largely on unfiltered car exhaust.",1
"is among the dirtier countries in terms of smog, ranked 123 out of 195 countries measured, where 1 is cleanest and 195 is most smog polluted.",1
"26 July 1943, Los Angeles, California: A smog so sudden and severe that ""Los Angeles residents believe the Japanese are attacking them with chemical warfare."" 30-31 October 1948, Donora, Pennsylvania: 20 died, 600 hospitalized, thousands more stricken. Lawsuits were not settled until 1951. 24 November 1966, New York City, New York: Smog kills at least 169 people.",1
"In the late 1990s, massive immigration to Ulaanbaatar from the countryside began. An estimated 150,000 households, mainly living in traditional Mongolian gers on the outskirts of Ulaanbaatar, burn wood and coal (some poor families burn even car tires and trash) to heat themselves during the harsh winter, which lasts from October to April, since these outskirts are not connected to the city's central heating system. A temporary solution to decrease smog was proposed in the form of stoves with improved efficiency, although with no visible results. Coal-fired ger stoves release high levels of ash and other particulate matter (PM).",1
"Usually, this means that non-essential government services are suspended, and all ports in the affected area are closed. There may also be prohibitions on private sector commercial and industrial activities in the affected area excluding the food sector. So far, the state of emergency rulings due to hazardous API levels was applied to the Malaysian towns of Port Klang, Kuala Selangor, and the state of Sarawak during 1997 Southeast Asian haze and the 2005 Malaysian haze. The London ""pea-soupers"" earned the capital the nickname of ""The Smoke"". Similarly, Edinburgh was known as ""Auld Reekie"".",1
"The smogs feature in many London novels as a motif indicating hidden danger or a mystery, perhaps most overtly in Margery Allingham's The Tiger in the Smoke (1952), but also in Dickens's Bleak House (1852) and T.S. Eliot's ""The Love Song of J. Alfred Prufrock"".",1
"Surface runoff is defined as precipitation (rain, snow, sleet, or hail) that reaches a surface stream without ever passing below the soil surface. It is distinct from direct runoff, which is runoff that reaches surface streams immediately after rainfall or melting snowfall and excludes runoff generated by the melting of snowpack or glaciers.Snow and glacier melt occur only in areas cold enough for these to form permanently. Typically snowmelt will peak in the spring and glacier melt in the summer, leading to pronounced flow maxima in rivers affected by them.",1
"In these regions, even on less infertile cracking clay soils, high amounts of rainfall and potential evaporation are needed to generate any surface runoff, leading to specialised adaptations to extremely variable (usually ephemeral) streams.",1
"When the soil is saturated and the depression storage filled, and rain continues to fall, the rainfall will immediately produce surface runoff. The level of antecedent soil moisture is one factor affecting the time until soil becomes saturated. This runoff is called saturation excess overland flow, saturated overland flow, or Dunne runoff.",1
"Soil surface roughness causes may cause runoff to become concentrated into narrower flow paths: as these incise, the small but well-defined channels which are formed are known as rills. These channels can be as small as one centimeter wide or as large as several meters. If runoff continue to incise and enlarge rills, they may eventually grow to become gullies. Gully erosion can transport large amounts of eroded material in a small time period. Reduced crop productivity usually results from erosion, and these effects are studied in the field of soil conservation.",1
"On the high central plateau of Madagascar, approximately ten percent of that country's land area, virtually the entire landscape is devoid of vegetation, with erosive gully furrows typically in excess of 50 meters deep and one kilometer wide. Shifting cultivation is a farming system which sometimes incorporates the slash and burn method in some regions of the world. Erosion causes loss of the fertile top soil and reduces its fertility and quality of the agricultural produce. Modern industrial farming is another major cause of erosion. Over a third of the U.S. Corn Belt has completely lost its topsoil.",1
Switching to no-till practices would reduce soil erosion from U.S. agricultural fields by more than 70 percent.,1
"Surface run-off results in a significant amount of economic effects. Pine straws are cost effective ways of dealing with surface run-off. Moreover, Surface run-off can be reused through the growth of elephant mass. In Nigeria, elephant grass is considered to be an economical way in which surface run-off and erosion can be reduced. Also, China has suffered significant impact from surface run-off to most of their economical crops such as vegetables. Therefore, they are known to have implemented a system which reduced loss of nutrients ( nitrogen and phosphorus) in soil.",1
"The benefit of the Monte Carlo analysis is not to decrease uncertainty in the input statistics, but to represent the different combinations of the variables that determine potential risks of water-quality excursions. One example of this type of stormwater model is the stochastic empirical loading and dilution model (SELDM) is a stormwater quality model. SELDM is designed to transform complex scientific data into meaningful information about the risk of adverse effects of runoff on receiving waters, the potential need for mitigation measures, and the potential effectiveness of such management measures for reducing these risks.",1
SELDM provides a method for rapid assessment of information that is otherwise difficult or impossible to obtain because it models the interactions among hydrologic variables (with different probability distributions) that result in a population of values that represent likely long-term outcomes from runoff processes and the potential effects of different mitigation measures. SELDM also provides the means for rapidly doing sensitivity analyses to determine the potential effects of different input assumptions on the risks for water-quality excursions.,1
"See also the PA NutrientNet website designed for Pennsylvania's nutrient trading program. Bioretention as a low impact development method of treating surface runoff Liu, Yang (2009). ""Automatic Calibration of a Rainfall-Runoff Model Using a Fast and Elitist Multi-objective Particle Swarm Algorithm"". Expert Systems with Applications. 36 (5): 9533–9538. doi:10.1016/j.eswa.2008.10.086. Liu, Yang; Pender, Gareth (2013). ""Automatic calibration of a rapid flood spreading model using multiobjective optimisations"". Soft Computing. 17 (4): 713–724. doi:10.1007/s00500-012-0944-z. S2CID 27947972. Liu, Yang; Sun, Fan (2010). ""Sensitivity analysis and automatic calibration of a rainfall-runoff model using multi-objectives"". Ecological Informatics. 5 (4): 304–310. doi:10.1016/j.ecoinf.2010.04.006.",1
Stormwater Model USGS Stochastic Empirical Loading and Dilution Model (SELDM),1
"In addition to mixing, the substances in a solution interact with each other at the molecular level. When something is dissolved, molecules of the solvent arrange around molecules of the solute. Heat transfer is involved and entropy is increased making the solution more thermodynamically stable than the solute and solvent separately. This arrangement is mediated by the respective chemical properties of the solvent and solute, such as hydrogen bonding, dipole moment and polarizability. Solvation does not cause a chemical reaction or chemical configuration changes in the solute.",1
"However, solvation resembles a coordination complex formation reaction, often with considerable energetics (heat of solvation and entropy of solvation) and is thus far from a neutral process. When one substance dissolves into another, a solution is formed. A solution is a homogeneous mixture consisting of a solute dissolved into a solvent. The solute is the substance that is being dissolved, while the solvent is the dissolving medium. Solutions can be formed with many different types and forms of solutes and solvents. Solvents can be broadly classified into two categories: polar and non-polar.",1
"This reduction is then compared to the field strength of the charged particle in a vacuum. Heuristically, the dielectric constant of a solvent can be thought of as its ability to reduce the solute's effective internal charge. Generally, the dielectric constant of a solvent is an acceptable predictor of the solvent's ability to dissolve common ionic compounds, such as salts.",1
"The Hansen solubility parameter (HSP) values are based on dispersion bonds (δD), polar bonds (δP) and hydrogen bonds (δH). These contain information about the inter-molecular interactions with other solvents and also with polymers, pigments, nanoparticles, etc. This allows for rational formulations knowing, for example, that there is a good HSP match between a solvent and a polymer. Rational substitutions can also be made for ""good"" solvents (effective at dissolving the solute) that are ""bad"" (expensive or hazardous to health or the environment).",1
"The values for mixtures are taken as the weighted averages of the values for the neat solvents. This can be calculated by trial-and-error, a spreadsheet of values, or HSP software. A 1:1 mixture of toluene and 1,4 dioxane has δD, δP and δH values of 17.8, 1.6 and 5.5, comparable to those of chloroform at 17.8, 3.1 and 5.7 respectively. Because of the health hazards associated with toluene itself, other mixtures of solvents may be found using a full HSP dataset.",1
"The autoignition temperature of carbon disulfide is below 100 °C (212 °F), so objects such as steam pipes, light bulbs, hotplates, and recently extinguished bunsen burners are able to ignite its vapors. In addition some solvents, such as methanol, can burn with a very hot flame which can be nearly invisible under some lighting conditions. This can delay or prevent the timely recognition of a dangerous fire, until flames spread to other materials.",1
"Ethers like diethyl ether and tetrahydrofuran (THF) can form highly explosive organic peroxides upon exposure to oxygen and light. THF is normally more likely to form such peroxides than diethyl ether. One of the most susceptible solvents is diisopropyl ether, but all ethers are considered to be potential peroxide sources. The heteroatom (oxygen) stabilizes the formation of a free radical which is formed by the abstraction of a hydrogen atom by another free radical. The carbon-centered free radical thus formed is able to react with an oxygen molecule to form a peroxide compound.",1
"General health hazards associated with solvent exposure include toxicity to the nervous system, reproductive damage, liver and kidney damage, respiratory impairment, cancer, and dermatitis.",1
"Chronic solvent exposures are often caused by the inhalation of solvent vapors, or the ingestion of diluted solvents, repeated over the course of an extended period. Some solvents including chloroform and benzene (a common ingredient in gasoline) are known to be proven carcinogens, while many others are considered by the World Health Organization to be likely carcinogens. Solvents can damage internal organs like the liver, the kidneys, the nervous system, or the brain. The cumulative effects of long-term or repeated exposure to solvents are called chronic solvent-induced encephalopathy (CSE).",1
"Chronic exposure to organic solvents in the work environment can produce a range of adverse neuropsychiatric effects. For example, occupational exposure to organic solvents has been associated with higher numbers of painters suffering from alcoholism. Ethanol has a synergistic effect when taken in combination with many solvents; for instance, a combination of toluene/benzene and ethanol causes greater nausea/vomiting than either substance alone. Many solvents are known or suspected to be cataractogenic, greatly increasing the risk of developing cataracts in the lens of the eye. Solvent exposure has also been associated with neurotoxic damage causing hearing loss and color vision losses.",1
"Solvent selection tool ACS Green Chemistry Institute ""European Solvents Industry Group - ESIG - ESIG European Solvents Industry Group"" Solvents in Europe. Table and text O-Chem Lecture Tables Properties and toxicities of organic solvents CDC – Organic Solvents – NIOSH Workplace Safety and Health Topic EPA – Solvent Contaminated Wipes",1
"Soot as an airborne contaminant in the environment has many different sources, all of which are results of some form of pyrolysis. They include soot from coal burning, internal-combustion engines, power-plant boilers, hog-fuel boilers, ship boilers, central steam-heat boilers, waste incineration, local field burning, house fires, forest fires, fireplaces, and furnaces. These exterior sources also contribute to the indoor environment sources such as smoking of plant matter, cooking, oil lamps, candles, quartz/halogen bulbs with settled dust, fireplaces, exhaust emissions from vehicles, and defective furnaces.",1
"Soot in very low concentrations is capable of darkening surfaces or making particle agglomerates, such as those from ventilation systems, appear black. Soot is the primary cause of ""ghosting"", the discoloration of walls and ceilings or walls and flooring where they meet. It is generally responsible for the discoloration of the walls above baseboard electric heating units. The formation of soot depends strongly on the fuel composition. The rank ordering of sooting tendency of fuel components is: naphthalenes benzenes aliphatics. However, the order of sooting tendencies of the aliphatics (alkanes, alkenes, and alkynes) varies dramatically depending on the flame type.",1
"The difference between the sooting tendencies of aliphatics and aromatics is thought to result mainly from the different routes of formation. Aliphatics appear to first form acetylene and polyacetylenes, which is a slow process; aromatics can form soot both by this route and also by a more direct pathway involving ring condensation or polymerization reactions building on the existing aromatic structure.",1
"The Intergovernmental Panel on Climate Change (IPCC) adopted the description of soot particles given in the glossary of Charlson and Heintzenberg (1995), ""Particles formed during the quenching of gases at the outer edge of flames of organic vapours, consisting predominantly of carbon, with lesser amounts of oxygen and hydrogen present as carboxyl and phenolic groups and exhibiting an imperfect graphitic structure"".Formation of soot is a complex process, an evolution of matter in which a number of molecules undergo many chemical and physical reactions within a few milliseconds. Soot is a powder-like form of amorphous carbon.",1
"Gas-phase soot contains polycyclic aromatic hydrocarbons (PAHs). The PAHs in soot are known mutagens and are classified as a ""known human carcinogen"" by the International Agency for Research on Cancer (IARC). Soot forms during incomplete combustion from precursor molecules such as acetylene. It consists of agglomerated nanoparticles with diameters between 6 and 30 nm. The soot particles can be mixed with metal oxides and with minerals and can be coated with sulfuric acid. Many details of soot formation chemistry remain unanswered and controversial, but there have been a few agreements: Soot begins with some precursors or building blocks.",1
"Soot also tends to form in chimneys in domestic houses possessing one or more fireplaces. If a large deposit collects in one, it can ignite and create a chimney fire. Regular cleaning by a chimney sweep should eliminate the problem. Soot mechanism is difficult to model mathematically because of the large number of primary components of diesel fuel, complex combustion mechanisms, and the heterogeneous interactions during soot formation.",1
"They are useful, especially when the accuracy of the model parameters is low. Unlike empirical models, phenomenological models are flexible enough to produce reasonable results when multiple operating conditions change. ""Blacks"" . Encyclopedia Americana. 1920.",1
"The nitrogen compounds through which excess nitrogen is eliminated from organisms are called nitrogenous wastes () or nitrogen wastes. They are ammonia, urea, uric acid, and creatinine. All of these substances are produced from protein metabolism. In many animals, the urine is the main route of excretion for such wastes; in some, it is the feces.",1
"Nitrates and nitrites are wastes produced by nitrifying bacteria, just as sulfur and sulfates are produced by the sulfur-reducing bacteria and sulfate-reducing bacteria. Insoluble iron waste can be made by iron bacteria by using soluble forms. In plants, resins, fats, waxes, and complex organic chemicals are exuded from plants, e.g., the latex from rubber trees and milkweeds. Solid waste products may be manufactured as organic pigments derived from breakdown of pigments like hemoglobin, and inorganic salts like carbonates, bicarbonates, and phosphate, whether in ionic or in molecular form, are excreted as solids.Animals dispose of solid waste as feces.",1
Ammonia poisoning Deamination,1
"Assume a uniform cloud that extends infinitely in the horizontal plane, also assume that the particle size distribution peaks near an average value of r ¯ {\displaystyle {\bar {r}}} . The formula for the optical depth of a cloud is τ = 2 π h r ¯ 2 N {\displaystyle \tau =2\pi \;\!h{\bar {r}}^{2}N} where τ {\displaystyle \tau } is the optical depth, h {\displaystyle h} is cloud thickness, r ¯ {\displaystyle {\bar {r}}} is the average particle size, and N {\displaystyle N} is the number density of cloud droplets.",1
"Taking our assumptions into account we can combine the previous two equations to yield τ = 3 2 h L W C ρ L r ¯ {\displaystyle \tau ={\frac {3}{2}}{\frac {h\,LWC}{\rho _{L}{\bar {r}}}}} To derive the effect of changing N {\displaystyle N} while keeping h {\displaystyle h} , ρ L {\displaystyle \rho _{L}} and L W C {\displaystyle LWC} constant, from the last equation we can write τ ∝ 1 r ¯ {\displaystyle \tau \propto {\frac {1}{\bar {r}}}} and from the equation for L W C {\displaystyle LWC} we can write r ¯ 3 ∝ 1 N {\displaystyle {\bar {r}}^{3}\propto {\frac",1
"Noxious vapors can cause health effects, either acutely such as CNS disturbances like headaches or mental status changes, and they can have chronic health effects, e.g. in the case of radon, which can cause lung cancer. Lastly, vapors can be severe ""aesthetic problems"", e.g., odors from hydrogen sulfide. In the United States, vapor intrusion is handled in individual states in different ways. Pathbreaking guidance on vapor intrusion was released by the New York Department of Health in 2006.In",1
"June 2010, the American Society for Testing and Materials (ASTM International) released a commercial ""Standard Guide for Vapor Encroachment Screening on Property Involved in Real Estate Transactions"" (ASTM E 2600–10).In 2002 the US EPA had issued its first draft guidance on the subject . The George W. Bush administration dropped the project in 2003, and only in 2013 Obama's appointee as EPA Assistant Administrator in the Office of Solid Waste and Emergency Response, made it a priority to complete the document.",1
"Design items and furniture are also seeing an increase in being traded as secondhand goods. With some designer items being sought after in marketplaces. When trading design furniture and items you usually must be aware of the original retail price as most of the goods, if kept well, retain their value quite well.",1
"A venturi scrubber consists of three sections: a converging section, a throat section, and a diverging section. The inlet gas stream enters the converging section and, as the area decreases, gas velocity increases. Liquid is introduced either at the throat or at the entrance to the converging section. The inlet gas, forced to move at extremely high velocities in the small throat section, turbulently mixes with the liquid, producing an enormous number of very tiny droplets. Particle and gas removal occur in the diverging section as the inlet gas stream mixes with the fog of tiny liquid droplets.",1
"The inlet stream then exits through the diverging section, where it is forced to slow down. If liquid is introduced above the converging section and coats the walls up to the throat, then the venturi is described as having a ""wet wall"" or ""wetted throat"" as seen in Figure 2. This method allows particulates in the stream that may be prone to caking onto surfaces to be washed away and reduces the mechanical abrasion of particles hitting the throat at high speed.",1
"Liquid can also be introduced by spray nozzles directly into the gas stream and for low gas flow velocities this may provide more efficient operation, either or both methods may be employed depending on the application. Simple venturis have fixed throat areas and so will only operate efficiently over a certain range of flow rates. Adjustable-throat venturis allow efficiency to be maintained over a much larger range of flows by changing the size of the throat in accordance with the gas flow rate.",1
"Certain types of orifices (throat areas) that create more turbulence than a true venturi were found to be equally efficient for a given unit of energy consumed and the results of these findings led to the development of the annular-orifice, or adjustable-throat, venturi scrubber (Figure 5). The size of the throat area is varied by moving a plunger, or adjustable disk, up or down in the throat, thereby decreasing or increasing the annular opening. Gas flows through the annular opening and atomizes liquid that is sprayed onto the plunger or swirled in from the top.",1
"These high pressure drops result in high operating costs. The liquid-injection rate, or liquid-to-gas ratio (L/G), also affects particle collection. The proper amount of liquid must be injected to provide adequate liquid coverage over the throat area and make up for any evaporation losses. If there is insufficient liquid, then there will not be enough liquid targets to provide the required capture efficiency. Most venturi systems operate with an L/G ratio of 0.4 to 1.3 L/m3 (3 to 10 gal/1000 ft3). L/G ratios less than 0.4",1
"L/m3 (3 gal/1000 ft3) are usually not sufficient to cover the throat, and adding more than 1.3 L/m3 (10 gal/1000 ft3) does not usually significantly improve particle collection efficiency.",1
"The gas velocities are lower and the liquid-to-gas ratios are higher for absorption. For a given venturi design, if the gas velocity is decreased, then the pressure drop (resistance to flow) will also decrease and vice versa. Therefore, by reducing pressure drop, the gas velocity is decreased and the corresponding residence time is increased. Liquid-to-gas ratios for these gas absorption applications are approximately 2.7 to 5.3 L/m3 (20 to 40 gal/1000 ft3). The reduction in gas velocity allows for a longer contact time between phases and better absorption.",1
"Gas velocities in the throat can reach speeds of 430 km/h (270 mph). Particles and liquid droplets traveling at these speeds can rapidly erode the scrubber shell. Abrasion can be reduced by lining the throat with silicon carbide brick or fitting it with a replaceable liner. Abrasion can also occur downstream of the throat section. To reduce abrasion here, the elbow at the bottom of the scrubber (leading into the separator) can be flooded (i.e. filled with a pool of scrubbing liquid). Particles and droplets impact on the pool of liquid, reducing wear on the scrubber shell.",1
"However, when heavy liquid slurries (either viscous or particle-loaded) are recirculated, open-weir injection is often necessary.",1
"Biogenic volatile organic compounds (BVOCs) encompass VOCs emitted by plants, animals, or microorganisms, and while extremely diverse, are most commonly terpenoids, alcohols, and carbonyls (methane and carbon monoxide are generally not considered). Not counting methane, biological sources emit an estimated 760 teragrams of carbon per year in the form of VOCs. The majority of VOCs are produced by plants, the main compound being isoprene. Small amounts of VOCs are produced by animals and microbes. Many VOCs are considered secondary metabolites, which often help organisms in defense, such as plant defense against herbivory.",1
"The strong odor emitted by many plants consists of green leaf volatiles, a subset of VOCs. Although intended for nearby organisms to detect and respond to, these volatiles can be detected and communicated through wireless electronic transmission, by embedding nanosensors and infrared transmitters into the plant materials themselves.Emissions are affected by a variety of factors, such as temperature, which determines rates of volatilization and growth, and sunlight, which determines rates of biosynthesis. Emission occurs almost exclusively from the leaves, the stomata in particular.",1
"VOCs emitted by terrestrial forests are often oxidized by hydroxyl radicals in the atmosphere; in the absence of NOx pollutants, VOC photochemistry recycles hydroxyl radicals to create a sustainable biosphere-atmosphere balance. Due to recent climate change developments, such as warming and greater UV radiation, BVOC emissions from plants are generally predicted to increase, thus upsetting the biosphere-atmosphere interaction and damaging major ecosystems. A major class of VOCs is the terpene class of compounds, such as myrcene.",1
"Existing buildings may be replenished with new VOC sources, such as new furniture, consumer products, and redecoration of indoor surfaces, all of which lead to a continuous background emission of TVOCs, requiring improved ventilation.Numerous studies show strong seasonal variations in indoors VOC emissions, with emission rates increasing in summer. This is largely due to the rate of diffusion of VOC species through materials to the surface, increasing with temperature. Most studies have shown that this leads to generally higher concentrations of TVOCs indoors in summer.",1
"Key signs or symptoms associated with exposure to VOCs include conjunctival irritation, nose and throat discomfort, headache, allergic skin reaction, dyspnea, declines in serum cholinesterase levels, nausea, vomiting, nose bleeding, fatigue, dizziness.The ability of organic chemicals to cause health effects varies greatly from those that are highly toxic to those with no known health effects. As with other pollutants, the extent and nature of the health effect will depend on many factors including level of exposure and length of time exposed.",1
"Eye and respiratory tract irritation, headaches, dizziness, visual disorders, and memory impairment are among the immediate symptoms that some people have experienced soon after exposure to some organics. At present, not much is known about what health effects occur from the levels of organics usually found in homes.",1
"A dark color, however, could require 5–15 ounces of colorant, adding up to 300 or more grams of VOCs per gallon of paint.",1
"However, one of these studies reported that ethanol, isopropanol, ether, and acetone were the main compounds in the interior of the site. Following the same line, in a study conducted in the United States, it was established that nursing assistants are the most exposed to compounds such as ethanol, while medical equipment preparers are most exposed to 2-propanol.In",1
"relation to exposure to VOCs by cleaning and hygiene personnel, a study conducted in 4 hospitals in the United States established that sterilization and disinfection workers are linked to exposures to d-limonene and 2-propanol, while those responsible for cleaning with chlorine-containing products are more likely to have higher levels of exposure to α-pinene and chloroform. Those who perform floor and other surface cleaning tasks (e.g.,",1
"Furthermore, in another study carried out in the same European country, it was found that there is a significant association between breathlessness in the elderly population and elevated exposure to VOCs such as toluene and o-xylene, unlike the remainder of the population.",1
"As applied to breath analysis, the following modalities are employed for sampling: gas sampling bags, syringes, evacuated steel and glass containers.",1
"In the U.S., standard methods have been established by the National Institute for Occupational Safety and Health (NIOSH) and another by U.S. OSHA. Each method uses a single component solvent; butanol and hexane cannot be sampled, however, on the same sample matrix using the NIOSH or OSHA method.VOCs are quantified and identified by two broad techniques. The major technique is gas chromatography (GC). GC instruments allow the separation of gaseous components. When coupled to a flame ionization detector (FID) GCs can detect hydrocarbons at the parts per trillion levels.",1
"measurement (signal integration) time. The mass resolution of these devices is between 7000 and 10,500 m/Δm, thus it is possible to separate most common isobaric VOCs and quantify them independently.",1
"Chemical fingerprinting and breath analysis of volatile organic compounds has also been demonstrated with chemical sensor arrays, which utilize pattern recognition for detection of component volatile organics in complex mixtures such as breath gas.",1
"To achieve comparability of VOC measurements, reference standards traceable to SI-units are required. For a number of VOCs gaseous reference standards are available from specialty gas suppliers or national metrology institutes, either in the form of cylinders or dynamic generation methods. However, for many VOCs, such as oxygenated VOCs, monoterpenes, or formaldehyde, no standards are available at the appropriate amount of fraction due to the chemical reactivity or adsorption of these molecules. Currently, several national metrology institutes are working on the lacking standard gas mixtures at trace level concentration, minimising adsorption processes, and improving the zero gas.",1
"The final scopes are for the traceability and the long-term stability of the standard gases to be in accordance with the data quality objectives (DQO, maximum uncertainty of 20% in this case) required by the WMO/GAW program.",1
"This is commonly referred to as waste heat or ""secondary heat"", or ""low-grade heat"". This heat is useful for the majority of heating applications, however, it is sometimes not practical to transport heat energy over long distances, unlike electricity or fuel energy. The largest proportions of total waste heat are from power stations and vehicle engines. The largest single sources are power stations and industrial plants such as oil refineries and steelmaking plants.",1
"Industrial processes, such as oil refining, steel making or glass making are major sources of waste heat.",1
"In cities this source typically contributes 15–50 W/m2 to the local heat balance, and several hundred W/m2 in the center of large cities in cold climates and industrial areas."" In 2020, the overall anthropogenic annual energy release was 168,000 terawatt-hours; given the 5.1×1014 m2 surface area of Earth, this amounts to a global average anthropogenic heat release rate of 0.04 W/m2.",1
"Anthropogenic heat is a small influence on rural temperatures, and becomes more significant in dense urban areas. It is one contributor to urban heat islands. Other human-caused effects (such as changes to albedo, or loss of evaporative cooling) that might contribute to urban heat islands are not considered to be anthropogenic heat by this definition. Anthropogenic heat is a much smaller contributor to global warming than greenhouse gases are. In 2005, anthropogenic waste heat flux globally accounted for only 1% of the energy flux created by anthropogenic greenhouse gases.",1
"The heat flux is not evenly distributed, with some regions higher than others, and significantly higher in certain urban areas. For example, global forcing from waste heat in 2005 was 0.028 W/m2, but was +0.39 and +0.68 W/m2 for the continental United States and western Europe, respectively.Although waste heat has been shown to have influence on regional climates, climate forcing from waste heat is not normally calculated in state-of-the-art global climate simulations. Equilibrium climate experiments show statistically significant continental-scale surface warming (0.4–0.9 °C) produced by one 2100 AHF scenario, but not by current or 2040 estimates.",1
"Simple global-scale estimates with different growth rates of anthropogenic heat that have been actualized recently show noticeable contributions to global warming, in the following centuries. For example, a 2% p.a. growth rate of waste heat resulted in a 3 degree increase as a lower limit for the year 2300. Meanwhile, this has been confirmed by more refined model calculations.A 2008 scientific paper showed that if anthropogenic heat emissions continue to rise at the current rate, they will become a source of warming as strong as GHG emissions in the 21st century.",1
"Both the scent and what produces it vary somewhat in different kinds of cars. Most of the interior of an automobile consists of plastic held together with a number of adhesives and sealers. Such materials release volatile organic compounds, via outgassing or off-gassing. These fumes are generally attributed to mixtures of many different chemicals off-gassing and to plasticizers, although their vapor pressures are very low and they are not considered volatile.Researchers tested more than 200 U.S. vehicles of model years 2011–2012 for chemicals such as organobromine compounds (associated with brominated flame retardants, or BFRs), organochlorine compounds (e.g.,",1
"The researchers observed that the potential toxicity of many of these compounds could pose a danger to human health.The total volatile organic compound levels can reach 7,500 micrograms per cubic meter. Concentrations decayed by approximately 90% over a three-week period. Over sixty chemical compounds were identified inside the interiors of the four vehicles in this study. In some instances, the odor results from a manufacturing defect. According to official documents of Bentley Motors (BT26), an ""obnoxious odor"" in Bentley cars for model years 1999–2002 was traced to a rust inhibitor.",1
"In some cultures, the new car smell is not considered desirable and manufacturers work to eliminate it. A two-year study released in 2001 by the CSIRO in Australia found several health problems associated with these chemicals. CSIRO research scientist, Dr. Stephen Brown, reported anecdotal accounts of disorientation, headache, and irritation in some drivers of new cars. He measured pollutant levels in new cars that were sufficient to cause similar effects within minutes in controlled experiments by other researchers. Chemicals found in the cars included the carcinogen benzene, two other possible carcinogens cyclohexanone and styrene, and several other toxic chemicals.",1
"A more recent study in Japan found that the volatile organic chemicals in a new minivan were over 35 times the health limit the day after its delivery. In four months levels had fallen under the limit but increased again in the hot summer months, taking three years to permanently remain below the limit. The limits were set by the Japanese health ministry in response to more car owners suffering from sick building syndrome. A Daily Telegraph article on the study described the enjoyment of new car smell as ""akin to glue-sniffing"".However, another study showed little toxicity in new car odors.The",1
"most common side effects of the new car smell are headaches, sore throats, nausea, and drowsiness. Nick Kurczewski (July 10, 2021), ""The Science of the New-Car Smell"", Car & Driver",1
"These problems are of special concern during measurement of chemicals assumed to be significant at very low concentrations.Sample preservation may partially resolve the second problem. A common procedure is keeping samples cold to slow the rate of chemical reactions and phase change, and analyzing the sample as soon as possible; but this merely minimizes the changes rather than preventing them.: 43–45 A useful procedure for determining influence of sample containers during delay between sample collection and analysis involves preparation for two artificial samples in advance of the sampling event.",1
The blank (negative control) and spiked sample (positive control) are carried with the sample of interest and analyzed by the same methods at the same times to determine any changes indicating gains or losses during the elapsed time between collection and analysis.,1
IWMI developed protocols for cleaning wells contaminated by saltwater; these were subsequently officially endorsed by the World Health Organization as part of its series of Emergency Guidelines.,1
"Wrecks all along the peninsular coast at Nouadhibou, in Mauritania Many wrecks along the Skeleton Coast in Namibia",1
"Several locations near the Aral Sea The ship-breaking yards of Alang (India), Chittagong (Bangladesh), and Gadani (Pakistan)",1
"Guilvinec-Lechiagat On the River Rance Magouër (Plouhinec, Morbihan) Plouhinec, Finistère Landévennec",1
"Most of the ships were excavated in the following years, but there are still 8 wrecks from this event and several others.",1
"The US Navy ""phantom fleet"" at Suisun Bay, to the north of San Francisco Bay The US Army Patuxent River ghost fleet"" of 1927-40, comprising the USAT Monticello (ex-USS Agamemnon, ex-German SS Kaiser Wilhelm II of 1903), America (ex-German SS Amerika of 1905), Mount Vernon (ex-German Kronprinzessin Cecile of 1907) and George Washington (ex-German SS George Washington of 1909) Witte's Marine Salvage - the Staten Island boat graveyard. Bikini Atoll was designated as a ship graveyard for the U.S. Pacific fleet; it later became known as a nuclear testing facility. Mallows Bay, Maryland. Green Jacket Shoal, Rhode Island",1
New South Wales: Stockton Breakwater (Newcastle) Homebush Bay Ships' Graveyard (Sydney) Pindimar Bay Ships' Graveyard/The Duckhole (Myall Lakes)Northern Territory: Darwin Harbour East ArmQueensland: Bishop Island Ships' Graveyard (Brisbane) Tangalooma Ships' Graveyard (Moreton Island) The Bulwer Wrecks (Moreton Island) Curtin Artificial ReefSouth Australia: As of November 2020 there are 19 ships' graveyards in South Australia.,1
ships graveyard,1
"By progressively converting dissolved material into solids, usually a biological floc or biofilm, which is then settled out or separated, an effluent stream of increasing purity is produced.",1
"Anaerobic wastewater treatment processes (for example UASB, EGSB) are also widely applied in the treatment of industrial wastewaters and biological sludge.",1
"Partial bans on motor vehicles from urban areas have been shown to have minimal impacts upon reducing sound levels (as would become clear from later modeling studies); for example, the partial ban in Gothenburg, Sweden resulted in minuscule reduction of sound levels.Regulation in the EU and Japan of tire and power-train noise has only sought to reduce noise by approx 3 dB, and will only slowly take effect because a few older noisier vehicles can dominate the soundscape. Small reductions in vehicle noise occurred in the 1970s as states and provinces enforced unmuffled vehicle ordinances.",1
"Traffic operations noise is affected significantly by vehicle speeds, since sound energy roughly doubles for each increment of ten miles an hour in vehicle velocity; an exception to this rule occurs at very low speeds where braking and acceleration noise dominate over aerodynamic noise.",1
"Trucks contribute a disproportionate amount of noise not only because of their large engines, but also the height of the diesel stack and the aerodynamic drag. Significant interior noise is usually present inside moving motor vehicles; in fact, passengers are generally not aware that these levels are high, because experience has led motorists to expect levels commonly exceeding 65 dBA.",1
have shown that cutting longitudinal grooves in the pavement reduces noise.,1
"Tire types can cause 10 dB(A) variations in noise, based on a 2001 sample of 100 commercially available tires. As of 2001, there was no correlation between grip and noise. Quieter tires may have slightly lower rolling resistance.Tire labeling for noise, grip, and rolling resistance has been widely introduced in Europe, with noisy tires being taxed.",1
"Roadway geometrics and surrounding terrain are interrelated, since the propagation of sound is sensitive to the overall geometry and must consider diffraction (bending of sound waves around obstacles), reflection, ground wave attenuation, spreading loss and refraction. A simple discussion indicates that sound will be diminished when the path of sound is blocked by terrain, or will be enhanced if the roadway is elevated so as to broadcast; however, the complexities of variable interaction are so great, that there are many exceptions to this simple argument.",1
"Micrometeorology is significant in that sound waves can be refracted by wind gradients or thermoclines, effectively dismissing the effect of some noise barriers or terrain intervention.",1
"At the micro level of managing particular roads, because of the complexity of the variables discussed above, it is necessary to create a computer model that can analyze sound levels in the vicinity of roadways. The first meaningful models arose in the late 1960s and early 1970s addressing the noise line source (e.g. roadway). Two of the leading research teams were BBN in Boston and ESL of Sunnyvale, California. Both of these groups developed complex mathematical models to allow the study of alternate roadway designs, traffic operations and noise mitigation strategies in an arbitrary setting.",1
"An interesting early case where two of the leading models were pitted against each other involved a proposed widening of the New Jersey Turnpike from six to twelve lanes. The BBN and ESL models were on opposing sides of a matter decided in New Jersey Superior Court. This case in the early 1970s was one of the first U.S. examples of acoustical scientists playing a role in the design of a major highway. The models allowed the court to understand the effects of roadway geometry (width in this case), vehicle speeds, proposed noise barriers, residential setback and pavement types.",1
"Later cases have occurred in every state, both in contentious actions and in routine highway planning and design. The public as well as governmental agencies have become aware of the value of acoustical science to provide useful insights to the roadway design process. Even without regulation, there are strong individual economic pressures for quieter vehicles, because owners and employers see quieter vehicles as more luxurious and less stressful. The tighter regulatory requirements of the EU and Japan encourage quieter design even in unregulated countries, because most car manufacturers aspire to international sales.",1
"When physicist Anders Ångström examined the spectrum of the aurora borealis, he discovered that even on nights when the aurora was absent, its characteristic green line was still present. It was not until the 1920s that scientists were beginning to identify and understand the emission lines in aurorae and of the sky itself, and what was causing them. The green line Angstrom observed is in fact an emission line with a wavelength of 557.7 nm, caused by the recombination of oxygen in the upper atmosphere.",1
"Airglow is the collective name of the various processes in the upper atmosphere that result in the emission of photons, with the driving force being primarily UV radiation from the Sun. Several emission lines are dominant: a green line from oxygen at 557.7 nm, a yellow doublet from sodium at 589.0 and 589.6 nm, and red lines from oxygen at 630.0 and 636.4 nm. The sodium emissions come from a thin sodium layer approximately 10 km thick at an altitude of 90–100 km, above the mesopause and in the D-layer of the ionosphere.",1
"The red oxygen lines originate at altitudes of about 300 km, in the F-layer. The green oxygen emissions are more spatially distributed. How sodium gets to mesospheric heights is not yet well understood, but it is believed to be a combination of upward transport of sea salt and meteoritic dust. In daytime, sodium and red oxygen emissions are dominant and roughly 1,000 times as bright as nighttime emissions because in daytime, the upper atmosphere is fully exposed to solar UV radiation.",1
"When the Sun's altitude is < -6° 99% of the atmosphere in zenith is in the Earth's shadow and second order scattering takes over. At the horizon, however, 35% of the atmosphere along the line of sight is still directly illuminated, and continues to be until the sun reaches -12°. From -12° to -18° only the uppermost parts of the atmosphere along the horizon, directly above the spot where the Sun is, is still illuminated. After that, all direct illumination ceases and astronomical darkness sets in.",1
"When the Sun has just set, the brightness of the sky decreases rapidly, thereby enabling the viewing of the airglow that is caused from such high altitudes that they are still fully sunlit until the Sun drops more than about 12° below the horizon. During this time, yellow emissions from the sodium layer and red emissions from the 630 nm oxygen lines are dominant, and contribute to the purplish color sometimes seen during civil and nautical twilight.",1
"After the Sun has also set for these altitudes at the end of nautical twilight, the intensity of light emanating from earlier mentioned lines decreases, until the oxygen-green remains as the dominant source. When astronomical darkness has set in, the green 557.7 nm oxygen line is dominant, and atmospheric scattering of starlight occurs. Differential refraction causes different parts of the spectrum to dominate, producing a golden hour and a blue hour.",1
"Note that the contributions from Airglow and Zodiacal light vary with the time of year, the solar cycle, and the observer's latitude roughly as follows: A i r g l o w / S 10 = 145 + 108 ( S − 0.8 ) {\displaystyle {\rm {Airglow}}/{\rm {S}}_{10}=145+108(S-0.8)} where S is the solar 10.7 cm flux in MJy, and various sinusoidally between 0.8 and 2.0 with the 11-year solar cycle, yielding an upper contribution of ~270 S10 at solar maximum.",1
"The intensity of zodiacal light depends on the ecliptic latitude and longitude of the point in the sky being observed relative to that of the Sun. At ecliptic longitudes differing from the Sun's by > 90 degrees, the relation is Z o d i a c a l L i g h t / S 10 = 140 − 90 sin ⁡ ( | β | ) {\displaystyle {\rm {ZodiacalLight}}/{\rm {S}}_{10}=140-90\sin(|\beta |)} where β is the ecliptic latitude and is smaller than 60°, when larger than 60 degrees the contribution is that given in the table.",1
"Several distinct sounds are created by various parts of the train, such as engines, traction motors, brakes, and the wheels rolling on the rails. Roughness and irregularities on the wheel and rail surfaces are a source of noise and vibration. Rail joints and squats on the rail cause a familiar ""clickety-clack"" sound as train wheels roll over them. Rail corrugation (a periodic wear pattern resembling corrugated metal) causes tonal noise and vibration; fine, short-wavelength corrugation is known as ""roaring rails"" due to its high-pitched sound, whereas coarse, long-wavelength corrugation can cause the ground and nearby buildings to vibrate.",1
"Significant concentrations of uranium occur in some substances such as phosphate rock deposits, and minerals such as lignite, and monazite sands in uranium-rich ores (it is recovered commercially from these sources). Coal fly ash from uranium bearing coal is particularly rich in uranium and there have been several proposals to ""mine"" this waste product for its uranium content. Due to the fact that part of the ash of a coal power plant escapes through the smokestack, the radioactive contamination released by coal power plants in regular operation is actually higher than that of nuclear power plants.Seawater contains about 3.3",1
"parts per billion of uranium by weight, approximately (3.3 µg/kg) or, 3.3 micrograms per liter of seawater.",1
"The radiation hazards of uranium mining and milling were not appreciated in the early years, resulting in workers exposed to high levels of radiation. Inhalation of radon gas caused sharp increases in lung cancers among underground uranium miners employed in the 1940s and 1950s.",1
"In 1950, the US Public Health service began a comprehensive study of uranium miners, leading to the first publication of a statistical correlation between cancer and uranium mining, released in 1962. The federal government eventually regulated the standard amount of radon in mines, setting the level at 0.3 WL on January 1, 1969.Out of 69 present and former uranium milling sites in 12 states, 24 have been abandoned, and are the responsibility of the US Department of Energy.",1
"Accidental releases from uranium mills include the 1979 Church Rock uranium mill spill in New Mexico, called the largest accident of nuclear-related waste in US history, and the 1986 Sequoyah Corporation Fuels Release in Oklahoma.In 1990, Congress passed the Radiation Exposure Compensation Act (RECA), granting reparations for those affected by mining, with amendments passed in 2000 to address criticisms with the original act.",1
"Multiple studies using cultured cells and laboratory rodents suggest the possibility of leukemogenic, genetic, reproductive, and neurological effects from chronic exposure. A 2005 epidemiology review concluded: ""In aggregate the human epidemiological evidence is consistent with increased risk of birth defects in offspring of persons exposed to DU."" The World Health Organization states that no risk of reproductive, developmental, or carcinogenic effects have been reported in humans due to DU exposure. This report has been criticized by Dr. Keith Baverstock for not including possible long-term effects.",1
"Most scientific studies have found no link between uranium and birth defects, but some claim statistical correlations between soldiers exposed to DU, and those who were not, concerning reproductive abnormalities. One study found epidemiological evidence for increased risk of birth defects in the offspring of persons exposed to DU. Several sources have attributed an increased rate of birth defects in the children of Gulf War veterans and in Iraqis to inhalation of depleted uranium. A 2001 study of 15,000 Gulf War combat veterans and 15,000 control veterans found that the Gulf War veterans were 1.8 (fathers) to 2.8",1
"(mothers) times more likely to have children with birth defects. A study of Gulf War Veterans from the UK found a 50% increased risk of malformed pregnancies reported by men over non-Gulf War veterans. The study did not find correlations between Gulf war deployment and other birth defects such as stillbirth, chromosomal malformations, or congenital syndromes. The father's service in the Gulf War was associated with increased rate of miscarriage, but the mother's service was not.",1
"Uranium causes reproductive defects and other health problems in rodents, frogs and other animals. Uranium was also shown to have cytotoxic, genotoxic and carcinogenic effects in animals. It has been shown in rodents and frogs that water-soluble forms of uranium are teratogenic. Bacteria and Pseudomonadota, such as Geobacter and Burkholderia fungorum (strain Rifle), can reduce and fix uranium in soil and groundwater. These bacteria change soluble U(VI) into the highly insoluble complex-forming U(IV) ion, hence stopping chemical leaching.",1
"Nakamura, Takashi; Halada, Kohmei (2014). Urban Mining Systems. Briefs in Applied Sciences and Technology. Springer. ISBN 9784431550754.",1
"mi) above sea level—that exhibits extreme cold, low pressure, desiccation, oxidation, and higher solar irradiation.Beyond investigating viability alone, concerns of whether microorganisms can survive deep space conditions and potentially be transported to other planets, such as Mars, has long been a concern to scientists. To further this understanding, it is necessary to determine if there is a genomic (genetic) adaptation that occurs with survival in this extreme environment. Analysis of RNA could provide valuable insight into the functional effects on surviving microorganisms.",1
"For instance, this approach could help identify genes associated with repairing damage to the cell envelope, genome, and core metabolic proteins. The microorganism tested was Bacillus pumilus (strain SAFR-032), a resilient radiation-tolerant spore-forming bacteria isolated from a clean room environment in a NASA spacecraft assembly. The 80-pound gondola features four doors that rotate to expose up to 10 experimental samples each for 8 hours. To terminate the flight, an explosive charge detonated, tearing a hole in the balloon.",1
"E-MIST and other science payloads attached to the balloon's gondola were returned to the surface under a parachute, where waiting researchers recovered the biological samples for analysis. Major payload components were a lithium-ion battery, an ultraviolet (UV) radiometer, humidity and temperatures sensors, and a flight computer. After 8 hours exposure in the stratosphere (31 km above sea level), 99.9% of the entire population was destroyed. According to the researchers, ""most terrestrial bacteria would be inactivated within the first [day] on Mars if contaminated spacecraft surfaces receive direct sunlight.""Of the 40 million spores exposed to the stratosphere, only 267 spores (or 0.0007%)",1
"remained viable. Extrapolating this, no viable spores would remain if flight samples had an additional 150 minutes of Sun exposure in the stratosphere (630 min total time). The survivors showed three single nucleotide (base pair) substitutions compared to unexposed controls kept on the ground. These three coding regions are associated with bacterial sporulation and metabolism. A similar observation was recorded on SAFR-032 samples that were exposed outside the International Space Station.Even",1
"after cleaning, spacecraft leaving Earth still carry microorganisms on board that are embedded within surfaces, instruments, electronics, and other inaccessible areas that cannot be readily cleaned and are not exposed to direct sunlight, so there is a concern about the few survivors, which may be pushed in evolutionarily consequential directions. The researchers suggest that ultraviolet-C lamps (UVC LED arrays) could be embedded in lander spacecraft hardware to help sterilize their interior. Extremophile Interplanetary contamination Life on Mars Panspermia Planetary protection Tersicoccus phoenicis Columbia Scientific Balloon Facility - NASA/JPL Tersicoccus phoenicis at the National Center for Biotechnology Information",1
"Mechanized sewage treatment typically includes settling in a primary clarifier, followed by biological treatment and a secondary clarifier. Both clarifiers produce waste sludge requiring sewage sludge treatment and disposal. Activated sludge agitates a portion of the secondary clarifier sludge in the primary clarifier effluent. Remaining secondary sludge and all primary sludge typically require digestion prior to disposal. Extended aeration agitates all incoming waste in the sludge from a single clarifier.",1
"The facultative lagoon in the pond sequence functions like the primary clarifier of a conventional sewage treatment system. Heavy solids will settle to the bottom of the lagoon, and lighter solids will float. This facultative lagoon lacks the sludge removal capability of a primary clarifier, so a population of anaerobic organisms will colonize accumulated sludge on the bottom of the lagoon. The surface area of the lagoon should be large enough to provide an atmospheric oxygen transfer rate adequate to prevent anaerobic conditions on the lagoon surface.",1
Overflow from the facultative lagoon may be routed through one or more polishing ponds supporting lower populations of anaerobic micro-organisms and a higher proportion of aerobic organisms adapted to survival in lower concentrations of organic material. Effluent from the final polishing pond may be suitable for discharge to natural receiving waters.,1
"Objectionable odors are likely when the rate of oxygen transfer from the lagoon surface is less than the rate of oxygen consumption in the lower levels of the lagoon. A 1-acre (4,000 m2) facultative lagoon might provide 50 pounds of oxygen per day (5 grams of oxygen per square meter per day) for biochemical catabolism. Biological activity within a facultative lagoon varies directly with temperature. Warm weather will require large oxygen transfer rates, and waste accumulation during cold weather can cause short-term warm weather oxygen requirements to exceed long-term waste loading rates.",1
"The aerobic surface layer limits release of malodorous gas from the anaerobic benthic zone. Algae and cyanobacteria typically grow in the aerobic zone and provide bacteria in the pond with plenty of oxygen during the daytime. However, algal photorespiration may consume oxygen during night time when it is dark. Waste stabilization ponds with large algal populations may show significant diurnal fluctuation in oxygen concentrations with a peak in the late afternoon, and a minimum at dawn.Kinds of algae growing in treatment ponds include green, red and brown algae.",1
"Wastewater nutrients may cause continuing growth of algae in the polishing ponds after the original wastes have been catabolized. Algae may cause measurable contribution to biochemical oxygen demand (BOD) and total suspended solids (TSS) concentrations where discharge regulations include limitations on those concentrations. The TSS contribution of algae tends to peak in the summer months, but the long-term BOD of decomposing algae may not be evident within the typical 5-day test.",1
The facultative lagoon may be replaced by an aerated lagoon as the first pond of the series. Aerated lagoons have mechanical aerators which minimize anaerobic zones by completely mixing the lagoon to achieve catabolism through a process called extended aeration. List of waste-water treatment technologies,1
"Contaminants located in sediments still pose a risk to the environment and human health. Some of the direct effects on aquatic life that can be associated with contaminated sediment include “the development of cancerous tumors in fish exposed to polycyclic aromatic hydrocarbons in sediments."" These high-risk sediments need to be remediated. There are usually only four options for remediation: Nonremoval technologiesContainment in-place (In-Situ Capping) Treatment in-place Removal technologiesRemoval and containment Removal and treatmentThe cap can be made up of many different things, including but not limited to sand, gravel, geotextiles, and multiple layers of these options.There",1
"are many ways that a contaminant inside sediment can become introduced to the environment. These ways include but are not limited to advection, diffusion, benthic organisms mixing and reworking of the upper layer of the contaminated sediment, and sediment re-suspension by different subaquatic forces. In-situ capping (ISC) can fix all of these adverse effects with three primary functions: Isolation of the contaminated sediment from the benthic environment; this prevents the contaminant from spreading up the food chain. This isolation of the contaminant is the most important factor in reducing exposure risks.",1
"Furthermore, if a remedial objective is desired, then the purpose of the ISC could be to isolate the contaminated soil from the surrounding environment, thus controlling the environment of the contaminated soil and causing possible degradation of the contaminate.",1
It is best if the area surrounding the ISC is flat for ease of installation.,1
Modeling must be done to determine if placement of the in-situ cap will alter existing hydrodynamic conditions.,1
"A study of the geotechnical and geological conditions must be made before the placement of the in-situ cap because of potential settling underneath the cap. If settling is predicted to be significant, the cap design may have to be designed thicker than originally projected to allow the settling to not alter the integrity of the cap.Hydrogeological conditions are important to consider before placement. It is important to locate areas of discharge, which are areas where the groundwater flow path has an upward component.",1
"It is important to know all of the regulatory standards in place for the desired location of the ISC. All ISC must comply with the requirements in the Resource Conservation and Recovery Act (RCRA) and the Toxic Substances Control Act (TSCA), although the ability of in-situ capping to meet those standards in the long term has not been successfully researched and studied enough due to lack of data. Cap design, which includes the composition and dimensions of the components, is probably the most important aspect of in-situ capping.",1
"This approach uses the idea that the many different components are additive and no cap component provides a dual function, although a component may provide a dual function in actual practice.",1
"Evaluate potential interactions and compatibility among cap components, including consolidation of compressible materials. Evaluate operational considerations and determine restrictions or additional protective measure needed to assure cap integrity.",1
Thus a fine grain material is a better capping component than factory-washed sand. It is important to have control the amount of organic material within the cap because the benthic organisms have shown interest in burrowing within any unconsolidated fine grained sediments containing organic matter. Increased levels of organic matter in sands have shown an increase in the retardation of hydrophobic organic contaminants through the cap and encourage degradation of contaminant. Thus a careful balance of organics is necessary.,1
Further research is needed to determine the overall effectiveness of geosynthetics for chemical isolation.,1
"Try to control the hydraulic forces to limit their effect on the cap layer with breakwaters, dams, navigational controls, etc.",1
"To prevent and reduce the impact of bioturbation on the cap, the cap should be designed with a sacrificial layer, typically only a few centimeters thick (5–10 cm). This layer will be assumed to be completely mixed with the environment and should prevent benthic organism from descending further into the in-situ cap. The thickness of the sacrificial layer should be based on a study of the local organisms and their behavior in the surrounding sediment near the area of the cap construction, since some benthic organisms have been known to burrow at depths of 1m or more.",1
"The presence of armor stone has been known to limit the colonization by deep burrowing benthic creatures. Another method of preventing benthic organisms from destroying the integrity of the cap design is to pick a granular media that the local benthic organism find unattractive and are not known to readily colonize on that surface, thus limiting the chance a benthic organism will grown on the cap. The consolidation of the in-situ cap must be considered, provided that the selected material for the cap “is fine-grained granular material.""",1
"It is important to note that ""many contaminated sediment sites exhibit exceedingly soft sediments that can be easily disturbed, may be dislocated or destabilized by uneven placement, and may have insufficient load bearing capacity to support some cap materials.""There are two basic was to construct an in-situ cap: Land-based placement: this involves using equipment near the shore or working in narrow channels. The cap in constructed with standard construction equipment such as ""backhoes, clamshells, dumped from trucks, and/or spread with bulldozers."" The major limitation of this method is the reach of the equipment.",1
Pipeline or barge placement: this involves placing the in-situ cap with a barge or a pipeline. Using different types of equipment to place the cap components on the ocean bed or lake bed. This is typically the desired method when working in deep areas or offshore.,1
"A long-term monitoring program should be established to provide data about the overall effectiveness of the cap design and to make sure the cap is meeting all of its required regulations and that the cap is not excessively eroded. This long-term monitoring need only be assessed on a yearly to bi-yearly basis unless a problem is discovered; then more frequent testing will be required.During monitoring, it is important to schedule routine maintenance. This may include placement of material equal to the predicted amount of material removed due to erosion.",1
"In Massena, New York, at the General Motors Superfund site, PCB-contaminated soils were dredged repeatedly but some areas still had high levels of contaminant (>10ppm). These areas were capped, an approximate area of 75,000 square feet (7,000 m2), with a three-layer ISC composed of 6 inches of sand, 6 inches of gravel and 6 inches of armor stone.",1
"In Manistique River, Michigan, PCB-contaminated sediments were capped with a 40mm thick plastic liner over an area of 20,000 square feet (1,900 m2) with varying depths of up to 15 ft.",1
"In Sheboygan River, Wisconsin, PCB-contaminated sediments were capped with a sand layer and armor stone layer. This was done in shallow regions were direct placement was possible.",1
"In Cold Spring, New York, in the Hudson River, sediment was contaminated with cadmium and nickel from a battery manufacturing facility. A Geosynthetic clay liner (GCL) and a 12-inch covering of sandy loam was planted on top of the contaminated area.",1
"In Elkton, Maryland, contaminated sediment was discovered with excess amounts of volatile organic components and dense non-aqueous phase liquids, resulting is severe discharge. The cap system constructed over the contaminated waste involved a geotextile working mat, a GCL, a scrim-reinforced polypropylene liner, a geotextile cushion, and a gabion mat. There are four major areas of research that currently need to be assessed: ""Research into the fate and transport behavior of specific contaminants that do not behave in the simple manner assumed in current cap evaluation approaches (e.g.",1
"mercury)"" ""Research into the fate processes associated with physical, chemical and biological gradients within a cap"" ""Research into the influence of transport processes facilitated by nonaqueous phase liquid (NAPL) or gas migration"" ""Research into cap amendments that may encourage sequestration or degradation fate processes"" In situ oxidation",1
"Because the temperature in the aquifer is usually less than the temperature in the area that the solution is mixed, the potassium permanganate becomes a solid material again. This solid material then does not react with the contaminants. Over time, the permanganate will become soluble again, but the process takes a long time. This compound has been shown to oxidize many different contaminants but is notable for oxidizing chlorinated solvents such as perchloroethylene (PCE), trichloroethylene (TCE), and vinyl chloride (VC). However, potassium permanganate is unable to efficiently oxidize diesel, gasoline, or BTEX.Sodium",1
"As the rock-like materials build up, it blocks the permanganate from getting to the rest of the contaminant and lowers the efficiency of the permanganate. This can be prevented by extracting the MnO2 from the contaminated area.",1
"Fenton's reagent is basically a mixture of ferrous iron salts as a catalyst and hydrogen peroxide. A similar sort of reaction can be made by mixing hydrogen peroxide with [ferric] iron (Iron III). When the peroxide is catalyzed by soluble iron it forms hydroxyl radicals(·OH) that oxidize contaminants such as chlorinated solvents, fuel oils, and BTEX. Traditional Fenton's reagent usually requires a significant pH reduction of the soils and groundwater in the treatment zone to allow for the introduction and distribution of aqueous iron as iron will oxidize and precipitate at a pH greater than 3.5.",1
"Unfortunately, the contaminated groundwater that needs to be treated has a pH level that is at or near neutral. Due to this, there are controversies on whether ISCO using Fenton's reagent is really a Fenton reaction. Instead, scientists call these reactions Fenton-like. However, some ISCO vendors successfully apply pH neutral Fenton's reagent by chelating the iron which keeps the iron in solution and mitigates the need for acidifying the treatment zone.",1
"The Fenton chemistry is complex and has many steps, including the following: Fe2+ + H2O2 → Fe3+ + OH· + OH− Fe3+ + H2O2 → Fe2+ + OOH· + H+ HO· + H2O2 → Fe(III) + HO·2 + H+ HO· + Fe(II) → Fe(III) + OH− Fe(III) + HO·2 → Fe(II) + O2H+ Fe(II) + HO·2 + H+ → Fe(III) + H2O2 HO·2 + HO·2 → H2O2 + O2These reactions do not occur step by step but simultaneously.",1
"NAPL concentrations) are present in an injection zone. Over the course of the reaction, the groundwater heats up and, in some cases, reagent and vapors can surface out of the soil. Stabilizing the peroxide can significantly increase the residence time and distribution of the reagent while reducing the potential for excessive temperatures by effectively isolating the peroxide from naturally occurring divalent transition metals in the treatment zone. However, NAPL contaminant concentrations can still result in rapid oxidation reactions with an associated temperature increase and more potential for surfacing even with reagent stabilization.",1
"The hydroxyl radicals can be scavenged by carbonate, bicarbonate, and naturally occurring organic matter in addition to the targeted contaminant, so it important to evaluate a site's soil matrix and apply additional reagent when these soil components are present in significant abundance.",1
"Therefore the performance of sulfate radicals is enhanced in an area where there are many electron donating organic compounds. The sulfate radical reacts with the organic compounds to form an organic radical cation. Examples of electron donating groups present in organic compounds are the amino (-NH2), hydroxyl (-OH), and alkoxy (-OR) groups. Conversely, the sulfate radical does not react as much in compounds that contain electron attracting groups like nitro (-NO2) and carbonyl (C=O) and also in the presence of substances containing chlorine atoms. Also, as the number of ether bonds increases, the reaction rates decrease.When",1
"The persulfate and the iron are not mixed beforehand, but are injected into the area of contamination together. The persulfate and iron react underground to produce the sulfate radicals. The rate of contaminant destruction increases as the temperature of the surroundings increases.The advantage of using persulfate is that persulfate is much more stable than either hydrogen peroxide or ozone above the surface and it does not react quickly by nature. This means fewer transportation limitations, it can be injected into the site of contamination at high concentrations, and can be transported through porous media by density driven diffusion.",1
"The disadvantage is that this is an emerging field of technology and there are only a few reports of testing it in the field and more research needs to be done with it. Additionally, each mole of persulfate creates one mole of oxidizer (sulfate radical or hydroxyl radical). These radicals have low atomic weights while the persulfate molecule has a high atomic weight (238). Therefore, the value (oxidizer produced when persulfate is activated) for expense (price of relatively heavy persulfate molecule) is low compared to some other oxidizing reagents.",1
"In addition, because ozone is a gas, adding ozone to the bottom of the contaminant pool forces the ozone to rise up through the contaminants and react. Because of this property, ozone can also be delivered more quickly. Also, in theory, H2O2 co-injected with ozone will result in -OH ions, which are very strong oxidants.However, ozone has many properties that pose problems. Ozone reacts with a variety of contaminants, but the problem is that it also reacts quickly with many other substances such as minerals, organic matter, etc. that are not the targeted substances.",1
"However, there are some specific methods of oxidant delivery including injection probes, hydraulic fracturing, soil mixing, vertical wells, horizontal wells, and treatment walls.",1
"In order to optimize the amount of contaminant that is oxidized, the probes are set into the ground relatively close together, about .6-1.2 meters apart.",1
The soil then has to be mixed by using mixing blades.,1
The ISCO technology has been tested many times in the field. The following are a few examples of studies that have been conducted to observe the effectiveness of ISCO.,1
"After 16 months of ozone treatment, there was a contaminant mass reduction of 44% in one site and 70% in the other site.",1
"Since the oxidation reaction takes place in the groundwater, contaminant destruction is restricted to only those contaminants which have partitioned into the groundwater phase. To overcome this limitation at sites which have substantial soil contamination, and/or non-aqueous phase liquid (NAPL), surfactants can be injected simultaneously with oxidants. The surfactants emulsify soil sorbed contaminants and/or NAPL enabling them to be destroyed in aqueous phase oxidative reactions; this patented technology is known as Surfactant-enhanced In Situ Chemical Oxidation (S-ISCO).The ISCO delivery technology and reagents also could be enhanced.",1
"Currently, an oxidant is injected into the contaminated site and is distributed by the injection pressure, turbulence and advection. This method is effective with appropriate point spacing and slightly overlapping radius of influence (ROI). However, peroxide-based reagents are not very stable and react with other substances soon after being injected into the sub-surface unless the peroxide is stabilized. Additionally, current persulfate activation methods often stall resulting in sub-optimal results. These problems could be fixed by creating oxidants that are more stable and specifically targeted to contaminants so that they do not oxidize other substances.",1
The delivery systems could also be improved so that the oxidants are sent to the correct locations. In-situ capping of subaqueous waste In situ chemical reduction Additional information on this topic may be found at the following sites: In Situ Chemical Oxidation for Groundwater Remediation—Book Principles and Practices of In Situ Chemical Oxidation: A Short Course Reaction and Transport Processes Controlling In Situ Chemical Oxidation of DNAPLs Technology Practices Manual US EPA Clean-Up Information Oregon Health and Science University Rate Constant Database,1
"of these pollutants include excess nutrients from fertilizers; pathogens; pet waste; gasoline, motor oil and heavy metals from vehicles; high sediment loads from stream bed erosion and construction sites; and waste such as cigarette butts, 6-pack holders and plastic bags carried by surges of stormwater. In some cities, the flood waters get into combined sewers, causing them to overflow, flushing their raw sewage into streams. Polluted runoff can have many negative effects on fish, animals, plants and people.Impervious surfaces collect solar heat in their dense mass.",1
"The coverage increases with rising urbanization. In rural areas, impervious cover may only be one or two percent. In residential areas, coverage increases from about 10 percent in low-density subdivisions to over 50 percent in multifamily communities. In industrial and commercial areas, coverage rises above 70 percent. In regional shopping centers and dense urban areas, it is over 90 percent. In the contiguous 48 states of the US, urban impervious cover adds up to 43,000 square miles (110,000 km2). Development adds 390 square miles (1,000 km2) annually. Typically, two-thirds of the cover is pavements and one-third is building roofs.",1
"For example, a two lane road in a grassy field has a TIA value of 100 percent, but the pixel containing the road would have a TIA value of 26 percent. If the road (equally) straddles the boundary of two pixels, each pixel would have a TIA value of 13 percent. The Data-quality analysis of the NLCD 2001 data set with manually delimited TIA sample areas indicates that the average error of predicted versus actual TIA may range from 8.8 to 11.4 percent.TIA",1
He noted that this method was advantageous because large basins could quickly be delineated and TIA estimated manually from available maps. Granato (2010) developed a regression equation by using data from 262 stream basins in 10 metropolitan areas of the conterminous United States with drainage areas ranging from 0.35 to 216 square miles and PDA values ranging from 0.16 to 99.06 percent. TIA also is estimated from population density data by estimating the population in an area of interest and using regression equations to calculate the associated TIA.,1
article incorporates public domain material from websites or documents of the United States Geological Survey and the Federal Highway Administration. YouTube presentation: The total impervious area (TIA) affects the volume and timing of runoff,1
"ISTD using TCH was developed by Shell Oil Co. in the late 1980s and grew out of research and development for enhanced oil recovery. During the mid-1990s Shell Oil Company commercialized ISTD with an investment of over $30 million. Thermal conductive heating is the application of heat to subsurface soils through conductive heat transfer. The source of the heat is applied via electric or gas powered thermal wells. Thermal wells are inserted vertically, or horizontally, in an array within the soil. Heat flows from the heating elements by conduction.",1
The heating process causes contaminants to be vaporized or destroyed by means of: evaporation steam stripping hydrolysis oxidation pyrolysisVaporized contaminants are collected from vapor extraction wells and containerized for removal or recycling. Soil vapor extraction thermal blanket,1
"For example, iron that has been embedded in a swellable, organically modified silica creates a permanent soft barrier underground to capture and reduce small, organic compounds as groundwater passes through it.",1
"One proprietary material for ISCR is the EHC technology created by Adventus. This particular product is actually a mixture of carbon, nutrients, and zero-valent iron. The theory behind this product is that the carbon in the mixture will promote bacterial growth in the subsurface. The growing bacteria consume oxygen, which easily accepts electrons, present in the subsurface which increases reducing potential. The growing bacteria also ferment and produce fatty acids that act as electron donors to other bacteria and substances. Adventus uses this combination of biotic and abiotic processes to implement ISCR.",1
"The reactions that occur with permeable reactive barriers and ferrous iron are surface based. The surface reactions take three different forms: direct reduction, electron shunting through ferrous iron, and reduction by production and reaction of hydrogen. Pathway A represents direct electron transfer (ET) for Fe0 to the adsorbed halocarbon (RX) at the metal/water point of contact, resulting in dechlorination and production of Fe2+. Pathway B shows that Fe2+ (resulting from corrosion of Fe0) may also dechlorinate RX, producing Fe3+. Pathway C shows that H2 from the anaerobic corrosion of Fe2+ might react with RX if a catalyst is present.",1
"The reductive processes discussed above can be enhanced in two ways. One is by increasing the amount of usable iron in the subsurface to increase the rate of the reduction by chemical or biological means. The second method is to enhance the reducing ability of the iron by coupling it with other chemical reductants or using biological reduction with it. Using this processes, scientists combined sodium dithionite with iron to treat Chrominum VI and TCE effectively.Combining bacterial action and biological processes with iron is also known to be effective.",1
"The most common type of implementation of ISCR is the installation of permeable reactive barriers (PRBs), but there are instances when the reductant can be directly injected into the subsurface to treat source areas.",1
"These barriers are usually made out of zero-valent iron (ZVI) but can also be made with any other zero-valent metal. The most common way they are made is by filling a trench with ZVI, nanoscale iron, or palladium. Nanoscale iron particles can also be injected directly into the subsurface to treat plumes, and they have large surface areas and, therefore, high reactivities and can be distributed more evenly in the contamination site. Palladium's reaction rates are rapid. The main advantages of PRBs are that it can reduce many a variety of contaminants and it has no above-ground structure.",1
"Problems with PRBs include that even with well constructed barriers, there might be the problem of hydraulic short-circuiting.",1
"1969: five sailors on a Japanese ship were injured when space debris from what was believed to be a Soviet spacecraft struck the deck of their boat. 1978: the Soviet reconnaissance satellite Kosmos 954 reentered the atmosphere over northwest Canada and scattered radioactive debris over northern Canada, some landing in the Great Slave Lake. 1979: portions of Skylab came down over Australia, and several pieces landed in the area around the Shire of Esperance, which fined NASA $400 for littering.",1
"2001: a Star 48 Payload Assist Module (PAM-D) rocket upper stage re-entered the atmosphere after a ""catastrophic orbital decay"", crashing in the Saudi Arabian desert. It was identified as the upper-stage rocket for NAVSTAR 32, a GPS satellite launched in 1993. 2002: 6-year-old boy Wu Jie became the first person to be injured by direct impact from space debris.",1
"He suffered a fractured toe and a swelling on his forehead after a block of aluminum, 80 centimeters by 50 centimeters and weighing 10 kilograms, from the outer shell of the Resource Second satellite struck him as he sat beneath a persimmon tree in the Shaanxi province of China. 2003: Columbia disaster, large parts of the spacecraft reached the ground and entire equipment systems remained intact. More than 83,000 pieces, along with the remains of the six astronauts, were recovered in an area from three to ten miles around Hemphill in Sabine County, Texas.",1
"More pieces were found in a line from west Texas to east Louisiana, with the westernmost piece found in Littlefield, TX and the easternmost found southwest of Mora, Louisiana. Debris was found in Texas, Arkansas and Louisiana. In a rare case of property damage, a foot-long metal bracket smashed through the roof of a dentist office. NASA warned the public to avoid contact with the debris because of the possible presence of hazardous chemicals. 15 years after the failure, people were still sending in pieces with the most recent, as of February 2018, found in the spring of 2017.",1
"2007: airborne debris from a Russian spy satellite was seen by the pilot of a LAN Airlines Airbus A340 carrying 270 passengers whilst flying over the Pacific Ocean between Santiago and Auckland. The debris was reported within 9.3 kilometres (5 nmi) of the aircraft. 2016: on 2 November, upper stage of Vega flight VV01 launched on 13 February 2012 reentered over Indian state of Tamil Nadu. A composite overwrapped pressure vessel survived reentry and was recovered.",1
"2020: The empty core stage of a Long March-5B rocket made an uncontrolled re-entry - the largest object to do so since the Soviet Union's 39-ton Salyut 7 space station in 1991 – over Africa and the Atlantic Ocean and a 12-meter-long pipe originating from the rocket crashed into the village of Mahounou in Côte d'Ivoire. 2021: A Falcon 9 second stage made an uncontrolled re-entry over Washington state on March 25, producing a widely seen ""light show"". SpaceX retrieved a piece of debris, a composite-overwrapped pressure vessel, that landed on a farm in Washington.",1
"Another piece of debris, likely a pressure vessel as well, also survived the re-entry and washed up ashore in Oregon. In September 2021 a high-pressure helium bottle weighing 50 kg from the aft end of the Centaur upper stage of an Atlas V rocket (international designator 2019 -094A) was discovered in south-eastern Australia near the town of Yambuk, Victoria. 2022: On 2 April, pieces of reentered space debris impacted multiple locations in Indian state of Maharashtra, the event of reentry was witnessed by many.",1
"Recovered debris consisted of metallic ring almost 3 meter in diameter along at least six composite overwrapped pressure vessels with some bearing '3CCA301001 B' marking. The debris is likely from third stage of Long March 3B rocket with Y77 serial, launched in February 2021. A month later on 12 May another incidence of space debris reentry and impact was reported over Indian state of Gujarat, surviving debris consisted of metal fragments and at least three composite overwrapped pressure vessels. Allegedly the falling debris killed a livestock animal and injured another as one metal fragment struck a sheep pen.",1
"The debris is likely from third stage of Long March 3B rocket with Y86 serial, launched in September 2021. Indian space agency ISRO is investigating both incidents. On 9 July 2022, trunk of SpaceX Crew-1 Dragon spacecraft reentered and its debris landed on multiple locations like Albury, Wagga Wagga and Canberra in New South Wales, Australia. Australia notified United Nations Committee on the Peaceful Uses of Outer Space about three pieces of recovered debris under Rescue Agreement on 26 August 2022. On 31 July 2022, empty core stage of Long March-5B made an uncontrolled reentry over Indonesia and Malaysia.",1
"The reentry was witnessed by many and later pieces of booster that survived reentry were recovered from multiple locations in Indonesia and Malaysia. 2023: On 27 April 2023, a space debris object bearing a pattern resembling Chinese national flag as well as a marking of ""ventilation duct"" in Chinese character was found on beach in Okinoerabu Island, Kagoshima Prefecture of Japan. On 16 July 2023, A composite motor case likely to be from third stage of Polar Satellite Launch Vehicle was found near Western Australian coast near Greenhead.",1
List Of Reported Space Objects Discovered By Member States of UN Media related to Space debris remains after reentry at Wikimedia Commons,1
"There were 190 known satellite breakups between 1961 and 2006. By 2015, the total had grown to 250 on-orbit fragmentation events.As of 2012 there were an estimated 500,000 pieces of debris in orbit, with 300,000 pieces below 2000 km (LEO). Of the total, about 20,000 are tracked. Also, about sixteen old Soviet nuclear space reactors are known to have released an estimated 100,000 NaK liquid metal coolant droplets 800–900 km up, which range in size from 1 – 6 cm.The greatest risk to space missions is from untracked debris between 1 and 10 cm in size.",1
"Large pieces can be tracked and avoided, and impact from smaller pieces are usually survivable.",1
"Additionally, ignorance of the laws that regulate the proper disposal of hazardous waste may cause improper disposal. According to a study by the Dutch organization VROM, 80% of people claim that ""everybody leaves a piece of paper, tin or something, on the street behind"". Young people from 12 to 24 years cause more litter than the average (Dutch or Belgian) person; only 18% of people who regularly cause litter were 50 years of age or older.",1
"However, a 2010 survey of littering in Maine, New Hampshire and Vermont in the United States, placed litterers aged 55 and over at less than 5%. The same observational study estimated that 78% of litterers are male. Litter organizations, such as Keep America Beautiful affiliates, Keep Northern Ireland Beautiful, and the Bay Area Stormwater Management Agencies Association, have focused educational efforts on youth littering. Negligent or lenient law enforcement contributes to littering behavior. Other causes are inconvenience, entitlement and economic conditions.",1
"A survey of dumping in Pennsylvania found that the largest number of illegal dumps were in townships without municipal trash hauling. The same report also cites unavailability of curbside trash and recycling service, shortage of enforcement, and habit as possible causes. The presence of litter invites more littering.",1
"The two-stage process model of littering behavior describes the different ways in which people litter. The model was proposed by Chris Sibley and James Liu and differentiates between two types of littering: active and passive.The theory has implications for understanding the different types of litter reduction interventions that will most effectively reduce littering in a given environment. The theory states that, all things being equal, passive littering will be more resistant to change because of two psychological processes: 1.",1
"diffusion of responsibility that increases as the latency between when an individual places litter in the environment and when they vacate the territory, and 2. forgetting, which is also more likely to occur at longer delays between when an individual places litter in the environment and when they vacate the territory. Litter can remain visible for extended periods of time before it eventually biodegrades, with some items made of condensed glass, styrofoam or plastic possibly remaining in the environment for over a million years.About 18 percent of litter, usually traveling through stormwater systems, ends up in local streams, rivers, and waterways.",1
"Uncollected litter can accrete and flow into streams, local bays and estuaries. Litter in the ocean either washes up on beaches or collects in ocean gyres such as the Great Pacific Garbage Patch. About 80 percent of marine debris comes from land-based sources.Some litter that is collected can be recycled; however, degraded litter cannot be recycled and eventually degrades to sludge, often toxic. The majority of litter that is collected goes to landfills. Litter can have a detrimental impact on humans and the environment in different ways.",1
"In addition, a spark or a lightning flash can start a fire if it strikes litter such as a paper bag or cardboard box. Litter can be hazardous to health. Debris falling from vehicles is an increasing cause of automobile accidents. Discarded dangerous goods, chemicals, tires, sharps waste and pathogens resulting from litter can cause accidental harm to humans. Litter also carries substantial cost to the economy. Cleaning up litter in the US costs hundreds of dollars per ton, about ten times more than the cost of trash disposal, with a cost totaling about $11 billion per year.",1
"A number of credible studies have shown that fast food packaging is one of the most common forms of litter, while McDonald's is the most common brand of litter, despite having messages to dispose of it properly, such as the Ronald McDonald ""tidy man"" marking. According to Keep Britain Tidy in 2013, Cadbury chocolate wrappers, Walkers crisp packets and Coca-Cola cans were the three top brands that were the most common pieces of rubbish found in UK streets.",1
People may blame a lack of well-placed bins for their littering. Hazardous materials may often be incorrectly disposed of in the bins and they can encourage dumpster diving.,1
"Volunteers, sometimes alone or coordinated through organizations, pick up litter and dispose of it. Clean up events may be organized in which participants will sometimes comb an area in a line to ensure that no litter is missed. Organizations may promote litter cleanup events and may also have separate media campaigns to prevent littering. In North America, Adopt a Highway programs are popular, in which companies and organizations commit to cleaning stretches of road. Keep America Beautiful has held litter cleanups called the Great America Cleanup since 1998 in over 20,000 communities nationwide.Earth Day cleanups have been held globally since 1970.",1
"In 2019, Earth Day Network partnered with Keep America Beautiful and National Cleanup Day for the inaugural nationwide Earth Day CleanUp. Cleanups were held in all 50 States, 5 US Territories, 5,300 sites and had more than 500,000 volunteers.Commercial properties such as retail, office and industrial have litter picking maintenance programs. This service may be provided by property owners or contracted to various service providers by property management companies acting on owner's behalf. Litter picking is performed on foot using simple hand tools.",1
"People can thus collect refund value money from this type of waste. The result of this is that in Germany, hardly any cans or plastic bottles can still be found along the road. In the Netherlands, the amount of litter has dropped considerably since the new law was implemented, and 95% of the plastic bottles are now recycled. According to Chris Snick, the revenue that can be obtained from waste picking can be financially profitable in countries where container deposit legislation has been introduced: in 1 hour he managed to pick up 108 cans and 31 plastic bottles, earning him 13.90",1
"euro (€0.10 per can/plastic bottle). By comparison, in countries where only the value of the aluminum for example would be refunded, 139 cans would yield only 1.72 euro (0.0124 euro per can; assuming there is 15 grams of aluminum in a can, and with scrap aluminum valued at 0.8267 euro/kg).",1
"Some countries and local authorities have introduced legislation to address the problem. Actions resulting in fines can include on-the-spot fines for individuals administered by authorised officers in public or on public transport or littering from a vehicle, in which the vehicle owner is fined - reported by either responsible officer or third party, sometimes online.Specific legislation exists in the following countries: United States - punishable by a minimum fine of $200 and a maximum fine of $1,000 or even more in some states for a first offence, community service, or both, as set out by state statutes and city ordinances.",1
"In the United States there are a number of organizations running anti-litter campaigns. Keep America Beautiful was founded in 1953, and promulgated the word litterbug, coined by its partner the Ad Council in 1947. At least 38 states have high profile, government-recognized slogan campaigns, including Don't Mess with Texas; Let's Pick It Up New York; Don't Trash California; Take Pride in Florida; Keep Iowa Beautiful. In Australia, Clean Up Australia Day is supported by many major Australian companies, firms and volunteers alike. Anti-litter organizations include ""Keep Australia Beautiful"", founded in 1963.",1
"Anti-littering legislation seems to have existed in ancient Greece, as is evidenced by a road marker discovered on the island of Paros, bearing the inscription ""whoever drops their litter on the street owes 51 drachmae to whoever wishes to claim them"".To address the growing amount of waste generated in the United States, the Solid Waste Disposal Act of 1965 was enacted. In 1976 the Federal government amended the Solid Waste Disposal Act, creating the Resource Conservation and Recovery Act (RCRA), which requires a ""cradle to grave"" approach to the proper handling of potentially hazardous materials.",1
"In Victoria, the first legislation included the Environment Protection Act (1970) and later the Litter Act (1987). The Environment Protection Authority (Victoria) was the first to facilitate report littering online (based on vehicle registration details) by introducing the appropriate legislation and dispense fines.",1
Northern Territory followed with the Litter Act (1972).,1
In South Australia the Container Deposit Legislation (1977) was introduced with the aim of reducing litter by encouraging recycling and remains the only state in Australia with this type of legislation.,1
Anti-litter legislation was introduced to Western Australia through the Litter Act (1979).,1
Litter legislation was introduced to the Australian Capital Territory with the Litter Regulations (1993).,1
"In New South Wales, legislation was introduced through the Protection of the Environment Operations Act 1997.",1
The Our marine environment 2019 report revealed 61% of litter on beaches to be of a plastic material and 11% of the plastic litter found on the country's beaches came from cigarettes. The second most common item were either glass or ceramic. These made up 21.7% of all items collected.: 30 The report revealed that the effect of single-use plastic poses a significant threat on the country's marine life.,1
"Because they resemble food and are ubiquitous in the environment due to issues like littering, microplastics are easily ingested by animals. The prevalence of plastic debris means that marine mammals are at risk of becoming trapped in or wounded by drifting materials. They are also at risk of ingesting plastic debris. The New Zealand Department of Conservation has reported that Māui dolphins, a critically endangered subspecies of the Hector's dolphin, are at risk of dying from marine litter. Māui dolphins are endemic to New Zealand's North Island where they are known to occupy harbours where commercial and amateur fisheries are located.Research",1
"conducted by the Royal Society of New Zealand has shown the country's seabirds to be at risk of consuming plastic with the earliest discovery of plastic ingestion dating back to 1958. One-third of all species of seabirds inhabit New Zealand. The country is also the main breeding ground for the highest number of seabird species globally. For these reasons, New Zealand has been described as being the ""seabird capital of the world"". 86 of the 360 global seabird species breed in New Zealand 37 are endemic to New Zealand, meaning they breed nowhere else in the world.",1
"The Department of Conservation has advised that human food products are unhealthy for a kea's digestive system and temporarily decrease their appetite. As a consequence, keas can become destructive with surrounding human belongings. To protect New Zealand's environment and the native species that inhabit it, visitors to conservation land are required to take their rubbish with them until they can dispose of it responsibly in an appropriate bin.",1
"The Litter Act 1979 is administered by the Ministry for the Environment. The Act defines littering as intentionally or unintentionally depositing of litter. It defines litter as including ""any refuse, rubbish, animal remains, glass, metal, garbage, debris, dirt, filth, rubble, ballast, stones, earth, or waste matter, or any other thing of a like nature."" The Act established Keep New Zealand Beautiful as the organisation responsible for the promotion of litter control in New Zealand.",1
"Section 5 of the Litter Act permits public authorities to appoint Litter Control Officers. Moreover, Section 6 of the Act states that anyone appointed to a particular public office is also conferred the powers and duties of a Litter Control Officer. Such persons include constables, traffic officers, harbourmasters, and national park rangers. Section 7 of the Act states that every appointed Litter Control Officer is authorised to enforce the provisions of the Act. It is within an Officer's powers and duties to intervene in the deposition or attempted deposition of litter in a public place or a private land.",1
"They are further authorised to intervene if they witness the deliberate damage or attempted deliberate damage of any litter receptacle in a public place. To support these provisions, a revised version of section 7 additionally references the Offences Act 1981.",1
"In a similar category as the Litter Control Officers, every public authority has the right to appoint a temporary Litter Warden. Section 8 of the Litter Act states that, unless the conditions of his appointment state otherwise, the Litter Warden is authorised to exercise the same duties as the Litter Control Officers. Within the parameters of their given district, the Litter Warden is conferred the same powers and duties as the Officer. However, unlike Litter Control Officers, Litter Wardens are not permitted to legally intervene if an offence is being committed. This means that they are unable to issue infringement notices.",1
"Section 9 of the Litter Act states that every person, public authority, and department of State is required to provide and be responsible for the maintenance of bins in public places. Maintenance refers to the regularly emptying of the bin's contents and efficient disposal of those contents. Wherever rubbish is generated and likely to be littered, a reasonable distribution of well-constructed and suitable bins is necessary. The provision of litter receptacles is a mandatory means of enforcing litter control.",1
"If a noticeable amount of litter in public areas originates from any particular land or premises, section 9 of the Litter Act states that intervention of the public authority is necessary. To control litter, the public authority must require the occupier of the land or premises to provide and maintain the number of bins necessary for the disposal of litter. If an occupier fails to comply with this request, the public authority may install bins and recover costs from the occupier.",1
"Under Section 11 of the Litter Act, local or public authorities are permitted to make grants for the purpose of litter prevention or abatement. Section 11 provides that any local or public authority can make grants to any non-for-profit organisation for the prevention or abatement of litter. Such authorities are permitted to provide monetary support to any anti-litter campaign or scheme.Section 12 of the Litter Act allows public authorities to make bylaws. It states that a public authority, whether it is acting independently or in collaboration with other public authorities, is permitted to occasionally make bylaws.",1
These bylaws must be in accordance with the Litter Act and function with the purpose of litter control and prevention.,1
"The Litter Amendment Act 2006 made changes to the principal Act, including significant increases to maximum fines. Section 15 of the 1979 Litter Act addresses the deposition of litter in public or on private land. The expense of fines within section 15 were revised. Subsection 2 states that litter disposed in a dangerous manner or in a manner likely to cause harm is an offence warranting a fine not exceeding $7,500 and for a body corporate, this fine is not exceeding $30,000. Before this emendation was made, subsection 2 read $750 instead of $7,500 and $30,000 was originally $5,000.",1
"These changes were inserted in the Litter Act 1979 on 28 June 2006.The Amendment Act also removed the defence of “reasonable excuse” and instituted strict liability, meaning that the prosecution does not need to prove that the defendant intentionally committed an offence under the Act. In 2018, Keep New Zealand Beautiful published a National Litter Behaviour Research report. The study details both intentional and unintentional litter disposal observations of people in public places. It was conducted in late 2017 by an Auckland-based consultancy firm called Sunshine Yates Consulting.",1
"The objective of the Litter Behaviour research project was to measure and evaluate litter behaviour through fieldwork undertaken across New Zealand. The project was undertaken by Sunshine Yates Consulting, with the purpose of informing litter abatement strategies and developing a precedent for future litter prevention activities. By conducting self-reports and through the collection of observational data, the report also aimed to establish a Disposal Behaviour Index (DBI) for each major region in the country.",1
"The research was conducted by Keep New Zealand Beautiful volunteers. All the volunteers were trained in ethnographic data gathering techniques. After observing an act of disposal, observers directed an interviewer to conduct a self-report. Fieldwork commenced on 23 November and finished on 13 December 2017. Observations were made during daylight hours only between 7am and 6pm. Speciality sites included beaches, these were not available in every region. Core sites included: Parks Markets Waterfronts Public buildings Shopping streets Public squares",1
"According to the executive summary of the National Litter Behaviour Research document, New Zealand has a litter rate of 16%. This means that the observational study of littering in public areas showed that 84% did not litter and disposed of their items responsibly. Results revealed that the National Deposit Behaviour Index score of New Zealand is 6 and therefore high. The Deposit Behaviour Index operates on a scale from 1 to 7. The score 1 equals a low level of responsible rubbish disposable and indicates a high prevalence of littering.",1
"The score 7 indicates minimal littering and a high prevalence of people disposing of their rubbish in bins. The report revealed that the Regional Disposal Behaviour Index score in Wellington is 7 and in Auckland and Canterbury it is 6. Observational data revealed that the most littered items were cigarette butts. Nationally, 78% of litter acts were of cigarette butts. Instances of cigarette butt disposal observed during the project recorded 57% of cigarette butts littered while 43% were disposed of in bins.National",1
"surveys revealed that 75% of respondents considered it extremely important that people do not litter in the area where they were interviewed. A further 18% of respondents considered it very important. The remaining 7% of respondents considered it moderately or slightly important. Nationally, 99% of respondents considered the maintenance of New Zealand's 'clean green' image to be of importance.",1
"The age and gender of people who were observed littering and subsequently agreed to be interviewed varied. The observational data collected in the Litter Behaviour Study revealed that 53% of people littering were male. In addition, people aged between 25 and 34 made up a quarter of the overall people observed littering.The survey data further revealed that 66% of the people who self-reported having littered were either in full or part-time employment. In addition, the study concluded that the likelihood of a person littering did not appear dependent on their level of education.",1
"The National Litter Audit 2019 was undertaken by Keep New Zealand Beautiful, using a methodology developed in conjunction with Statistics New Zealand, the Department of Conservation and the Ministry for the Environment. It was supported by the Waste Minimisation Fund which is administered by the Ministry for the Environment. The Audit has been referred to as ""the most comprehensive litter audit of its scale carried out in New Zealand.""",1
"The audit revealed that 80% of the litter found in the country's waterways originated from the land. For this reason, the audit is primarily concerned with land-based litter. The main site types inspected in the audit were residential, retail and industrial areas as well as carparks, highways, railways and public recreational areas. These types of sites were surveyed within the local territorial authority regions of Auckland, Gisborne, Nelson, Tasman and Marlborough. The highest numbers of littered items discovered per 1,000 m2 were within industrial sites. This was followed by retail and highway sites.The",1
"highest volume of litter objects recorded per 1,000 m2 were found at highway sites, railway sites and industrial sites.Railway sites, highway sites and industrial sites also accounted for the highest weights per 1,000 m2.",1
"The main categories of litter materials identified in the audit included cigarette butts, paper and cardboard, metal, glass, plastic and organic waste. The most frequently found item nationally was cigarette butts. 39 butts were recorded per 1,000 m2. Disposable nappies, which were included in ""miscellaneous"" items, made up the largest contribution to the estimated national litter volumes, recording 1.50 litres of volume per 1,000 m2. Glass beer bottles made up the largest contribution to the national litter weights, recording 0.12 kg of weight per 1,000 m2.",1
"While the smoking rate in New Zealand is low, cigarette butts are the most littered item in the country. A 2018 study conducted by the Keep New Zealand Beautiful council recorded that cigarette butts made up 78% of all items littered nationally. For these reasons, the littering of cigarette butts is recognised as a pervasive issue in New Zealand. While the littering of cigarette butts is considerable in New Zealand, it is also of international concern. According to the Tobacco-Free Life campaign, the littering of cigarette butts is a global issue with an estimated 4,5 trillion butts littered internationally every year.",1
"In addition, research conducted by the Royal Society of New Zealand has revealed that cigarette butts are amongst the most common plastic items collected in international beach clean-ups.",1
"The National Litter Behaviour study conducted by Keep New Zealand Beautiful in 2018, revealed the littering of cigarette butts to be prevalent throughout New Zealand. The study observed that 59% of cigarette butts disposed of in Auckland were littered. In Canterbury 71% of cigarette butts observed being disposed of were littered and Wellington the percentage of cigarette butts observed being littered was 39%. The rate of littering cigarette butts is believed to be high because people do not generally view cigarette butts as a valid form of litter or they believe it to be harmless.",1
"In a survey conducted by Keep New Zealand Beautiful 42% of respondents who were observed littering cigarette butts claimed they had never littered. In addition, the study found that the smokers did not believe their littering of cigarette butts to be a real form of litter or that they believed them to be biodegradable.A study conducted in urban Wellington in 2011 found that smokers littering cigarette butts was conventional behaviour, even when rubbish bins were nearby. Littering of cigarette butts was more common in the evening, where 85.8% of smokers were observed littering, compared with the afternoon, when 68.1%",1
"were observed littering. In addition, 73.5% of smokers did not extinguish their butts, making them fire hazards.",1
"To address the issue of cigarette butt littering, New Zealand's office of the prime minister's chief science advisor has cited research which states that:""There is a need to change perceptions about cigarette butts as harmless litter.""A series of behavioural strategies have been suggested by the office of the prime minister's chief science advisor to reduce cigarette butt litter. The strategies involve: creating a suitable environment for the correct disposal of cigarette butts with signage on pathways directing smokers to the nearest bin.",1
"fostering a feeling of pride and ownership in smokers to maintain a clean environment and thereby encourage a commitment to dispose of their cigarette butts in a bin implementing positive social norming so that the binning of cigarette butts becomes standard practice. warning smokers of the consequences of littering. This means raising awareness about fines, implementing enforcement officers to monitor and speak to smokers and thereby increase recognition of cigarette butts as a form of litter.These strategies were trialled by Australia's NSW Environment Protection Authority (EPA) across 40 smoking sights.",1
"All the strategies led to an increased rate of binning cigarette butts. Fostering a feeling of pride and ownership was the most effective strategy but creating signage on pathways was considered the simplest and most cost-effective intervention.In 2019, New Zealand launched a No Butts campaign. The purpose of the campaign is to emphasise the negative impact of littering cigarette butts and to promote the correct disposal of butts.",1
"Under the Offences and Penalties section of the Litter Act 1979, anyone who deposits litter in or on a public place or on private land without the occupier's consent can be fined. The fines for rubbish dumping and littering in Auckland and Wellington range from NZ$100 to NZ$400.The dumping of rubbish on public conservation land in New Zealand warrants a fine of up to $100,000 or up to two years' imprisonment. The Department of Conservation also has the authority to issue infringement notices for minor cases of littering. Penalties for littering on public conservation land result in a $300 infringement fee.Restrictions",1
"to freedom camping in New Zealand were introduced to Parliament in 2011 with the Freedom Camping Bill. The bill passes a $200 instant fine for Illegal camping and another fine of up to $10,000 for the illegal emptying of a campervans sewage.",1
"The consultation process revealed that 85% of responses were in favour of the bylaw and 14% were in opposition. The introduction of the bylaw was criticised by some members of the council because they believed it was impossible to enforce.In May 2018, the Wellington City Council Strategy Committee voted to repeal the clause. Councillor Brian Dawson claimed that the most effective way to reduce cigarette butt litter was to reduce the number of people smoking. In 2019, Wellington City Council launched the Smokefree Wellington Action Plan in support of the government's Smokefree Aotearoa 2025 campaign.",1
"This government plan was established in 2011 which, amongst health incentives, plans on preventing and ultimately ending cigarette butt litter nationally.",1
"With a secure design and sensor technology, the smart bins would be able detect the amount of rubbish being disposed and therefore be emptied by council staff before they overflowed. In November 2021, the Banks Peninsula settlement of Akaroa reported overflowing bins and an increase in littering due to jammed bins, lack of staff and not enough smart bins to replace traditional bins.Another approach to litter abatement in New Zealand has been the removal of bins. In 2019, the city of Whangārei removed bins from three of its beaches. The primary incentive behind removing the bins was to avoid illegal dumping.",1
"Since removing the bins, the Whangārei District Council has reported a reduction in the amount of litter found on the beaches.",1
"To achieve a circular economy, it also aims to put better systems in place for the efficient reuse, repairing and recycling of plastic materials. Overall, the National Plastics Action Plan has invested approximately $100 million in resource recovery infrastructure.",1
"The most recognised anti-litter organisation in New Zealand is Keep New Zealand Beautiful, originally established by government in 1967 as the Anti-Litter Council. With the passing of the Litter Act in 1979, the council became an Incorporated Society under the name New Zealand Litter Control Council, and was officially recognised in the Act as the primary body responsible for promotion of litter control in New Zealand. In 1984, the organisation adopted a more community-based approach to the problem of littering and changed its name to the Keep New Zealand Beautiful Society Inc.",1
The National Litter Hub is a resource launched by Keep New Zealand Beautiful. It allows people in New Zealand to access information regarding litter disposal and recycling policies around the country. This resource was created in response to survey results which were recorded in the National Litter Behaviour Study in 2018.,1
"With Doug living in Hong Kong, the group set up two points of operation on either side of the Pacific (San Francisco and Hong Kong) to help begin to bring all parties to the table to stem the flow of plastic and marine debris into our ocean. The project was launched on 19 March 2009, with plans for an initial phase of scientific study of the plastic debris in the North Pacific Gyre and feasibility study of the recovery and recycling technologies.",1
"The goal is to bring about a global collaboration of science, technology and solutions, to help remove some of the floating waste. New catch methods for the debris are being studied, which would have low energy input and low marine life loss. Technologies for remediation or recycling are being evaluated, to potentially create secondary products from the waste, which in turn could help subsidize a larger scale cleanup. The project has completed two expeditions, one in the summer of 2009, and one in 2010.",1
"Two days later the Kaisei a smaller tall ship, owned by the Ocean Voyages Institute, departed San Francisco on 4 August, and was expected to undertake a 30-day voyage. The Kaisei was to investigate the size and concentration of the debris field, and explore retrieval methods, while the New Horizon would join her and study the effect of the debris field on marine life.",1
"On reaching the patch, 1,900 kilometres (1,000 nautical miles) from the Californian coast, New Horizon began intensive sampling on 9 August. The crew took samples every few hours around the clock, using nets of various sizes and collecting samples at various depths. New Horizon returned on Friday 21 August 2009. SEAPLEX reported their initial findings on Thursday 27 August 2009, declaring that the patch stretched at least 3,100 km (1,700 nmi) across, and that from 100 consecutive surface samples taken along that 1,700 path track taken through the patch, plastic was found in every one.",1
"The tiny portions of the debris field was said to be pervasive, and was found both at the surface and at deeper areas. It was also described as a ""nearly inconceivable amount of tiny, confettilike pieces of broken plastic"", increasing in density the further they sampled into the patch. Findings suggested that the presence of small debris, of a similar size to the existent marine life, could prove an obstacle to cleanup efforts.Larger",1
"debris found consisted of mainly plastic bottles, but also included shoe soles, plastic buckets, patio chairs, Styrofoam pieces, old toys and fishing vessel buoys, and a large collection of floating debris entangled in fishing net. Various types of marine life were found on, around and within the larger types of debris. Some of the garbage collected was put on display at the Bay Model Visitor Center in Sausalito, California.",1
"The initial feasibility mission aimed to collect 40 tonnes of debris, using special nets designed not to catch fish, in two passes through the field. The project would later test methods of recycling the collected garbage into new plastic, or commercial products such as diesel fuel or clothing. If the initial mission proved the collection and processing technologies to be viable, it was expected that the Kaisei would lead a full scale commercial cleanup voyage with other vessels, becoming operational within 18 months. Ocean Voyages Institute raised $500,000 for the Project Kaisei initial voyages.",1
"The SEAPLEX expedition cost $387,000, funded with $190,000 from UC Ship Funds, $140,000 from Project Kaisei and $57,000 from the National Science Foundation. Project Kaisei is also partnered with the California Department of Toxic Substances Control.The group has since been recognized by the United Nations Environment Programme (UNEP) in 2009 as a Climate Hero, by Google as a Google Earth Hero for its work with a video blogging voyage tracking system, and it was recently part of the Clinton Global Initiative in September 2010.",1
"The United States Oak Ridge National Laboratory operated for more than 50 years, performing research and production at its facility in the Melton Valley area of the Oak Ridge Reservation, in Oak Ridge, Tennessee, before it was decommissioned in the mid 1960s. One of the results of this activity was a waste pond, which was contaminated with radioactive waste including strontium-90, caesium-137; tritium, and transuranics. During the 1970s, the pond was backfilled with clay and shale, and finally capped with asphalt.",1
"The soil in the areas surrounding the frozen pond contained lower levels of contamination than the pond itself, but enough contamination that it had to be removed. Approximately 10,000 cubic yards (7,600 m3) of soil were removed from the surrounding areas. Another 5,400 cubic yards (4,100 m3) of soil were excavated from the pond itself. Evaporation ponds Waste stabilization pond",1
"Police officers or litter wardens are empowered and trained to deal with offenders. It is also possible for the public to report information about littering incidents to the police, the local authority or a litter warden, who would then decide whether or not they wish to proceed any further. Whilst it is possible to take out a private prosecution, it would be at a person's own expense, and strong evidence would be needed in court to secure a conviction.In",1
the reaction for biochemical oxidation may be written as: Oxidizable material + bacteria + nutrient + O2 → CO2 + H2O + oxidized inorganics such as NO−3 or SO2−4Oxygen consumption by reducing chemicals such as sulfides and nitrites is typified as follows: S2− + 2 O2 → SO2−4NO−2 + 1⁄2 O2 → NO−3,1
"As an example an effluent consisting of a solution of simple sugars that might discharge from a confectionery factory is likely to have organic components that degrade very quickly. In such a case, the 5 day BOD and the ultimate BOD would be very similar since there would be very little organic material left after 5 days.",1
"Nitrogen is an important nutrient for plant and animal growth. Atmospheric nitrogen is less biologically available than dissolved nitrogen in the form of ammonia and nitrates. Availability of dissolved nitrogen may contribute to algal blooms. Ammonia and organic forms of nitrogen are often measured as Total Kjeldahl Nitrogen, and analysis for inorganic forms of nitrogen may be performed for more accurate estimates of total nitrogen content.: 406–407",1
"NSF/ANSI also sets standards for certifying polytanks, though the Food and Drug Administration (FDA) approves the materials.",1
"In the US, the National Institute for Occupational Safety and Health (NIOSH) and the Occupational Safety and Health Administration (OSHA) work together to provide standards and regulations for noise in the workplace.National Institute for Occupational Safety and Health (NIOSH), Occupational Safety and Health Administration (OSHA), Mine Safety and Health Administration (MSHA), Federal Railroad Administration (FRA) have all set standards on hazardous occupational noise in their respective industries. Each industry is different, as workers' tasks and equipment differ, but most regulations agree that noise becomes hazardous when it exceeds 85 decibels, for an 8-hour time exposure (typical work shift).",1
"This relationship between allotted noise level and exposure time is known as an exposure action value (EAV) or permissible exposure limit (PEL). The EAV or PEL can be seen as equations which manipulate the allotted exposure time according to the intensity of the industrial noise. This equation works as an inverse, exponential, relationship. As the industrial noise intensity increases, the allotted exposure time, to still remain safe, decreases. Thus, a worker exposed to a noise level of 100 decibels for 15 minutes would be at the same risk level as a worker exposed to 85 decibels for 8 hours.",1
"There are also special exposure meters available that integrate noise over a period of time to give an Leq value (equivalent sound pressure level), defined by standards.",1
"These numerical values do not fully reflect the real situation. For example, the OSHA standard sets the Action Level 85 dBA, and the PEL 90 dBA. But in practice, the Compliance Safety and Health Officer must record the excess of these values with a margin, in order to take into account the potential measurement error. And, in fact, instead of PEL 90 dBA, it turns out 92 dBA, and instead of AL 85 dBA - 87 dBA.",1
"Occupational noise, if experienced repeatedly, at high intensity, for an extended period of time, can cause noise-induced hearing loss (NIHL) which is then classified as occupational hearing loss. Most often, this is a type of sensorineural hearing loss.Noise, in the context of industrial noise, is hazardous to a person's hearing because of its loud intensity through repeated long-term exposure. In order for noise to cause hearing impairment for the worker, the noise has to be close enough, loud enough, and sustained long enough to damage the hair cells in the auditory system.",1
"These factors have been taken into account by the governing occupational health and safety organization to determine the unsafe noise exposure levels and durations for their respective industries. Noise can also affect the safety of the employee and others. Noise can be a causal factor in work accidents as it may mask hazards and warning signals and impede concentration. High intensity noise interferes with vital workplace communication which increases the chance of accidents and decreases productivity.Noise may also act synergistically with other hazards to increase the risk of harm to workers. In particular, toxic materials (e.g.",1
"some solvents, metals, asphyxiants and pesticides) have some ototoxic properties that may affect hearing function. Modern thinking in occupational safety and health further identifies noise as hazardous to workers' safety and health. This hazard is experienced in various places of employment and through a variety of sources. There are several ways to limit exposure to hazardous occupational noise. The hierarchy of controls is a guideline for reducing hazardous noise. Before starting a noise reduction program, base noise levels should first be recorded. After this the company can start to eliminate the noise source.",1
"If the noise source cannot be eliminated, the company must try to reduce the noise with alternative methods. This process is called acoustic quieting. Acoustic quieting is the process of making machinery quieter by damping vibrations to prevent them from reaching the observer. The company can isolate the certain piece of machinery by placing materials on the machine or in between the machine and the worker to decreases the signal intensity that reaches the worker's ear. If elimination and substitution are not sufficient in reducing the noise exposure, engineering controls should be put in place by the employer.",1
"An engineering control usually changes the physical environment of a workplace. For noise reduction, an engineering control might be as simple as putting barriers in-between the noise source and the employee in order to disrupt the transmission path. An engineering control might also involve changing the machine that produces the noise. Ideally, most machines should be made with noise reduction in mind, but this doesn't always happen. Changing the machinery involved in an industrial process may not be possible, but is a good way to reduce the noise at its source.",1
"Unfortunately, the ability of HPDs decrease the risk of health damage is close to zero in practice. Since the hazards of occupational noise exposure were realized, programs and initiatives such as the US Buy Quiet program have been set up to regulate or discourage noise exposure. The Buy Quiet initiative promotes the purchase of quieter tools and equipment and encourages manufacturers to design quieter machines. Additionally, the Safe-In-Sound Award was created to recognize successes in hearing loss prevention programs or initiatives.",1
"Chemicals with high partition coefficients, for example, tend to accumulate in the fatty tissue of organisms (bioaccumulation). Under the Stockholm Convention, chemicals with a log Kow greater than 5 are considered to bioaccumulate.Furthermore, the parameter plays an important role in drug research (Rule of Five) and toxicology. Ernst Overton and Hans Meyer discovered as early as 1900 that the efficacy of an anaesthetic increased with increasing Kow value (the so-called Meyer-Overton rule).Kow values also provide a good estimate of how a substance is distributed within a cell between the lipophilic biomembranes and the aqueous cytosol.",1
"Definition of the Kow or P-valueThe Kow or P-value always only refers to a single species or substance: K o w = P = c o S i c w S i {\displaystyle K_{\mathrm {ow} }=P={\frac {c_{o}^{S_{i}}}{c_{w}^{S_{i}}}}} with: c o S i {\displaystyle c_{o}^{S_{i}}} concentration of species i of a substance in the octanol-rich phase c w S i {\displaystyle c_{w}^{S_{i}}} concentration of species i of a substance in the water-rich phaseIf different species occur in the octanol-water system by dissociation or association, several P-values and one D-value exist for the system.",1
"If, on the other hand, the substance is only present in a single species, the P and D values are identical.P is usually expressed as a common logarithm, i.e. Log P (also Log Pow or, less frequently, Log pOW): log ⁡ P = log ⁡ c o S i c w S i = log ⁡ c o S i − log ⁡ c w S i {\displaystyle \log {P}=\log {\frac {c_{o}^{S_{i}}}{c_{w}^{S_{i}}}}=\log c_{o}^{S_{i}}-\log c_{w}^{S_{i}}} Log P is positive for lipophilic and negative for hydrophilic substances or species.Definition",1
"In the case of a substance that occurs as multiple species, it can therefore be calculated by summing the concentrations of all n species in the octanol phase and the concentrations of all n species in the aqueous phase: D = c o c w = c o S 1 + c o S 2 + ⋯ + c o S n c w S 1 + c w S 2 + ⋯ + c w S n {\displaystyle D={\frac {c_{o}}{c_{w}}}={\frac {c_{o}^{S_{1}}+c_{o}^{S_{2}}+\dots +c_{o}^{S_{n}}}{c_{w}^{S_{1}}+c_{w}^{S_{2}}+\dots +c_{w}^{S_{n}}}}} with: c o {\displaystyle c_{o}} concentration of the substance in the octanol-rich phase c w {\displaystyle c_{w}}",1
"concentration of the substance in the water-rich phaseD values are also usually given in the form of the common logarithm as Log D: log ⁡ D = log ⁡ c o c w = log ⁡ c o − log ⁡ c w {\displaystyle \log {D}=\log {\frac {c_{o}}{c_{w}}}=\log c_{o}-\log c_{w}} Like Log P, Log D is positive for lipophilic and negative for hydrophilic substances. While P values are largely independent of the pH value of the aqueous phase due to their restriction to only one species, D values are often strongly dependent on the pH value of the aqueous phase.",1
"Values for log Kow typically range between -3 (very hydrophilic) and +10 (extremely lipophilic/hydrophobic).The values listed here are sorted by the partition coefficient. Acetamide is hydrophilic, and 2,2′,4,4′,5-Pentachlorobiphenyl is lipophilic. Hydrophobic effect Dortmund Data Bank Virtual Computational Chemistry Laboratory interactive calculation and interactive comparison of several methods LogP-Berechnungssoftware von ACD (commercial) Directory of reference works and databases with octanol-water partition coefficients Comprehensive free database of evaluated octanol-water partition coefficients from Sangster Research Laboratories",1
"on regulations, the following values must be recorded by the system: Date and time of the discharge Location of the ship Oil content of the discharge in ppm Total quantity discharged Discharge rateAll records of Oil Detection Monitoring Equipment must be stored on board ships for no less than 3 years.Oil Discharge Monitoring systems today consist of a computing unit that is installed in the cargo control room. The computer unit control and receives data from other ODME components.ODME",1
"After April 20, 2010, when an explosion on the Deepwater Horizon Macondo oil drilling platform triggered the largest oil spill in US history, another opportunity for oil toxicity research was presented. Approximately 171 million gallons of crude oil flowed from the seafloor into the Gulf of Mexico, exposing the majority of the surrounding biota. The Deepwater Horizon oil spill also coincided directly with spawning window of various ecologically and commercially important fish species, including yellowfin and Atlantic bluefin tuna.",1
"The oil spill directly affected Atlantic bluefin tuna, as approximately 12% of larval tuna were located in oil-contaminated waters, and Gulf of Mexico is the only known spawning grounds for the western population of bluefin tuna. Oil spills, as well as daily oil runoff from urbanized areas, can lead to polycyclic aromatic hydrocarbon (PAHs) entering marine ecosystems. Once PAHs enter the marine environment, fish can be exposed to them via ingestion, ventilation of the gills, and dermal uptake.",1
"The major route of uptake will depend on the behavior of the species of fish and the physicochemical properties of the PAH of concern. Habitat can be a major deciding factor for the route of exposure. For example, demersal fish or fish that consume demersal fish are highly likely to ingest PAHs that have sorbed to the sediment, whereas fish that swim at the surface are at a higher risk for dermal exposure. Upon coming in contact with a PAH, bioavailability will affect how readily the PAH is taken up.",1
"Once a PAH is taken up, the fish's metabolism can affect the duration and intensity of the exposure to target tissues. Fish are able to readily metabolize 99% of PAHs to a more hydrophilic metabolite through their hepato-biliary system. This allows for the excretion of PAHs. The rate of metabolism of PAHs will depend on the sex and size of the species. The ability to metabolize PAHs into a more hydrophilic form can prevent bioaccumulation and halt PAHs from being passed on to organisms further up the food web.",1
"Because oil can persist in the environment long after oil spills via sedimentation, demersal fish are likely to be continually exposed to PAHs many years after oil spills. This has been proven by looking at the biliary PAH metabolites of bottom-dwelling fish. For instance, bottom-dwelling fish still showed elevated levels of low molecular weight PAH metabolites 10 years after Exxon Valdez oil spill.",1
"Crude oil is composed of more than 17,000 compounds. Among these 17,000 compounds are PAHs, which are considered the most toxic components of oil. PAHs are formed by pyrogenic and petrogenic processes. Petrogenic PAHs are formed by the elevated pressure of organic material. In contrast, pyrogenic PAHs are formed through the incomplete combustion of organic material. Crude oil naturally contains petrogenic PAHs and these PAH levels are increased significantly through the burning of oil which creates pyrogenic PAHs. The level of PAHs found in crude oil differs with the type of crude oil.",1
"For example, crude oil from the Exxon Valdez oil spill had PAH concentrations of 1.47%, while PAH concentrations from the North Sea have much lower PAH concentrations of 0.83%.",1
"Crude oil contamination in marine ecosystems can lead to both pyrogenic and petrogenic PAHs entering these ecosystems. Petrogenic PAHs can enter waterways through oil seeps, major oil spills, creosote and fuel oil runoff from urban areas. Pyrogenic PAH sources consist of diesel soot tire rubber and coal dust. Although there are natural sources of PAHs such as volcanic activity and seepage of coal deposits, anthropogenic sources pose the most significant input of PAHs into the environment. These anthropogenic sources include residential heating, asphalt production, coal gasification, and petroleum usage.",1
"Many effects of PAH exposure have been observed in marine fish. Specifically, studies have been conducted on the embryonic and larval fish, the development of fish exposed to PAHs, and uptake of PAHs by fish via various routes of exposure. One study on found that Pacific herring eggs exposed to conditions mimicking the ‘’Exxon Valdez’’ oil spill resulted in premature hatching of eggs, reduced size as fish matured and significant teratogenic effects, including skeletal, cardiovascular, fin and yolk sac malformations. Yolk sac edema was responsible for the majority of herring larval mortality.",1
"The teratogenic malformations in the dorsal fin and spine, and in the jaw were observed to effectively decrease the survival of developing fish, through the impairing of swimming and feeding ability respectively. Feeding and prey avoidance via swimming are crucial for the survival of larval and juvenile fish. All effects observed in herring eggs in the study were consistent with effects observed in exposed fish eggs following the Exxon Valdez oil spill. Zebrafish embryos exposed to oil were observed to have severe teratogenic defects similar to those seen in herring embryos, including edema, cardiac dysfunction, and intracranial hemorrhages.",1
"In a study focused on the uptake of PAHs by fish, salmon embryos were exposed to crude oil in three various situations, including via effluent from oil-coated gravel. PAH concentrations in embryos directly exposed to oil and those exposed to PAH effluent were not significantly different. PAH exposure was observed to lead to death, even when the PAHs were exposed to fish via effluent. From the results, it was determined that fish embryos near the Exxon Valdez spill in Prince William Sound that were not directly in contact with oil still may have accumulated lethal levels of PAHs.",1
"While many laboratory and natural studies have observed significant adverse effects of PAH exposure to fish, a lack of effects has also been observed for certain PAH compounds, which could be due to a lack of uptake during exposure to the compound.",1
"The narcosis model was not able to accurately predict the outcome of PAH mixture exposure of herring and pink salmon, according to a study. The primary toxicity of these PAHs in fish embryos has been observed to be AhR independent, and their cardiac effects are not associated with AhR activation or Cytochrome P450, family 1, member A induction in the endocardium. The alkyl phenanthrene model has been studied by exposing herring and pink salmon to mixtures of PAHs in an attempt to better understand the toxicity mechanisms of PAHs.",1
"Coalescence is the breakdown of surface tension between oil droplets in an oil/water mixture which causes them to join and increase in size. The oil from the collecting spaces is drained away automatically or manually. In most modern ships, the oil from collecting spaces is drained away automatically. All Cargo vessels where MARPOL Convention is applicable must have an oil record book where the chief engineer will record all oil or sludge transfers and discharges within the vessel.",1
"This is necessary in order for authorities to be able to monitor if a vessel's crew has performed any illegal oil discharges at sea. When making entries in the oil record book Part I, the date, operational code, and item number are inserted in the appropriate columns and the required particulars shall be recorded in chronological order as they have been executed on board. Each operation is to be fully recorded without delay so that all the entries in the book appropriate to that operation are completed.",1
Wastewater purification of oils and contaminants by electrochemical emulsification is actively in research and development. Electrochemical emulsification involves the generation of electrolytic bubbles that attract pollutants such as sludge and carry them to the top of the treatment chamber. Once at the top of the treatment chamber the oil and other pollutants are transferred to a waste oil tank.,1
"At present, there is no clear and efficient method of determining whether regulations are violated or not. At the most basic level, the absolute absence of any type of standardization of OWS systems makes the initial investigation confusing, dirty, time-consuming and sometimes plain incorrect. In the marine industry there is a long-standing and important tradition of ""jointness"" in marine forensic investigations, where all parties at interest examine the same things at the same time.",1
"It is hydraulic type and able to operate also in classified areas, as ATEX Zone 0, 1 and 2.",1
"WEPP is applicable for a wide range of geographic and land-use and management conditions, and capable of predicting spatial and temporal distributions of soil detachment and deposition on an event or continuous basis at both small (hillslopes, roads, small parcels) and large (watershed) scales. Hillslope applications of the model can simulate a single profile having various distributions of soil, vegetation, and plant/management conditions. In WEPP watershed applications, multiple hillslopes, channels, and impoundments can be linked together, and runoff and sediment yield from the entire catchment predicted. The model has been parameterized for a large number of soils across the U.S.",1
"and model performance has been assessed under a wide variety of land-use and management conditions. In addition, WEPP can generate long-term daily climatic data with CLIGEN, an auxiliary stochastic climate generator. The CLIGEN database contains weather statistics from more than 2,600 weather stations in the United States. The WEPP climate database is supplemented by the PRISM database, which further refines the climatic data based on longitude, latitude, and elevation.",1
"WEPP can provide daily runoff, subsurface flow, and sediment output categorized into five particle-size classes: primary clay, primary silt, small aggregates, large aggregates, and primary sand, allowing calculation of selective sediment transport, and enrichment of the fine sediment sizes. Over the last decade, researchers have made significant improvements to the WEPP model.",1
"These include improved algorithms to simulate the effect of hydraulic structures and impoundments on runoff and sediment delivery, the addition of Penman-Monteith ET algorithms, subsurface converging lateral flow to represent variable source area runoff, improved canopy biomass routines for forested applications, and the incorporation of an alternative, energy-balance-based winter hydrologic routine. A number of modern graphical user interface programs have also been created, to assist in easier application of WEPP. The main interface for the model is a standalone Windows application (downloadable via: http://www.ars.usda.gov/Research/docs.htm?docid=10621),",1
"Forest Service has developed a suite of internet interfaces, the Forest Service WEPP (FS WEPP) interfaces, for easier applications by stakeholders in forest and rangeland management (forest engineers, rangeland scientists, federal and state regulatory personnel) and the general public. The interfaces can be readily accessed and run through the internet (http://forest.moscowfsl.wsu.edu/fswepp/), and do not require any in-depth understanding of the hydrology, hydraulic and erosion principles embedded in the WEPP model.",1
"The FS WEPP interfaces include: Cross Drain - to predict sediment yield from a road segment across a buffer Rock:Clime - to create and download a modified WEPP climate file WEPP:Road - to predict erosion from a forest road segment WEPP:Road Batch - to predict erosion from multiple forest road segments Disturbed WEPP - to predict erosion from rangeland and forest disturbances (wildfire, harvest operations) Tahoe Basin Sediment Model (under construction) - to predict runoff and erosion for the Lake Tahoe Basin WEPP FuME (Fuel Management) - to predict erosion from fuel management practices ERMiT (Erosion Risk Management Tool) - to",1
"predict the probability of sediment delivery with various mitigation treatments in each of five years following wildfire Erosion Erosion prediction Erosion control Sediment control Hydrology (agriculture) Hydrological modelling Hydrological transport model Runoff model (reservoir) WEPP - Official site - National Soil Erosion Research Laboratory (NSERL), USDA Agricultural Research Service WEPP Web Interfaces - NSERL, USDA Agricultural Research Service Forest Service WEPP Interfaces - USDA Forest Service Rocky Mountain Research Station GeoWEPP - SUNY Buffalo NetMap - Earth Systems Institute",1
"Nurdles are the second largest source of microplastics in the ocean. Approximately 27 million tonnes (60 billion pounds) of nurdles are manufactured annually in the United States. One pound of pelletized HDPE contains approximately 25,000 nurdles (approximately 20 mg per nurdle). They are typically under 5 mm (0.20 in) in diameter. Worldwide, about 230,000 tonnes of nurdles are thought to be deposited in the oceans each year.",1
"As more plastic is being produced, more plastic pellets are being deposited in waterways. A study on a polyethylene production facility in Sweden found that between 3 and 36 million of plastic pellets enter the environment from production sites every year. These nurdles spill during transportation and production and due to inadequate precautions and regulations, millions of pellets of plastic end up in nearby waterways and eventually the ocean. Nurdles are a major contributor to marine debris. During a three-month study of Orange County beaches researchers found them to be the most common beach contaminant.",1
"San Francisco Bay Coastal Cleanup from multiple nurdle spills.In Hong Kong, after being blown by Typhoon Vicente on 24 July 2012, some containers belonging to Chinese oil giant Sinopec which were carrying over 150 tonnes of plastic pellets were blown into the sea, washing up on southern Hong Kong coasts, such as Shek O, Cheung Chau, Ma Wan and Lamma Island. Though nurdles are not toxic or hazardous on their own according to Sinopec, the spill disrupted marine life and is being credited with killing stocks of fish on fish farms.",1
"A semi-truck crash led to the release of bright blue colored nurdles into Pocono Creek and the waterways of the Lehigh Valley, Pennsylvania.",1
"Michelle Allsopp; Adam Walters; David Santillo & Paul Johnston (2006). ""Plastic Debris in the World's Oceans"" (PDF). Netherlands: Greenpeace.",1
"With the increasing presence of plastics in the environment, certain species of bacteria have evolved to degrade plastics into harmless by-products. Over the last 70 years, microbes have evolved to degrade plastics, as the global production of plastics steadily increased from 2 million metric tons to 380 million metric tons per year. A study performed in 2021, led by Jan Zrimec of National Institute of Biology, Slovenia, was able to isolate 30,000 non-redundant enzyme homologues from more than 200 million genes in DNA samples obtained from the environment capable of degrading 10 different types of plastics.The",1
"With over 5000 grades of plastic polymers and variations in coatings such as flame retardants and pigments, diverse plastic polymer substrates suggest the existence of very heterogenous metabolic processes in plastic degradation. Dynamic ocean conditions ranging in humidity, temperature, UV irradiation, pH, wind, and waves, create varied growth conditions for bacteria and increase the possibility of diversified plastic degradation metabolisms.",1
"As a developing topic, few studies have characterized the metabolic and biochemical mechanisms involved in the degradation of plastic by marine microbes. A limited number of plastic degradation pathways in marine microbes have been extensively studied. It is important to note that although several metabolic processes in plastic degradation have been well-documented, these processes are likely not representative of the microbial population capable of plastic degradation. Additionally, reaction times of plastic biodegradation metabolisms are poorly understood and are estimated to range between 1–400 hours in the marine environment.",1
"Bacteria capable of polyethylene degradation have been described to utilize oxygenase to initiate biodegradation. The formation of alcohol groups through oxygenase makes polyethylene more labile for degradation. The hydrophilic properties of polyethylene polymers increase as the material experiences degradation and oxidation, which causes polyethylene to become less recalcitrant. Lipases, esterase, endopeptidases, and other extracellular enzymes then further degrade the polyethylene polymers. The role of laccase in polyethylene degradation by Rhodococcus ruber is well-documented as an important enzyme for biodegradation. Alkane hydroxylase is thought to play a similar role in pseudomonas species capable of polyethylene degradation.",1
"Once enzymes degrade polyethylene polymers into oligomers, microbial cells uptake the molecules through either Major Facilitator Superfamily proteins or ATP binding cassettes. The polyethylene oligomers are converted into Acetyl-CoA and succinyl-CoA and enter the tricarboxylic acid cycle, and eventually the respiratory chain to produce ATP.",1
"Several bacterial species in Betaproteobacteria, Myxococcota (formerly included in Deltaproteobacteria), and Gammaproteobacteria are capable of PET Biodegradation.",1
"Polystyrene consists of molecules with both strong hydrophobicity and a high molecular weight. Bacteria that are capable of degrading this molecule are documented to release monooxygenases to initiate the oxidization of polystyrene molecules. Following the monooxygenase step, the polystyrene molecule is transformed into phenylacetic acid during the upper pathway of styrene metabolism. Phenylacetic acid is first converted into phenylacetyl-coA, and later acetyl-CoA and succinyl-CoA after a series of enzymatic reactions. Acetyl-CoA and succinyl-CoA then enter the tricarboxylic acid cycle. Several Rhodococcus ruber strains are capable of polystyrene biodegradation.",1
"The resulting oligomers cross bacterial membranes through passive diffusion in a form that can directly enter β-oxidation to yield acetyl-CoA. The resulting acetyl-CoA then enters the TCA cycle. Several bacterial species in the genera Gracilibacillus, Enterobacter, and Bacillus are capable of polyhydroxyalkanoate biodegradation.",1
"Literature frequently discusses the biological constraints that organisms must overcome to degrade plastic. Features that make plastic challenging to degrade include long-chain polymers, high molecular weight, hydrophobicity, and crystallinity. Although hydrocarbons found in plastic are potential sources of carbon and energy for bacteria, the lack of essential nutrients like nitrogen in plastic make it insufficient to support microbial growth without additional nutrient sources. According to the National Ocean Service, it is estimated that there are 8 million metric tons of plastic in the ocean. Ocean plastic affects many marine species in the form of whole plastic and micro plastics.",1
"Since the discovery of bacteria that can feed on plastic, there has been hope that these microbes could help clean the ocean of plastic, but Ramani Narayan, a professor in chemical engineering at Michigan State University says that this viewpoint misses the point. Moreover, after Kale et al. performed an extensive review of all data available on these bacteria, they have found that there are currently no practical industrial applications of these microbes in environments to make a substantial impact on the plastic problem in the ocean.",1
"This can be attributed to findings that have found the rate of degradation by these microbes to be low, even when optimized in laboratory settings. Hence, researchers at the University of Portsmouth have been working on genetically engineering these bacteria to be more efficient at degrading the plastic.",1
Scientists are working on genetically engineering Ideonella sakaiensis to break down PET plastic at a faster rate in order to make it a viable option to help recycle plastic. Researchers at the University of Portsmouth have discovered that mixing PETase with a second enzyme called MHETase has created an “enzyme cocktail” that degrades PET plastic at 6 times the rate it did before.,1
"As a natural bioplastic, PHAs have similar properties to synthetic plastics and are biodegradable as well as nontoxic making them useful for biomedical applications. Its utility even extends to its potential for the production of hydrocarbon jet fuel if further chemically catalyzed.Genetically engineered bacteria also do not have a practical application in the ocean, yet, according to the Ocean Conservatory group. Dr. Naryan believes that releasing genetically engineered bacteria into the ocean ecosystems could be irresponsible and have many negative side effects on the ecosystem.",1
"Without efficient collection in the first place, the high energy cost of enzymatic recycling would be more burdening than the amount of waste it would break down. Another problem includes the fact that this may not be applicable at a wide scale since enzymes have a short half-life so engineered organisms may not remain catalytically active for long enough to be effective. On the other hand, to fix unpredictable enzyme-polymer interactions, there has been development of new techniques such as computational tools to visualize the 3-D interactions between plastics and enzymes.",1
"Thus, engineered microbes can remain as a hopeful solution for plastic remediation.",1
"A study was performed to understand the toxicity of the degradation of polythene bags and cups by P. aeruginosa, Streptomyces sp., Aspergillus niger, Staphylococcus aureus, and Rhizopus sp. The study found carbon dioxide gas to be the main byproduct of the degradation process of polythene by the bacteria mentioned before. However, the particles produced as a byproduct of PE bio-degradation had negative impacts on the production of polysaccharides, proteins, and nutrient uptake in roots of plants. Another study performed by Aswale focused on how biodegraded polythene affected seed germination in plants.",1
"It found that biodegraded polythene was correlated with a decrease in percentage of seed germination, indicating that the byproducts of the breakdown could have negative effects on the seed health.",1
"As seen in Figure 4, food web biomagnification refers to the process by which concentrations of contaminants increase as the trophic levels increase. In terms of plastic, this means when plankton eat plastic, then fish eat the plankton, and larger fish eat that fish, the amount of plastic accumulates in the largest fish. Therefore, removing plastic from the system at the bacteria level would prevent the plastic from bioaccumulating in larger fish. However, as mentioned above, these bacteria are not very efficient at degrading plastic, and therefore do not have the capabilities to create a substantial impact on this problem.",1
"The IEC 61672-1 specifies ""three kinds of sound measuring instruments"". They are the ""conventional"" sound level meter, the integrating-averaging sound level meter, and the integrating sound level meter. The standard sound level meter can be called an exponentially averaging sound level meter as the AC signal from the microphone is converted to DC by a root-mean-square (RMS) circuit and thus it must have a time constant of integration; today referred to as the time-weighting. Three of these time-weightings have been internationally standardized, 'S' (1 s) originally called Slow, 'F' (125 ms) originally called Fast, and 'I' (35 ms) originally called Impulse.",1
Their names were changed in the 1980s to be the same in any language. I-time-weighting is no longer in the body of the standard because it has little real correlation with the impulsive character of noise events. The output of the RMS circuit is linear in voltage and is passed through a logarithmic circuit to give a readout linear in decibels (dB). This is 20 times the base 10 logarithm of the ratio of given root-mean-square sound pressure to the reference sound pressure. Root-mean-square sound pressure being obtained with a standard frequency weighting and standard time weighting.,1
"A common variant of the sound level meter is a noise dosemeter (dosimeter in American English). However, this is now formally known as a personal sound exposure meter (PSEM) and has its own international standard IEC 61252:1993. A noise dosimeter (American) or noise dosemeter (British) is a specialized sound level meter intended specifically to measure the noise exposure of a person integrated over a period of time; usually to comply with Health and Safety regulations such as the Occupational Safety and Health (OSHA) 29 CFR 1910.95 Occupational Noise Exposure Standard or EU Directive 2003–10/EC.",1
"Traditionally, noise dosemeters were relatively large devices with a microphone mounted near the ear and having a cable going to the instrument body, itself usually belt worn. These devices had several issues, mainly the reliability of the cable and the disturbance to the user's normal work mode, caused by the presence of the cable. In 1997 following a UK research grant an EU patent was issued for the first of a range of devices that were so small that they resembled a radiation badge and no cable was needed as the whole unit could be fitted near the ear.",1
"UK designer and manufacturer, Cirrus Research, introduced the doseBadge personal noise dosimeter, which was the world's first truly wireless noise dosimeter. Today these devices measure not only simple noise dose, but some even have four separate dosemeters, each with many of the functions of a full-sized sound level meter, including in the latest models full octave band analysis.",1
"For compliance purposes, readings with an ANSI Type 2 sound level meter and dosimeter are considered to have an accuracy of ±2 dBA, while a Type 1 instrument has an accuracy of ±1 dBA. A Type 2 meter is the minimum requirement by OSHA for noise measurements and is usually sufficient for general-purpose noise surveys. The Type 1 meter is preferred for the design of cost-effective noise controls. For unusual measurement situations, refer to the manufacturer's instructions and appropriate ANSI standards for guidance in interpreting instrument accuracy.""",1
"The second letter indicates the frequency weighting. ""Pattern approved"" sound level meters typically offer noise measurements with A, C and Z frequency weighting.Z-weighting represents the sound pressure equally at all frequencies. A-weighting, weights lower and higher frequencies much less, and has a slight boost in the mid-range, representing the sensitivity of normal human hearing at low (quiet) levels. C-Weighting, more sensitive to the lower frequencies, represents what humans hear when the sound is loud (near 100 dB SPL).",1
"The A-weighting curve was based on the historical equal-loudness contours and while arguably A-weighting is no longer the ideal frequency weighting on purely scientific grounds, it is nonetheless the legally required standard for almost all such measurements and has the huge practical advantage that old data can be compared with new measurements. It is for these reasons that A-weighting is the only weighting mandated by the international standard, the frequency weightings 'C' and 'Z' being options.",1
"If the third letter is F, S or I, this represents the time weighting, with F = fast, S = slow, I = impulse. Time weighting is applied so that levels measured are easier to read on a sound level meter. The time weighting damps sudden changes in level, thus creating a smoother display. The graph indicates how this works. In this example, the input signal suddenly increases from 50 dB to 80 dB, stays there for 6 seconds, then drops back suddenly to the initial level.",1
A slow measurement (yellow line) will take approximately 5 seconds (attack time) to reach 80 dB and around 6 seconds (decay time) to drop back down to 50 dB. S is appropriate when measuring a signal that fluctuates a lot. A fast measurement (green line) is quicker to react. It will take approximately 0.6 seconds to reach 80 dB and just under 1 second to drop back down to 50 dB. F may be more suitable where the signal is less impulsive.,1
"eq = equivalent. Equivalent values are a form of time weighting that is easier to read on a display than the instantaneous sound level. If you look at these graphs of sound level over time, the area under the blue curve represents the energy. The horizontal red line drawn to represent the same area under the blue curve, gives us the LAeq. That is the equivalent value or average of the energy over the entire graph. LAeq is not always a straight line.",1
"However, for mainly historical reasons, LAT is commonly referred to as Leq.Formally, LAT is 10 times the base 10 logarithm of the ratio of a root-mean-square A-weighted sound pressure during a stated time interval to the reference sound pressure and there is no time constant involved. To measure LAT an integrating-averaging meter is needed; this in concept takes the sound exposure, divides it by time, and then takes the logarithm of the result.",1
"An important variant of overall LAT is ""short Leq"" where very short Leq values are taken in succession, say at 1/8 second intervals, each being stored in a digital memory. These data elements can either be transmitted to another unit or be recovered from the memory and re-constituted into almost any conventional metric long after the data has been acquired. This can be done using either dedicated programs or standard spreadsheets. Short Leq has the advantage that as regulations change, old data can be re-processed to check if a new regulation is met.",1
"Short Leq is a very valuable method for acoustic data storage; initially, a concept of the French Government's Laboratoire National d'Essais (ref 1), it has now become the most common method of storing and displaying a true time history of the noise in professional commercial sound level meters. The alternative method, which is to generate a time history by storing and displaying samples of the exponential sound level, displays too many artifacts of the sound level meter to be as valuable and such sampled data cannot be readily combined to form an overall set of data.",1
"Until 2003 there were separate standards for exponential and linear integrating sound level meters, (IEC 60651 and IEC 60804—both now withdrawn), but since then the combined standard IEC 61672 has described both types of meter. For short Leq to be valuable the manufacturer must ensure that each separate Leq element fully complies with IEC 61672.",1
"If the words max or min appear in the label, this simply represents the maximum or minimum value measured over a certain period of time.",1
"Most national regulations also call for the absolute peak value to be measured to protect workers hearing against sudden large pressure peaks, using either 'C' or 'Z' frequency weighting. 'Peak sound pressure level' should not be confused with 'MAX sound pressure level'. 'Max sound pressure level' is simply the highest RMS reading a conventional sound level meter gives over a stated period for a given time-weighting (S, F, or I) and can be many decibels less than the peak value.",1
"In the European Union, the maximum permitted value of the peak sound level is 140 dB(C) and this equates to 200 Pa pressure. The symbol for the A-frequency and S-time weighted maximum sound level is LASmax. For the C-frequency weighted peak it is LCpk or LC,peak.",1
IEC61672 Ed. 2.0 (2013) IEC60651 Ed 1.2 (2001) plus Amendment 1 (1993-02) and Amendment 2 (2000–10) IEC60804 (2000–10) ANSI S1.4-2014 (a U.S. nationally adopted international standard from IEC 61672:2013),1
IEC61260 Ed. 1.0 (2014) Electroacoustics – Octave-band and fractional-octave-band filters ANSI S1.11-2004 (R2009),1
IEC61252 Ed. 1.1 (2002–03) ANSI S1.25-1991(R2007),1
IEC 61094 : 2000,1
IEC61010-1 Ed. 2.0 (2001–02),1
"The following International standards define sound level meters, PSEM and associated devices. Most countries' national standards follow these very closely, the exception being the USA. In many cases the equivalent European standard, agreed by the EU, is designated for example EN 61672 and the UK national standard then becomes BS. EN 61672.",1
"IEC 61672 : 2013 ""Electroacoustics – sound level meters"" IEC 61252 : 1993 ""Electroacoustics – specifications for personal sound exposure meters"" IEC 60942 : 2003 ""Electroacoustics – sound calibrators"" IEC 62585 : 2012 ""Electroacoustics – Methods to determine corrections to obtain the free-field response of a sound level meter""These International Standards were prepared by IEC technical committee 29:Electroacoustics, in cooperation with the International Organization of Legal Metrology (OIML). Until 2003 there were separate standards for exponential and linear integrating sound level meters, but since then IEC 61672 has described both types.",1
"The classic exponential meter was originally described in IEC 123 for 'industrial' meters followed by IEC 179 for 'precision' meters. Both of these were replaced by IEC 651, later renamed IEC 60651, while the linear integrating meters were initially described by IEC 804, later renamed IEC 60804. Both IEC 60651 and 60804 included four accuracy classes, called ""types"". In IEC 61672 these were reduced to just two accuracy classes 1 and 2.",1
"Combatants in every branch of the United States' military are at risk for auditory impairments from steady state or impulse noises. While applying double hearing protection helps prevent auditory damage, it may compromise effectiveness by isolating the user from his or her environment. With hearing protection on, a soldier is less likely to be aware of his or her movements, alerting the enemy to their presence. Hearing protection devices (HPD) could also require higher volume levels for communication, negating their purpose.",1
"MIL-STD 1474D The first military standard (MIL-STD) on sound was published in 1984 and underwent revision in 1997 to become MIL-STD-1474D. This standard establishes acoustical noise limits and prescribes testing requirements and measurement techniques for determining conformance to the noise limits specified herein. This standard applies to the acquisition and product improvement of all designed or purchased (non-developmental items) systems, subsystems, equipment, and facilities that emit acoustic noise. This standard is intended to address noise levels emitted during the full range of typical operational conditions.",1
"MIL-STD 1474E In 2015, MIL-STD 1474D evolved to become MIL-STD-1474E which, as of 2018, remains to be the guidelines for United States' military defense weaponry development and usage. In this standard, the Department of Defense established guidelines for steady state noise, impulse noise, aural non-detectability, aircraft and aerial systems, and shipboard noise. Unless marked with warning signage, steady state and impulse noises are not to exceed 85 decibels A-weighted (dBA) and, if wearing protection, 140 decibels (dBP) respectively. It establishes acoustical noise limits and prescribes testing requirements and measurement techniques for determining conformance to the noise limits specified herein.",1
"This standard applies to the acquisition and product improvement of all designed or purchased (non-developmental items) systems, subsystems, equipment, and facilities that emit acoustic noise. This standard is intended to address noise levels emitted during the full range of typical operational conditions. This standard includes two methods for assessing the impulse noise and risk to hearing. The Auditory Hazard Assessment Algorithm for Humans (AHAAH), a one-dimensional electro-acoustic analog of the auditory system, produced MIL-STD 1474E's numerical guidelines. Over time the predictability of this algorithm has been claimed to have increased to 95% accuracy.",1
"US Army Research Laboratory researchers state that almost every error resulted in overcalculation of risk. By comparison, the MIL-STD-147D was deemed correct in 38% of cases with the same data. Originally developed from a cat animal model and later informed by human data, the AHAAH sums the basilar membrane displacements of 23 locations.The AHAAH model calculates the estimated displacement of the basilar membrane and summates the accumulation of the flexure of the basilar membrane. The user inputs their noise exposure, protection level, and whether they were forewarned of the noise, to receive their hazard vulnerability in auditory risk units (ARU).",1
"This value can be converted to compound threshold shifts and the allowed number of exposure (ANE). Compound threshold shifts is a value that integrates both temporary and permanent shifts in auditory threshold, the latter being correlated to hair cell function.The AHAAH's claimed improvements in accuracy are often attributed to its sensitivity to the flexing of the middle ear muscle (MEM) and annular ligament of the stapes. When someone is forewarned of a sound, the MEM flexes, which is associated with reduced ability of the sound waves to reverberate.",1
"When an impulse sound is produced, the stape's annular ligament flexes and strongly clips the sound's oscillation peak. As the MIL-STD-1474 has evolved, technology and methods have improved the AHAAP's accuracy. Researchers claim that the AHAAP has been proven to be more accurate in cases of double protection but not always in unwarned impulse noise instances relative to the competitive metric LAeq8hr. Some suggestions for further development focus on creating a more user-friendly software, the placement of the microphone in data collection, the absence of the MEM reflex in populations, and the reevaluation of free-field conditions in calculations.",1
"Agencies such as NATO, the American Institute of Biological Sciences, and the National Institute for Occupational Safety and Health agreed that these suggestions be attended to before the metric is implemented. This shared conclusion was made prior to the development of MIL-STD-1474E. The Level Impulse Equivalent Energy for 100 milliseconds (LIAeq100ms) computes the integrated energy and equates it to a 100 ms interval. (LIAeq100ms) incorporates an adjustment for the initial duration of a blast wave.",1
The United Kingdom professional body for acoustics The International Institute for Noise control The home page of the IEC standards body,1
"A problem in selecting a sound level meter is ""How do you know if it complies with its claimed standard?"" This is a difficult question and IEC 61672 part 2 tries to answer this by the concept of ""pattern approval"". A manufacturer has to supply instruments to a national laboratory which tests one of them and if it meets its claims issue a formal Pattern Approval certificate. In Europe, the most common approval is often considered to be that from the PTB in Germany (Physikalisch-Technische Bundesanstalt).",1
"If a manufacturer cannot show at least one model in his range that has such approval, it is reasonable to be wary, but the cost of this approval militates against any manufacturer having all his range approved. Inexpensive sound level meters (under $200) are unlikely to have a Pattern Approval and may produce incorrect measurement results. Even the most accurate approved sound level meter must be regularly checked for sensitivity—what most people loosely call 'calibration'. The procedures for periodic testing are defined within IEC61672.3-2013.",1
"The acoustic level generated is 94 dB which is 1 pascal and is at a frequency of 1 kHz where all the frequency weightings have the same sensitivity. For a complete sound level meter check, periodic testing outlined in IEC61672.3-2013 should be carried out. These tests excite the sound level meter across the entire frequency and dynamic range ensuring compliance with expected design goals defined in IEC61672.1-2013.",1
"Sound level meters are also divided into two types in ""the Atlantic divide"". Sound level meters meeting the USA American National Standards Institute (ANSI) specifications cannot usually meet the corresponding International Electrotechnical Commission (IEC) specifications at the same time, as the ANSI standard describes instruments that are calibrated to a randomly incident wave, i.e. a diffuse sound field, while internationally meters are calibrated to a free field wave, that is sound coming from a single direction.",1
"Some advanced sound level meters can also include reverberation time (RT60) (a measure of the time required for the sound to ""fade away"" in an enclosed area after the source of the sound has stopped) measurement capabilities. Measurements can be done using the integrated impulse response or interrupted noise methods. Such sound level meters should comply with latest ISO 3382-2 and ASTM E2235-04 measurement standards. Required for measuring the acoustics in buildings is a signal generator that provides pink or white noise through an amplifier and omnidirectional speakers.",1
"Some applications require the ability to monitor noise continuously on a permanent or semi-permanent basis. Some manufacturers offer permanent and semi-permanent noise monitoring stations for this purpose. Such monitoring stations are typically based on a sound level meter at the heart and some added capabilities such as remote communication, GPS, and weather stations. These can often also be powered using solar power. Applications for such monitoring stations include airport noise, construction noise, mining noise, traffic noise, rail noise, community noise, wind farm noise, industrial noise, etc.",1
"Modern monitoring stations can also offer remote communication capabilities using cellular modems, WiFi networks or direct LAN wires. Such devices allow for real-time alerts and notifications via email and text messages upon exceeding a certain dB level. Systems can also remotely email reports on a daily, weekly or monthly basis. Real-time data publication is often also desired, which can be achieved by pushing data to a website.",1
"The ubiquity of smartphones, their constant network connectivity, the built-in geographic information system functionality and user-interactivity features present a great opportunity to revolutionize the way we look at noise, its measurement, and its effects on hearing and overall health. The ability to acquire and display real-time noise exposure data raises people's awareness about their work (and off-work) environment and allows them to make informed decisions about hearing hazards and overall well-being.",1
"The National Institute for Occupational Safety and Health (NIOSH) conducted a pilot study to select and characterize the functionality and accuracy of smartphone sound measurement applications (apps) as an initial step in a broader effort to determine whether these apps can be relied on to conduct participatory noise monitoring studies in the workplace.Researchers reported that challenges remain with using smartphones to collect and document noise exposure data due to encounters with privacy and collection of personal data, motivation to participate in such studies, corrupted or bad data, and the ability to store the data collected.",1
"This study indicated that the gap between professional instruments and smartphone-based apps are narrowing.Healthy Hearing, an organization dedicated to hearing health, reported on the top smartphone sound level meter apps: NIOSH Sound Level Meter, Decibel X, and Too Noisy Pro. Equal-loudness contour ITU-R 468 noise weighting Audio system measurements Sound pressure Clap-o-meterGeneral: Noise measurement Noise regulation Health effects from noise",1
"The potential problem of lunar and planetary contamination was first raised at the International Astronautical Federation VIIth Congress in Rome in 1956.In 1958 the U.S. National Academy of Sciences (NAS) passed a resolution stating, “The National Academy of Sciences of the United States of America urges that scientists plan lunar and planetary studies with great care and deep concern so that initial operations do not compromise and make impossible forever after critical scientific experiments.”",1
"This led to creation of the ad hoc Committee on Contamination by Extraterrestrial Exploration (CETEX), which met for a year and recommended that interplanetary spacecraft be sterilized, and stated, “The need for sterilization is only temporary. Mars and possibly Venus need to remain uncontaminated only until study by manned ships becomes possible”.In 1959, planetary protection was transferred to the newly formed Committee on Space Research (COSPAR).",1
"sterilization techniques is required on the part of all deep space probe launching authorities to avoid such contamination. In 1967, the US, USSR, and UK ratified the United Nations Outer Space Treaty. The legal basis for planetary protection lies in Article IX of this treaty: ""Article IX: ...",1
"States Parties to the Treaty shall pursue studies of outer space, including the Moon and other celestial bodies, and conduct exploration of them so as to avoid their harmful contamination and also adverse changes in the environment of the Earth resulting from the introduction of extraterrestrial matter and, where necessary, shall adopt appropriate measures for this purpose... This treaty has since been signed and ratified by 104 nation-states. Another 24 have signed but not ratified. All the current space-faring nation-states, along with all current aspiring space-faring nation-states, have both signed and ratified the treaty.The",1
"Outer Space Treaty has consistent and widespread international support, and as a result of this, together with the fact that it is based on the 1963 declaration which was adopted by consensus in the UN National Assembly, it has taken on the status of customary international law. The provisions of the Outer Space Treaty are therefore binding on all states, even those who have neither signed nor ratified it.For forward contamination, the phrase to be interpreted is ""harmful contamination"". Two legal reviews came to differing interpretations of this clause (both reviews were unofficial).",1
"However the currently accepted interpretation is that “any contamination which would result in harm to a state’s experiments or programs is to be avoided”. NASA policy states explicitly that “the conduct of scientific investigations of possible extraterrestrial life forms, precursors, and remnants must not be jeopardized”. The Committee on Space Research (COSPAR) meets every two years, in a gathering of 2000 to 3000 scientists, and one of its tasks is to develop recommendations for avoiding interplanetary contamination. Its legal basis is Article IX of the Outer Space Treaty (see history below for details).",1
"Its recommendations depend on the type of space mission and the celestial body explored. COSPAR categorizes the missions into 5 groups: Category I: Any mission to locations not of direct interest for chemical evolution or the origin of life, such as the Sun or Mercury. No planetary protection requirements. Category II: Any mission to locations of significant interest for chemical evolution and the origin of life, but only a remote chance that spacecraft-borne contamination could compromise investigations. Examples include the Moon, Venus, and comets.",1
"Requires simple documentation only, primarily to outline intended or potential impact targets, and an end of mission report of any inadvertent impact site if such occurred. Category III: Flyby and orbiter missions to locations of significant interest for chemical evolution or the origin of life, and with a significant chance that contamination could compromise investigations e.g., Mars, Europa, Enceladus. Requires more involved documentation than Category II. Other requirements, depending on the mission, may include trajectory biasing, clean room assembly, bioburden reduction, and if impact is a possibility, inventory of organics.",1
"Category IV: Lander or probe missions to the same locations as Category III. Measures to be applied depend on the target body and the planned operations. ""Sterilization of the entire spacecraft may be required for landers and rovers with life-detection experiments, and for those landing in or moving to a region where terrestrial microorganisms may survive and grow, or where indigenous life may be present. For other landers and rovers, the requirements would be for decontamination and partial sterilization of the landed hardware.""Missions to Mars in category IV are subclassified further:Category IVa.",1
"Landers that do not search for Martian life - uses the Viking lander pre-sterilization requirements, a maximum of 300,000 spores per spacecraft and 300 spores per square meter. Category IVb. Landers that search for Martian life. Adds stringent extra requirements to prevent contamination of samples. Category IVc. Any component that accesses a Martian special region (see below) must be sterilized to at least to the Viking post-sterilization biological burden levels of 30 spores total per spacecraft.Category V: This is further divided into unrestricted and restricted sample return.Unrestricted Category V: samples from locations judged by scientific opinion to have no indigenous lifeforms.",1
"No special requirements. Restricted Category V: (where scientific opinion is unsure) the requirements include: absolute prohibition of destructive impact upon return, containment of all returned hardware which directly contacted the target body, and containment of any unsterilized sample returned to Earth.For Category IV missions, a certain level of biological burden is allowed for the mission.",1
Category V missions also have to fulfill the requirements of Category IV to protect the target body from forward contamination.,1
"The 2009 COSPAR Workshop on Planetary Protection for Outer Planet Satellites and Small Solar System Bodies covered this in some detail. Most of these assessments are from that report, with some future refinements. This workshop also gave more precise definitions for some of the categories:",1
"“not of direct interest for understanding the process of chemical evolution or the origin of life.” Io, Sun, Mercury, undifferentiated metamorphosed asteroids",1
"… where there is only a remote chance that contamination carried by a spacecraft could jeopardize future exploration”. In this case we define “remote chance” as “the absence of niches (places where terrestrial microorganisms could proliferate) and/or a very low likelihood of transfer to those places.” Callisto, comets, asteroids of category P, D, and C, Venus, Kuiper belt objects (KBO) < 1/2 size of Pluto.",1
"This is why both Ganymede and Titan were assigned a reasonably firm provisional Category II, but pending results of future research. Icy bodies that show signs of recent resurfacing need further discussion and might need to be assigned to a new category depending on future research. This approach has been applied, for instance, to missions to Ceres. The planetary protection Category is subject for review during the mission of the Ceres orbiter (Dawn) depending on the results found.",1
"Unrestricted Category V: “Earth-return missions from bodies deemed by scientific opinion to have no indigenous life forms.” Restricted Category V: ""Earth-return missions from bodies deemed by scientific opinion to be of significant interest to the process of chemical evolution or the origin of life."" In the category V for sample return the conclusions so far are: Unrestricted Category V: Venus, the Moon. Restricted Category V: Mars, Europa, Enceladus. The aim of the current regulations is to keep the number of microorganisms low enough so that the probability of contamination of Mars (and other targets) is acceptable.",1
"where N 0 {\displaystyle N_{0}} = the number of microorganisms on the spacecraft initially R {\displaystyle R} = Reduction due to conditions on spacecraft before and after launch P S {\displaystyle P_{S}} = Probability that microorganisms on the spacecraft reach the surface of the planet P t {\displaystyle P_{t}} = Probability that spacecraft will hit the planet - this is 1 for a lander P R {\displaystyle P_{R}} = Probability of microorganism to be released in the environment when on the ground, usually set to 1 for crashlanding. P g {\displaystyle P_{g}} = Probability of growth.",1
"The Coleman–Sagan equation has been criticised because the individual parameters are often not known to better than a magnitude or so. For example, the thickness of the surface ice of Europa is unknown, and may be thin in places, which can give rise to a high level of uncertainty in the equation. It has also been criticised because of the inherent assumption made of an end to the protection period and future human exploration. In the case of Europa, this would only protect it with reasonable probability for the duration of the period of exploration.Greenberg",1
"In the case of restricted Category V missions, Earth would be protected through quarantine of sample and astronauts in a yet to be built Biosafety level 4 facility. In the case of a Mars sample return, missions would be designed so that no part of the capsule that encounters the Mars surface is exposed to the Earth environment. One way to do that is to enclose the sample container within a larger outer container from Earth, in the vacuum of space.",1
"The integrity of any seals is essential and the system must also be monitored to check for the possibility of micro-meteorite damage during return to Earth.The recommendation of the ESF report is that “No uncontained Mars materials, including space craft surfaces that have been exposed to the Mars environment should be returned to Earth unless sterilised""...""For unsterilised samples returned to Earth, a programme of life detection and biohazard testing, or a proven sterilisation process, shall be undertaken as an absolute precondition for the controlled distribution of any portion of the sample.” No restricted category V returns have been carried out.",1
"Also the lunar receiving laboratory would be judged a failure by its own design criteria as the sample return didn't contain the lunar material, with two failure points during the Apollo 11 return mission, at the splashdown and at the facility itself. However the Lunar Receiving Laboratory was built quickly with only two years from start to finish, a time period now considered inadequate. Lessons learned from it can help with design of any Mars sample return receiving facility.Design",1
"criteria for a proposed Mars Sample Return Facility, and for the return mission, have been developed by the American National Research Council, and the European Space Foundation. They concluded that it could be based on biohazard 4 containment but with more stringent requirements to contain unknown microorganisms possibly as small as or smaller than the smallest Earth microorganisms known, the ultramicrobacteria. The ESF study also recommended that it should be designed to contain the smaller gene transfer agents if possible, as these could potentially transfer DNA from martian microorganisms to terrestrial microorganisms if they have a shared evolutionary ancestry.",1
"For Category IVa missions (Mars landers that do not search for Martian life), the aim is to reduce the bioburden to 300,000 bacterial spores on any surface from which the spores could get into the Martian environment. Any heat tolerant components are heat sterilized to 114 °C. Sensitive electronics such as the core box of the rover including the computer, are sealed and vented through high-efficiency filters to keep any microbes inside.For more sensitive missions such as Category IVc (to Mars special regions), a far higher level of sterilization is required.",1
"These need to be similar to levels implemented on the Viking landers, which were sterilized for a surface which, at the time, was thought to be potentially hospitable to life similar to special regions on Mars today. In microbiology, it is usually impossible to prove that there are no microorganisms left viable, since many microorganisms are either not yet studied, or not cultivable. Instead, sterilization is done using a series of tenfold reductions of the numbers of microorganisms present. After a sufficient number of tenfold reductions, the chance that there any microorganisms left will be extremely low.The",1
"They need to be tested for compatibility with spacecraft materials and hardware geometries, and are not yet ready for review.Some other methods are of interest as they can sterilize the spacecraft after arrival on the planet. Supercritical carbon dioxide snow (Mars) - is most effective against traces of organic compounds rather than whole microorganisms. Has the advantage though that it eliminates the organic traces - while other methods kill the microorganisms, they leave organic traces that can confuse life detection instruments. Is under study by JPL and ESA. Passive sterilization through UV radiation (Mars).",1
"Highly effective against many microorganisms, but not all, as a Bacillus strain found in spacecraft assembly facilities is particularly resistant to UV radiation. Is also complicated by possible shadowing by dust and spacecraft hardware. Passive sterilization through particle fluxes (Europa). Plans for missions to Europa take credit for reductions due to this.",1
"It is also long been recognized that spacecraft cleaning rooms harbour polyextremophiles as the only microbes able to survive in them. For example, in a recent study, microbes from swabs of the Curiosity rover were subjected to desiccation, UV exposure, cold and pH extremes. Nearly 11% of the 377 strains survived more than one of these severe conditions. The genomes of resistant spore producing Bacillus sp. have been studied and genome level traits potentially linked to the resistance have been reported.This does not mean that these microbes have contaminated Mars.",1
"This is just the first stage of the process of bioburden reduction. To contaminate Mars they also have to survive the low temperature, vacuum, UV and ionizing radiation during the months long journey to Mars, and then have to encounter a habitat on Mars and start reproducing there. Whether this has happened or not is a matter of probability. The aim of planetary protection is to make this probability as low as possible. The currently accepted target probability of contamination per mission is to reduce it to less than 0.01%,",1
"Two recent molecular methods have been approved for assessment of microbial contamination on spacecraft surfaces. Adenosine triphosphate (ATP) detection - this is a key element in cellular metabolism. This method is able to detect non cultivable organisms. It can also be triggered by non viable biological material so can give a ""false positive"". Limulus Amebocyte Lysate assay - detects lipopolysaccharides (LPS). This compound is only present in Gram-negative bacteria. The standard assay analyses spores from microbes that are primarily Gram-positive, making it difficult to relate the two methods.",1
"This particularly applies to orbital missions, Category III, as they are sterilized to a lower standard than missions to the surface. It is also relevant to landers, as an impact gives more opportunity for forward contamination, and impact could be on an unplanned target, such as a special region on Mars. The requirement for an orbital mission is that it needs to remain in orbit for at least 20 years after arrival at Mars with probability of at least 99% and for 50 years with probability at least 95%.",1
"Despite these measures there has been one notable failure of impact prevention. The Mars Climate Orbiter which was sterilized only to Category III, crashed on Mars in 1999 due to a mix-up of imperial and metric units. The office of planetary protection stated that it is likely that it burnt up in the atmosphere, but if it survived to the ground, then it could cause forward contamination.Mars Observer is another Category III mission with potential planetary contamination. Communications were lost three days before its orbital insertion maneuver in 1993.",1
"It seems most likely it did not succeed in entering into orbit around Mars and simply continued past on a heliocentric orbit. If it did succeed in following its automatic programming, and attempted the manoeuvre, however, there is a chance it crashed on Mars.Three landers have had hard landings on Mars. These are Schiaparelli EDM lander, the Mars Polar Lander, and Deep Space 2. These were all sterilized for surface missions but not for special regions (Viking pre-sterilization only).",1
"Mars Polar Lander, and Deep Space 2 crashed into the polar regions which are now treated as special regions because of the possibility of forming liquid brines.",1
"The meteorite argument was examined by the NRC in the context of back contamination. It is thought that all the Martian meteorites originate in relatively few impacts every few million years on Mars. The impactors would be kilometers in diameter and the craters they form on Mars tens of kilometers in diameter. Models of impacts on Mars are consistent with these findings.Earth receives a steady stream of meteorites from Mars, but they come from relatively few original impactors, and transfer was more likely in the early Solar System.",1
"Also some life forms viable on both Mars and on Earth might be unable to survive transfer on a meteorite, and there is so far no direct evidence of any transfer of life from Mars to Earth in this way. The NRC concluded that though transfer is possible, the evidence from meteorite exchange does not eliminate the need for back contamination protection methods.Impacts on Earth able to send microorganisms to Mars are also infrequent.",1
"Impactors of 10 km across or larger can send debris to Mars through the Earth's atmosphere but these occur rarely, and were more common in the early Solar System.",1
"In their 2013 paper ""The Over Protection of Mars"", Alberto Fairén and Dirk Schulze-Makuch suggested that we no longer need to protect Mars, essentially using Zubrin's meteorite transfer argument. This was rebutted in a follow-up article ""Appropriate Protection of Mars"", in Nature by the current and previous planetary protection officers Catharine Conley and John Rummel.",1
"The scientific consensus is that the potential for large-scale effects, either through pathogenesis or ecological disruption, is extremely small. Nevertheless, returned samples from Mars will be treated as potentially biohazardous until scientists can determine that the returned samples are safe. The goal is to reduce the probability of release of a Mars particle to less than one in a million.",1
"A COSPAR workshop in 2010, looked at issues to do with protecting areas from non biological contamination. They recommended that COSPAR expand its remit to include such issues. Recommendations of the workshop include: Recommendation 3 COSPAR should add a separate and parallel policy to provide guidance on requirements/best practices for protection of non-living/nonlife-related aspects of Outer Space and celestial bodies Some ideas proposed include protected special regions, or ""Planetary Parks"" to keep regions of the Solar System pristine for future scientific investigation, and also for ethical reasons.",1
"Astrobiologist Christopher McKay has argued that until we have better understanding of Mars, our explorations should be biologically reversible. For instance if all the microorganisms introduced to Mars so far remain dormant within the spacecraft, they could in principle be removed in the future, leaving Mars completely free of contamination from modern Earth lifeforms. In the 2010 workshop one of the recommendations for future consideration was to extend the period for contamination prevention to the maximum viable lifetime of dormant microorganisms introduced to the planet. ""'Recommendation 4.'",1
"COSPAR should consider that the appropriate protection of potential indigenous extraterrestrial life shall include avoiding the harmful contamination of any habitable environment —whether extant or foreseeable— within the maximum potential time of viability of any terrestrial organisms (including microbial spores) that may be introduced into that environment by human or robotic activity."" In the case of Europa, a similar idea has been suggested, that it is not enough to keep it free from contamination during our current exploration period.",1
"It might be that Europa is of sufficient scientific interest that the human race has a duty to keep it pristine for future generations to study as well. This was the majority view of the 2000 task force examining Europa, though there was a minority view of the same task force that such strong protection measures are not required. ""One consequence of this view is that Europa must be protected from contamination for an open-ended period, until it can be demonstrated that no ocean exists or that no organisms are present.",1
"Thus, we need to be concerned that over a time scale on the order of 10 million to 100 million years (an approximate age for the surface of Europa), any contaminating material is likely to be carried into the deep ice crust or into the underlying ocean."" In July 2018, the National Academies of Sciences, Engineering, and Medicine issued a Review and Assessment of Planetary Protection Policy Development Processes. In part, the report urges NASA to create a broad strategic plan that covers both forward and back contamination.",1
"The report also expresses concern about private industry missions, for which there is no governmental regulatory authority.",1
"The proposal by the German physicist Claudius Gros, that the technology of the Breakthrough Starshot project may be utilized to establish a biosphere of unicellular organisms on otherwise only transiently habitable exoplanets, has sparked a discussion, to what extent planetary protection should be extended to exoplanets. Gros argues that the extended timescales of interstellar missions imply that planetary and exoplanetary protection have different ethical groundings.",1
"Astrobiology – Science concerned with life in the universe ExoMars – Astrobiology programme List of microorganisms tested in outer space Mars 2020 – Astrobiology Mars rover mission by NASA Panspermia – Hypothesis on the interstellar spreading of primordial life No bugs please, this is a clean planet! (ESA article) Kminek, G.; Conley, C.; Hipkin, V.; Yano, H. (December 2017). COSPAR planetary protection policy (PDF) (Report). (COSPAR article) NASA Planetary Protection Website JPL Develops High-Speed Test to Improve Pathogen Decontamination at JPL.",1
"Geoethics in Planetary and Space Exploration Catharine Conley: NASA & international planetary protection policy, methodology & applications, The Space Show, October 2012",1
"the 2013 book on a history of these two blighted cities, Plutopia: Nuclear Families, Atomic Cities, and the Great Soviet and American Plutonium Disasters (Oxford), Kate Brown explores the health of affected citizens in both the United States and Russia, and the “slow-motion disasters” that still threaten the environments where the plants are located. According to Brown, the plants at Hanford and Mayak, over a period of four decades, “both released more than 200 million curies of radioactive isotopes into the surrounding environment -- twice the amount expelled in the Chernobyl disaster in each instance”.Most",1
"It slowly falls to earth as global fallout and is not soluble, and as a result it is difficult for this plutonium to be incorporated into an organism if ingested. Much of this plutonium is absorbed into sediments of lakes, rivers and oceans. However, about 66% of the plutonium from a bomb explosion is formed by the neutron capture of uranium-238; this plutonium is not converted by the bomb into a high fired oxide as it is formed more slowly. This formed plutonium is more soluble and more harmful as fallout.Some plutonium can be deposited close to the point of detonation.",1
"The glassy trinitite formed by the Trinity bomb has been examined to determine what actinides and other radioisotopes it contained. A 2006 paper reports the levels of long lived radioisotopes in the trinitite. 152Eu and 154Eu was mainly formed by the neutron activation of the europium in the soil, and the level of radioactivity for these isotopes is highest where the neutron dose to the soil was larger.",1
"As the 239Pu/240Pu ratio only changed slightly during the Trinity detonation, it has been commented that this isotope ratio for the majority of atomic bombs (in Japan the 239Pu/240Pu ratio in soil is normally in the range 0.17 to 0.19) is very different than from the bomb dropped upon Nagasaki.",1
"A paper on the radioisotopes left on an island by the French nuclear bombs tests of the 20th century has been printed by the International Atomic Energy Agency and a section of this report deals with plutonium contamination resulting from such tests.Other related trials were conducted at Maralinga, South Australia where both normal bomb detonations and ""safety trials"" have been conducted. While the activity from the fission products has decayed away almost totally (as of 2006) the plutonium remains active.",1
"As a result, the fuel in an RTG is consumed much more slowly and much less power is produced. RTGs are still a potential source of radioactive contamination: if the container holding the fuel leaks, the radioactive material will contaminate the environment. The main concern is that if an accident were to occur during launch or a subsequent passage of a spacecraft close to Earth, harmful material could be released into the atmosphere. However, this event is extremely unlikely with current RTG cask designs.In",1
"order to minimise the risk of the radioactive material being released, the fuel is typically stored in individual modular units with their own heat shielding. They are surrounded by a layer of iridium metal and encased in high-strength graphite blocks. These two materials are corrosion and heat-resistant. Surrounding the graphite blocks is an aeroshell, designed to protect the entire assembly against the heat of reentering the Earth's atmosphere. The plutonium fuel is also stored in a ceramic form that is heat-resistant, minimising the risk of vaporization and aerosolization. The ceramic is also highly insoluble.The",1
"US Department of Energy has conducted seawater tests and determined that the graphite casing, which was designed to withstand reentry, is stable and no release of plutonium should occur. Subsequent investigations have found no increase in the natural background radiation in the area. The Apollo 13 accident represents an extreme scenario due to the high re-entry velocities of the craft returning from cislunar space. This accident has served to validate the design of later-generation RTGs as highly safe.",1
These were later cleaned at a cost of two million euro.,1
"Plutonium like other actinides readily forms a dioxide plutonyl core (PuO2). In the environment, this plutonyl core readily complexes with carbonate as well as other oxygen moieties (OH−, NO2−, NO3−, and SO42−) to form charged complexes which can be readily mobile with low affinities to soil. PuO2(CO3)12− PuO2(CO3)24− PuO2(CO3)36−PuO2 formed from neutralizing highly acidic nitric acid solutions tends to form polymeric PuO2 which is resistant to complexation. Plutonium also readily shifts valences between the +3, +4, +5 and +6 states. It is common for some fraction of plutonium in solution to exist in all of these states in equilibrium.",1
"It has been shown that colloidal transport processes control the migration of Cs (and will control the migration of Pu) in the soil at the Waste Isolation Pilot Plant according to R.D. Whicker and S.A. Ibrahim. J.D. Chaplin et al. recently reported advances in the Diffusive gradients in thin films technique, which have provided a method to measure labile bioavailable Plutonium in soils, as well as in freshwater and seawater.",1
Inhaled plutonium has been shown to lead to lung cancer in experimental animals. Actinides in the environment,1
"It notes a campaign by the London Borough of Lewisham's mayor, who complains that an estimated 5,000 bands are dropped in his borough each month; it details the response to a November 2005 BBC Radio Essex programme in which listeners were asked to send in found rubber bands - allegedly 10,000 were received; and it makes a range of more or less whimsical suggestions for the re-use of such bands—as rubber balls, ""chopsticks for butterfingers"", and rubber band tanks. Lewisham's campaign was picked up by a number of other news outlets, such as the BBC.",1
"The story resurfaces from time to time, independently of specific campaigns.At least one report of injury to wildlife has been presumed because of Royal Mail rubber bands, in the case of a duck observed with a rubber band wrapped around its head. Cases of hedgehogs dying from their contact with rubber bands have been reported, with fatalities being caused by the objects sticking to the animal and the creature's flesh becoming enmeshed with it over time.",1
"In April 2009, the Keep Britain Tidy campaign has involved itself in the issue as part of its Big Tidy Up campaign, and returned some 13,000 bands that had been collected by the public to the Royal Mail. The campaign, together with a similar initiative by the Keep Scotland Beautiful organisation, once again raised the profile of the issue, gaining coverage by the press.",1
"In general, plastic sequestration begins by segregating plastic from organics and other materials. The plastic is then cleaned and dried before it is manually compacted into dense blocks—typically using a stick or a press.",1
"The concept of plastic sequestration as an ecological service that follows Earth's example of carbon sequestration was laid out at the Le Havre University, 50th Annual Bandung Spirit Conference, in a paper presented by Ani Himawati and Russell Maier. Building on this concept, the Global Ecobrick Alliance developed a theoretical framework and criteria for plastic sequestration in order to exclude applications that are not ecological services, and to encourage sequestration methodologies and applications that are.",1
"The process results in the sequestration of more carbon and more plastic than is added through emissions and replacement plastic. The process and its outputs support the diversification of life. The enterprise tracks and publicly discloses all the plastic, carbon and biodiversity impacts of its process.",1
"The goal of plastic sequestration is to create the conditions to prevent the physical and chemical degradation of plastic (i.e. depolymerization, chemical modification, mass loss or mineralization to CO2 and H2O) and the emissions of industrial processing. Plastic polymer degradation occurs in two ways: (i) physical, such as cracking, embrittlement, and flaking, or (ii) chemical, referring to changes at the molecular level. Chemical and physical degradation happens through biotic and abiotic pathways. Plastic sequestration methods must prevent chemical and physical degradation, by blocking biotic (microbial action) and abiotic (light, heat, acids, etc.) degradation pathways and by preventing industrial reprocessing.",1
"Emissions occur when plastic is processed industrially (i.e. recycling, landfilling, incineration)",1
"Research into the polymer degradation shows that in the environment, degradation occurs on the exposed surface of plastic and that net degradation is directly proportional to the amount of surface area exposed. Mathematical extrapolation indicates that a thin film of HDPE plastic (high surface area) can degrade 1100 times faster than a bead of plastic of the same weight (low surface area). Whereas a thin film of plastic will degrade in 1.8 ± 0.4 years a bead of plastic will endure for 2000 ± 400 years.",1
"Furthermore, by reducing the specific surface degradation rate (SSDR) of the low-surface-area plastic, it can endure indefinitely. Thus, plastic sequestration methodologies prioritize the terminal reduction of net surface area of the thin film plastics through compaction and building methods that prevent abiotic and biotic degradation, reducing the SSDR of the plastic to below 0.1 μm year–1.",1
"On average globally, each metric ton of plastic processed by recycling, land-filing and incineration generates 689kg, 65Kg and 2967kg of CO2e respectively. Research also shows that of all the plastic generated over all-time, the industrial processing of plastic has dispersed 91% of into the biosphere. There it is subject to the chemical and physical degradation pathways mentioned above. Plastic sequestration aims to avoid these emissions and this dispersal by preventing plastic's industrial processing.",1
"Research has shown that covering plastic in earth is an effective method of preventing abiotic plastic degradation (i.e. preventing exposure to sunlight, friction, heat, etc.). Even plastic that is designed to degrade, when it is buried in low-oxygen soil, abiotic and biotic are prevented. Research also shows that submerging plastic in inert soil (minimal bacteria, micro-organisms) can further slow plastic degradation.",1
"Just as the Earth sequestered carbon under ground indefinitely, long-term plastic sequestration applications immerse its blocks in earthen constructions, blocking biotic and abiotic forms of plastic degradation (i.e. photo-degradation, heat, fire and friction).",1
"Over the last decade, research on plastic loose in the environment has demonstrated clearly the deleterious effects on human health and ecological effects. leading to a steady increase in the awareness of the effects of dumped, recycled and burned plastic. As awareness increased, the focus of grassroots upcycling shifted from creating products of value to a focus on securing plastic from contaminating the biosphere and being industrially processed, leading to the concept of 'plastic sequestration' being coined.",1
Plastic sequestration emerged to focus on the value of 'the absence of plastic from the biosphere' and the value of avoiding the carbon impact of industrial processing.,1
"WR3A is a Fair Trade association (tradename Fair Trade Recycling reserved in 2013) established both to improve the export markets for surplus electronics and e-waste, and to defend them from biased reporting and racial profiling. WR3A was conceived in 2006 following a visit to China by a group including a USA electronics recycler (American Retroworks Inc.), a University of California Davis recycling program director, and a Seattle recycler with a zero-export policy. The group was inspired by a visit to three of China's semi knock down factories. Those factories purchased USA computer monitors which still have functional CRTs.",1
"WR3A provided reporters with World Bank statistics showing domestic Ghana generation more than accounted for the e-waste observed in Ghana, and recorded the organization's own interviews of Ghana Tech Sector representatives (uploaded to Youtube / WR3A). In September 2013, the WR3A adapted the tradename ""Fair Trade Recycling"". The trademark was registered with the USPTO and registered as a supplemental certification on May 26, 2015. The organization does not claim to be recognized by ""fairtrade"" (one word). In April 2013, WR3A held a ""Fair Trade Recycling Summit"" at Middlebury College in Vermont.",1
"The first year, the group will document efforts to develop a ""Fair Trade Recycling"" model in Mexico (see NPR, PBS, AP, coverage), and then research the possible application of the model to Peru, Bangladesh, and China. WR3A formerly adapted and registered the tradename ""Fair Trade Recycling"" in 2012.WR3A collaborated with Massachusetts Institute of Technology for publication of MIT's January 2012 study on E-waste generation and exports. WR3A provided researchers with detailed reconciliations of 3 years of exports from WR3A members. MIT compared WR3A data to corroborating data from ISRI, USEPA, Basel Secretariat (Ghana, Nigeria) studies.In",1
"July 30, 2010, Discovery News presented an analysis contrasting WR3A's ""fair trade"" engagement approach with the Basel Action Network's (BAN) ""trade restriction"" approach, and abstained from choosing sides.,On May 15, 2009, National Public Radio's (NPR) program Living On Earth profiled one of WR3A's members - a women's cooperative doing TV repair and recycling in Mexico.In January 2009, the organization presented statistics and a film at the Keynote Address of the CES 2009 in Las Vegas. The statistics demonstrated that the rate of growth of internet access is much higher in countries with very low incomes.",1
"Exhaust gas temperature (EGT) is important to the functioning of the catalytic converter of an internal combustion engine. It may be measured by an exhaust gas temperature gauge. EGT is also a measure of engine health in gas-turbine engines (see below). During the first two minutes after starting the engine of a car that has not been operated for several hours, the amount of emissions can be very high.",1
"This time has been much reduced by moving the converter closer to the exhaust manifold and even more so placing a small yet quick-to-heat-up converter directly at the exhaust manifold. The small converter handles the start-up emissions, which allows enough time for the larger main converter to heat up. Further improvements can be realised in many ways, including electric heating, thermal battery, chemical reaction preheating, flame heating and superinsulation.",1
"The CO content for petrol engines varies from ~ 15 ppm for well tuned engine with fuel injection and a catalytic converter up to 100,000 ppm (10%) for a richly tuned carburetor engine, such as typically found on small generators and garden equipment.",1
"Exhaust gas from an internal combustion engine whose fuel includes nitromethane will contain nitric acid vapour, which is corrosive, and when inhaled causes a muscular reaction making it impossible to breathe. People who are likely to be exposed to it should wear a gas mask.",1
"In aircraft gas turbine engines, ""exhaust gas temperature"" (EGT) is a primary measure of engine health. Typically the EGT is compared with a primary engine power indication called ""engine pressure ratio"" (EPR). For example: at full power EPR there will be a maximum permitted EGT limit. Once an engine reaches a stage in its life where it reaches this EGT limit, the engine will require specific maintenance in order to rectify the problem. The amount the EGT is below the EGT limit is called EGT margin.",1
"The EGT margin of an engine will be greatest when the engine is new, or has been overhauled. For most airlines, this information is also monitored remotely by the airline maintenance department by means of ACARS.",1
"In jet engines and rocket engines, exhaust from propelling nozzles which in some applications shows shock diamonds.",1
Flue gas,1
In steam engine terminology the exhaust is steam that is now so low in pressure that it can no longer do useful work.,1
"Mono-nitrogen oxides NO and NO2 (NOx)(whether produced this way or naturally by lightning) react with ammonia, moisture, and other compounds to form nitric acid vapor and related particles. Small particles can penetrate deeply into sensitive lung tissue and damage it, causing premature death in extreme cases. Inhalation of NO species increases the risk of lung cancer and colorectal cancer. and inhalation of such particles may cause or worsen respiratory diseases such as emphysema and bronchitis and heart disease.In a 2005 U.S.",1
"EPA study the largest emissions of NOx came from on road motor vehicles, with the second largest contributor being non-road equipment which is mostly gasoline and diesel stations.The resulting nitric acid may be washed into soil, where it becomes nitrate, which is useful to growing plants.",1
"Ozone is beneficial in the upper atmosphere, but at ground level ozone irritates the respiratory system, causing coughing, choking, and reduced lung capacity. It also has many negative effects throughout the ecosystem.",1
"Chronic (long-term) exposure to benzene (C6H6) damages bone marrow. It can also cause excessive bleeding and depress the immune system, increasing the chance of infection. Benzene causes leukemia and is associated with other blood cancers and pre-cancers of the blood.",1
"The health effects of inhaling airborne particulate matter have been widely studied in humans and animals and include asthma, lung cancer, cardiovascular issues, premature death. Because of the size of the particles, they can penetrate the deepest part of the lungs. A 2011 UK study estimates 90 deaths per year due to passenger vehicle PM. In a 2006 publication, the U.S. Federal Highway Administration (FHWA) state that in 2002 about 1 per-cent of all PM10 and 2 per-cent of all PM2.5 emissions came from the exhaust of on-road motor vehicles (mostly from diesel engines).",1
"In Chinese, European, and Indian markets, both diesel and gasoline vehicles are required to have a tailpipe filter installed, while the United States has mandated it for diesel only. In 2022, British testing specialist Emissions Analytics estimated that the 300 million or so gasoline vehicles in the US over the subsequent decade would emit around 1.6 septillion harmful particles.",1
"Carbon dioxide is a greenhouse gas. Motor vehicle CO2 emissions are part of the anthropogenic contribution to the growth of CO2 concentrations in the atmosphere which according to the vast majority of the scientific community is causing climate change. Motor vehicles are calculated to generate about 20% of the European Union's man-made CO2 emissions, with passenger cars contributing about 12%. European emission standards limit the CO2 emissions of new passenger cars and light vehicles. The European Union average new car CO2 emissions figure dropped by 5.4% in the year to the first quarter of 2010, down to 145.6 g/km.",1
Department of Labor Occupational Safety & Health Administration: Safety and Health Topics: Diesel Exhaust Partial List of Chemicals Associated with Diesel Exhaust Diesel Exhaust Particulates: Reasonably Anticipated to Be A Human Carcinogen Scientific Study of Harmful Effects of Diesel Exhaust: Acute Inflammatory Responses in the Airways and Peripheral Blood After Short-Term Exposure to Diesel Exhaust in Healthy Human Volunteers Diesel exhaust: what you need to know,1
"Sewer solids deposition during low flow periods and subsequent resuspension during peak flow events is the major pollutant source for the first-flush combined-sewer overflow (CSO) phenomenon.Sanitary sewage solids can either go through the system or settle out in laminar flow portions of the sewer to be available for washout during peak flows. The wetted perimeter of sewers may also be colonized by biofilm nourished by soluble sanitary wastes. Hydraulic design is the underlying reason for solids deposition in sewers. Combined sewers sized for peak runoff events expected once a decade can carry up to 1,000 times the average sanitary flow.",1
"Erosion of sediments in sewers can release pollutants in concentrations exceeding levels found in contributing sources. The initial highly polluting foul flush is released at the start of wet weather flow during speedy erosion of a weak layer of highly concentrated surficial sediment bed-load. When conditions favor dry-weather solids deposition, the first foul flush may contain as much as 30 percent of the annual total suspended solids discharged to a combined sewer system. Combined sewer suspended solids concentrations of several thousand milligrams per liter (mg/L) may be observed during the first foul flush.Pollutant",1
"concentration levels are influenced by the age and condition of the collection system and the amount of infiltration/inflow in comparison to the sanitary flow. Pollutant concentration peaks depend on size and slope of the piping system, time interval between storms, and solids accumulation in the collection system. Steeper sewer gradients and pipe bottom shapes that maintain high velocity flow during low-flow conditions will reduce sediment accumulation in sewers; and periodic sewer flushing of individual lines during dry weather may move accumulated solids to the wastewater treatment plant before stormwater runoff causes simultaneous peak flow in the entire collection system.",1
"In general, fish are less likely to be trapped in gear that has been down a long time.Fishermen sometimes abandon worn-out nets because it is often the easiest way to get rid of them.The French government offered a reward for ghost nets handed in to local coastguards along sections of the Normandy coast between 1980 and 1981. The project was abandoned when people vandalized nets to claim rewards, without retrieving anything at all from the shoreline or ocean.In",1
"September 2015, the Global Ghost Gear Initiative (GGGI) was created by the World Animal Protection to give a unique and stronger voice to the cause. The term ALDFG means ""abandoned, lost and discarded fishing gear"". From 2000 to 2012, the National Marine Fisheries Service reported an average of 11 large whales entangled in ghost nets every year along the US west coast. From 2002 to 2010, 870 nets were recovered in Washington (state) with over 32,000 marine animals trapped inside. Ghost gear is estimated to account for 10% (640,000 tonnes) of all marine litter.An",1
"estimated 46% of the Great Pacific garbage patch consists of fishing related plastics. Fishing nets account for about 1% of the total mass of all marine macroplastics larger than 200 millimetres (7.9 in), and plastic fishing gear overall constitutes over two-thirds of the total mass.According to the SeaDoc Society, each ghost net kills $20,000 worth of Dungeness crab over 10 years. The Virginia Institute of Marine Science calculated that ghost crab pots capture 1.25 million blue crabs each year in the Chesapeake Bay alone.In",1
"Footage of ghost nets found on Google and YouTube were obtained and analyzed to arrive at the results of the study. They found that ghost nets have an adverse effect on several marine species, including large marine animals, such as the Bryde's whale and Guiana dolphin.",1
"Legalizing gear retrievals and establishing waste management systems is required to manage and mitigate abandoned, lost and discarded fishing gear at-sea. The company Net-works worked out a solution to turn discarded fishing nets into carpet tiles.Between 2008 and 2015, the US Fishing for Energy initiative collected 2.8 million pounds of fishing gear, and in partnership with Covanta Energy turned this into enough electricity to power 182 homes for one year by incineration.One",1
"retrieval initiative in Southwest Nova Scotia in Canada conducted 60 retrieval trips, searched ~1523 square kilometers of the seafloor and removed 7064 kg of abandoned, lost, and discarded fishing gear (ALDFG) (comprising 66% lobster traps and 22% dragger cable). Lost traps continued to capture target and non-target species. A total of 15 different species were released from retrieved ALDFG, including 239 lobsters (67% were market-sized) and seven groundfish (including five species-at-risk). The commercial losses from ALDFG in Southwest Nova Scotia were estimated at $175,000 CAD annually.In",1
2009 world-renowned Dutch technical diver Pascal van Erp started to recover abandoned ghost fishing gear entangled on North Sea wrecks. He soon inspired others. Organised teams of volunteer technical divers recovered tons of ghost fishing gear off the Netherlands coastline. The loop was then closed - after a season's diving 22 tons of fishing gear was sent to the Aquafil Group for recycling back into new Nylon 6 material. In 2012 Pascal van Erp formally founded the not-for-profit Ghost Fishing organisation. In 2020 the Ghost Fishing Foundation rebranded as the Ghost Diving Foundation.A,1
"plan to protect UK seas from ghost fishing was backed by the European Parliament Fisheries Committee in 2018. Mr. Flack, who led the committee, said: ""Abandoned fishing nets are polluting our seas, wasting fishing stocks and indiscriminately killing whales, sea lions or even dolphins. The tragedy of ghost fishing must end"".Net amnesty schemes such as Fishing for Litter create incentives for the collection and responsible disposal of end of life fishing gear. These schemes address the root cause for many net abandonments, which is the financial cost of their disposal.Fishing",1
Nutrient limitation of productivity also depends on the rate at which nutrients and algae are physically flushed out of that system or region. In addition light is an essential factor so productivity will be low at depth and in temperate winter when light levels are low.,1
"The sources of excess phosphate are phosphates in detergent, industrial/domestic run-offs, and fertilizers. With the phasing out of phosphate-containing detergents in the 1970s, industrial/domestic run-off, sewage and agriculture have emerged as the dominant contributors to eutrophication. The main sources of nitrogen beside natural nitrogen fixation are from agricultural runoff (from fertilizers and animal wastes), from sewage and from atmospheric deposition of nitrogen originating from combustion or animal waste.",1
"The main difference between natural and anthropogenic eutrophication is that the natural process is very slow, occurring on geological time scales.",1
"Eutrophication can have the following ecological effects: increased biomass of phytoplankton, changes in macrophyte species composition and biomass, dissolved oxygen depletion, increased incidences of fish kills, loss of desirable fish species.",1
"Under eutrophic conditions, dissolved oxygen greatly increases during the day, but is greatly reduced after dark by the respiring algae and by microorganisms that feed on the increasing mass of dead algae. When dissolved oxygen levels decline to hypoxic levels, fish and other marine animals suffocate. As a result, creatures such as fish, shrimp, and especially immobile bottom dwellers die off. In extreme cases, anaerobic conditions ensue, promoting growth of bacteria. Zones where this occurs are known as dead zones.",1
"Eutrophication may cause competitive release by making abundant a normally limiting nutrient. This process causes shifts in the species composition of ecosystems. For instance, an increase in nitrogen might allow new, competitive species to invade and out-compete original inhabitant species. This has been shown to occur in New England salt marshes. In Europe and Asia, the common carp frequently lives in naturally eutrophic or hypereutrophic areas, and is adapted to living in such conditions. The eutrophication of areas outside its natural range partially explain the fish's success in colonizing these areas after being introduced.",1
"Some harmful algal blooms resulting from eutrophication, are toxic to plants and animals. Toxic compounds can make their way up the food chain, resulting in animal mortality. Freshwater algal blooms can pose a threat to livestock. When the algae die or are eaten, neuro- and hepatotoxins are released which can kill animals and may pose a threat to humans. An example of algal toxins working their way into humans is the case of shellfish poisoning. Biotoxins created during algal blooms are taken up by shellfish (mussels, oysters), leading to these human foods acquiring the toxicity and poisoning humans.",1
"Examples include paralytic, neurotoxic, and diarrhoetic shellfish poisoning. Other marine animals can be vectors for such toxins, as in the case of ciguatera, where it is typically a predator fish that accumulates the toxin and then poisons humans.",1
"Increased competition for the added nutrients can cause potential disruption to entire ecosystems and food webs, as well as a loss of habitat, and biodiversity of species.When macrophytes and algae die in over-productive eutrophic lakes, rivers and streams, they decompose and the nutrients contained in that organic matter are converted into inorganic form by microorganisms. This decomposition process consumes oxygen, which reduces the concentration of dissolved oxygen. The depleted oxygen levels in turn may lead to fish kills and a range of other effects reducing biodiversity.",1
"This could account for around one third of the ocean's external (non-recycled) nitrogen supply, and up to 3% of the annual new marine biological production.Coastal waters embrace a wide range of marine habitats from enclosed estuaries to the open waters of the continental shelf. Phytoplankton productivity in coastal waters depends on both nutrient and light supply, with the latter an important limiting factor in waters near to shore where sediment resuspension often limits light penetration. Nutrients are supplied to coastal waters from land via river and groundwater and also via the atmosphere.",1
"A third key nutrient, dissolved silicon, is derived primarily from sediment weathering to rivers and from offshore and is therefore much less affected by human activity.",1
These increasing nitrogen and phosphorus nutrient inputs exert eutrophication pressures on coastal zones. These pressures vary geographically depending on the catchment activities and associated nutrient load. The geographical setting of the coastal zone is another important factor as it controls dilution of the nutrient load and oxygen exchange with the atmosphere. The effects of these eutrophication pressures can be seen in several different ways: There is evidence from satellite monitoring that the amounts of chlorophyll as a measure of overall phytoplankton activity are increasing in many coastal areas worldwide due to increased nutrient inputs.,1
"The phytoplankton species composition may change due to increased nutrient loadings and changes in the proportions of key nutrients. In particular the increases in nitrogen and phosphorus inputs, along with much smaller changes in silicon inputs, create changes in the ratio of nitrogen and phosphorus to silicon. These changing nutrient ratios drive changes in phytoplankton species composition, particularly disadvantaging silica rich phytoplankton species like diatoms compared to other species. This process leads to the development of nuisance algal blooms in areas such as the North Sea (see also OSPAR Convention) and the Black Sea.",1
"The increased primary production driving this anoxia is fueled by nutrients supplied by the Mississippi river. A similar process has been documented in the Black Sea. Surveys showed that 54% of lakes in Asia are eutrophic; in Europe, 53%; in North America, 48%; in South America, 41%; and in Africa, 28%. In South Africa, a study by the CSIR using remote sensing has shown more than 60% of the reservoirs surveyed were eutrophic.The",1
"World Resources Institute has identified 375 hypoxic coastal zones in the world, concentrated in coastal areas in Western Europe, the Eastern and Southern coasts of the US, and East Asia, particularly Japan.",1
"The technology to safely and efficiently reuse wastewater, both from domestic and industrial sources, should be a primary concern for policy regarding eutrophication.",1
"There are many ways to help fix cultural eutrophication caused by agriculture. Safe farming practices is the number one way to fix the problem. Some safety precautions are: Nutrient Management Techniques - Anyone using fertilizers should apply fertilizer in the correct amount, at the right time of year, with the right method and placement. Year - Round Ground Cover - a cover crop will prevent periods of bare ground thus eliminating erosion and runoff of nutrients even after the growing season has occurred.",1
This suggests that the most effective means of prevention is from the primary source.,1
"In the United States, the most well known inter-state effort to prevent eutrophication is the Chesapeake Bay.",1
"Organically fertilized fields can ""significantly reduce harmful nitrate leaching"" compared to conventionally fertilized fields. Eutrophication impacts are in some cases higher from organic production than they are from conventional production.",1
"It has been suggested that nitrogen removal by oyster reefs could generate net benefits for sources facing nitrogen emission restrictions, similar to other nutrient trading scenarios. Specifically, if oysters maintain nitrogen levels in estuaries below thresholds that would lead to the imposition of emission limits, oysters effectively save the sources the compliance costs they otherwise would incur. Several studies have shown that oysters and mussels have the capacity to dramatically impact nitrogen levels in estuaries. Additionally, studies have demonstrated seaweed's potential to improve nitrogen levels.",1
"Seaweed aquaculture offers an opportunity to mitigate, and adapt to climate change. Seaweed, such as kelp, also absorbs phosphorus and nitrogen and is thus useful to remove excessive nutrients from polluted parts of the sea. Some cultivated seaweeds have a very high productivity and could absorb large quantities of N, P, CO2, producing large amounts of O2 having an excellent effect on decreasing eutrophication. It is believed that seaweed cultivation in large scale should be a good solution to the eutrophication problem in coastal waters.",1
"For example, atmospheric CO2 fertilization can exacerbate the eutrophication of the boreal forest biome.",1
"This is usually true for populations that have been exposed to contaminants for a long time, and have developed a high tolerance. Hyperaccumulation occurs via biosorption on the cellular surface, where the metals enter the mycelium passively with very little intracellular uptake. A variety of fungi, such as Pleurotus, Aspergillus, Trichoderma has proven to be effective in the removal of lead, cadmium, nickel, chromium, mercury, arsenic, copper, boron, iron and zinc in marine environments, wastewater and on land.Not all the individuals of a species are effective in the same way in the accumulation of toxins.",1
"Fungi are amongst the primary saprotrophic organisms in an ecosystem, as they are efficient in the decomposition of matter. Wood-decay fungi, especially white rot, secretes extracellular enzymes and acids that break down lignin and cellulose, the two main building blocks of plant fiber. These are long-chain organic (carbon-based) compounds, structurally similar to many organic pollutants. They achieve this using a wide array of enzymes. In the case of polycyclic aromatic hydrocarbons (PAHs), complex organic compounds with fused, highly stable, polycyclic aromatic rings, fungi are very effective in addition to marine environments.",1
"The enzymes involved in this degradation are ligninolytic and include lignin peroxidase, versatile peroxidase, manganese peroxidase, general lipase, laccase and sometimes intracellular enzymes, especially the cytochrome P450.Other toxins fungi are able to degrade into harmless compounds include petroleum fuels, phenols in wastewater, polychlorinated biphenyl (PCB) in contaminated soils using Pleurotus ostreatus, polyurethane in aerobic and anaerobic conditions, such as conditions at the bottom of landfills using two species of the Ecuadorian fungus Pestalotiopsis, and more.",1
"The mechanisms of degradation are not always clear, as the mushroom may be a precursor to subsequent microbial activity rather than individually effective in the removal of pollutants.",1
"fungi, especially AMF, can greatly improve the phytoremediation capacity of some plants. This is mostly due to the stress the plants suffer because of the pollutants is greatly reduced in the presence of AMF, so they can grow more and produce more biomass. The fungi also provide more nutrition, especially phosphorus, and promote the overall health plants. The mycelium's quick expansion can also greatly extend the rhizosphere influence zone (hyphosphere), providing the plant with access to more nutrients and contaminants. Increasing the rhizosphere overall health also means a rise in the bacteria population, which can also contribute to the bioremediation process.This",1
"relationship has been proven useful with many pollutants, such as Rhizophagus intraradices and Robinia pseudoacacia in lead contaminated soil, Rhizophagus intraradices with Glomus versiforme inoculated into vetiver grass for lead removal, AMF and Calendula officinalis in cadmium and lead contaminated soil, and in general was effective in increasing the plant bioremediation capacity for metals, petroleum fuels, and PAHs. In wetlands AMF greatly promote the biodegradation of organic pollutants like benzene-, methyl tert-butyl ether- and ammonia from groundwater when inoculated into Phragmites australis. Antarctic fungi species such as Metschnikowia sp.,",1
"Cryptococcus gilvescens, Cryptococcus victoriae, Pichia caribbica and Leucosporidium creatinivorum can withstand extreme cold and still provide efficient biodegradation of contaminants. Due to the nature of colder, remote environments like Antarctica, usual methods of contaminant remediation, such as the physical removal of contaminated media, can prove costly. Most species of psychrophilic Antarctic fungi are resistant to the decreased levels of ATP (adenosine triphosphate) production causing reduced energy availability, decreased levels of oxygen due to the low permeability of frozen soil, and nutrient transportation disruption caused by freeze-thaw cycles.",1
"These species of fungi are able to assimilate and degrade compounds such as phenols, n-Hexadecane, toluene, and polycyclic aromatic hydrocarbons in these harsh conditions. These compounds are found in crude oil and refined petroleum. Some fungi species, like Rhodotorula taiwanensis, are resistant to the extremely low pH (acidic) and radioactive medium found in radioactive waste and can successfully grow in these conditions, unlike most other organisms. They can also thrive in the presence of high concentrations of mercury and chromium.",1
"research groups developed variations of the computer modeling techniques: Caltrans Headquarters in Sacramento, California; the ESL Inc. group in Sunnyvale, California; the Bolt, Beranek and Newman group in Cambridge, Massachusetts, and a research team at the University of Florida. Possibly the earliest published work that scientifically designed a specific noise barrier was the study for the Foothill Expressway in Los Altos, California.Numerous case studies across the U.S. soon addressed dozens of different existing and planned highways. Most were commissioned by state highway departments and conducted by one of the four research groups mentioned above. The U.S.",1
"The theory is based upon blockage of sound ray travel toward a particular receptor; however, diffraction of sound must be addressed. Sound waves bend (downward) when they pass an edge, such as the apex of a noise barrier. Barriers that block line of sight of a highway or other source will therefore block more sound. Further complicating matters is the phenomenon of refraction, the bending of sound rays in the presence of an inhomogeneous atmosphere. Wind shear and thermocline produce such inhomogeneities.",1
"The sound sources modeled must include engine noise, tire noise, and aerodynamic noise, all of which vary by vehicle type and speed. The noise barrier may be constructed on private land, on a public right-of-way, or on other public land. Because sound levels are measured using a logarithmic scale, a reduction of nine decibels is equivalent to elimination of approximately 86 percent of the unwanted sound power.",1
Health effects from noise Noise control Safety barrier Soundproofing Media related to Noise barriers at Wikimedia Commons,1
"Natural gas liquids (NGL) are the fraction of the hydrocarbons, primarily having 2-8 carbon atoms, that are present in the flash gas during oil production or as liquids in natural gas production. In other words, NGL is the liquids removed from natural gas such as ethane and heavier products. Components of NGL’s have varying states during production, meaning that some will exist solely as a liquid or vapor, and some will be a mixture of the two depending on the current temperature and pressure.",1
"Therefore, it is necessary that components of NGL are distinguished as either natural-gas condensate, heavier components (C5+), or “other NGL”, lighter components that typically remain in the vapor phase during production. NGL is not to be confused with its subcategory LPG, liquefied petroleum gas, described as “hydrocarbon mixtures in which the main components are propane, iso and normal butane, propylene and butylenes.”Capturing NGL’s has shown an uptick in their economic share of U.S. production levels the past few years, sparking interest for advancement in recovery techniques for petroleum extraction.",1
"Profitability under current models is highly dependent on the access to pipeline infrastructure, gas volume produced, and the number of/distance between production facilities (batteries). Flash gas is the emissions from flash evaporation, breathing emissions, and working emissions. Breathing, or standing emissions, occur naturally as liquid sits in a vessel and undergoes normal evaporation into the atmosphere. Working emissions are created when the liquid is agitated, such as during transportation, emptying/filling of tanks, sampling, etc. Contained within all of these emissions are materials that have been deemed hazardous to humans and the environment by regulatory agencies and scientific bodies worldwide.",1
Reports also go into detail about potential cancers and health problems associated with the level of reported toxins.,1
"Greenhouse gases are classified by their ability to absorb and emit radiation energy in atmosphere. This process of energy capture and release is what allows for the greenhouse effect, when energy trapped within the gas causes a resulting warming of the atmospheric temperature. Greenhouse gases are necessary for keeping our atmosphere warm enough to sustain life but also serve as a medium for over-heating to occur, a phenomenon referred to as global warming. GHGs are produced both directly and indirectly during many production phases of the oil and gas industry.",1
"It is estimated that 90% of GHG emissions from fossil fuels is due to its combustion. As of 2009, energy-related CO2 emissions made up more than 80% of total U.S. greenhouse gas emissions. Flare and flash gas both contain GHGs and therefore contribute to their release into the atmosphere, estimates of their emission levels during petroleum production vary due to largely unmeasured release of flash gas and other forms of fugitive emissions. One study estimated a 40% increase in the atmospheric concentration of the GHG carbon dioxide (CO2) is due directly to human activities since 1750.",1
"GHGs other than CO2 which are produced during petroleum operations are also a concern to the environment. On average, 43.6% of waste gas from a typical plant is methane. Methane has 28-36 times the amount of global warming potential (GWP) as CO2 because of its ability to absorb more radiation energy. Nitrous oxide has a GWP of 265-298 times that of CO2 and is known to also be released during flaring and combustion of fossil fuels.",1
"VOCs are hazardous to the environment due to their ability to form ground level ozone or smog through photochemical reactions. As well as contributing to indoor pollutants, VOCs are also known to have “respiratory, allergic, or immune effects in infants and children”. There are concerns that these compounds can be cancer causing in both humans and animals. In particular, exposure to the VOC benzene during crude oil production could pose potentially serious health risks to workers.",1
"Much of the negative impact associated with VOCs stems from their ability to participate in photochemical reactions with primary pollutants (NOx) in the atmosphere. Photochemical reactions are defined as, “a chemical reaction initiated by the absorption of energy in the form of light”. These reactions often result in the production of photo-chemical oxidants, such as nitrogen dioxide (NO2), ozone (O3), and other peroxy compounds in the atmosphere. These oxidants participate in further atmospheric reactions which are said to “produce haze, damage plant and animal life, and materials such as rubber, induce discomfort and are suspected to have toxic effects on humans.”Mechanistic",1
description for the formation of Photochemical Smog N O 2 + h v ⟶ N O + O {\displaystyle {\ce {{{\mathit {N}}O2}+{\mathit {h}}v->{{\mathit {N}}O}+{\mathit {O}}}}} (1)Nitrogen dioxide reacts with UV radiation to form nitrogen oxide and an oxygen radical. O + O 2 ⟶ O 3 {\displaystyle {\ce {{\mathit {O}}+{\mathit {O}}_{2}->{{\mathit {O}}_{3}}}}} (2)The radical oxygen combines with O2 gas in the atmosphere to form ozone. O 3 + N O ⟶ N O 2 + O 2 {\displaystyle {\ce {{{\mathit {O}}_{3}}+{\mathit {N}}O->{{\mathit {N}}O_{2}}+{\mathit {O}}_{2}}}} (3)Ozone reacts with nitrogen oxide to form nitrogen dioxide and oxygen.,1
"{N}}O_{2}}}} (6)The VOC oxygen bond is broken in the presence of nitrogen oxide, forming a VOC-oxygen anion and nitrogen dioxide to further participate in reaction 3. Where hv is UV radiation and R is a volatile organic compound (VOC). Additionally, some organic compounds (notably aldehydes) can photolyze in the atmosphere to form radicals which participate in atmospheric reactions. [46] VOCs or oxidant precursors are emitted to the atmosphere from both natural and man-made sources. Globally, natural emissions appear to outweigh anthropogenic emissions.",1
"However, it is the high concentration of anthropogenic sources of volatile organics together with NOx emissions from combustion processes in urban areas which increase the risk of the urban ozone problem. Wind and other climatological activities (transport mechanisms) then carry the formed oxidant into rural areas.",1
Studies have been done to try to find if VOCs can be directly related to cancers in the human body. One such example is a group that collected breath samples from a lung cancer patient to determine the VOC content of the lungs before and after surgery. This study suggests that there may be certain biomarker VOCs that indicate the presence of a disease or cancer in a patient. Additional researchers have also begun trying to identify ties between the onset of cancer and the levels of VOCs in the environment.,1
"A database to gather information on cancer and other aspects of VOCs in human cell lines, the human volatilome, has been started by researchers.",1
"Secondary Organic Aerosols (SOA) are a type of hazardous particulate that is not currently well understood, but is thought to make up a significant portion of the tropospheric aerosol or submicron atmospheric particle mass. [50,51] Aerosols effect the atmospheric radiative balance through the absorption and scattering of radiant energy, leading to shifts in weather via changes in cloud drop nucleation and the solar radiation budget. They are said to be formed “when the atmospheric oxidation products of volatile organic compounds undergo gas-particle transfer.”",1
"Alternatively, a captured liquid or gas sample can be analyzed in a laboratory setting to determine the composition and dissolved gas-oil-ratio (GOR) using precise measurement techniques. However, this only provides insight on the sample of flash gas and does not account for real time fluctuations of all on-site sources of flash gas, including working and standing losses.",1
"The revenue produced is dependent on the amount of vapor captured and sold into a pipeline. Analysis has been done to show the economic impacts from emission reduction and capture using VRU and other technology. These units also reduce the amount of emissions of VOCs associated with oil and natural gas production, again by preventing them from being vented directly into the atmosphere. There have been concerns raised about the efficiency of VRU’s.",1
There have also been reports of fatalities caused by manual tank gauging and sampling via thief hatches.Vapor recovery towers (VRT) have been posed as a potential solution for vapor loss via thief hatches. VRTs are a way to reduce the vapor loading on storage tanks by removing some of the flash gas before it gets to the oil tanks. The VRT can improve safety by reducing the potential for issues relating to high vapor evolution from the oil tanks.,1
Flash-gas (refrigeration) Vapor recovery,1
"micron particles and are oil-proof, and therefore their filter-media material has the exact same specification as a P100 filter.Since filters are tested against the most penetrating particle size of 0.3 μm, an APR with a P100 classification would be at least 99.97% efficient at removing particles of this size. Particles with a size both less than and greater than 0.3 μm are filtered at an efficiency greater than 99.97%. (That statement does not derive from given reference). Although it is counter-intuitive that particle sizes of less than 0.3",1
"South Korea (KMOEL - 2017-64): EU grades, KF 80/94/99 for second/first/special European respirator standards",1
"According to the Congressional mandate, the research was to include programs for: 1. Identifying the sources of atmospheric emissions contributing to acid precipitation;2. Establishing and operating a nationwide long term monitoring network to detect and measure levels of acid precipitation;3. Research in atmospheric physics and chemistry to facilitate understanding of the processes by which atmospheric emissions are transformed into acid precipitation;4. Development and application of atmospheric transport models to enable prediction of long range transport of substances causing acidic precipitation;5. Defining geographic areas of impact through deposition monitoring, identification of sensitive areas, and identification of areas at risk;6.",1
"National Acid Precipitation Assessment Program: Interim Assessment: The Causes and Effects of Acidic Deposition, issued September 17, 1987",1
"Ethylene spent caustic comes from the caustic scrubbing of cracked gas from an ethylene cracker. This liquor is produced by a caustic scrubbing tower. Ethylene product gas is contaminated with H2S(g) and CO2(g), and those contaminants are removed by absorption in the caustic scrubbing tower to produce NaHS(aq) and Na2CO3(aq). The sodium hydroxide is consumed and the resulting wastewater (ethylene spent caustic) is contaminated with the sulfides and carbonates and a small fraction of organic compounds. Refinery spent caustic comes from multiple sources: the Merox processing of gasoline; the Merox processing of kerosene/jet fuel; and the caustic scrubbing/Merox processing of LPG.",1
"In these streams sulfides and organic acids are removed from the product streams into the caustic phase. The sodium hydroxide is consumed and the resulting wastewaters (cresylic for gasoline; naphthenic for kerosene/jet fuel; sulfidic for LPG -spent caustics) are often mixed and called refinery spent caustic. This spent caustic is contaminated with sulfides, carbonates, and in many cases a high fraction of organic acids. Spent caustics are malodorous wastewaters that are difficult to treat in conventional wastewater processes.",1
"The 'Ndrangheta, an Italian mafia-type syndicate, has been accused by pentito Francesco Fonti, a former member of 'Ndrangheta, of sinking at least 30 ships loaded with toxic waste, much of it radioactive. In 2005, Fonti revealed the conspiracy in the news magazine L'espresso. His statements led to widespread investigations into the radioactive waste disposal rackets, involving Giorgio Comerio and his disposal company, the Odm (Oceanic Disposal Management).Legambiente, an Italian NGO for the protection of the environment, provided the public prosecutor's office with all the data collected by Legambiente since 1994 concerning the disappearance of at least 40 ships in Mediterranean waters.",1
"He said 'Ndrangheta received £100,000 for the job. Fonti had been put on the job by his boss Sebastiano Romeo of the 'Ndrangheta clan from San Luca in collaboration with Giuseppe Giorgi. Another 'Ndrangheta boss involved was Natale Iamonte who sank ships near Melito di Porto Salvo.However, the vessel they surveyed off Cetraro in deep waters off the coast of Calabria turned out to be a passenger steamship sunk by a German submarine in 1917.",1
"Fonti claims that Italian TV journalist Ilaria Alpi and her cameraman Miran Hrovatin were murdered in 1994 in Somalia because they had seen toxic waste arrive in Bosaso, Somalia.According to Fonti, Christian Democrat politicians, including former prime minister Ciriaco De Mita, had been involved in illegal disposal operations, using the secret service SISMI to cover up their connection. De Mita denied the allegations. Fonti also claimed that Socialist politicians Gianni De Michelis and Bettino Craxi intervened to ensure that Italian peacekeeping troops in Somalia turned a blind eye to the transports.The",1
"huge waves which battered northern Somalia after the 2004 Indian Ocean tsunami were initially believed to have stirred up illegally dumped toxic and nuclear waste. There are also heavy metals such as lead, cadmium and mercury. The waves broke up rusting barrels and other containers and hazardous waste dumped along the long, remote shoreline in the war-racked country during the early 1990s, according to the United Nations Environment Programme (UNEP).However, a United Nations technical fact-finding mission in 2005 did not find any traces of toxic waste along the shorelines after the tsunami.",1
"In 2006, the Somali NGO Daryeel Bulsho Guud, with access to the different warring clans, conducted a survey and identified 15 containers of ""confirmed nuclear and chemical wastes"" in eight coastal areas. A source with the United Nations Development Programme (UNDP) described the search for hazardous material in Somalia as ""like looking for a needle in a haystack. It's not that they don't know it's there ... but that they don't know where to start looking for it."" Triangle of death (Italy)",1
"Reports of medical waste and sewage spills drove away hundreds of thousands of vacationers, costing the $7.7-billion-a-year tourism industry on the Jersey Shore more than $1 billion in lost revenue that summer, tourism officials say. Later the losses were tallied between 15 and 40% of typical tourism revenue. It was a source of even greater turmoil due to the HIV/AIDS epidemic of the 1980s. Officials finally traced the source of the waste to the Fresh Kills Landfill on Staten Island.",1
"Milhouse accidentally pricks himself on a syringe, and Skinner replies ""Well, just keep working. You'll prick yourself with the antidote sooner or later."" The 1988 Skinny Puppy song ""Hospital Waste"" was written about the incident. In the episode ""The Gang Goes to the Jersey Shore"" from It's Always Sunny In Philadelphia, Frank and Mac are on a beach covered in needles but blame it on New Jersey being the steroid capital of the world. Marine debris Ocean Dumping Act Medical Waste Tracking Act",1
"Effluents are sent to a second tank called a dosing chamber, from which they are distributed to the mound at a metered rate (in doses). Wastewater is partially treated as it moves through the mound sand. Final treatment and disposal occur in the soil beneath the mound. The mound system does not allow all the effluent to enter the mound at once, accordingly allowing it to clean the effluent more effectively and helping keep the system from failing. The absorption mound is built in layers.",1
"Ohio State University. Accessed on 15 Oct 2007. Link. Darby, J, G. Tchobanoglous, M. Arsi Nor, and D. Maciolek. 1996. Shallow intermittent sand filtration: performance evaluation. The Small Flows Journal. 2:3-16.",1
"Annoyance implies a negative factor on an individual's well-being and comfort. Its effects may include physiological responses, central nervous system reactions, and biochemical changes.Physiological reactions to sound annoyance include increased heart rate and increased blood pressure which, among others, may lead to hypertension. Hearing impairment, such as increased hearing threshold, and tinnitus are considered as another possible consequence of sound annoyance.EEG and magnetoencephalography studies show an increased activity in several parts of the Central Nervous System.Biochemical",1
"changes due to sound annoyance include increased secretion of epinephrine, which is related to the 'fight'-reaction (See fight-or-flight response) and increased adrenal cortical activity (see adrenal cortex), which is related to intense and/or stressful events.Epidemiological investigations have shown that the negative effects of sound annoyance include ""a feeling of resentment, displeasure, dissatisfaction, discomfort or offence when noise interferes with someones thoughts, feelings or actual activities"". Besides that, unwanted sounds can mask the positive indicators of safety. These factors may diminish well-being of people that suffer from sound annoyance.",1
"Other factors that correlate with sound annoyance are increased absence form work, sleep disturbance, and interference with performing cognitive tasks like paying attention at school.For a more detailed article about health effects: health effects from noise. Historically, nuisance sound has been measured using A-weighted sound pressure level metrics such as the maximum sound pressure level with one-second time integration, day-night average sound level (a 24-hour average of daytime and weighted nighttime sound level), or other long term time-averages.",1
"Measurement is made using a sound level meter with appropriate statistical averaging and corrections to predict the level of sound presented to a human listener. Psychoacoustic analysis reveals that sound pressure level is a less than ideal predictor of human reception of noise, so efforts have been made since the 1960s to apply loudness metrics instead, which can incorporate other factors such as spectral and temporal auditory masking and level-dependent frequency weighting to more accurately track human reception.",1
"The specified limit, also called the ‘upper bound’ can only be exceeded exceptionally. The municipal exemption is insufficient in this case. The laws for aviation induced noise at the main airport of the Netherlands, Schiphol, state that the volume of sounds produced by airplanes may not be higher than 63,46 dB(A) and at different (mostly residential) areas around Schiphol there are specific limits for the noise levels that are allowed. An overview of the locations and their noise limits can be found here:. The sound limits of these locations are reevaluated every year.For",1
"sound annoyance induced by neighbors there is no law. However, the government offers neighborhood mediation by an independent mediator.",1
"The biofilm that develops in a trickling filter may become several millimetres thick and is typically a gelatinous matrix that may contain many species of bacteria, ciliates and amoeboid protozoa, annelids, round worms, insect larvae, other microfauna. (If annelids are abundant, the filter may be considered a vermifilter.) This is very different from many other biofilms, which may be less than 1 mm thick. Within the biofilm, both aerobic and anaerobic zones can exist supporting both oxidative and reductive biological processes.",1
"At certain times of year, especially in the spring, rapid growth of organisms in the film may cause the film to be too thick and it may slough off in patches leading to the ""spring slough"". A typical trickling filter is circular and between 10 metres and 20 metres across and between 2 metres to 3 metres deep. A circular wall, often of brick, contains a bed of filter media which in turn rests on a base of under-drains.",1
Every few days the filters are switched round to balance the load. This method of treatment can improve nitrification and de-nitrification since much of the carbonaceous oxidative material is removed on the first pass through the filters.,1
"Synthetic filter media may pose a significant risk of flammability as demonstrated in Christchurch, New Zealand in May 2022 when two large trickling filters filled with plastic filter bales caught fire. The resultant smell had a significant impact on many city residents and this event put out of action a significant proportion of the sewage treatment capacity.",1
"The convention came into force in 1983, and has now been ratified by 47 European countries, two North American countries (Canada and the United States) and Armenia. The CLRTAP now includes eight protocols that identify specific obligations to be taken by Parties. The Gothenburg Protocol was signed on 30 November 1999 in Gothenburg, Sweden, to support the CLRTAP. The Gothenburg Protocol entered into force on 17 May 2005.",1
"The following are the main provisions of the Protocol: Annex 1 - Critical loads and levels Annex 2 - Maximum allowable emissions (emission ceilings) are adopted for 2010 for sulphur, nitrogen oxides (NOx), Volatile Organic Compounds (VOCs) and ammonia (NH3). The selection of the specific emission levels (in tons/year) were based on the predicted effects of the pollutants and the pollutant control options and costs. Emission limits are set for each participating country.",1
"Those countries participating in the Protocol (""the Parties"") with significant emission levels of the most harmful pollutants and whose emissions are relatively cheap to reduce must make larger emission reductions.Following the revision of the Gothenburg Protocol, to which the Parties agreed in May 2012, Annex 2 will now also contain reduction commitments, expressed as a percentage reduction compared to 2005 emission levels, that Parties should meet in 2020. Annexes 4, 5, 6, 8 and 9 list 'limit values' for specific emission sources, such as for combustion plants, electricity generation, cement production or dry cleaning.",1
"Best available techniques are required to control emissions. With the exception of Annex 9, all the emission limit values specified were also updated in 2012 by the Parties. Annex 4 is for sulphur from stationary sources Annex 5 is for nitrogen oxides (NOx) from stationary sources Annex 6 is for Volatile Organic Compounds (VOCs) from stationary sources Annex 8 is for fuels and new mobile sources Annex 9 is for ammonia (NH3) from agricultural sourcesGuidance documents adopted together with the Protocol provide a range of abatement techniques and economic instruments for the reduction of emissions.",1
The Annexes typically allow Canada and the United States to participate with different commitments than other Parties to the Protocol. This is due to the different regulatory nature of Canada and the United States versus most European countries.,1
"In the EU, the Gothenburg protocol is implemented through the National Emission Ceilings (NEC) directive. Of all the countries that ratified the 1999 Gothenburg Protocol, most are expected to meet their obligations. Progress towards reducing sulphur emissions was greater than the Protocol commitments due to a widespread European shift from coal to natural gas as an industrial fuel in the 1970s and 1980s. As a result, the acidification of forests and lakes was halted in large parts of Europe. Reduction of NOx emissions from traffic has less than originally expected.",1
"The Protocol required only modest ammonia emission reductions and therefore in most parts of Europe, excess nitrogen deposition will be reduced only by a small percentage.It is predicted that the implementation of the Protocol in Europe will reduce sulphur emissions there by at least 63%, NOx emissions by 41%, VOC emissions by 40% and ammonia emissions by 17% compared to levels in 1990.",1
"The Parties agreed to include more stringent emission reduction commitments for 2020, including reduction targets for particulate matter (PM). Subsequently, the technical annexes were also amended to update them with improved emission limit values. The protocol now also includes, as the first international agreement between countries, measures addressing short-lived climate forcers, such as black carbon.The work to revise the Protocol was coordinated by the Working Group on Strategies and Review and supported by varies technical groups, such as the Expert Group on Techno-Economic Issues.",1
CLRTAP text (pdf) Status of Protocol signature/ ratification Summary of Gothenburg Protocol NOx Emission Limits From New Stationary Engines,1
"The Food and Agriculture Organization (FAO) has defined pesticide as: any substance or mixture of substances intended for preventing, destroying, or controlling any pest, including vectors of human or animal disease, unwanted species of plants or animals, causing harm during or otherwise interfering with the production, processing, storage, transport, or marketing of food, agricultural commodities, wood and wood products or animal feedstuffs, or substances that may be administered to animals for the control of insects, arachnids, or other pests in or on their bodies.",1
"These include the pyrethroids, rotenoids, nicotinoids, and a fourth group that includes strychnine and scilliroside.: 15 Many pesticides can be grouped into chemical families. Prominent insecticide families include organochlorines, organophosphates, and carbamates. Organochlorine hydrocarbons (e.g., DDT) could be separated into dichlorodiphenyl ethanes, cyclodiene compounds, and other related compounds. They operate by disrupting the sodium/potassium balance of the nerve fiber, forcing the nerve to transmit continuously. Their toxicities vary greatly, but they have been phased out because of their persistence and potential to bioaccumulate.: 239–240 Organophosphate and carbamates largely replaced organochlorines.",1
"Both operate through inhibiting the enzyme acetylcholinesterase, allowing acetylcholine to transfer nerve impulses indefinitely and causing a variety of symptoms such as weakness or paralysis. Organophosphates are quite toxic to vertebrates and have in some cases been replaced by less toxic carbamates.: 136–137 Thiocarbamate and dithiocarbamates are subclasses of carbamates. Prominent families of herbicides include phenoxy and benzoic acid herbicides (e.g. 2,4-D), triazines (e.g., atrazine), ureas (e.g., diuron), and Chloroacetanilide (e.g., alachlor). Phenoxy compounds tend to selectively kill broad-leaf weeds rather than grasses.",1
"Combinations that included surfactants and the solvent clearly showed that pretreatment with them markedly increased the viral lethality in the test mice.Pesticides can be classified based upon their biological mechanism function or application method. Most pesticides work by poisoning pests. A systemic pesticide moves inside a plant following absorption by the plant. With insecticides and most fungicides, this movement is usually upward (through the xylem) and outward. Increased efficiency may be a result. Systemic insecticides, which poison pollen and nectar in the flowers, may kill bees and other needed pollinators.In",1
"The paldoxins inhibit the fungi's detoxification enzymes. They are believed to be safer and greener.Fungicide resistance is increasing the proportion of inactive enantiomers in fungicide applications: The evolution of resistance necessitates research and discovery of new active ingredients, which trends away from already-discovered classes and toward more complex chemical structures. These tend to have more chiral centers more often which means more off products during synthesis.Insecticide development is being discouraged and slowed down by public sentiment surrounding the worldwide colony collapse disorder crisis. Although CCD is a serious problem, there are indications that other facts are involved, especially Cox-Foster et al.",1
"In one study, it was estimated that for every dollar ($1) that is spent on pesticides for crops can yield up to four dollars ($4) in crops saved. This means based that, on the amount of money spent per year on pesticides, $10 billion, there is an additional $40 billion savings in crop that would be lost due to damage by insects and weeds. In general, farmers benefit from having an increase in crop yield and from being able to grow a variety of crops throughout the year.",1
Consumers of agricultural products also benefit from being able to afford the vast quantities of produce available year-round.Post- WWII conditions caused the pesticide industry to flourish for several reasons including the growing middle class and the invention of cheap tractor-drawn spraying equipment. By the 1980s the demand for pesticides had dropped due to farmers struggling financially and the market for chemicals becoming oversaturated. There were also new costs for producing pesticides due to the strict EPA laws surrounding the chemicals.,1
"Limited evidence also exists for other negative outcomes from pesticide exposure including neurological, birth defects, and fetal death.The American Academy of Pediatrics recommends limiting exposure of children to pesticides and using safer alternatives:Owing to inadequate regulation and safety precautions, 99% of pesticide-related deaths occur in developing countries that account for only 25% of pesticide usage.One study found pesticide self-poisoning the method of choice in one third of suicides worldwide, and recommended, among other things, more restrictions on the types of pesticides that are most harmful to humans.A",1
"2014 epidemiological review found associations between autism and exposure to certain pesticides, but noted that the available evidence was insufficient to conclude that the relationship was causal.",1
"Studies show that farm workers in Ethiopia, Kenya, and Zimbabwe have decreased concentrations of plasma acetylcholinesterase, the enzyme responsible for breaking down acetylcholine acting on synapses throughout the nervous system. Other studies in Ethiopia have observed reduced respiratory function among farm workers who spray crops with pesticides. Numerous exposure pathways for farm workers increase the risk of pesticide poisoning, including dermal absorption walking through fields and applying products, as well as inhalation exposure.",1
"There are multiple approaches to measuring a person's exposure to pesticides, each of which provides an estimate of an individual's internal dose. Two broad approaches include measuring biomarkers and markers of biological effect. The former involves taking direct measurement of the parent compound or its metabolites in various types of media: urine, blood, serum. Biomarkers may include a direct measurement of the compound in the body before it's been biotransformed during metabolism. Other suitable biomarkers may include the metabolites of the parent compound after they've been biotransformed during metabolism.",1
"Toxicokinetic data can provide more detailed information on how quickly the compound is metabolized and eliminated from the body, and provide insights into the timing of exposure. Markers of biological effect provide an estimation of exposure based on cellular activities related to the mechanism of action. For example, many studies investigating exposure to pesticides often involve the quantification of the acetylcholinesterase enzyme at the neural synapse to determine the magnitude of the inhibitory effect of organophosphate and carbamate pesticides.Another method of quantifying exposure involves measuring, at the molecular level, the amount of pesticide interacting with the site of action.",1
"Multiple challenges exist in assessing exposure to pesticides in the general population, and many others that are specific to occupational exposures of agricultural workers. Beyond farm workers, estimating exposure to family members and children presents additional challenges, and may occur through ""take-home"" exposure from pesticide residues collected on clothing or equipment belonging to parent farm workers and inadvertently brought into the home. Children may also be exposed to pesticides prenatally from mothers who are exposed to pesticides during pregnancy. Characterizing children's exposure resulting from drift of airborne and spray application of pesticides is similarly challenging, yet well documented in developing countries.",1
"Because of critical development periods of the fetus and newborn children, these non-working populations are more vulnerable to the effects of pesticides, and may be at increased risk of developing neurocognitive effects and impaired development.While measuring biomarkers or markers of biological effects may provide more accurate estimates of exposure, collecting these data in the field is often impractical and many methods are not sensitive enough to detect low-level concentrations. Rapid cholinesterase test kits exist to collect blood samples in the field.",1
"Conducting large scale assessments of agricultural workers in remote regions of developing countries makes the implementation of these kits a challenge. The cholinesterase assay is a useful clinical tool to assess individual exposure and acute toxicity. Considerable variability in baseline enzyme activity among individuals makes it difficult to compare field measurements of cholinesterase activity to a reference dose to determine health risk associated with exposure. Another challenge researchers face in deriving a reference dose is identifying health endpoints that are relevant to exposure. More epidemiological research is needed to identify critical health endpoints, particularly among populations who are occupationally exposed.",1
"The Stockholm Convention on Persistent Organic Pollutants, listed 9 of the 12 most dangerous and persistent organic chemicals that were (now mostly obsolete) organochlorine pesticides. Since chlorinated hydrocarbon pesticides dissolve in fats and are not excreted, organisms tend to retain them almost indefinitely. Biological magnification is the process whereby these chlorinated hydrocarbons (pesticides) are more concentrated at each level of the food chain. Among marine animals, pesticide concentrations are higher in carnivorous fishes, and even more so in the fish-eating birds and mammals at the top of the ecological pyramid.",1
"Global distillation is the process whereby pesticides are transported from warmer to colder regions of the Earth, in particular the Poles and mountain tops. Pesticides that evaporate into the atmosphere at relatively high temperature can be carried considerable distances (thousands of kilometers) by the wind to an area of lower temperature, where they condense and are carried back to the ground in rain or snow.In order to reduce negative impacts, it is desirable that pesticides be degradable or at least quickly deactivated in the environment.",1
"In addition, EPA is registering reduced-risk pesticides in increasing numbers.",1
"Some disadvantages of the push-pull strategy are that if there is a lack of appropriate knowledge of the behavioral and chemical ecology of the host-pest interactions then this method becomes unreliable. Furthermore, because the push-pull method is not a very popular method of IPM operational and registration costs are higher.",1
"Additional silicon nutrition protects some horticultural crops against fungal diseases almost completely, while insufficient silicon sometimes leads to severe infection even when fungicides are used.Pesticide resistance is increasing and that may make alternatives more attractive. Pesticides are often referred to according to the type of pest they control.",1
"Pesticides can also be considered as either biodegradable pesticides, which will be broken down by microbes and other living beings into harmless compounds, or persistent pesticides, which may take months or years before they are broken down: it was the persistence of DDT, for example, which led to its accumulation in the food chain and its killing of birds of prey at the top of the food chain. Another way to think about pesticides is to consider those that are chemical pesticides are derived from a common source or production method.",1
"Pyrethroid insecticides were developed as a synthetic version of the naturally occurring pesticide pyrethrin, which is found in chrysanthemums. They have been modified to increase their stability in the environment. Some synthetic pyrethroids are toxic to the nervous system.",1
"A number of sulfonylureas have been commercialized for weed control, including: amidosulfuron, flazasulfuron, metsulfuron-methyl, rimsulfuron, sulfometuron-methyl, terbacil, nicosulfuron, and triflusulfuron-methyl. These are broad-spectrum herbicides that kill plants weeds or pests by inhibiting the enzyme acetolactate synthase. In the 1960s, more than 1 kg/ha (0.89 lb/acre) crop protection chemical was typically applied, while sulfonylureates allow as little as 1% as much material to achieve the same effect.",1
"Biopesticides are certain types of pesticides derived from such natural materials as animals, plants, bacteria, and certain minerals. For example, canola oil and baking soda have pesticidal applications and are considered biopesticides. Biopesticides fall into three major classes: Microbial pesticides which consist of bacteria, entomopathogenic fungi or viruses (and sometimes includes the metabolites that bacteria or fungi produce). Entomopathogenic nematodes are also often classed as microbial pesticides, even though they are multi-cellular. Biochemical pesticides or herbal pesticides are naturally occurring substances that control (or monitor in the case of pheromones) pests and microbial diseases.",1
Pesticides that are related to the type of pests are:,1
"The term pesticide also includes these substances: Defoliants: Cause leaves or other foliage to drop from a plant, usually to facilitate harvest. Desiccants: Promote drying of living tissues, such as unwanted plant tops. Insect growth regulators: Disrupt the molting, maturity from pupal stage to adult, or other life processes of insects. Plant growth regulators: Substances (excluding fertilizers or other plant nutrients) that alter the expected growth, flowering, or reproduction rate of plants. Soil sterilant: a chemical that temporarily or permanently prevents the growth of all plants and animals, depending on the chemical. Soil sterilants must be registered as pesticides.",1
"other efforts to improve regulation of international pesticide trade are the United Nations London Guidelines for the Exchange of Information on Chemicals in International Trade and the United Nations Codex Alimentarius Commission. The former seeks to implement procedures for ensuring that prior informed consent exists between countries buying and selling pesticides, while the latter seeks to create uniform standards for maximum levels of pesticide residues among participating countries.Pesticides safety education and pesticide applicator regulation are designed to protect the public from pesticide misuse, but do not eliminate all misuse.",1
Pesticide residue refers to the pesticides that may remain on or in food after they are applied to food crops. The maximum allowable levels of these residues in foods are often stipulated by regulatory bodies in many countries. Regulations such as pre-harvest intervals also often prevent harvest of crop or livestock products if recently treated in order to allow residue concentrations to decrease over time to safe levels before harvest.,1
"Exposure of the general population to these residues most commonly occurs through consumption of treated food sources, or being in close contact to areas treated with pesticides such as farms or lawns.Many of these chemical residues, especially derivatives of chlorinated pesticides, exhibit bioaccumulation which could build up to harmful levels in the body as well as in the environment. The problem is most acute in China, the largest producer of chlorinated pesticides.",1
"The increased temperature can also change the balance of microbial growth, including the rate of algae blooms which reduce dissolved oxygen concentrations.Temperature changes of even one to two degrees Celsius can cause significant changes in organism metabolism and other adverse cellular biology effects. Principal adverse changes can include rendering cell walls less permeable to necessary osmosis, coagulation of cell proteins, and alteration of enzyme metabolism. These cellular level effects can adversely affect mortality and reproduction.",1
Discharge permits for these POTWs typically have additional requirements that require facility improvements to reduce or eliminate the overflows.Ships at sea are forbidden from discharging their sewage overboard unless three miles or more from shore.,1
"A 2014 case study of Vermont phosphate policies around Lake Champlain showed that while the bans reduced the phosphate contribution by treated wastewater from households to five percent of the total contribution, phosphate levels did not decline and in fact increased slightly, due primarily to increased contributions of similar magnitudes from stormwater runoff and agricultural sources. As a result, algal blooms have continued to worsen.Most dishwasher detergent contains complex phosphates, as they have several properties that aid in effective cleaning.",1
"In the 21st century phosphates began to be reduced in percentage terms as an ingredient, leading to a New York Times report that said ""low- or phosphate-free dishwasher detergents it tested, including those from environmentally friendly product lines that have been on the market for years, none matched the performance of products with phosphates"".",1
"To obtain high efficiency removal of 1 micrometer (or less) particles generally requires high-energy devices such as venturi scrubbers or augmented devices such as condensation scrubbers. Additionally, a properly designed and operated entrainment separator or mist eliminator is important to achieve high removal efficiencies. The greater the number of liquid droplets that are not captured by the mist eliminator, the higher the potential emission levels. Wet scrubbers that remove gaseous pollutants are referred to as absorbers. Good gas-to-liquid contact is essential to obtain high removal efficiencies in absorbers.",1
Some components that are specific to the wet scrubbing process include: venturi scrubber spray chamber/tower cyclonic spray scrubber packed bed ejector venturi scrubberA system may include one or multiple of these components in addition to various supporting components such as: Ductwork and fan system A saturation chamber (optional) Entrainment separator or mist eliminator Pumping (and possible recycle system) Spent scrubbing liquid treatment and/or reuse system An exhaust stackA typical wet scrubbing process can be described as follows: Hot flue gas from a furnace enters a saturator (if present) where gases are cooled and humidified prior to entering the scrubbing area.,1
"The saturator removes a small percentage of the particulate matter present in the flue gas. Next, the gas enters a venturi scrubber where approximately half of the gases are removed. Venturi scrubbers have a minimum particle removal efficiency of 95%. The gas flows through a second scrubber, a packed bed absorber, where the rest of the gases (and particulate matter) are collected. An entrainment separator or mist eliminator removes any liquid droplets that may have become entrained in the flue gas.",1
"A recirculation pump moves some of the spent scrubbing liquid back to the venturi scrubber where it is recycled and the remainder is sent to a treatment system. Treated scrubbing liquid is recycled back to the saturator and the packed bed absorber. Fans and ductwork move the flue gas stream through the system and eventually out the stack. Since wet scrubbers vary greatly in complexity and method of operation, devising categories into which all of them neatly fit is extremely difficult. Scrubbers for particle collection are usually categorized by the gas-side pressure drop of the system.",1
"RIMPUFF builds from parameterized formulas for puff diffusion, wet and dry deposition, and gamma dose radiation. Its range of application covers distances up to ~1000 km from the point of release. RIMPUFF calculates the instantaneous atmospheric dispersion taking into account the local wind variability and the local turbulence levels. The puff sizes represent instantaneous relative diffusion (no averaging) and is calculated from similarity scaling theory. Puff diffusion is parameterized for travel times in the range from a few seconds and up to ~1 day. Wet and dry deposition is also calculated as a function of local rain intensity and turbulence levels.",1
(Click on the blue up arrow to display the text portion relevant to the reference) Model Documentation System - a detailed catalogue of the models developed in Europe.,1
"EDCs affect the synthesis, storage, release, transport, clearance, receptor recognition, binding, or post-receptor responses of hormones. This results in either stimulative or inhibitive effects, resulting in overproduction or underproduction of hormones. The effects of hormones on behaviour have been well studied, and often produce direct behavioural effects by acting on the central nervous system. Indirectly, behaviours may be altered by hormones influencing an animal's metabolism or other important processes. Since behaviours also influence hormones, chemical pollutants that induce behavioural changes may also affect hormone levels, which could result in more behavioural or other changes.",1
"An example is when researchers examined the effects of an aerosol on the spatial learning of mice. Thirdly, questions of adaptation consider how behavioural modifications resulting from exposure will influence fitness. Scientists have investigated the reproductive success of white ibises exposed to methylmercury, for instance. Lastly, questions of phylogeny consider how phylogenetic history might predetermine sensitivity or resistance to pollutants in a particular behaviour. This could include investigating how animals that are better at learning might be better at avoiding toxins in the environment.",1
"Reproductive behaviour effects may involve changes in courtship and mating behaviours, mate choice, or changes in nest building. Most studies on this topic have been conducted on fish and birds. For example, treating adult male zebra fish with biphenol A for 7 weeks resulted in decreased courtship behaviour of females. 17β-trenbolone exposure in adult guppies and mosquitofish also altered female mate selection, as they preferred unexposed males. Guppies treated with atrazine during breeding and through gestation were less likely to engage in and showed fewer numbers of courtship displays and other reproductive behaviours. Additionally, females preferred untreated males.Studies",1
"Illustrating this, female rats three generations removed from vinclozolin exposure show changes in mate preference, preferring unexposed mates, while male rats do not, and this could have complex effects on the population. Chemical-induced changes in animal behaviour often have consequences for wild populations. The effects of concern aren’t limited to reproductive effects, which have obvious implications for population vitality. For example, frogs exposed to pesticide-levels found in the environment demonstrate hyperactivity, whip-like convulsions, and depressed avoidance behaviour, which may increase their vulnerability to predation.As well, guppies from crude oil-polluted environments are less exploratory after both short-term and long-term exposure.",1
"Anthropogenic noise and light can result in altered antipredator behaviour, reproductive behaviour, communication, foraging behaviour, population distribution, male-male competition and more. However, the mechanisms behind these altered behaviours is relatively unknown within the literature.",1
"Porpoises have been found to make fewer prey capture attempts, dive deeper, and cut their foraging behaviour short when a vessel passes by, which results in a higher energy expenditure. Shore crabs were also observed interrupting their foraging behaviour when in the presence of ship noise. Antipredator behaviour in marine animals has also been known to change when noise levels are high. Shore crabs took longer to return to their shelters when in the presence of ship noise. Neolamprologus pulcher (a cichlid fish) females defended their nest less against predators when boat noise was present.",1
"Ghost crabs are attracted to artificial lights and begin to exhibit more aggressive predatory behaviour in the presence of the light. This study hypothesizes that loggerhead hatchling predation would also increase as a result of this modified predatory behaviour and the predator-prey relationship would, therefore, be altered.",1
"The advent of microfabrication techniques, microelectro-mechanical systems, energy efficient sensor circuits, and advanced computer power has allowed portable sensors to thrive, but continued advancement of those components would further advance the benefits of using portable systems.",1
"The control of the norm is responsibility of the company that provides the service of recollection of wastewater, being the regulator of sanitary services companies the main responsible. If a company produces disruption in the service, in terms of quality or quantity of the recollection, the companies of recollection of wastewater could suspend the service to that company.",1
"According to the city's responsible, Marcelo Vidal, because of the constant rain added to garbage and plastic bags, the sewer system is not working properly. Even though he pointed that the main problem's origin is in the pumping station, the situation has not been solved up to date. In Peru, the norm has only few parameters with limits. These parameters are: temperature (35 °C (95 °F)), fats and oil (100 mg/lt), PH (5 – 8.5), BOD (1000 mg/lt) and settleable solids.",1
"However a more comprehensive norm was developed by the ministry of housing, which now is under review and analysis of the Ministry of the Environment. In the present article, the values presented are the ones under approval. This new regulation was developed because of the damage that industrial wastewater is causing to the sewer system. For example, in year 2006 a study showed that 58% of the sample (24 companies) surpassed the limit of BOD5 established in the current norm. In the same year other study showed that 57% of the sample (9 companies) surpassed the same norm.Case",1
"The regulation of the parameters is under the decree N°18.328 of June 8, 1997. In the norm is established the maximum limit for industrial effluents in the federal district. Also it's stated the fines applied in the case the companies surpass the norm. Also the decree indicates the type of industry and the types of parameters, that each of them must control.",1
"For purposes of having an idea of the requirements of the regulation, an index was created with the aim to rank the countries. This concept assumes that if a country has tighten limits than other, or if it declares explicitly a limit, then the regulation could be considered more stringent. This index takes in account all the parameters listed in the table, assuming the following criteria. If a country doesn't have any regulation, then it will get 1, from a scale of 10.",1
"If the country has the minimum limit it will get 10 points, if it has the maximum then it will get 5 points. Later, an average is taken from all the parameters of the country, giving the index a relative position of all the countries. Afterwards, all the values are classified using quartiles. A summary with the values of each country is presented below.",1
"In this case, Peru was the country with the smallest range (6–8) and Argentina and Mexico were the ones with the widest range (5.5–10). No limit was found for Canada Regulation.",1
"The value presented for Colombia was extracted from the technical norm for wastewater discharges management and control in public sewage for the capital district. Within these two limit values is shown a big difference among the two countries regulations for these standard, whereas for Canada was encountered an average value of 350 mg/L.",1
"In this case, is also taken the value from the Capital District Regulation, because there wasn't a specific value presented in the national norm, just said that BOD5 removal must be greater than 80% for a new user. In comparison with Canada and the other countries, Chile's limit is a very strict value.",1
"Arsenic is considered as a substance of sanitary interest and at the same time is one of the most toxic elements that exist. Arsenic can be found naturally in the environment and also be an essential trace element for some animals. Due to human activities, mainly through mining and melting, Arsenic can now be found on many more places than where they existed naturally. World production of arsenic, in the form of its oxide, is around 50,000 tons per year. Chile and Mexico are primary exporters of arsenic.",1
"Also, it is mainly emitted by copper producing industries, but also during lead and zinc production and in agriculture. Arsenic can't be destroyed once it has entered the environment, which causes severe health effects on humans and animals.As mentioned before, Chile and Mexico are primary producers of arsenic and when checking arsenic limit values in their regulations aren't the more severe ones. Mexico and Brazil are the countries with a higher limit value and Ecuador stays with the lower limit.",1
"As Arsenic is also linked with agriculture; it is important to emphasize that the majority of the Latin-American countries are characterized by having an agricultural economy. As a result, limit values encountered for Arsenic in all the regulations varies from a small range of 0,1 to 1 mg/L.",1
"In the regulations comparison, Cadmium standard was more severe in Ecuador with an acceptance of 0,02 mg/L, whilst Brazil was the laxer one with 1,5 mg/L. For the case of Canada, Mexico and Peru, the latter has the stricter limit among them with 0,2 mg/L, while the other two remain in the average with 0,7 mg/L.",1
"terms of Latino-American regulations, Argentina is the country that presents the harsher limit value with 0,1 mg/L. By the contrary, Mexico was the one with the higher limit value with 1,5 mg/L. Among the Latin-American countries, Colombia is the only one that is mentioned as having gold mining industry. The limit value for Cyanide is quite high (1 mg/L) to the limit value of Argentina. However, three more other countries have the same limit value for Cyanide.",1
"Primary treatment settling removes about half of the solids and a third of the BOD from raw sewage. Secondary treatment is defined as the ""removal of biodegradable organic matter (in solution or suspension) and suspended solids. Disinfection is also typically included in the definition of conventional secondary treatment."": 11 Biological nutrient removal is regarded by some sanitary engineers as secondary treatment and by others as tertiary treatment.: 11 After this kind of treatment, the wastewater may be called secondary-treated wastewater.",1
"Secondary treatment systems are classified as fixed-film or suspended-growth systems A great number of secondary treatment processes exist, see List of wastewater treatment technologies. The main ones are explained below.",1
"Biofilms of bacteria, protozoa and fungi form on the media’s surfaces and eat or otherwise reduce the organic content.: 12 The filter removes a small percentage of the suspended organic matter, while the majority of the organic matter supports microorganism reproduction and cell growth from the biological oxidation and nitrification taking place in the filter. With this aerobic oxidation and nitrification, the organic solids are converted into biofilm grazed by insect larvae, snails, and worms which help maintain an optimal thickness.",1
Overloading of beds may increase biofilm thickness leading to anaerobic conditions and possible bioclogging of the filter media and ponding on the surface.,1
"Activated sludge is a common suspended-growth method of secondary treatment. Activated sludge plants encompass a variety of mechanisms and processes using dissolved oxygen to promote growth of biological floc that substantially removes organic material.: 12–13 Biological floc is an ecosystem of living biota subsisting on nutrients from the inflowing primary clarifier effluent. These mostly carbonaceous dissolved solids undergo aeration to be broken down and either biologically oxidized to carbon dioxide or converted to additional biological floc of reproducing micro-organisms. Nitrogenous dissolved solids (amino acids, ammonia, etc.)",1
"Like most ecosystems, population changes among activated sludge biota can reduce treatment efficiency. Nocardia, a floating brown foam sometimes misidentified as sewage fungus, is the best known of many different fungi and protists that can overpopulate the floc and cause process upsets. Elevated concentrations of toxic wastes including pesticides, industrial metal plating waste, or extreme pH, can kill the biota of an activated sludge reactor ecosystem.",1
"One type of system that combines secondary treatment and settlement is the cyclic activated sludge (CASSBR), or sequencing batch reactor (SBR). Typically, activated sludge is mixed with raw incoming sewage, and then mixed and aerated. The settled sludge is run off and re-aerated before a proportion is returned to the headworks.The disadvantage of the CASSBR process is that it requires a precise control of timing, mixing and aeration. This precision is typically achieved with computer controls linked to sensors.",1
"Such a complex, fragile system is unsuited to places where controls may be unreliable, poorly maintained, or where the power supply may be intermittent.",1
"Membrane bioreactors (MBR) are activated sludge systems using a membrane liquid-solid phase separation process. The membrane component uses low pressure microfiltration or ultrafiltration membranes and eliminates the need for a secondary clarifier or filtration. The membranes are typically immersed in the aeration tank; however, some applications utilize a separate membrane tank. One of the key benefits of an MBR system is that it effectively overcomes the limitations associated with poor settling of sludge in conventional activated sludge (CAS) processes.",1
"The technology permits bioreactor operation with considerably higher mixed liquor suspended solids (MLSS) concentration than CAS systems, which are limited by sludge settling. The process is typically operated at MLSS in the range of 8,000–12,000 mg/L, while CAS are operated in the range of 2,000–3,000 mg/L. The elevated biomass concentration in the MBR process allows for very effective removal of both soluble and particulate biodegradable materials at higher loading rates. Thus increased sludge retention times, usually exceeding 15 days, ensure complete nitrification even in extremely cold weather.",1
Aerobic granular sludge can be formed by applying specific process conditions that favour slow growing organisms such as PAOs (polyphosphate accumulating organisms) and GAOs (glycogen accumulating organisms). Another key part of granulation is selective wasting whereby slow settling floc-like sludge is discharged as waste sludge and faster settling biomass is retained. This process has been commercialized as Nereda process.,1
"Biological Aerated (or Anoxic) Filter (BAF) or Biofilters combine filtration with biological carbon reduction, nitrification or denitrification. BAF usually includes a reactor filled with a filter media. The media is either in suspension or supported by a gravel layer at the foot of the filter. The dual purpose of this media is to support highly active biomass that is attached to it and to filter suspended solids. Carbon reduction and ammonia conversion occurs in aerobic mode and sometime achieved in a single reactor while nitrate conversion occurs in anoxic mode.",1
"A sewage treatment plant providing both primary and secondary treatment is expected to remove at least 85 percent of the BOD and suspended solids from domestic sewage. The EPA regulations describe stabilization ponds as providing treatment equivalent to secondary treatment removing 65 percent of the BOD and suspended solids from incoming sewage and discharging approximately 50 percent higher effluent concentrations than modern bioreactors. The regulations also recognize the difficulty of meeting the specified removal percentages from combined sewers, dilute industrial wastewater, or Infiltration/Inflow.",1
"Waste containing biocide concentrations exceeding the secondary treatment ecosystem tolerance level may kill a major fraction of one or more important ecosystem species. BOD reduction normally accomplished by that species temporarily ceases until other species reach a suitable population to utilize that food source, or the original population recovers as biocide concentrations decline.",1
Secondary treatment ecosystems of college communities acclimated to waste loading fluctuations from student work/sleep cycles may have difficulty surviving school vacations. Secondary treatment systems accustomed to routine production cycles of industrial facilities may have difficulty surviving industrial plant shutdown. Populations of species feeding on incoming waste initially decline as concentration of those food sources decrease. Population decline continues as ecosystem predator populations compete for a declining population of lower trophic level organisms.,1
Normal BOD removal efficiency will not be restored until populations of aerobic species recover after oxygen concentrations rise to normal.,1
"Biological oxidation processes are sensitive to temperature and, between 0 °C and 40 °C, the rate of biological reactions increase with temperature. Most surface aerated vessels operate at between 4 °C and 32 °C. List of wastewater treatment technologies Sanitation",1
"Many health departments require a percolation test (""perc"" test) to establish the suitability of drain field soil to receive septic tank effluent. An engineer, soil scientist, or licensed designer may be required to work with the local governing agency to design a system that conforms to these criteria. A more progressive way to determine leach field sizing is by direct observation of the soil profile. In this observation, the engineer evaluates many features of the soil such as texture, structure, consistency, pores/roots, etc.",1
"Groundwater flow is laminar in the aquifer soils surrounding the drain field. Septic tank effluent with soluble organic compounds passing through the biofilm forms a mounded lens atop the groundwater underlying the drain field. Molecular diffusion controls the mixing of soluble organic compounds into the groundwater and the transport of oxygen from underlying groundwater or the capillary fringe of the groundwater surface, to micro-organisms capable of catabolizing dissolved organic compounds remaining in the effluent plume.",1
"A drain field may be designed to offer several separate disposal areas for effluent from a single septic tank. One area may be ""rested"" while effluent is routed to a different area. The nematode community in the resting drain field continues feeding on the accumulated biofilm and fats when the anaerobic septic tank effluent is no longer available. This natural cleansing process may reduce bioclogging to improve the hydraulic capacity of the field by increasing the available interstitial area of the soil as the accumulated organic material is oxidized.",1
"Septic tank and drain field microorganisms have very limited capability for catabolizing petroleum products and chlorinated solvents, and cannot remove dissolved metals; although some may be absorbed into septic tank sludge or drain field soils, and concentrations may be diluted by other groundwater in the vicinity of the drain field. Cleaning formulations may reduce drain field efficiency. Laundry bleach may slow or stop microbial activity in the drain field, and sanitizing or deodorizing chemicals may have similar effects.",1
"The idea was the brainchild of the project manager from Proquip, who supplied the giant screen, and engineers from Moles Recording Studio in Bath, Somerset, who were working with Radio Avalon. In May 2000, BBC Live Music held a ""silent gig"" at Chapter Arts Centre in Cardiff, where the audience listened to a band, Rocketgoldstar, and various DJs through headphones.In May 2002 artist Meg Duguid hosted Dance with me...",1
"a silent dance party at the Museum of Contemporary Art Chicago where she created an outdoor club installation complete with velvet ropes and glow rope in which a DJ spun a transmission to wireless headsets that audience members put on and danced to. Duguid threw a second dance party at the Museum of Contemporary Art, Chicago the following year, entitled Dueling DJs where two DJS simultaneously spun two separate musical transmissions various wireless headsets that audience members put on and danced to. This performance was repeated the following year (2004) at the Chicago Cultural Center.The",1
"term ""silent disco"" has been in existence since at least 2005 with Bonnaroo Music Festival advertising such an event that year with DJ’s Motion Potion, Quickie Mart and DJ medi4 and headphones provided by KOSS. In recent years Silent Events has presented Bonaroo's Silent Disco.United States HUSHconcerts (previously, Silent Frisco) was the first company to produce a multi-city Silent Disco tour in 2008 with Silent Soundclash kicking off at Winter Music Conference in Miami, followed by Atlanta, Athens, Savannah, Wilmington NC, Charlottesville Va, Baltimore, New York City, Syracuse, Pittsburgh and St. Louis.",1
"During this tour, the company became the first to produce American silent discos on a beach (Miami Beach) and a boat (the Rocksoff Cruise in New York Harbor).The Oxford Dictionary Online added the term ""silent disco"" to their website in February 2011. As interest has increased, there has been a rise in the number of companies organizing parties and providing events with wireless headphones. Some companies have offered home kits.Becoming",1
"ever more popular, Silent Discos continue to be featured in popular media, including NBC's Brooklyn Nine-Nine, Season 2, Episode 5 ""The Mole""; Netflix's Atypical Season 1, Episode 8 ""The Silencing Properties of Snow"" & most recently, FX's new comedy series ""Dave"" starring American rapper, Lil Dicky. A silent concert (or headphones concert) is a live music performance where the audience, in the same venue as the performing artist, listens to the music through headphones.",1
"The idea originated in 1997 when Erik Minkkinen, an electronic artist from Paris, streamed a live concert from his closet over the internet to three listeners in Japan. The concept led to a decentralized organization known as le placard (""the Cupboard""), which allowed anybody to establish a streaming or listening room.The first headphone concert taking place in front of a live audience took place March 17, 1999, at Trees in Dallas, Texas.",1
"In August 2008, the first silent Battle of the Bands was held at The Barfly music venue in Cardiff. The event featured bands going directly head-to-head, with a stage at each end of the venue, allowing gig-goers to choose which group they wished to listen to. In 2013 Metallica performed live in Antarctica utilizing headphones instead of traditional concert amplification, due to concerns about harming the environment. Theatre and performance companies are using silent disco technology as well.",1
"2015 Lincoln Center staged a production of the Rocky Horror Picture Show utilizing Quiet Events Headphones, where an audience wearing headphones could switch between the audio for the live performance and the soundtrack of the film version being projected behind it. During the COVID-19 outbreak in 2020, in compliance with CDC guidelines, music events and theatre came to a halt.",1
"The supply of waste silk is drawn from the following sources: The silkworm, when commencing to spin, emits a dull, lustreless and uneven thread with which it suspends itself from the twigs and leaves of the tree upon which it has been feeding, or the straws provided for it by attendants in the worm-rearing establishments: this first thread is unreelable, and, moreover, is often mixed with straw, leaves and twigs.",1
"The outside layers of the true cocoon are too coarse and uneven for reeling; and as the worm completes its task of spinning, the thread becomes finer and weaker, so both the extreme outside and inside layers are put aside as waste. Pierced cocoons, that is, those from which the moth of the silkworm has emerged-and damaged cocoons. During the process of reeling from the cocoon the silk often breaks; and both in finding a true and reliable thread, and in joining the ends, there is unavoidable waste.",1
"Raw silk skeins are often re-reeled; and in this process part has to be discarded: this being known to the trade as gum-waste. The same term—gum-waste—is applied to ""waste"" made in the various processes of silk throwing; but manufacturers using threads known technically as organzines and trams call the surplus ""manufacturer's waste."" A silk ""throwster"" receives the silk in skein form, the thread of which consists of a number of silk fibres wound together to make a certain diameter or size, the separate fibre having actually been spun by the worm.",1
"The silk-waste spinner receives the silk in quite a different form: merely the raw material, packed in bales of various sizes and weights, the contents being a much-tangled mass of all lengths of fibre mixed with much foreign matter, such as ends of straws, twigs, leaves, worms and chrysalis. It is the spinner's business to straighten out these fibres, with the aid of machinery, and then to so join them that they become a thread, which is known as spun silk.",1
"The former, schapping, is the French, Italian and Swiss method, from which the silk when finished is neither so bright nor so good in colour as the discharged silk; but it is very clean and level, and for some purposes essential, as, for instance, in velvet manufacture. Bourette Matka (silk) Textile manufacturing Brown, Susan (2016). Scraps : fashion, textiles, and creative reuse. Baumann, Caroline,, McQuaid, Matilda,, Cooper-Hewitt Museum. New York, NY. ISBN 9781942303176. OCLC 946579927.{{cite book}}: CS1 maint: location missing publisher (link) Rayner, Hollins (1903). Silk throwing and waste silk spinning. Scott, Greenwood, Van Nostrand. OL 7174062M.This",1
"article incorporates text from a publication now in the public domain: Mellor, Arthur (1911). ""Silk"". In Chisholm, Hugh (ed.). Encyclopædia Britannica. Vol. 25 (11th ed.). Cambridge University Press. pp. 105–106. Essay on silk waste",1
"Historically one of the most polluted freshwater lakes in the world, its salinity and toxic constituents like mercury rose to unsafe levels as large corporations begun to set up shop around the lake. High levels of salinity would be disastrous for any native freshwater marine life and pollutants like mercury are dangerous to most organisms.Higher levels of urbanization typically mean a greater presence of urban stream syndrome.Hydrology plays a key role in urban stream syndrome.",1
"As urbanization of these streams continue, there is in turn a decrease in the perviousness of the catchment to precipitation, which leads to a decrease in the infiltration and an increase in the surface runoff. This can cause problems during flood discharges. For example, flood discharges in urban catchments were at least 250% higher in urban catchments than in forested catchments in New York and Texas during similar storms.",1
"The main noise indicators for noise mapping are long-term averaged sound levels, determined over all the correspondent periods of a year. All of these indicators may be defined in terms of A-weighted decibels (dBA, dB(A)). The result can be determined by computation or measurement methods. Computation methods are widely preferred, because of the large amount of yearly averaged locations required.Using either approach, a grid of receivers must be defined in order to measure or calculate noise levels. When results are obtained, using GIS tools, spatial interpolation must be applied in order to give a continuous graphical representation of sound levels.",1
"The creation of a good acoustic model can be quite complicated. Simulation tools are very useful specially at planning stages, where measurements are not possible. The consultant can evaluate the effectiveness for decisions in action plans, in order to minimize noise. UK Department for Environment, Food & Rural Affairs: Noise Mapping England European Commission: Noise policy FHWA Traffic Noise Model MAPSOUNDS",1
"Field calibration of contemporary dosimeters has been mostly automated through PC-based programs that run the calibration routine, document the time and date, and adjust for any offset in levels. Current dosimeters are designed to provide the user with parameters such as noise dose, time-weighted average, sound exposure level, as well as peak, maximum, and minimum sound pressure levels. Most dosimeters also generate statistical and graphical representations of the collected data. ANSI S1.25",1
"specifies that dosimeters should at least provide the following parameters: Frequency weighting: A-weighting or C-weighting Exponential averaging: F (fast); S (slow) Criterion level: 90, 85, 84, 80, or V (variable) Criterion duration: Hours Threshold level: 90, 80, or V (variable) Exchange rate: 5, 4, or 3 A noise or sound dose is the amount of sound a person is exposed to in a day. The dose is represented by a percentage. A noise dose of 100% means that a person has exceeded the permissible amount of noise. Any noise exposure after the 100% noise dose may damage hearing.",1
"The original dosimeters were designed to be belt worn with a microphone connected to the body of the dosimeter and mounted on the shoulder as near to the ear as practicable. These devices were worn for the full work shift and at the end would give a readout initially in percentage dose, or in some other exposure metric. These were the most common way of making measurements to meet legislation in the USA, but in Europe, the conventional sound level meter was favoured.",1
"There were many reasons for this, but in general in Europe the dosimeter was distrusted for several reasons, some being. The cable was considered dangerous as it could catch on rotating machinery The dosimeter could tell you the level had been exceeded, but it did not say when this happened Workers could falsify the data very easily The device was big enough to affect the work patternIn the USA – where most of the early devices were manufactured, these reasons did not seem to matter so much.",1
"By the time the PSEM standard was published, many major sound level meter companies – in both Europe and the USA had a dosimeter in their range. Noise dosimeters are worn by workers in order to track their sound exposure over a period of time. With the accuracy of a type 2 sound level meter, a majority of noise dosimeters measure within ±2 dB A. One must make sure to the noise dosimeter is properly calibrated and kept out of extreme temperature and humidity. The noise dosimeter is typically programmed by a hearing conservationist, sound engineer or audiologist.",1
"When the professional is setting up the noise dosimeter, settings like frequency of sound sampling and log information should be considered. When placing any dosimeter, the microphones should be clipped to the shoulder with the microphone facing upwards. The microphone should be placed in the open and clear from any surrounding fabric. It should also be protected from any wind source when outdoors and should have a wind screen over it for protection if needed. Over the course of the day, the dosimeter will measure the time-weighted average of the sound level the user experienced.",1
"United Kingdom Cirrus Research plc United Kingdom Pulsar Instruments plc USA 3M USA Larson-Davis France 01dB-Metravib Poland SVANTEK Japan RION CO., Ltd",1
"Regulations on nitrogen oxide emissions (NOx) were introduced in the United States, Japan, and Canada in 1973 and 1974, with Sweden following in 1976 and the European Economic Community in 1977. These standards gradually grew more and more stringent but have never been unified.There are largely three main sets of standards: United States, Japanese, and European, with various markets mostly using these as their base. Sweden, Switzerland, and Australia had separate emissions standards for many years but have since adopted the European standards.",1
"In the US, this is given in pounds of carbon dioxide per megawatt-hour (lbs. CO2/MWhr), and kilograms CO2/MWhr elsewhere. Before the European Union began streamlining emissions standards, there were several different sets of rules. Members of the European Economic Community (EEC) had a unified set of rules, considerably laxer than those of the United States or Japan. These were tightened gradually, beginning on cars of over two liters displacement as the price increase would have less of an impact in this segment.",1
"The ECE 15/05 norms (also known as the Luxemburg accord, strict enough to essentially require catalytic converters) began taking effect gradually: the initial step applied to cars of over 2000 cc in two stages, in October 1988 and October 1989. There followed cars between 1.4 and 2.0 liters, in October 1991 and then October 1993. Cars of under 1400 cc had to meet two subsequent sets of regulations that applied in October 1992 and October 1994 respectively. French and Italian car manufacturers, strongly represented in the small car category, had been lobbying heavily against these regulations throughout the 1980s.Within",1
"the EEC, Germany was a leader in regulating automobile emissions. Germany gave financial incentives to buyers of cars that met US or ECE standards, with lesser credits available to those that partially fulfilled the requirements. These incentives had a strong impact; only 6.5 percent of new cars registered in Germany in 1988 did not meet any emissions requirements and 67.3 percent were compliant with the strictest US or ECE standards.Sweden was one of the first countries to instill stricter rules (for 1975), placing severe limitations on the number of vehicles available there.",1
"These standards also caused drivability problems and steeply increased fuel consumption - in part because manufacturers could not justify the expenditure to meet specific regulations that applied only in one very small market. In 1982, the European Community calculated that the Swedish standards increased fuel consumption by 9 percent, while it made cars 2.5 percent more expensive. For 1983 Switzerland (and then Australia) joined in the same set of regulations, which gradually increased the number of certified engines.",1
"One problem with the strict standards was that they did not account for catalyzed engines, meaning that vehicles thus equipped had to have the catalytic converters removed before they could be legally registered. In 1985 the first catalyzed cars entered certain European markets such as Germany. At first, the availability of unleaded petrol was limited and sales were small. In Sweden, catalyzed vehicles became allowed in 1987, benefitting from a tax rebate to boost sales. By 1989 the Swiss/Swedish emissions rules were tightened to the point that non-catalyzed cars were no longer able to be sold.",1
"In early 1989 the BMW Z1 was introduced, only available with catalyzed engines. This was a problem in some places like Portugal, where unleaded fuel was still almost non-existent, although European standards required unleaded gasoline to be ""available"" in every country by 1 October 1989.",1
"The main source of greenhouse gas emissions in the European Union is transportation. In 2019, it contributes to about 31% of global emissions and 24% of emissions in the EU. In addition, up to the COVID-19 pandemic, emissions have only increased in the transport economic sector. In 2019, about 95% of the fuel came from fossil sources.The European Union has its own set of emissions standards that all new vehicles must meet. Currently, standards are set for all road vehicles, trains, barges and 'nonroad mobile machinery' (such as tractors). No standards apply to seagoing ships or airplanes.",1
"EU Regulation No 443/2009 set an average CO2 emissions target for new passenger cars of 130 grams per kilometre. The target was gradually phased in between 2012 and 2015. A target of 95 grams per kilometre applies from 2021. For light commercial vehicle, an emissions target of 175 g/km applies from 2017, and 147 g/km from 2020, a reduction of 16%. The EU introduced Euro 4 effective 1 January 2008, Euro 5 effective 1 January 2010, and Euro 6 effective 1 January 2014. These dates had been postponed for two years to give oil refineries the opportunity to modernize their plants.",1
"From January 2022, all new light vehicles must comply with Euro 6d. From 1 January 2023, all new motorcycles must comply with Euro 5.",1
According to the German federal automotive office 37.3% (15.4 million) cars in Germany (total car population 41.3 million) conform to the Euro 4 standard from Jan 2009.,1
All new light vehicles must comply with Euro 5 since January 2016. All new heavy vehicles must comply with Euro 5 since 2018.,1
"Several local authorities in the UK have introduced Euro 4 or Euro 5 emissions standards for taxis and licensed private hire vehicles to operate in their area. Emissions tests on diesel cars have not been carried out during MOTs in Northern Ireland for 12 years, despite being legally required.From January 2022, all new light vehicles must comply with Euro 6d. From 1 January 2023, all new motorcycles must comply with Euro 5.",1
"From 1 July 2019, all new heavy vehicles must comply with EPA 07 and Euro 5. From 1 January 2025, all new heavy vehicles must comply with EPA 10 and Euro 6.",1
"December 2021 EPA issued new greenhouse gas standards for passenger cars and light trucks, effective for the 2023 vehicle model year.",1
"By mid-2009, 16 other states had adopted CARB rules; given the size of the California market plus these other states, many manufacturers choose to build to the CARB standard when selling in all 50 states. CARB's policies have also influenced EU emissions standards.California is attempting to regulate greenhouse gas emissions from automobiles, but faces a court challenge from the federal government. The states are also attempting to compel the federal EPA to regulate greenhouse gas emissions, which as of 2007 it has declined to do.",1
"On 19 May 2009, news reports indicate that the Federal EPA will largely adopt California's standards on greenhouse gas emissions.California and several other western states have passed bills requiring performance-based regulation of greenhouse gases from electricity generation. In an effort to decrease emissions from heavy-duty diesel engines faster, CARB's Carl Moyer Program funds upgrades that are in advance of regulations. The California ARB standard for light vehicle emissions is a regulation of equipment first, with verification of emissions second.",1
"From 1 January 2016, all new heavy vehicles in Argentina must comply with Euro 5. From 1 January 2018, all new light and heavy vehicles in Argentina must comply with Euro 5.",1
"From 1 January 2012, all new heavy vehicles in Brazil must comply with Proconve P7 (similar to Euro 5) From 1 January 2015, all new light vehicles in Brazil must comply with Proconve L6 (similar to Euro 5). From 1 January 2022, all new light vehicles in Brazil must comply with Proconve L7 (similar to Euro 6). From 1 January 2023, all new heavy vehicles in Brazil must comply with Proconve P8 (similar to Euro 6). From 1 January 2025, the new light vehicle fleets in Brazil must comply with the first stage of Proconve L8 (automaker average).",1
"From September 2014, all new cars in Chile must comply with Euro 5. From September 2022, all new light and medium vehicle models in Chile must comply with Euro 6b. From September 2024, all new light and medium vehicle models in Chile must comply with Euro 6c.",1
"From 1 January 2023, all new vehicles in Colombia must comply with Euro 6.",1
"Beijing introduced the Euro IV standard in advance on 1 January 2008, becoming the first city in mainland China to adopt this standard. From 1 January 2018, all new vehicles must comply with China 5 (similar to Euro 5). From 1 January 2021, all new vehicles in China must comply with China 6a (similar to Euro 6). From 1 July 2023, all new vehicles in China must comply with China 6b (stricter than Euro 6).",1
"From 1 January 2006, all new passenger cars with spark-ignition engines in Hong Kong must meet either Euro IV petrol standard, Japanese Heisei 17 standard or US EPA Tier 2 Bin 5 standard. For new passenger cars with compression-ignition engines, they must meet US EPA Tier 2 Bin 5 standard. The current standard is Euro 6C, it has been phased in since 2019.",1
"By 2014, the country was under a combination of Euro 3 and Euro 4-based norms, with Euro 4 standards partly implemented in 13 major cities. Till April 2017, the entire country was under BS IV norms, which is based on Euro 4.As of now manufacturing and registration of BS VI vehicles has started, from April 2020 all BS VI manufacturing is mandatory, respectively.",1
Since January 2012 vehicles which do not comply with Euro 6 emission values are not allowed to be imported to Israel.,1
"The amended rule is called the ""Law Concerning Special Measures to Reduce the Total Amount of Nitrogen Oxides and Particulate Matter Emitted from Motor Vehicles in Specified Areas"", or in short the Automotive NOx and PM Law. Emission StandardsThe NOx and PM Law introduces emission standards for specified categories of in-use highway vehicles including commercial goods (cargo) vehicles such as trucks and vans, buses, and special purpose motor vehicles, irrespective of the fuel type. The regulation also applies to diesel powered passenger cars (but not to gasoline cars).",1
"In-use vehicles in the specified categories must meet 1997/98 emission standards for the respective new vehicle type (in the case of heavy duty engines NOx = 4.5 g/kWh, PM = 0.25 g/kWh). In other words, the 1997/98 new vehicle standards are retroactively applied to older vehicles already on the road. Vehicle owners have two methods to comply: Replace old vehicles with newer, cleaner models Retrofit old vehicles with approved NOx and PM control devicesVehicles have a grace period, between 8 and 12 years from the initial registration, to comply.",1
"The grace period depends on the vehicle type, as follows: Light commercial vehicles (GVW ≤ 2500 kg): 8 years Heavy commercial vehicles (GVW > 2500 kg): 9 years Micro buses (11-29 seats): 10 years Large buses (≥ 30 seats): 12 years Special vehicles (based on a cargo truck or bus): 10 years Diesel passenger cars: 9 yearsFurthermore, the regulation allows fulfillment of its requirements to be postponed by an additional 0.5–2.5 years, depending on the age of the vehicle. This delay was introduced in part to harmonize the NOx and PM Law with the Tokyo diesel retrofit program.",1
"The NOx and PM Law is enforced in connection with Japanese vehicle inspection program, where non-complying vehicles cannot undergo the inspection in the designated areas. This, in turn, may trigger an injunction on the vehicle operation under the Road Transport Vehicle Law.",1
"From 1 January 2022, all new cars in Vietnam must comply with Euro 5.",1
"From 1 January 2024, all new vehicles in Morocco must comply with Euro 6b.",1
"South Africa's first clean fuels programme was implemented in 2006 with the banning of lead from petrol and the reduction of sulphur levels in diesel from 3,000 parts per million (ppm) to 500ppm, along with a niche grade of 50 ppm. The Clean Fuels 2 standard, expected to begin in 2017, includes the reduction of sulphur to 10 ppm; the lowering of benzene from 5 percent to 1 percent of volume; the reduction of aromatics from 50 percent to 35 percent of volume; and the specification of olefins at 18 percent of volume.",1
"Australian noxious emission standards are based on European regulations for light-duty and heavy-duty (heavy goods) vehicles, with acceptance of selected US and Japanese standards. The current policy is to fully harmonize Australian regulations with United Nations (UN) and Economic Commission for Europe (ECE) standards. In November 2013, the first stage of the stringent Euro 5 emission standards for light vehicles was introduced, which includes cars and light commercial vehicles. The development of emission standards for highway vehicles and engines is coordinated by the National Transport Commission (NTC) and the regulations—Australian Design Rules (ADR)—are administered by the Department of Infrastructure and Transport.All",1
"new vehicles manufactured or sold in the country must comply with the standards, which are tested by running the vehicle or engine in a standardized test cycle.In April 2023, the Australian government released its National Electric Vehicle Strategy, which included a commitment to introduce a Fuel Efficiency Standard to address greenhouse gas emissions.",1
"Depending on the situation and the size of the oil spill, it can be applied either diluted or at full strength. Oil spill Crude oil Bioremediation Microorganisms Biological agent Nokomis 3 Nokomis 3-F4 EPA Technical Product Bulletin",1
"Sources include construction sites (although these are point sources, which can be managed with erosion controls and sediment controls), agricultural fields, stream banks, and highly disturbed areas.",1
"interflow and tile drainage) is the most likely to transport it, rather than surface runoff.",1
"Compounds including heavy metals like lead, mercury, zinc, and cadmium, organics like polychlorinated biphenyls (PCBs) and polycyclic aromatic hydrocarbons (PAHs), fire retardants, and other substances are resistant to breakdown. These contaminants can come from a variety of sources including human sewage sludge, mining operations, vehicle emissions, fossil fuel combustion, urban runoff, industrial operations and landfills.Toxic chemicals mainly include organic compounds and inorganic compounds. These compounds include pesticides like DDT, acids, and salts that have severe effects to the ecosystem and water-bodies.",1
"may contaminate runoff due to poorly managed livestock operations, faulty septic systems, improper handling of pet waste, the over application of human sewage sludge, contaminated storm sewers, and sanitary sewer overflows.",1
"Forestry operations reduce the number of trees in a given area, thus reducing the oxygen levels in that area as well. This action, coupled with the heavy machinery (harvesters, etc.) rolling over the soil increases the risk of erosion.",1
"With a well-planned placement of both logging trails, also called skid trails, can reduce the amount of sediment generated. By planning the trails location as far away from the logging activity as possible as well as contouring the trails with the land, it can reduce the amount of loose sediment in the runoff. Additionally, by replanting trees on the land after logging, it provides a structure for the soil to regain stability as well as replaces the logged environment.",1
"The road itself wears and releases particulate matter into the air.The friction between the tire surface and the road surface which leads to tire abrasion is also liable to abrade the road surface, especially where this is already fragmenting. Hence, road surface wear particles are also released to the atmosphere. More comprehensive regulation of tires has been suggested. Lighter vehicles pollute less and reducing vehicle kilometers traveled is another method of mitigating non-exhaust emissions.",1
"On the first day of the presidency of Donald Trump, the White House website announced that Obama's Climate Action Plan would be eliminated, stating it is ""harmful and unnecessary"". In March 2017, Trump signed an executive order to officially nullify Obama's Clean Power Plan in an effort, it said, of reviving the coal industry. In January 2021, on the Inauguration Day of U.S. president Joe Biden, Trump's executive order was revoked by the executive order ""Protecting Public Health and the Environment and Restoring Science to Tackle the Climate Crisis"", thereby reinstating the Obama Climate Action Plan.",1
"Climate Action Plan Climate change in the United States National Climate Assessment National Research Council, report on climate change State of the Climate Executive Office of the President. June 2013. The President’s Climate Action Plan. Washington, D. C.: whitehouse.gov, retrieved June 25, 2013 Link: President Obama is taking action on climate change President Obama's Climate Action Plan. 2nd anniversary progress report Climate change and President Obama's action plan (White House)",1
"The stakes are installed on the downhill side of the fence, and the bottom edge of the fabric can be trenched into the soil and backfilled on the uphill side, although it is quite difficult to move the trenched ""spoil"" from the downside to the upside of the trench. The design/placement of the silt fence should create a pooling of runoff, which then allows sedimentation to occur.",1
"Depending on the protected watershed and erosion, larger soil particles will settle out, ultimately filling the silt fence to the top of the structure; requiring another silt fence above or below it (creating a new ponding area), or for the silt fence to be removed, the sediment removed or spread out, and a new fence installed. The fence is not designed to concentrate or channel stormwater. The fence is installed on a site before soil disturbance begins, and is placed down-slope from the disturbance area.Sediment",1
"Some state agencies recommend an installation technique called ""static slicing"" as an improved method for ensuring effectiveness and longevity of a silt fence system on a construction site. The technique involves inserting a narrow blade into the soil with a wedge-type point on its tip to slightly disrupt the soil upward, while simultaneously inserting the silt fence fabric into the slot with a moving pivot, while the machine is moving forward. This step is followed by mechanical soil compaction, setting of fence posts, and attaching the fabric.",1
"Silt fence fabrics (geotextiles) tested in laboratory settings have shown to be effective at trapping sediment particles.: 45–47 Although there have been few field tests of silt fences installed at construction sites, these tests have shown generally poor results.: 27–31, 53–55 (Effectiveness testing involved measurements for both total suspended solids and turbidity.) Other studies and articles about silt fence usage and practice document problems with installation and maintenance, implying poor performance.Since",1
"A silt fence top-full of sediment may need maintenance/replacement, but it is a huge success.: p.6–10 The fabric may become damaged with holes and tears if construction materials are stored next to or on top of the fence. During various phases of construction at a site, a silt fence may be removed relocated and reinstalled multiple times.: 30–31 It may be difficult to maintain effectiveness of a silt fence under such operating conditions. Location of fences in areas with high flows may lead to fence failures when the installation is not adequately back-filled and properly compacted, and/or the post-spacing is inadequate.:",1
"Sometimes two levels of packaging are needed for separate distribution, resulting in production inefficiencies.",1
"The total amount of MSW generated for paper and paperboard containers and packaging was 39.9 million tons or 15.1 percent in 2015. Although, the recycled rate is about 78.2 percent and 4.3 percent of small proportions were combusted with energy recovery and 17.6 percent in landfill.",1
"percent of the wood containers and packaging waste generated was combusted with energy recovery, while the 58.6 percent went to the land filled.",1
"Litter mostly consists of packaging waste. Besides the disfigurement of the landscape, it also poses a health hazard for various life forms. Packaging materials such as glass and plastic bottles are the main constituents of litter. It has a huge impact on the marine environment as well, when animals are caught in or accidentally consume plastic packaging.",1
"The 20 percent of packaging waste that comes from marine sources comes from the rivers of China starting from least to greatest contributors, the Hanjiang, Zhujiang, Dong, Huangpu, Xi, and Yangtze river. All other marine sources comes from rivers of Africa and Southeast Asia. Most marine species and wildlife species suffer from the following: Entanglement: At least 344 species are entangled by packaging waste, specifically the ones that are plastics. Most of the victims are marine species like whales, seabirds, turtles, and fish. Ingestion: 233 marine species are recorded that had consumed plastic packaging waste of either unintentionally, intentionally, or indirectly.",1
"Bisphenol A (BPA), styrene and benzene can be found in certain packaging waste. BPA can affect the hearts of women, permanently damage the DNA of mice, and appear to be entering the human body from a variety of unknown sources. Studies from Journal of American Association shows that higher bisphenol A levels were significantly associated with heart diseases, diabetes, and abnormally high levels of certain liver enzymes. Toxins such as these are found within our food chains. When fish or plankton consume microplastics, it can also enter our food chain.",1
"Segregation of waste at sources: plastics, organic, metals, paper, etc. Effective collection of the segregated waste, transport and safe storage Cost-effective recycling of materials (including plastics) Less land filling and dumping in the environment",1
"Governments working with industries could support the development and promotion of sustainable alternatives in order to phase out single-use plastics progressively. If governments were to introduce economic incentives, supporting projects which upscale or recycle single-use items and stimulating the creation of micro-enterprises, they could contribute to the uptake of eco-friendly alternatives to single-use plastics.",1
"Social awareness and education is also one of the ways to help contribute to issues similar to helping reducing packaging waste. Using the media gives quick access for the individuals or groups to spread information and awareness in regarding to letting the public know what is going on in the world and ways that others can contribute to assist in fixing problems of packaging wastes. Schools are also good for spreading the education with factual knowledge, possible outcomes for the increase of packaging waste, and provide ways to get individuals to give a helping hand in keeping our planet clean.",1
Reuse bags Bring reusable bags to supermarkets Repair broken objects instead of throwing them away Exchange packaging materials on BoxGiver Recycle Clean up in coastal areas Do community services to clean up parks and streets from packaging waste Plastic waste – Accumulation of plastic in natural ecosystemsPages displaying short descriptions of redirect targets Waste & Resources Action Programme – British charitable organizationPages displaying wikidata descriptions as a fallback Packaging Recovery Note – documenting packaging recyclingPages displaying wikidata descriptions as a fallback Packaging and packaging waste directive – Directive of EU Producer Responsibility Obligations (Packaging Waste) Regulations 2007 – UK waste management,1
regulations Reusable packaging – manufactured of durable materials and is specifically designed for multiple trips and extended life.,1
"A reusable package or container is ""designed for reuse without impairment of its protective function""Pages displaying wikidata descriptions as a fallback Sustainable packaging – Packaging which results in improved sustainability Fast food – Food prepared and served in a small amount of time Waste minimization – Process that involves reducing the amount of waste produced in societyPages displaying short descriptions of redirect targets Circular economy – Regenerative system in which resource input and waste, emission, and energy leakage, are minimised Disposable food packaging",1
"With placement (localised) spraying of broad spectrum pesticides, wind drift must be minimised, and considerable efforts have been made to quantify and control spray drift from hydraulic nozzles. Conversely, wind drift is also an efficient mechanism for moving droplets of an appropriate size range to their targets over a wide area with ultra-low volume (ULV) spraying.Himel (1974) made a distinction between exo-drift (the transfer of spray out of the target area) and endo-drift, where the active ingredient (AI) in droplets falls into the target area, but does not reach the biological target.",1
"Endo-drift is volumetrically more significant and may therefore cause greater ecological contamination (e.g. where chemical pesticides pollute ground water).Bystander exposure describes the event when individuals unintentionally come in contact with airborne pesticides. Bystanders include workers working in an area separate to the pesticide application area, individuals living in the surrounding areas of an application area, or individuals passing by fields as they are being treated with a pesticide. Herbicide volatilisation refers to evaporation or sublimation of a volatile herbicide.",1
"For example, the American Soybean Association and various land-grant universities are cooperating in the race to find ways to preserve the usability of dicamba while ending drift injury. Application of herbicides later in the season to protect herbicide-resistant genetically modified plants increases the risk of volatilisation as the temperature is higher and incorporation into the soil impractical. To mitigate pesticide drift one will need to inspect their equipment. Before application, check to see if applicators, hoses, braces, springs, clamps, or any other equipment is bent, damaged, or clogged.",1
If any of the equipment is damaged there is a higher chance for airflow to move droplets from the intended application site. When using ground boom sprayers be sure to set nozzle heights that are not too high above the intended crop. Nozzles that are too high above the target will lead to more airflow under the nozzle and carry droplets of pesticides to other unintended locations.,1
"When pesticides drift, they can be inhaled or land on the skin and eyes. Symptoms include eye and nose irritation, runny nose, coughing, or rash. However, different pesticides can affect different body systems, inflicting different symptoms. Pesticide drift can result in more serious harm to one's health depending on how much and what type of pesticide is entering the body. Some pesticides cause little to no harm from low toxicity. Others can be very toxic and cause serious effects from little exposure. Yet, these pesticides are kept in tight control.",1
"Some pesticides, at significantly high exposures, can cause long-term health effects, including neurodevelopmental disorders in children, infertility and reproductive issues, cancer, pulmonary disease, and much more.",1
"The USDA and EPA are working together to examine new studies and how to improve scientific models to estimate the exposure, risk, and drift of pesticides. The EPA is also working with pesticide manufacturers to ensure labels are easy to read, contain the correct application process and DRT for that specific pesticide.",1
"Many things have previously been unknown regarding pesticide drift, including the direct health impacts on humans, effective ways to prevent pesticide drift (other than placing the responsibility on the farmer), and if the public should be concerned about their general health being impacted by pesticide drift. Recent research has come out that has shed light on a lot of different subject surrounding pesticide drift that have made it much easier to understand, and therefore easier to control.One",1
"recent study has compared cytotoxicity and genotoxicity of rural agricultural residents to that of a control group and have found that individuals in agricultural areas are at risk for increased genotoxicity because of pesticide drift from farmers in the area.Despite this alarming diagnosis, more research has also gone into finding effective ways to reduce the effects of pesticide drift without relying on compliance of the farmers. Farmers can struggle to walk the line between reducing pesticide drift and still being productive farmers, which has led to more research on alternative solutions for pesticide drift.",1
"Researchers understand that farmers cannot hold off spraying crops for extended periods of time, so research has gone into determining which is the best combination of the worst weather conditions to help optimize spray time while also maintaining the health of nearby aquatic ecosystems. One-way researchers have begun to do this is using computer programs to simulate the efficiency of the spray and reach of the spray drift.",1
"On their introduction in the 1940s, PFASs were considered inert. Early occupational studies revealed elevated levels of fluorochemicals, including perfluorooctanesulfonic acid (PFOS) and perfluorooctanoic acid (PFOA, C8), in the blood of exposed industrial workers, but cited no ill health effects. These results were consistent with the measured serum concentrations of PFOS and PFOA in 3M plant workers ranging from 0.04 to 10.06 ppm and 0.01 to 12.70 ppm, respectively, well below toxic and carcinogenic levels cited in animal studies.",1
"comprehensive epidemiological studies linking adverse human health effects to PFASs, particularly PFOA, come from the C8 Science Panel. The panel was formed as part of a contingency to a class action lawsuit brought by communities in the Ohio River Valley against DuPont in response to landfill and wastewater dumping of PFAS-laden material from DuPont's West Virginia Washington Works Plant. The panel measured PFOA (also known as C8) serum concentrations in 69,000 individuals from around DuPont's Washington Works Plant and found a mean concentration of 83.0 ng/mL, compared to 4 ng/mL in a standard population of Americans.",1
"This panel reported probable links between elevated PFOA blood concentration and hypercholesterolemia, ulcerative colitis, thyroid disease, testicular cancer, kidney cancer as well as pregnancy-induced hypertension and preeclampsia.",1
"PFOA and PFOS have been shown to significantly alter immune and inflammatory responses in human and animal species. In particular, IgA, IgE (in females only) and C-reactive protein have been shown to decrease whereas antinuclear antibodies increase as PFOA serum concentrations increase. These cytokine variations allude to immune response aberrations resulting in autoimmunity. One proposed mechanism is a shift towards anti-inflammatory M2 macrophages and/or T-helper (TH2) response in intestinal epithelial tissue which allows sulfate-reducing bacteria to flourish. Elevated levels of hydrogen sulfide result, which reduce beta-oxidation and nutrient production, leading to a breakdown of the colonic epithelial barrier.",1
"Hypothyroidism is the most common thyroid abnormality associated with PFAS exposure. PFASs have been shown to decrease thyroid peroxidase, resulting in decreased production and activation of thyroid hormones in vivo. Other proposed mechanisms include alterations in thyroid hormone signaling, metabolism and excretion as well as function of nuclear hormone receptor.",1
"Rat studies investigating the carcinogenicity of PFASs reported significant correlation with liver adenomas, Leydig cell tumors of the testis, and pancreatic acinar cell tumors and dietary PFOA consumption. The C8 Science Panel investigated the potential relationship between PFAS exposure and these three cancer types as well as 18 other cancer types in their epidemiological studies. Contrary to the animal studies, the C8 studies did not find a probable link between elevated C8 exposure and liver adenomas or pancreatic acinar cell tumors; however, a probable link was found with regards to testis and kidney cancer.Two",1
"mechanisms have been proposed by which PFOA could cause Leydig cell tumors. Both mechanisms propose that PROA exposure results in increased PPAR alpha activation in the liver which increases hepatic aromatase concentration and subsequent serum estrogen levels. The mechanisms diverge at this point, with one pathway suggesting elevated estradiol levels increase tissue growth factor alpha, which prompts Leydig cell proliferation, while the other pathway suggests that the aromatization of testosterone to estradiol reduces serum testosterone levels, resulting in increased release of luteinizing hormone from the pituitary gland which directly results in Leydig Cell tumorgenesis.",1
A mechanism has not yet been proposed to explain how kidney cancer could be caused by C8 exposure as no in vivo animal studies have been able to model this epidemiological outcome.,1
"Pregnancy-induced hypertension is diagnosed when maternal systolic blood pressure exceeds 140 mmHg or diastolic blood pressure exceeds 90 mmHg after 20 weeks gestation. Diagnostic criteria are the same for pre-eclampsia as pregnancy-induced hypertension, but it also confers proteinuria. Mechanisms by which pregnancy-induced hypertension and preeclampsia could be caused by PFAS exposure have remained elusive and are largely speculative to date. One proposed mechanism highlights alterations in immune function leading to disruption of placentation, specifically as it pertains to natural killer cell infiltration of the placenta to facilitate trophoblastic integration with placental blood supply.",1
"Another mechanism refers to agonism of PPARs contributing to alterations in cholesterol, triglyceride and uric acid levels, all of which may lead to vascular inflammation and elevated blood pressure.Other adverse health outcomes that have been attributed to elevated PFAS exposure but were not found to be probable links in the C8 studies are decreased antibody response to vaccines, asthma, decreased mammary gland development, low birth weight (-0.7oz per 1 ng/mL increase in blood PFOA or PFOS level), decreased bone mineral density, and neurodevelopmental abnormalities.",1
"Fluorosurfactants such as PFOS, PFOA, and PFNA have caught the attention of regulatory agencies because of their persistence, toxicity, and widespread occurrence in the blood of general populations and wildlife. In 2009, PFOS, its salts, and perfluorooctanesulfonyl fluoride were listed as persistent organic pollutants under the Stockholm Convention due to their ubiquitous, persistent, bioaccumulative, and toxic nature. PFAS chemicals were dubbed the ""forever chemicals"" following a 2018 op-ed in the Washington Post.",1
"Biomagnification is the process by which the amount of PFAS contamination increases with increasing trophic level, due to predation by the species higher in the food web. Top predators have higher levels of PFASs than species lower down the food chain. Seabirds that feed on fish have among the highest levels of PFAS contamination. In marine species of the food webPFOS, a long chain sulfonic acid, was found at the highest concentrations relative to other PFASs measured in fish and birds in Northern seas such as the Barents Sea and the Canadian Arctic.",1
"A study and an interactive map by the EWG using its results showed freshwater fish in the U.S. ubiquitously contain high levels of harmful PFAS, with a single serving typically significantly increasing the blood PFOS level.Bioaccumulation and biomagnification of PFASs in marine species throughout the food web, particularly frequently consumed fish and shellfish, can have important impacts on human populations.",1
"PFASs have been frequently documented in both fish and shellfish that are commonly consumed by human populations, which poses health risks to humans and studies on the bioaccumulation in certain species are important to determine daily tolerable limits for human consumption, and where those limits may be exceeded causing potential health risks. This has particular implications for populations that consume larger numbers of wild fish and shellfish species.",1
"In addition to health risks, populations may be impacted by advisories, limits of fishing closures for certain species that are put in place to help mitigate health risks from potential consumption of species with higher levels of accumulated PFASs, but result in a loss of food sources and important subsistence species depended on by local communities. There is research being done in this area, including into spatial patterns of PFAS bioaccumulation in fish and crustaceans. There is a need for more research on membrane transport mechanisms, which transfer PFASs into marine organisms, and the biological behavior of shorter chain PFASs.",1
"Since the 1970s, 3M scientists learned that PFOS and PFOA were toxic to humans, and documented damage to the human immune system. They also found that these substances accumulate over time in the human body, but the company suppressed dissemination of these facts to the public or to regulators.In 2018 White House staff and the EPA pressured the U.S. Agency for Toxic Substances and Disease Registry to suppress a study that showed PFASs to be even more dangerous than previously thought.",1
"The proposal was submitted on 13 January 2023 and published by the European Chemicals Agency (ECHA) on 7 February. From 22 March to 21 September, citizens, companies and other organizations can comment on the proposal during a public consultation. Based on the information in the restriction proposal and the consultation, two committees from ECHA formulate an opinion on the risk and socio-economic aspects of the proposed restriction. Within a year of publication, the opinions are sent to the European Commission, which makes a final proposal that is submitted to the EU Member States for discussion and decision.",1
"Eighteen months after the publication of the restriction decision (which may differ from the original proposal), it will enter the ban.",1
"Although in 2020 the European Food Safety Agency (EFSA) has reduced by more than four times the maximum tolerable limit of PSAS that can be taken through the diet, the region has not carried out new assessments or implemented concrete actions to protect the population and the agri-food and livestock sectors.",1
"Some limits were added to monitoring the geographical area, which does not include the orange zone and other areas affected by contamination, as well as the insufficiency of analysis on important productions widespread in the areas concerned: eggs (up to 37,100 ng/kg), fish (18,600 ng/kg) spinach and radicchio (only one sampling carried out), kiwis, melons, watermelons, cereals (only one sample was analyzed), soy, wines and apples.",1
"As many as 13 types of individual PFAS compounds were found in each product. Since PFAS compounds are highly mobile, they are readily absorbed through human skin and through tear ducts, and such products on lips are often unwittingly ingested. Manufacturers often fail to label their products as containing PFASs, which makes it difficult for cosmetics consumers to avoid products containing PFASs. In response, Senators Susan Collins of Maine and Richard Blumenthal of Connecticut proposed the No PFAS in Cosmetics Act in the United States Senate.",1
"It was also introduced in the United States House of Representatives by Michigan Representative Debbie Dingell, but the U.S. chemical industry lobby has killed efforts to regulate this.",1
"October 2018, a class action suit was filed by an Ohio firefighter against several producers of fluorosurfactants, including the 3M and DuPont corporations, on behalf of all U.S. residents who may have adverse health effects from exposure to PFASs. The story is told in the film Dark Waters.",1
"The change adds 38 additional sites to the state's list of known PFAS contaminated areas, bringing the total number of known sites to 137. About half of these sites are landfills and 13 are former plating facilities.In 2022 PFOS was found in beef produced at a Michigan farm: the cattle had been fed crops fertilized with contaminated biosolids. State agencies issued a consumption advisory, but did not order a recall, because there currently is no PFOS contamination in beef government standards.",1
"Serum levels of PFOA in ski wax technicians were positively correlated with years spent working, suggesting bioaccumulation of PFOA over time.",1
"Among fluorochemical workers, those with direct contact with PFASs have higher PFAS concentrations in their blood than those with intermittent contact or no direct PFAS contact. Blood PFAS levels have been shown to decline when direct contact ceases. PFOA and PFOS levels have declined in U.S. and European fluorochemical workers due to improved facilities, increased usage of personal protective equipment, and the discontinuation of these chemicals from production. Occupational exposure to PFASs in manufacturing continues to be an active area of study in China with numerous investigations linking worker exposure to various PFASs.",1
"responders who were working at or near ground zero were assessed for respiratory and other health effects from exposure to emissions at the World Trade Center. Early clinical testing showed a high prevalence of respiratory health effects. Early symptoms of exposure often presented with persistent coughing and wheezing. PFOA and PFHxS levels were present in both smoke and dust exposure, but first responders exposed to smoke had higher concentrations of PFOA and PFHxS than those exposed to dust.",1
"""If we can remove it from wastewater, we can reduce its occurrence in surface waters."" In September 2019, it was reported Acidimicrobium sp. strain A6 could be a potential remediator of PFAS, including saturated ones such as PFOS. PFAS with unsaturated bonds are easier to break down: the commercial dechlorination culture KB1 (contains Dehalococcoides) is capable of breaking down such substances, but not saturated PFAS. When alternative, easier-to-digest substrates are present, microbes may prefer them over PFAS.",1
A more recent study published in Chemical Science shows breakdown of C-F bonds and their mineralization as YF3 or YF6 clusters. Another study in the Journal of the American Chemical Society described the PFAs breakdown using metal-organic frameworks (MOFs).,1
"that are angled 30° from the horizontal are standard. Although 45° nozzle angles achieve longer distances from a ballistics perspective, 45° nozzles have been observed to create large craters. In addition, a high amount of sand flows back towards the dredger. 30° nozzles instead project the sand with a flatter trajectory, minimizing back flow while achieving a final distance comparable to that reached by a 45° nozzle.Other methods of disposing and transferring the slurry include pumping the slurry through pipelines or using natural forces such as wave currents.",1
"In addition, coral can be removed or become buried by the sediment. https://web.archive.org/web/20061117204621/http://channel.nationalgeographic.com/channel/totalmegastructures/photogallery_rainbowing_island.html http://www.accessmylibrary.com/premium/0286/0286-11654915.html",1
"The tasks listed here are common to almost all Phase I ESAs: Performance of an on-site visit to view present conditions (chemical spill residue, die-back of vegetation, etc.); hazardous substances or petroleum products usage (presence of above ground or underground storage tanks, storage of acids, etc.); and evaluate any likely environmentally hazardous site history.",1
"Former Bulk Fuels Facility, Owen Sound, Ontario, Canada Dakin Building, Brisbane, California East Elk Grove Specific Plan, Elk Grove, California Mariners Marsh Park, Staten Island, New York Richmond State Hospital Farm Industrial Park, Wayne County, Indiana Sydney Steel Plant Lands, Sydney, Nova Scotia Weyerhauser Technology Center, Federal Way, Washington In Japan, with the passage of the 2003 Soil Contamination Countermeasures Law, there is a strong movement to conduct Phase I studies more routinely. At least one jurisdiction in Canada (Ontario) now requires the completion of a Phase I prior to the transfer of some types of industrial properties.",1
"Some parts of Europe began to conduct Phase I studies on selected properties in the 1990s, but still lack the comprehensive attention given to virtually all major real estate transactions in the USA. In the United Kingdom contaminated land regulation is outlined in the Environment Act 1995. The Environment Agency of England and Wales have produced a set of guidance; CLEA a standardized approach to the assessment of land contamination. A Phase 1 Desktop Study is often required in support of a planning application. In the UK these reports must be assembled by a ""competent person"".",1
"Phase III investigations aim to delineate the physical extent of contamination based on recommendations made in Phase II assessments. Phase III investigations may involve intensive testing, sampling, and monitoring, ""fate and transport"" studies and other modeling, and the design of feasibility studies for remediation and remedial plans. This study normally involves assessment of alternative cleanup methods, costs and logistics. The associated reportage details the steps taken to perform site cleanup and the follow-up monitoring for residual contaminants.",1
"Similarly, increasing hard disk drives' and optical disc drives' rotation speeds increases performance, but generally also vibration and bearing friction. Though standards do exist for measuring and reporting sound power output by such things as computer components, they are often ignored. Many manufacturers do not give sound power measurements. Some report sound pressure measurements, but those that do often do not specify how sound pressure measurements were taken. Even such basic information as measurement distance is rarely reported. Without knowing how it was measured, it is not possible to verify these claims, and comparisons between such measurements (e.g.",1
"for product selection) are meaningless. Comparative reviews, which test several devices under the same conditions, are more useful, but even then, an average sound pressure level is only one factor in determining which components will be perceived as quieter.",1
"Isolate hard disk noise, either by using anti-vibration mounts (generally rubber or silicone grommets), or by suspending the hard disk to fully decouple it from the computer chassis by mounting it in a 5.25 inch drive bay with viscoelastic polymer mounts. Set the hard disk's AAM value to its lowest setting. This reduces the seek noise produced by the hard drive, but also reduces performance slightly. Set operating system to spin down hard drives after a short time of inactivity.",1
A quiet power supply is selected to be efficient while providing enough power for the computer.,1
"Motherboard voltage regulators also often have heat sinks and may need airflow to ensure adequate cooling. Some motherboards can control the fan speed using an integrated hardware monitoring chip (often a function within a Super I/O solution), which can be configured through BIOS or with a system monitoring software like SpeedFan and Argus Monitor, and most recent motherboards have built-in PWM fan control for one or two fans.",1
"Even though a given hardware monitoring chip may be capable of performing fan control, a motherboard manufacturer may not necessarily wire up the fan header pins of the motherboard correctly to the hardware monitoring chip, thus sometimes computer fan control cannot be performed on a given motherboard due to the wiring irregularities, even though the software may indicate that the fan control is available due to the underlying support by the hardware monitoring chip itself.",1
"Other times, it may be the case that a single fan-control setting may affect all fan connector headers on the motherboard at the same time, even if individual settings for each fan are available in the hardware monitoring chip itself; these wiring issues being very common makes it difficult to design good general-purpose user interfaces for configuring fan control.Motherboards can also produce audible electromagnetic noise.",1
"The heat output of a CPU can vary according to its brand and model or, more precisely, its thermal design power (TDP). Intel's third revision Pentium 4, using the ""Prescott"" core, was infamous for being one of the hottest-running CPUs on the market. By comparison, AMD's Athlon series and the Intel Core 2 perform better at lower clock speeds, and thus produce less heat. Modern CPUs often incorporate energy saving systems, such as Cool'n'Quiet, LongHaul, and SpeedStep. These reduce the CPU clock speed and core voltage when the processor is idle, thus reducing heat.",1
"The heat produced by CPUs can be further reduced by undervolting, underclocking or both. Most modern mainstream and value CPUs are made with a lower TDP to reduce heat, noise, and power consumption. Intel's dual-core Celeron, Pentium, and i3 CPUs generally have a TDP of 35–54 W, while the i5 and i7 are generally 64–84 W (newer versions, such as Haswell) or 95W (older versions, such as Sandy Bridge). Older CPUs such as the Core 2 Duo typically had a TDP of 65 W, while the Core 2 Quad CPUs were mostly 65–95 W.",1
"AMD's Athlon II x2 CPUs were 65 W, while the Athlon x4 was 95 W. The AMD Phenom ranged from 80 W in the x2 variant to 95 and 125 W in the quad-core variants. The AMD Bulldozer CPUs range from 95–125 W. AMD APUs range from 65 W for the lower-end dual-core variants, such as the A4, to 100 W in the higher-end quad-core variants, such as the A8. Some processors come in special low power versions. For example, Intel's lower TDP CPUs end in T (35 W) or S (65 W).",1
"Most modern graphics cards come with tools that allow the user to reduce the power target and adjust fan curves, resulting in quieter operation at a cost of performance",1
"Power supplies are typically less efficient when lightly or heavily loaded. High wattage power supplies will typically be less efficient when lightly loaded, for instance when the computer is idle or sleeping. Most desktop computers spend most of their time lightly loaded. For example, most desktop PCs draw less than 250 watts at full load, and 200 watts or less is more typical.Power",1
The electrical coils in power supplies can produce audible electromagnetic noise which can become noticeable in a quiet PC. Equipping the PSU with a power cord that uses a ferrite bead can sometimes help to reduce humming from the PSU.,1
"Case designed for low noise usually include quiet fans, and often come with a quiet power supply. Some incorporate heatsinks to cool components passively.Larger cases provide more space for airflow, larger coolers and heat sinks, and sound dampening material.",1
"However, the filter itself can increase noise if it restricts airflow too much or is not kept clean, requiring a larger or faster fan to handle the pressure drop behind the filter.",1
"The inside of a case can be lined with dampening materials to reduce noise by: attenuating the vibration of the case panels via extensional damping or constrained-layer damping reducing the amplitude of the vibration of the case panels by increasing their mass absorbing airborne noise, such as with foam",1
"Fan controllers can produce a fixed fan speed using an inline resistor or diode; or a variable speed using a potentiometer to supply a lower voltage. Fan speed can also be reduced more crudely by plugging them into the power supply's 5 volt line instead of the 12 volt line (or between the two for a potential difference of 7 volts, although this cripples the fan's speed sensing). Most fans will run at 5 volts once they are spinning, but may not start reliably at less than 7 V.",1
"Some simple fan controllers will only vary the fans' supply voltage between 8 V and 12 V to avoid this problem entirely. Some fan controllers start the fan at 12 V, then drop the voltage after a few seconds. PWM fan control, however, is the easiest and most efficient option for modern motherboards that have PWM fan headers. PWM fan control rapidly cycles between feeding the fan full voltage and no voltage, to control rotational speed. Typically the motherboard chipset provides temperature data from sensors on the CPU itself to control speed. Bearing and motor noise is an important consideration.",1
"Devices such as GPUs, Northbridges, Southbridges, hard disk drives, memory, voltage regulator modules (VRMs), and even power supplies can be separately watercooled; in fact the whole PC can be immersed, in some cases.",1
"Hard disk enclosures can also help reduce drive noise, but care must be taken to ensure that the drive gets adequate cooling - with disk temperatures often be monitored by SMART software.",1
"A CRT monitor can produce coil noise, as can the external power supply for an LCD monitor or the voltage converter for the monitor's backlight. LCD monitors tend to produce the least noise (whine) when at full brightness. Reducing brightness using the video card does not introduce whine, but may reduce color accuracy. An LCD monitor with an external power supply tucked out of the way will produce less noticeable noise than one with the power supply built into the screen housing.",1
"What is a ""Silent"" Computer? (in Dutch), Vrad. Reference/Recommended, Silent PC Review. In a nutshell, Silent PC Review. PC, SE: Silent.",1
"Founded in 2010 by Angela Haseltine Pozzi, an artist and educator for over 30 years, the unique non-profit organization has built over 66 giant sculptures from over 17 tons of ocean garbage, and the exhibit, including educational signage, has appeared at numerous venues including SeaWorld Parks throughout the US, The Virginia Aquarium, San Francisco Zoo, The Marine Mammal Center in Sausalito, California Newport Visual Arts Center, the Chula Vista, California Nature Center, Portland Community College, America's Cup Healthy Oceans Exhibit and the Oregon Coast Aquarium.",1
"Based in Bandon, Oregon, the project uses local and area volunteers in workshops held at Bandon's Harbortown Event Center Thursdays through Saturdays (winter hours). The workshops consist of assembling ""piece work"" which involves drilling holes through plastic and stitching the plastic to wire mesh. These panels will later be fastened by Lead Artist, Angela Haseltine Pozzi, and her team, to welded structures and other artwork as part of Washed Ashore's Traveling Exhibits.",1
There are two main categories of Safe-in-Sound Awards: the Excellence Award and the Innovation Award.,1
"The Safe-in-Sound Excellence in Hearing Loss Prevention Award is meant to honor remarkable hearing loss prevention implementations in the workplace. This award was initially divided into three possible awards based on the sector the project is working with: construction, manufacturing, and service. In 2016, applications for the award started to be accepted from all industrial sectors.",1
"The Safe-in-Sound Innovation in Hearing Loss Prevention Award may be awarded to individuals or organizations that address challenges in workplace hearing loss prevention in an innovative way. Consideration for this award may include advancements in the areas of policy, program development/implementation, and outreach. 2012 (Excellence): Colgate-Palmolive, for interventions such as an online training in noise control engineering, and company-wide implementation of the NIOSH recommended 85-dBA limit for 8-hour noise exposure. In 2013, the Occupational Safety and Health Administration (OSHA) highlighted this particular Safe-in-Sound recipient in their OSHA Technical Manual (OTM), which provides information and guidance on workplace hazards.",1
"2014 (Excellence): Northrop Grumman Systems Corporation, Linthicum, Maryland. This facility has implemented a process to identify and effectively control hazardous noise sources that have reduced or eliminated individual worker daily noise exposures and the need for most of their workers to be enrolled in a hearing loss prevention program. 2015 (Excellence): United Technologies Corporation (UTC), for their extensive efforts to reduce the exposure of their employees to hazardous chemicals and industrial noise. 2016 (Excellence): 3M Alexandria plant, for their successful reduction of noise exposure within their facility (12-14 dBA across 24 departments).",1
"The initiatives implemented by 3M proved to be cost-effective, utilized Buy-Quiet principles, and resulted in 199 of 203 no longer being required to complete the 3M Alexandria Hearing Conservation Program. 2020 (Innovation): 2020 Multilateral Medical Operations Panel's Acoustics Sub-Working Group for the International Space Station (ISS). ISS Crewmembers are exposed to noise 24 hours a day, seven days a week, with current missions averaging 6 months in duration. Concerns over noise exposure are not restricted to risks to hearing effects, but also to crew health and performance in the form of interference in sleep and communication, and reduced alarm audibility.",1
"The Acoustics Sub-Working Group work with the astronauts to monitor noise levels on the Space Station, identify noisy tasks or equipment for their Noise Hazard Inventory, test equipment for noise levels before it is sent to the ship, develop and implement solutions to reduce noise levels, recommends hearing protective devices to reduce crew noise exposures and perform audiometric testing before, during (on-orbit) and after flights. 2022 (Innovation): Michael Lawrence and Jamie Anderson, Rational Acoustics LLC. Rational Acoustics LLC develops, distributes, and supports audio measurement software for the worldwide professional sound industry. Their focus goes beyond product development.",1
"They have addressed the compounding issues related to risks of overexposures to music experienced by live sound mixers, event crew and attendees of concerts. Their efforts contributed to the 2022 World Hearing Day theme, “To hear for life, listen with care!” World Hearing Day is hosted by the World Health Organization (WHO) and celebrated each year on March 3. 2022 (Excellence): Northrop Grumman, St. Augustine site.",1
"At this site, Northrop Grumman conducts ongoing noise monitoring; implements noise controls; adopts buy-quiet strategies in the purchase of new equipment and tools; provides several alternatives of hearing protection devices and hearing protection fit-testing with accompanying individual, periodic training; provides state-of-the art communication-enhanced electronic hearing protection devices; carefully analyzes pure tone audiometry results aiming to identify early changes, and finally; continuously improving their training to ensure relevance. Employees at all levels are engaged in the initiatives.",1
Buy Quiet List of occupational health and safety awards Health effects from noise Occupational hearing loss Hearing Conservation Occupational noise World Hearing Day Official Website https://www.cdc.gov/niosh/enews/enewsv13n11.html https://www.cdc.gov/niosh/enews/enewsv10n11.html https://blogs.cdc.gov/niosh-science-blog/2017/03/03/firing-range-program/ Council for Accreditation in Occupational Hearing Conservation National Hearing Conservation Association Workplace Noise Assessments,1
"Sources, by motion Stationary source – flue gas stacks are examples of stationary sources Mobile source – buses are examples of mobile sources Sources, by urbanization level – whether the source is within a city or not is relevant in that urban areas constitute a so-called heat island and the heat rising from an urban area causes the atmosphere above an urban area to be more turbulent than the atmosphere above a rural area Urban source – emission is in an urban area Rural source – emission is in a rural area Sources, by elevation Surface or ground-level source Near surface",1
"Such that, for flows where the cloud of pollutant is smaller than the largest eddies present, there will be mixing. There is no limit on the size on mixing motions in the atmosphere and therefore bigger clouds will experience larger and stronger mixing motions. And hence, this type of dispersion is scale dependent.",1
The stability class can be defined also by using the Temperature gradient fluctuations in wind direction Richardson number Bulk Richardson number Monin–Obukhov length,1
"The SafeMed II Project assists the Mediterranean partner Beneficiaries with the further implementation of the 2007 adopted Regional Transport Action Plan (RTAP) for the Mediterranean 2007-2013. The Project offers training programmes and assistance, promotes a common platform for best practices to regulate maritime traffic in the Mediterranean, and seeks to achieve improved access to information for all. The Project funds scholarships to internationally recognized maritime universities (such as the World Maritime University), organises seminars and workshops and publishes its own quarterly newsletter, the SafeMed Beacon. SafeMed Project Official Site SafeMed II Technical Annex Summary",1
"The study attempted to resolve this issue by introducing clinoptilolite to the diet of the herd, but has found inconclusive evidence which requires more study of clinoptilolite effects on methanogenesis and biohydrogenation.",1
Saving on capital expenditure while benefiting from new technologies Optimization of existing plant components Adaptation of the plant for new or changed products Increase in piece number and cycle time Guaranteed spare parts availability Reduced maintenance costs and increased reliability,1
"Car customizing is a form of retrofitting, where older vehicles are fitted with new technologies: power windows, cruise control, remote keyless systems, electric fuel pumps, driverless systems, etc. Trucks and agricultural machines can also be given retrofits to make them driverless.",1
"Many naval vessels have undergone retrofitting and refitting, sometimes entire classes at once. For instance, the New Threat Upgrade program of the US Navy saw many vessels retrofitted for improved anti-air capability. Naval vessels are often retrofit for one of three reasons: to incorporate new technology, to compensate for performance gaps or weaknesses in design, or to change the ship's classification. Militaries of the world are often ardent adopters of the latest technology, and many technological advances have been spurred by warfare, especially in fields such as radar and radio communications.",1
"Because of this, and the significant investment that a ship hull represents, it is common for retrofitting to be performed whenever new systems are developed. This may be as small as replacing one type of radio with another, or replacing out-dated cryptography equipment with more secure methods of communication, or as major as replacing entire guns and turrets, adding armor plate, or new propulsion systems. Other ships are retrofit to compensate for weaknesses perceived in their operational capabilities. This was the secondary purpose of the US Navy's New Threat Upgrade program, for instance.",1
"As an example, in the Star Trek MMORPG Star Trek Online players can purchase retrofitted ships of famous Star Trek ship classes, such as those crewed by the protagonists of the Star Trek TV series. This is done to allow players to pilot iconic ships from old series of the show, that wouldn't naturally be latest-and-greatest ships due to their obsolescence or size, but are retrofitted to be suitable for a maximum-level player-character admiral.",1
"Research indicates that when viewed from nearby, about half of skyglow arises from direct upward emissions, and half from reflected, though the ratio varies depending on details of lighting fixtures and usage, and distance of the observation point from the light source. In most communities, direct upward emission averages about 10–15%. Fully shielded lighting (with no light emitted directly upward) decreases skyglow by about half when viewed nearby, but by much greater factors when viewed from a distance. Skyglow is significantly amplified by the presence of snow, and within and near urban areas when clouds are present.",1
"In remote areas, snow brightens the sky, but clouds make the sky darker. There are two kinds of light scattering that lead to sky glow: scattering from molecules such as N2 and O2 (called Rayleigh scattering), and that from aerosols, described by Mie theory. Rayleigh scattering is much stronger for short-wavelength (blue) light, while scattering from aerosols is less affected by wavelength. Rayleigh scattering makes the sky appear blue in the daytime; the more aerosols there are, the less blue or whiter the sky appears.",1
"In many areas, most particularly in urban areas, aerosol scattering dominates, due to the heavy aerosol loading caused by modern industrial activity, power generation, farming and transportation. Despite the strong wavelength dependence of Rayleigh scattering, its effect on sky glow for real light sources is small. Though the shorter wavelengths suffer increased scattering, this increased scattering also gives rise to increased extinction: the effects approximately balance when the observation point is near the light source.For",1
"Sky glow brightness arising from artificial light sources falls steeply with distance from the light source, due to the geometric effects characterized by an inverse square law in combination with atmospheric absorption. An approximate relation is given by intensity ∝ 1 distance 2.5 {\displaystyle {\text{intensity}}\ \propto \ {\frac {1}{{\text{distance}}^{2.5}}}\,} which is known as ""Walker's Law.""",1
"Walker's Law has been verified by observation to describe both the measurements of sky brightness at any given point or direction in the sky caused by a light source (such as a city), as well as to integrated measures such as the brightness of the ""light dome"" over a city, or the integrated brightness of the entire night sky. At very large distances (over about 50 km) the brightness falls more rapidly, largely due to extinction and geometric effects caused by the curvature of the Earth. Different light sources produce differing amounts of visual sky glow.",1
"The dominant effect arises from the Purkinje shift, and not as commonly claimed from Rayleigh scattering of short wavelengths (see § Mechanism). When observing the night sky, even from moderately light polluted areas, the eye becomes nearly or completely dark-adapted or scotopic. The scotopic eye is much more sensitive to blue and green light, and much less sensitive to yellow and red light, than the light-adapted or photopic eye. Predominantly because of this effect, white light sources such as metal halide, fluorescent, or white LED can produce as much as 3.3",1
"times the visual sky glow brightness of the currently most-common high-pressure sodium lamp, and up to eight times the brightness of low-pressure sodium or amber Aluminium gallium indium phosphide LED. In detail, the effects are complex, depending both on the distance from the source as well as the viewing direction in the night sky.",1
"But the basic results of recent research are unambiguous: assuming equal luminous flux (that is, equal amounts of visible light), and matched optical characteristics of the fixtures (particularly the amount of light allowed to radiate directly upward), white sources rich in shorter (blue and green) wavelengths produce dramatically greater sky glow than sources with little blue and green. The effect of Rayleigh scattering on skyglow impacts of differing light source spectra is very small. Much discussion in the lighting industry and even by some dark-sky advocacy organizations (e.g.",1
"International Dark-Sky Association) of the sky glow consequences of replacing the currently prevalent high-pressure sodium roadway lighting systems with white LEDs neglects critical issues of human visual spectral sensitivity, or focuses exclusively on white LED light sources, or focuses concerns narrowly on the blue portion (<500 nm) of the spectrum. All of these deficiencies lead to the incorrect conclusion that increases in sky glow brightness arising from the change in light source spectrum are minimal, or that light-pollution regulations that limit the CCT of white LEDs to so-called ""warm white"" (i.e. CCT <4000K or 3500K) will prevent sky glow increases.",1
"Improved efficiency (efficiency in distributing light onto the target area – such as the roadway – with diminished ""waste"" falling outside of the target area and more uniform distribution patterns) can allow designers to lower lighting amounts. But efficiency improvement sufficient to overcome sky glow doubling or tripling arising from a switch to even warm-white LED from high-pressure sodium (or a 4–8x increase compared to low-pressure sodium) has not been demonstrated.",1
"Fainter sights like the zodiacal light and Andromeda Galaxy are nearly impossible to discern even with telescopes. The effects of sky glow in relation to the ecosystem have observed to be detrimental to a variety of different organisms. The lives of plants and animals alike (especially those which are nocturnal) are affected as their natural environment becomes subjected to unnatural change. It can be assumed that the rate of human development technology exceeds the rate of non-human natural adaptability to their environment, therefore, organisms such as plants and animals are unable to keep up and can suffer as a consequence.",1
"Although sky glow can be the result of a natural occurrence, the presence of artificial sky glow has become a detrimental problem as urbanization continues to flourish. The effects of urbanization, commercialization, and consumerism are the result of human development; these developments in turn have ecological consequences. For example, lighted fishing fleets, offshore oil platforms, and cruise ships all bring the disruption of artificial night lighting to the world's oceans.As",1
"a whole, these effects derive from changes in orientation, disorientation, or misorientation, and attraction or repulsion from the altered light environment, which in turn may affect foraging, predator-prey dynamics, reproduction, migration, and communication. These changes can even result in the death of some species such as certain migratory birds, sea creatures, and nocturnal predators.Besides the effect on animals, crops and trees are also very susceptible to destruction. The constant exposure to light has an impact of the photosynthesis of a plant, as a plant needs a balance of both sun and darkness in order for it to survive.",1
"In turn, the effects of sky glow can affect production rates of agriculture, especially in farming areas that are close to large city centers.",1
SPIE Newsroom article on reducing skyglow,1
"Hassan, John. The Seaside, Health and Environment in England and Wales Since 1800. Ashgate Publishing.",1
9–38,1
"The organic matter in sewage can be classified in terms of form and size: Suspended (particulate) or dissolved (soluble). Secondly, it can be classified in terms of biodegradability: either inert or biodegradable.: 35 The organic matter in sewage consists of protein compounds (about 40%), carbohydrates (about 25–50%), oils and grease (about 10%) and urea, surfactants, phenols, pesticides and others (lower quantity).:",1
The mass load of organic content is calculated as the sewage flowrate multiplied with the concentration of the organic matter in the sewage.: 55 Typical values for physical–chemical characteristics of raw sewage is provided further down below.,1
"are either inorganic (polyphosphates and orthophosphates) and their main source is from detergents and other household chemical products. The other form is organic phosphorus, where the source is organic compounds to which the organic phosphorus is bound.: 45",1
"Human feces in sewage may contain pathogens capable of transmitting diseases.: 9–38 The following four types of pathogens are found in sewage: Bacteria like Salmonella, Shigella, Campylobacter, or Vibrio cholerae; Viruses like hepatitis A, rotavirus, coronavirus, enteroviruses; Protozoa like Entamoeba histolytica, Giardia lamblia, Cryptosporidium parvum; and Helminths and their eggs including Ascaris (roundworm), Ancylostoma (hookworm), and Trichuris (whipworm)In most practical cases, pathogenic organisms are not directly investigated in laboratory analyses. An easier way to assess the presence of fecal contamination is by assessing the most probable numbers of fecal coliforms (called thermotolerant coliforms), especially Escherichia coli.",1
"Escherichia coli are intestinal bacteria excreted by all warm blooded animals, including human beings, and thus tracking their presence in sewage is easy, because of their substantially high concentrations (around 10 to 100 million per 100 mL).: 52",1
"The ability of a flush toilet to make things ""disappear"" is soon recognized by young children who may experiment with virtually anything they can carry to the toilet. Adults may be tempted to dispose of toilet paper, wet wipes, diapers, sanitary napkins, tampons, tampon applicators, condoms, and expired medications, even at the risk of causing blockages. The privacy of a toilet offers a clandestine means of removing embarrassing evidence by flushing such things as drug paraphernalia, pregnancy test kits, combined oral contraceptive pill dispensers, and the packaging for those devices.",1
"There may be reluctance to retrieve items like children's toys or toothbrushes which accidentally fall into toilets, and items of clothing may be found in sewage from prisons or other locations where occupants may be careless. Trash and garbage in streets may be carried to combined sewers by stormwater runoff.",1
"Typical values for physical–chemical characteristics of raw sewage in developing countries have been published as follows: 180 g/person/d for total solids (or 1100 mg/L when expressed as a concentration), 50 g/person/d for BOD (300 mg/L), 100 g/person/d for COD (600 mg/L), 8 g/person/d for total nitrogen (45 mg/L), 4.5 g/person/d for ammonia-N (25 mg/L) and 1.0 g/person/d for total phosphorus (7 mg/L).:",1
"57 The typical ranges for these values are: 120–220 g/person/d for total solids (or 700–1350 mg/L when expressed as a concentration), 40–60 g/person/d for BOD (250–400 mg/L), 80–120 g/person/d for COD (450–800 mg/L), 6–10 g/person/d for total nitrogen (35–60 mg/L), 3.5–6 g/person/d for ammonia-N (20–35 mg/L) and 0.7–2.5 g/person/d for total phosphorus (4–15 mg/L).: 57 For high income countries, the ""per person organic matter load"" has been found to be approximately 60 gram of BOD per person per day.",1
"mg/L) and 3.28 g/person/d for total phosphorus (17.3 mg/L). The concentration values given here are based on a flowrate of 190 L per person per day.: 183 A United States source published in 1972 estimated that the daily dry weight of solid wastes per capita in sewage is estimated as 20.5 g (0.72 oz) in feces, 43.3 g (1.53 oz) of dissolved solids in urine, 20 g (0.71 oz) of toilet paper, 86.5 g (3.05 oz) of greywater solids, 30 g (1.1",1
"Sewage is commonly collected and transported in gravity sewers, either in a sanitary sewer or in a combined sewer. The latter also conveys urban runoff (stormwater) which means the sewage gets diluted during rain events.: 9",1
"27 Mixing industrial wastewater with sewage does nothing to reduce the mass of pollutants to be treated, but the volume of sewage lowers the concentration of pollutants unique to industrial wastewater, and the volume of industrial wastewater lowers the concentration of pollutants unique to sewage.",1
"In order to maintain low gas velocities, spray towers must be larger than other scrubbers that handle similar gas stream flow rates. Another problem occurring in spray towers is that after the droplets have fallen a short distance, they tend to agglomerate or hit the walls of the tower. Consequently, the total liquid surface area for contact is reduced, reducing the collection efficiency of the scrubber. In addition to a countercurrent-flow configuration, the flow in spray towers can be either a cocurrent or crosscurrent in configuration. In cocurrent-flow spray towers, the inlet gas and liquid flow in the same direction.",1
"Because the gas stream does not ""push"" against the liquid sprays, the gas velocities through the vessels are higher than in countercurrent-flow spray towers. Consequently, cocurrent-flow spray towers are smaller than countercurrent-flow spray towers treating the same amount of exhaust flow. In crosscurrent-flow spray towers, also called horizontal-spray scrubbers, the gas and liquid flow in directions perpendicular to each other. In this vessel, the gas flows horizontally through a number of spray sections.",1
"They are adequate for the collection of coarse particles larger than 10–25 µm in diameter, although with increased liquid inlet nozzle pressures, particles with diameters of 2.0 µm can be collected. Smaller droplets can be formed by higher liquid pressures at the nozzle. The highest collection efficiencies are achieved when small droplets are produced and the difference between the velocity of the droplet and the velocity of the upward-moving particles is high. Small droplets, however, have small settling velocities, so there is an optimum range of droplet sizes for scrubbers that work by this mechanism.",1
"The last cases of smallpox occurred in an outbreak of two cases, one of which was fatal, in Birmingham, United Kingdom, in 1978. A medical photographer, Janet Parker, contracted the disease at the University of Birmingham Medical School and died on September 11, 1978. In light of this incident, all known stocks of the smallpox virus were destroyed or transferred to one of two World Health Organization reference laboratories which had BSL-4 facilities—the Centers for Disease Control and Prevention (CDC) in the United States and the State Research Center of Virology and Biotechnology VECTOR in Koltsovo, Russia.",1
"Since 1984, these two labs have been the only ones authorized by the WHO to hold stocks of live smallpox virus.In 1986, the WHO first recommended destruction of all smallpox samples, and later set the date of destruction to be 30 December 1993. This was postponed to 30 June 1999, then again to 30 June 2002. Due to resistance from the U.S. and Russia, in 2002 the World Health Assembly agreed to permit temporary retention of the virus stocks for specific research purposes.",1
"Destroying existing stocks would reduce the risk involved with ongoing smallpox research; the stocks are not needed to respond to a smallpox outbreak. Some scientists have argued that the stocks may be useful in developing new vaccines, antiviral drugs, and diagnostic tests. A 2010 review by a team of public health experts appointed by the WHO, however, concluded that no essential public health purpose is served by the American and Russian laboratories continuing to retain live virus stocks. The latter view is frequently supported in the scientific community, particularly among veterans of the WHO Smallpox Eradication Program (1958–1979).",1
"An Ad Hoc Committee on Orthopox Infections, advising the WHO, has debated the fate of the remaining samples of smallpox in the remaining two official repositories since 1980. Smallpox expert D. A. Henderson has been foremost in favor of destruction, while U.S. Army scientist Peter Jahrling has argued against it on the basis that further research is needed, since he believes that smallpox almost certainly exists outside of the repositories. Other scientists have expressed similar opinions.",1
"In 2011, Kathleen Sebelius, Secretary of the U.S. Department of Health and Human Services, laid out the rationale of the administration of President Barack Obama in a New York Times op-ed piece. She said, in part: The global public health community assumes that all nations acted in good faith; however, no one has ever attempted to verify or validate compliance with the WHO request…. Although keeping the samples may carry a minuscule risk, both the United States and Russia believe the dangers of destroying them now are far greater…. It is quite possible that undisclosed or forgotten stocks exist.",1
"Also, 30 years after the disease was eradicated, the virus' genomic information is available online and the technology now exists for someone with the right tools and the wrong intentions to create a new smallpox virus in a laboratory…. Destroying the virus now is merely a symbolic act that would slow our progress and could even stop it completely, leaving the world vulnerable…. Destruction of the last securely stored viruses is an irrevocable action that should occur only when the global community has eliminated the threat of smallpox once and for all.",1
"To do any less keeps future generations at risk from the re-emergence of one of the deadliest diseases humanity has ever known. Until this research is complete, we cannot afford to take that risk.",1
"In 2013, cloned variola major (smallpox) DNA fragments were found in a South African laboratory. The WHO arranged to oversee their destruction, which took place in January 2014. On July 1, 2014, the U.S. National Institutes of Health (NIH) notified the regulatory agency, the Division of Select Agents and Toxins (DSAT) of the CDC, that employees had discovered vials labeled ""variola"" in an unused portion of a storage room in a U.S. Food and Drug Administration (FDA) laboratory located on the NIH Bethesda campus.",1
"In a media statement made seven days later, the CDC confirmed that variola major had been found and it had been transferred to a BSL-4 laboratory at the CDC in Atlanta. Overnight PCR testing had shown the vials did contain variola major. The vials were believed to have been from the 1950s. Further testing showed that the vials contained viable (live) variola major virus. As of the end of 2014, the vials were placed in a secure freezer to await destruction. The protocol for destruction of variola major virus involves a member of the WHO being present at the destruction.",1
"Usually the observer watches via closed-circuit television outside the room where the variola virus is autoclaved to destroy it. As a result of the Ebola outbreak in parts of Africa around the same time, the WHO were overstretched and stated they had no one locally with sufficient security clearance to enter a BSL-4 laboratory. Due to this the WHO were planning to fly an official into Atlanta to oversee the destruction at a future date. The vials were finally destroyed on February 24, 2015, under the supervision of WHO officials.",1
"In September 2019, the Russian lab housing smallpox samples experienced a gas explosion that injured one worker. It did not occur near the virus storage area, and no samples were compromised, but the incident prompted a review of risks to containment.",1
"Xylenes are an important petrochemical produced by catalytic reforming and also by coal carbonisation in the manufacture of coke fuel. They also occur in crude oil in concentrations of about 0.5–1%, depending on the source. Small quantities occur in gasoline and aircraft fuels. Xylenes are produced mainly as part of the BTX aromatics (benzene, toluene, and xylenes) extracted from the product of catalytic reforming known as reformate. Several million tons are produced annually. In 2011, a global consortium began construction of one of the world's largest xylene plants in Singapore.",1
"Xylene was first isolated and named in 1850 by the French chemist Auguste Cahours (1813–1891), having been discovered as a constituent of wood tar. Xylenes are produced by the methylation of toluene and benzene. Commercial or laboratory-grade xylene produced usually contains about 40–65% of m-xylene and up to 20% each of o-xylene, p-xylene and ethylbenzene. The ratio of isomers can be shifted to favor the highly valued p-xylene via the patented UOP-Isomar process or by transalkylation of xylene with itself or trimethylbenzene. These conversions are catalyzed by zeolites.ZSM-5",1
"Oxidation and ammoxidation also target the methyl groups, affording dicarboxylic acids and the dinitriles. Electrophiles attack the aromatic ring, leading to chloro- and nitroxylenes. Xylene is flammable but of modest acute toxicity, with LD50 ranges from 200 to 5000 mg/kg for animals. Oral LD50 for rats is 4300 mg/kg. The principal mechanism of detoxification is oxidation to methylbenzoic acid and hydroxylation to hydroxylene.The main effect of inhaling xylene vapor is depression of the central nervous system (CNS), with symptoms such as headache, dizziness, nausea and vomiting. At an exposure of 100 ppm, one may experience nausea or a headache.",1
"At an exposure between 200 and 500 ppm, symptoms can include feeling ""high"", dizziness, weakness, irritability, vomiting, and slowed reaction time.The side effects of exposure to low concentrations of xylene (< 200 ppm) are reversible and do not cause permanent damage. Long-term exposure may lead to headaches, irritability, depression, insomnia, agitation, extreme tiredness, tremors, hearing loss, impaired concentration and short-term memory loss. A condition called chronic solvent-induced encephalopathy, commonly known as ""organic-solvent syndrome"" has been associated with xylene exposure. There is very little information available that isolates xylene from other solvent exposures in the examination of these effects.Hearing",1
"NIOSH Pocket Guide to Chemical Hazards (o-Xylene) NIOSH Pocket Guide to Chemical Hazards (m-Xylene) NIOSH Pocket Guide to Chemical Hazards (p-Xylene) Xylene, Hazard Summary (EPA) (Mixed Isomers) The Ear Poisons, The Synergist, American Industrial Hygiene Association, November, 2018",1
The low-pressure sodium arc discharge lamp was first made practical around 1920 owing to the development of a type of glass that could resist the corrosive effects of sodium vapor. These operated at pressures of less than 1 Pa and produced a near monochromatic light spectrum around the sodium emission lines at 589.0 and 589.56 nanometres wavelength. The yellow light produced by these limited the range of applications to those where color vision was not required.Research into high-pressure sodium lamps occurred in both the United Kingdom and the United States.,1
"The material was available in the form of tubing by 1962, but additional techniques were required to seal the tubes and add the necessary electrodes—the material could not be fused like quartz. The end caps of the arc tube would get as hot as 800 degrees C in operation, then cool to room temperature when the lamp was turned off, so the electrode terminations and arc tube seal had to tolerate repeated temperature cycles. This problem was solved by Michael Arendash at the GE Nela Park plant.",1
"The discharge tube may be linear (SLI lamp) or U-shaped. When the lamp is first started, it emits a dim red/pink light to warm the sodium metal; within a few minutes as the sodium metal vaporizes, the emission becomes the common bright yellow. These lamps produce a virtually monochromatic light averaging a 589.3 nm wavelength (actually two dominant spectral lines very close together at 589.0 and 589.6 nm). The colors of objects illuminated by only this narrow bandwidth are difficult to distinguish.",1
"LPS lamps have an outer glass vacuum envelope around the inner discharge tube for thermal insulation, which improves their efficiency. Earlier LPS lamps had a detachable dewar jacket (SO lamps). Lamps with a permanent vacuum envelope (SOI lamps) were developed to improve thermal insulation. Further improvement was attained by coating the glass envelope with an infrared reflecting layer of indium tin oxide, resulting in SOX lamps.LPS lamps are among the most efficient electrical light sources when measured in photopic lighting conditions, producing above 100 and up to 206 lm/W.",1
"They do not exhibit a bright arc as do High-intensity discharge (HID) lamps; they emit a softer luminous glow, resulting in less glare. Unlike HID lamps, during a voltage dip low-pressure sodium lamps return to full brightness rapidly. LPS lamps are available with power ratings from 10 to 180 W; longer lamp lengths can, however, suffer design and engineering problems. Modern LPS lamps have a service life of about 18,000 hours and do not decline in lumen output with age, though they do increase in energy consumption by about 10% towards end of life.",1
"This property contrasts with mercury vapor HID lamps, which become dimmer towards the end of life to the point of being ineffective, while consuming undiminished electrical power. In 2017 Philips Lighting, the last manufacturer of LPS lamps, announced they were discontinuing production of the lamps due to falling demand. Initially, production was due to be phased out in the course of 2020, but this date was brought forward and the last lamps were produced at the Hamilton factory on December 31, 2019.",1
"The yellow color of low-pressure sodium lamps also leads to the least visual sky glow, due primarily to the Purkinje shift of dark-adapted human vision, causing the eye to be relatively insensitive to the yellow light scattered at low luminance levels in the clear atmosphere. One consequence of widespread public lighting is that on cloudy nights, cities with enough lighting are illuminated by light reflected off the clouds. Where sodium vapor lights are the source of urban illumination, the night sky is tinged with orange.",1
"An amalgam of metallic sodium and mercury lies at the coolest part of the lamp and provides the sodium and mercury vapor that is needed to draw an arc. The temperature of the amalgam is determined to a great extent by lamp power. The higher the lamp power, the higher will be the amalgam temperature. The higher the temperature of the amalgam, the higher will be the mercury and sodium vapor pressures in the lamp and the higher will be the terminal voltage.",1
"As the temperature rises, the constant current and increasing voltage consumes increasing energy until the operating level of power is reached. For a given voltage, there are generally three modes of operation: The lamp is extinguished and no current flows. The lamp is operating with liquid amalgam in the tube. The lamp is operating with all amalgam evaporated.The first and last states are stable, because the lamp resistance is weakly related to the voltage, but the second state is unstable.",1
"Any anomalous increase in current will cause an increase in power, causing an increase in amalgam temperature, which will cause a decrease in resistance, which will cause a further increase in current. This will create a runaway effect, and the lamp will jump to the high-current state (#3). Because actual lamps are not designed to handle this much power, this would result in catastrophic failure. Similarly, an anomalous drop in current will drive the lamp to extinction.",1
"The ballast is usually inductive rather than simply being resistive to minimize energy waste from resistance losses. Because the lamp effectively extinguishes at each zero-current point in the AC cycle, the inductive ballast assists in the reignition by providing a voltage spike at the zero-current point. The light from the lamp consists of atomic emission lines of mercury and sodium, but is dominated by the sodium D-line emission. This line is extremely pressure (resonance) broadened and is also self-reversed because of absorption in the cooler outer layers of the arc, giving the lamp its improved color rendering characteristics.",1
"In addition, the red wing of the D-line emission is further pressure broadened by the Van der Waals forces from the mercury atoms in the arc. At end of life, high-pressure sodium (HPS) lamps exhibit a phenomenon known as cycling, caused by a loss of sodium in the arc. Sodium is a highly reactive element and is lost in a reaction with the aluminum oxide of the arc tube.",1
"The products are sodium oxide and aluminum: 6 Na + Al2O3 → 3 Na2O + 2 AlAs a result, these lamps can be started at a relatively low voltage, but, as they heat up during operation, the internal gas pressure within the arc tube rises, and more and more voltage is required to maintain the arc discharge. As a lamp gets older, the maintaining voltage for the arc eventually rises to exceed the maximum voltage output by the electrical ballast. As the lamp heats to this point, the arc fails, and the lamp goes out.",1
"Eventually, with the arc extinguished, the lamp cools down again, the gas pressure in the arc tube is reduced, and the ballast can once again cause the arc to strike. The effect of this is that the lamp glows for a while and then goes out, typically starting at a pure or bluish white then moving to a red-orange before going out. More sophisticated ballast designs detect cycling and give up attempting to start the lamp after a few cycles, as the repeated high-voltage ignitions needed to restart the arc reduce the lifetime of the ballast.",1
"If power is removed and reapplied, the ballast will make a new series of startup attempts. LPS lamp failure does not result in cycling; rather, the lamp will simply not strike or will maintain the dull red glow of the start-up phase. In another failure mode, a tiny puncture of the arc tube leaks some of the sodium vapor into the outer vacuum bulb. The sodium condenses and creates a mirror on the outer glass, partially obscuring the arc tube. The lamp often continues operating normally, but much of the light generated is obscured by the sodium coating, providing no illumination.",1
"van Vliet; J A J M (1986). The High-Pressure Sodium Lamp. Deventer: Kluwer Technische Boeken BV. ISBN 978-90-201-1902-2. OCLC 16637733. Waymouth, John F (1971). Electric Discharge Lamps. Cambridge, MA: MIT Press. ISBN 978-0-262-23048-3. OCLC 214331. USA patent US3737717A, Arendash, Michael, ""High intensity lamp containing thermal shorting fuse"", published 1972-03-13, issued 1973-06-05, assigned to General Electric Co Museum of Electric Discharge Lamps",1
Overwatering through irrigation by sprinkler may produce runoff reaching receiving waters during low flow conditions. Runoff carries accumulated pollutants to streams with unusually low dilution ratios causing higher pollutant concentrations than would be found during regional precipitation events.,1
"Urban runoff is a major cause of urban flooding, the inundation of land or property in a built-up environment caused by rainfall overwhelming the capacity of drainage systems, such as storm sewers. Triggered by events such as flash flooding, storm surges, overbank flooding, or snow melts, urban flooding is characterized by its repetitive, costly, and systemic impacts on communities, even when not within floodplains or near any body of water.There",1
"prevention practices include low impact development (LID) or green infrastructure techniques - known as Sustainable Drainage Systems (SuDS) in the UK, and Water-Sensitive Urban Design (WSUD) in Australia and the Middle East - such as the installation of green roofs and improved chemical handling (e.g. management of motor fuels & oil, fertilizers, pesticides and roadway deicers). Runoff mitigation systems include infiltration basins, bioretention systems, constructed wetlands, retention basins, and similar devices.Providing effective urban runoff solutions often requires proper city programs that take into account the needs and differences of the community.",1
"The SPEAR Calculator provides most recent information on species traits and allows specific user settings. The SPEARpesticides index is computed as relative abundance of vulnerable 'SPecies At Risk' (SPEAR) to be affected by pesticides. Relevant species traits comprises the physiological sensitivity towards pesticides, generation time, migration ability and exposure probability.",1
The indicator value of SPEARpesticides at a sampling site is calculated as follows: S P E A R p e s t i c i d e s = ∑ i = 1 n log ⁡ ( x i + 1 ) y ∑ i = 1 n log ⁡ ( x i + 1 ) {\displaystyle SPEAR_{pesticides}={\frac {\sum _{i=1}^{n}\log(x_{i}+1)y}{\sum _{i=1}^{n}\log(x_{i}+1)}}} with n = number of taxa; xi = abundance of taxon i; y = 1 if taxon i is classified as SPEAR-sensitive; y = 0 if taxon i is classified as SPEAR-insensitive. An application is available as download for PC.,1
Web address to download the SPEAR calculator,1
"The change of atmospheric pressure with altitude can be obtained from this equation: P a = 0.9877 a {\displaystyle P_{a}=0.9877^{a}} Given an atmospheric pollutant concentration at an atmospheric pressure of 1 atmosphere (i.e., at sea level altitude), the concentration at other altitudes can be obtained from this equation: C a = C ⋅ 0.9877 a {\displaystyle C_{a}=C\cdot 0.9877^{a}} As an example, given a concentration of 260 mg/m3 at sea level, calculate the equivalent concentration at an altitude of 1,800 meters: Ca = 260 × 0.9877",1
That being understood: 1 Nm3 of any gas (measured at 0 °C and 1 atmosphere of absolute pressure) equals 37.326 scf of that gas (measured at 60 °F and 1 atmosphere of absolute pressure). 1 kmol of any ideal gas equals 22.414 Nm3 of that gas at 0 °C and 1 atmosphere of absolute pressure ... and 1 lbmol of any ideal gas equals 379.482 scf of that gas at 60 °F and 1 atmosphere of absolute pressure.,1
) = 44.44 ppmv.,1
ppmv (dry basis) of NOx when corrected to a gas having a specified reference O2 content of 3 volume %.,1
"TEOM instruments are faster than and avoid difficulties with beta attenuation and quartz crystal microbalance (QCM) methods.TEOM is the basis for a continuous personal dust monitor (CPDM) for coal dust in mines, to protect workers from exposure to coal mine dust which leads to black lung disease and progressive massive fibrosis. Prior to the introduction of CPDMs, dust particles collected on a filter needed to be analyzed in a laboratory, leading to a delay of weeks in obtaining results.",1
"and continued by Thermo Fisher under contract from the U.S. National Institute for Occupational Safety and Health with input from other government, labor, and industry organizations. Machine-mounted continuous dust monitors have been available since 1997. Patashnick, H.; Meyer, M.; Rogers, B. (2002). ""Tapered element oscillating microbalance technology"". Mine Ventilation. Taylor & Francis. pp. 625–631. doi:10.1201/9781439833742.ch89. ISBN 9789058093875.",1
"In the discussions between countries on long-term sustainability, technical improvements are given more importance than introducing and applying new legal regimes. Specifically, technical approaches to space debris have been proposed, such as debris removal. Specific data on space debris is also being explored to help study its impact on sustainability and promote further cooperation between countries. Space sustainability comes into play to address the pressing current state of near-Earth orbits and its high amounts of orbital debris. Spacecraft collisions with orbital debris, space weather, overcrowding in low earth orbit (LEO) makes spacecraft susceptible to higher rates of failure.",1
"The current end-of-life protocol for spacecraft exacerbates the space sustainability crisis; many spacecraft are not properly disposed, which increasing the likelihood of further collisions.",1
"Orbital debris is defined as unmanned, inoperate objects that exist in space. This orbital debris breaks down further as time progresses as a result of naturally occurring events, such as high-velocity collisions with micrometeoroids, and forced events, such as a controlled release of a launch vehicle. In LEO, these collisions can take place at speeds anywhere between an average velocity of 9 kilometers per second (km/s) and 14 km/s relative to the debris and spacecraft.",1
"In GEO, however, these high-speed collisions are a much lower risk as the average relative velocity between the debris and spacecraft is typically between 0 km/s and 2.5 km/s. As of 2012, the United States Joint Space Operations Center tracked 21,000 pieces of orbital debris larger than 10 cm in Earth's nearby orbits (LEO, GEO, and sun-synchronous), where 16,000 of these pieces are catalogued. Space debris can be categorized into three categories: small, medium, and large. Small debris is for pieces that are less than 10 centimeters (cm).",1
"Space weather poses a risk to satellite health, consequently, resulting in greater amounts of orbital debris. Space weather impacts satellite health in a variety of ways. Firstly, surface charging from the sun's surface facilitates electrical discharges, damaging on-orbit electronics, posing a threat to mission failure. Single Event Upsets (SEUs) can also damage electronics. Dielectric charging and bulk charging can also occur, causing energy problems within the spacecraft. Additionally, at altitudes less than one thousand kilometers, atmospheric drag can increase during solar storms by increasing the altitude of the spacecraft, only adding more drag onto the spacecraft.",1
"These factors degrade performance over the spacecraft's lifetime, leaving the spacecraft more susceptible to further system and mission failures.",1
"Microsatellites built by universities or research organizations have also increased in popularity, contributing to the overcrowding of near earth orbits. This overcrowding of LEO and GEO orbits increases the likelihood of potential collisions among satellites and orbital debris, contributing further to the large amount of orbital debris present in space.",1
"The current end of life protocol is that at the end of mission, spacecraft are either added to the graveyard orbit or at a low enough altitude that drag will allow the spacecraft to burn up upon reentry and fall back to Earth. Approximately twenty satellites are put into the graveyard orbit each year. There is no current process to return satellites to Earth after entering the graveyard orbit. The process of a spacecraft returning to Earth via drag can take between ten and one hundred years. This protocol is critical to reduce overcrowding in near-Earth orbits.",1
"The impact of constellations on the space environment has also been studied, such as the probability of collisions of mega constellations in the presence of large amounts of space debris. Although studies have shown that the predictors of mega constellations are highly variable, specific information related to mega constellations is not transparent.But any catastrophic collision, as in the case of Kessler syndrome, has consequences for people and the environment. Putting this thinking into mega constellations, mega constellations existence may have potential benefits, but it will not bring adequate help to the governance of space debris.",1
"At the same time, the space debris situation cannot be underestimated or ignored because of the existence of mega constellations. The existence of orbital debris has caused great trouble to the conduct of space activities. The development of space sustainability has not given sufficient political attention, although some warnings and discussions have made this abundantly clear. Debris management is still voluntary on the part of the state, and there are no laws mandating debris management practices, including the amount of debris to be managed.",1
"Although the UN Space Debris Mitigation Guidelines were promulgated in 2007 as an initial measure of space debris governance, there is still no broad consensus or action on further limits on space debris after that. The difficulties for individuals wishing to participate in debris management initiatives cannot be ignored. Any individual or sector desiring to participate in space debris operations needs to obtain permission from the launching state, which is difficult for the launching state to do.",1
"This is because the process of space debris management inevitably has a negative impact on other space objects, and there is a lot of subsequent liability in terms of financial consumption. Therefore, the launching state would argue that space debris management requires the joint efforts of all states. However, it is difficult to determine what actions can be taken to gain acceptance between countries. Current space sustainability efforts rely heavily on the precedent set by regulatory agreements and conventions of the twentieth century.",1
"Much of this precedent is included in or is related to the Outer Space Treaty of 1963, which represented one of the initial major efforts by the United Nations to create legal frameworks for the operation of nations in space.",1
"The international community has had concerns about space contamination since the 1950s prior to the launch of Sputnik I. These concerns stemmed from the idea that increasing rates of exploration into further areas of outer space could lead to contamination capable of damaging other planetary bodies, resulting in limitations to human exploration on these bodies and potential harm to the Earth. Efforts to combat these concerns began in 1956 with the International Astronautical Federation (IAF) and the United Nations Committee on the Peaceful Uses of Outer Space (COPUOUS).",1
These efforts continued to 1957 through the National Academy of Sciences and International Council for Science (ICSU). Each of these organizations aimed to study space contamination and develop strategies for how to best address its potential consequences. The ICSU went on to create the Committee on Contamination by Extraterrestrial Exploration (CETEX) that put forward recommendations leading to the establishment of the Committee on Space Research (COSPAR). COSPAR continues to address outer space research on an international scale today [cite cospar].,1
"Relevant regulations of international space law to sustainability in space can be found in the Outer Space Treaty, which was adopted by the UN General Assembly in 1963. The Outer Space Treaty contains seventeen articles designed to create a basic framework for how international law can be applied in outer space. Basic principles of the Outer Space Treaty include the provision in Article IX that parties should ""avoid harmful contamination of space and celestial bodies;"" definitions of ""harmful contamination"" are not provided.",1
"Principles of Article IX provided the basis for the Committee of Space Research (COSPAR) Planetary Protection Policy guidelines, which are generally well-regarded among scientific experts. Such guidelines, however, are non-binding and often described as ""soft-law,"" as they lack legal mandate. The Planetary Protection Policy is primarily concerned with providing information regarding best practices to avoid contamination of the space environment during space exploration missions. COSPAR believes that the prevention of such contamination is in the best interest of humanity as it may impede scientific progress, exploration, and the mission of a search for life.",1
"In addition, the argument is made that cross-contamination of the Earth can be potentially harmful to its environment due to the largely unknown nature of potential space contaminants.",1
"Regulatory clarifications concerning the Outer Space Treaty of 1963 of relevance to space sustainability were made in subsequent years. The 1967 Return Agreement relates mainly to the return of lost astronauts to their appropriate nations, but also requires Outer Space Treaty signing nations to assist other nations with the return of objects that return to Earth from orbit to their proper owners The 1972 Liability Convention attributes liability for damages from space objects to the nation that launched the object, regardless of whether that damage occurred in space or on Earth.",1
"Other clarifications include the 1975 registration convention that attempted to create mechanisms for nations to identify space objects, and the 1979 Moon Agreement that established protections for the environments of the Moon and other nearby planetary bodies. These agreements and conventions represented attempts to improve the initial Outer Space Treaty as space exploration continued to grow in importance throughout the 20th century.",1
"Both the state and space agencies are working to improve the laws and regulations that facilitate the long-term sustainability of space. For example, the European Code of Conduct for Space Debris Mitigation signed by France, the UK and other countries in 2016. China, Brazil, Mexico and others have legal background and methodological measures under long-term space sustainability. However, the main problem is that until the concept of space sustainability is agreed between countries, inter-regional efforts are not working well.Currently,",1
"the Committee on the Peaceful Uses of Outer Space (COPUOS) encourages states to incorporate the space debris mitigation guidelines developed by bodies such as the Inter-Agency Space Debris Coordination (IADC) into their national legislation, thereby regulating state behavior. Some countries have responded positively to this, such as Switzerland, the Netherlands and Spain. However, there are still some countries that do not consider debris management approaches in their national legislation, such as Japan and Australia. Many delegates at the COPUOS meeting expressed their reasons for doing so, arguing that space debris management is closely linked to technology and funding.",1
"Technology is dynamic and constantly evolving. Therefore, the incorporation of debris governance guidelines into national law is not an immediate priority at this time.",1
"A study outlined rationale for governance that regulates the current free externalization of true costs and risks, treating orbital space around the Earth as an ""additional ecosystem"" or a common ""part of the human environment"" which should be subject to the same concerns and regulations like oceans on Earth. While scientists may not have the means to make and enforce global laws themselves, the study concluded in 2022 that it needs ""new policies, rules and regulations at national and international level"".",1
"Sustainability mitigation efforts include but are not limited to design specifications, policy change, removal of space debris, and restoration of orbiting semi-functional technologies. Efforts begin by regulating the debris released during normal operations and post-mission breakups [6]. Due to the increased awareness of high-velocity collisions and orbital debris in the previous decades, missions have adapted design specifications to account for these risks. For example, the RADARSAT program implemented 17 kilograms of shielding to their spacecraft, which increased the program's predicted success rate to 87% from 50%.",1
"Another effort in mitigation is restoring semi-functional satellites, which allows a spacecraft classified as “debris” to “functional.” Space debris mitigation focuses on limiting debris release during normal operations, collisions and intentional destruction. Mitigation also includes reducing the possibility for post-mission breakups due to stored energy and/or operations phases, as well as addressing procedure for end of mission disposal for spacecraft.",1
"One example leading the regulatory sustainability measures is the Space Sustainability Rating (SSR), which is an instigator for industry competitors to incorporate sustainability into spacecraft design. The Space Sustainability Rating was first conceptualized at the World Economic Forum Global Future Council on Space Technologies designed by international and transdisciplinary consortia. The four leading organizations are the European Space Agency, Massachusetts Institute of Technology, University of Texas at Austin, and BryceTech with the goal to define the technical and programmatic aspects of the SSR.",1
"Several of the factors emphasized in the rating were extracted from LEED design considerations like the incorporation of feedback and public comments, or the rating's advocacy to influence policy, such as orbit fragmentation risks, collision avoidance capabilities, trackability, and adoption of international standards.",1
"Tracking is one of the main Space Sustainability Rating modules’ efforts. The module ""Detectability, Identification and Tracking"" (DIT) consists of standardizing the comparison of satellite missions to encourage satellite operators to improve their satellite design and operational approaches for the observer to detect, identify, and track the satellites. Tracking presents challenges when the observer seeks to monitor and predict the spacecraft behavior over time. While the observer may know the name, owner, and instantaneous location of the satellite, the operator controls the full knowledge of the orbital parameters.",1
"The Space Situational Awareness (SSA) is one the tools geared towards solving the challenges presented when tracking orbiting satellites and debris. The SSA continuously tracks objects using ground-based radar and optical stations so the orbital paths of debris can be predicted and operations avoid collisions. It feeds data to 30 different systems like satellites, optical telescopes, radar systems, and supercomputers to predict risk of collision days in advance. Other efforts in tracking orbital debris are made by the US Space Surveillance Network (SSN).",1
"Since policy has not caught up to ensure the longevity of LEO for future generations, actions like Active Debris Removal (ADR) are being considered to stabilize the future of LEO environment. Most famous removal concepts are based on directed energy, momentum exchange or electrodynamics, aerodynamic drag augmentation, solar sails, auxiliary propulsion units, retarding surfaces and on-orbit capture. As ADR consists of an external disposal method to remove obsolete satellites or spacecraft fragments.",1
"Since large-sized debris objects in orbit provide a potential source for tens of thousands of fragments in the future, ADR efforts focus on objects with high mass and large cross-sectional areas, in densely populated regions, and at high altitudes; in this instance, retired satellites and rocket bodies are a priority. Other practical advancements toward space debris removal include missions like RemoveDEBRIS and End-of-Life Service (ELS-d). The previous reduced state of regulation and mitigation on space debris and rocket fuel emissions is aggravating the Earth's stratosphere through collisions and ozone depletion, increasing the risk for spacecraft health through its lifetime.",1
"Due to the increase of satellites being launched and the growing amount of orbital debris in LEO, the risk of LEO becoming inaccessible over time (in accordance with the Kessler syndrome) is increasing in likelihood. The mitigation policies for creating space debris fall under an area of voluntary codes by the states, although it has been disputed whether the Article I Outer Space Treaty or the Article IX Outer Space Treaty protects the space environment from deliberate harm, which has yet to be upheld.",1
"In 2007, an inactive Chinese satellite was purposefully destroyed by the Chinese government as a part of their anti-satellite weapon test (ASAT), spreading nearly 2800 objects of space debris five centimeters or larger into LEO. An analysis concluded that about eighty percent of the debris will remain in LEO nine years after this destruction. In addition, the destruction increased the collision likelihood for three Italian satellites that launched the same year as the Fengyun-1C destruction. The increase in collision ranged between ten and sixty percent. However, there were no legal consequences against the Chinese government.",1
"In addition, the soot particles form over a black umbrella over the stratosphere which can cause the temperature of the Earth's surface to lower and further depleting the ozone layer, an unintentional form of geoengineering. The nature of geoengineering has been disputed as a form of mitigating global warming and has the possibility of being banned and holding rockets accountable for the soot particles they distribute to the stratosphere.",1
"New types of engines and fuels are emerging, mainly the liquid oxygen (LOX) and monomethylhydrazine engine, but there is minimal research on their impact on the environment besides their emission of hydroxide and nitrogen oxide compounds, two molecules that have significant impact on the ozone layer. Currently, rocket fuel emissions have been deemed insignificant when it comes to their consequences to Earth's environment and LEO. However, emissions will increase in the coming years, making rocket fuel's contribution to global warming much more significant. Space sustainability concepts and mindsets tend to stay in Low Earth Orbit (LEO).",1
"One reason that cannot be ignored is that it is easier to discuss the problem at hand than to speculate on the unknown. There are also examples to prove that since Apollo 17 completed its mission and stayed in Low Earth orbit in 1972, human-crewed space missions in Low Earth orbit have ceased to exist. In this way, it is a reasonable assumption that the closer Moon could be the next object to be explored when the gaze is not limited to LEO. Both lunar orbit and LEO are part of the space environment.",1
"In the context of the presence of space debris in LEO, it is normal to speculate that lunar orbit also possesses the nuisance of debris. Space debris measures similar to those in LEO related to space sustainability would be taken.Not only has the Moon been the subject of study, but other bodies have also been taken into account. Elon Musk, the chief executive of SpaceX at the International Astronautical Congress in 2016, explained the ambitious goal of exploring Mars in the 22nd century.",1
"But complicated issues remain, such as the technical aspects of achieving long-distance space flight and the rules and legal aspects associated with the technology, all of which need to be considered. Asteroid mining#Regulation and safety Common heritage of humanity Graveyard orbit Human presence in space Kessler syndrome List of space debris producing events Rights of nature Satellite collision Spacecraft cemetery Space debris Space law",1
"Steven Reinhold started the TrashTag Challenge in 2015 after accidentally littering on a road trip. He vowed to gather 100 pieces of trash. ""On this road trip, we went to all these different national parks and we were basically geotagging the trash as we picked it up,"" Reinhold said. ""At some point, we said 'why not hashtag it #trashtag?'"" Reinhold partnered with UCO Gear and developed a cleanup ambassador program spreading the challenge in the outdoor community.Byron",1
"Roman, a Phoenix, Arizona, resident, reposted a picture on March 5, 2019, of a litter-strewn roadside area in Algeria along with an ""after"" shot of Drici Tani Younes posing with nine massive bags of trash, all stuffed to the brim in the middle of the freshly cleaned strip of dirt. The post went viral and was shared more than 300,000 times, prompting over fifty million new posts and imitators seeking to outdo Román or simply add to the impact of the #trashtag efforts. Trashtag has an estimated five million monthly participants.TrashTag",1
"cleanups have been held globally in cities, mountains, rivers, and beaches. They have ranged from Mount Everest to undersea diving excursions. Cleanup challenges have been held globally including the United States, Algeria, Malaysia, Mexico, India, Nepal, Norway, Scotland, RoC, and PR China as well as being replicated in other languages such as ""#basurachallenge"" for Spanish. Ocean Conservancy Outdoor recreation Plogging SpoGomi Littering TrashTag official website",1
"Toluene is an organic compound which is mostly harmless to adults and is sometimes abused as an inhalant. Fetal toluene syndrome has been defined and resembles fetal alcohol syndrome with resultant birth defects, but the U.S. Centers for Disease Control and Prevention have identified differentiating features between the two syndromes including FTS having the additional facial features of micrognathia, large anterior fontanel, down-turned mouth corners, hair patterning abnormalities, bifrontal narrowing of the face, and ear abnormalities.",1
It wasn't until the late 1990s that the federal government tried to track down people who may have been exposed.,1
"In some cases where results must be refereed (such as legal cases), model validation may be needed with field test data in the local setting; this step is not usually warranted, because the best models have been extensively validated over a wide spectrum of input data variables. The product of the calculations is usually a set of isopleths or mapped contour lines either in plan view or cross sectional view. Typically these might be stated as concentrations of carbon monoxide, total reactive hydrocarbons, oxides of nitrogen, particulate or benzene.",1
The resulting solution for an infinite line source is: χ = ∫ 0 ∞ q π ( u c d x 2 ) ( c o s α ) ( exp ⁡ y 2 2 c 2 x 2 ) d x {\displaystyle \chi \ =\int _{0}^{\infty }{\frac {q}{\pi \left(ucdx^{2}\right)\left(cos\alpha \ \right)}}\left(\exp {\frac {y^{2}}{2c^{2}x^{2}}}\right)dx} where: x is the distance from the observer to the roadway y is the height of the observer u is the mean wind speed α is the angle of tilt of the line source relative to the reference frame c and d are the standard deviation of,1
"The ESL research group also extended their model by introducing the area source concept of a vertical strip to simulate the mixing zone on the highway produced by vehicles turbulence. This model too was validated in 1971 and showed a good correlation with field test data. There were several early applications of the model in somewhat dramatic cases. In 1971 the Arlington Coalition on Transportation (ACT) was the plaintiff in an action against the Virginia Highway Commission over the extension of Interstate 66 through Arlington, Virginia, having filed a suit in the federal district court.",1
"One major option of the take-back system includes store retailers or producers taking back the products that have been distributed to their consumers in order to recycle the materials of these products. The take-back system encourages businesses to redesign their products into ones that are easily recyclable, reducing the burden that virgin materials have on the environment for the present and the future. This also gives companies an alternative supply of raw minerals. The other major option of the take-back system includes the store retailers or producers taking back their products in order to create new ones.",1
"Due to a high cost in recycling but low amount of customer incentive, companies and countries refrain from adapting a take-back system. To fix this, e-waste could be taken back by the producers for donations, for re-manufacturing, or for upgrades.",1
"Without legislation, a prominent take-back system cannot be achieved because current e-waste regulation systems are ""limited to private recycling of high-value waste with only limited consumer participation"". Rules and regulations that would incentive and fix issues regarding to the dumping electronic waste into landfills and prevent the illegal exportation of electronic waste are important to achieve success in e-waste management. The government would need to support it by giving incentives and the correct infrastructure in order to create such a system.",1
"""Initiatives refer to programs or schemes required to promote effective collection, recycling and disposal of e-waste"". Through these incentives, the government and producers of waste must promote e-waste management on their own by giving effort in collecting e-waste to recycle, renew, or reuse it.",1
"Consumers of the products must become aware to how managing their waste affects the environment and the lack of programs that help teach these aspects show to be big barriers to the effective management of waste. To manage the waste properly, consumers must begin to show responsibility in bringing in their e-waste while companies such as the producers of these products must be responsible for taking it back and dealing with it. Germany had set in put a packaging ordinance on June 12, 1991. ""It specifies mandatory quotas for recycling for glass, paper/paperboard/carton, tin plate, aluminum, plastic, and composites"".",1
"The responsibility for handling waste was put onto the manufacturer and distributor. As a result of the ordinance, ""in 1993, the beginning of the mandatory quotas, compared to 1992, there were 500,000 fewer tons of packaging"" and ""From 1993 to 1994, paper packaging recycling increased from 55% to 70.6%"". The system showed to be a success, as it reduced waste and redesigned packaging to be more environmentally friendly simply from integrating a version of the take-back system. While the take-back system aims to create more eco-friendly businesses, there are reasons why it does not profoundly exist today.",1
"The main reason for this is the lack of incentives. Being that there are products such as cars and computers that are unappealing to transport, the consumer finds it troubling and unappealing to bring these products back. Also, since many consumers see refurbished products as inferior and do not trust them, it is unappealing for companies to re-manufacture their own products for reselling purposes and thus cannot profit from it.",1
The Belgian company Eloy uses Xylit as filtering media in its X-Perco Aquaterra Solutions uses Xylit for riverbank stabilization lignite peat This article is partially translated from German and French Wikipedia articles.,1
Most SDG 14 targets are not measurable in quantitative terms because the data is not available yet; only target 14.5 is quantifiable.,1
"For all other sustainable development goals, there is no specific target in decreasing microplastics due to limitations of data. Furthermore, there are no targets in reference to reducing microplastics, thus presenting a large challenge for governments to report and monitor microplastics in the environment.Target 14.1 is supposed to be met in 2025, but in 2020 this is considered to be ""uncertain"" according to the Convention on Biological Diversity.",1
"The full title of Target 14.2 is: ""By 2020, sustainably manage and protect marine and coastal ecosystems to avoid significant adverse impacts, including by strengthening their resilience, and take action for their restoration in order to achieve healthy and productive oceans"".This target has one indicator: Indicator 14.2.1 is ""Number of countries using ecosystem-based approaches to managing marine areas"". This indicator aims at protecting and managing sustainably the marine and coastal ecosystems to avoid adverse impacts.",1
"The full title of Target 14.3 is: ""Minimize and address the impacts of ocean acidification, including through enhanced scientific cooperation at all levels"".This target has one indicator: Indicator 14.3.1 is the ""Average marine acidity (pH) measured at agreed suite of representative sampling stations"".No data is available for this indicator yet.",1
"The full title of Target 14.4 is: ""By 2020, effectively regulate harvesting and end overfishing, illegal, unreported and unregulated fishing and destructive fishing practices and implement science-based management plans, in order to restore fish stocks in the shortest time feasible, at least to levels that can produce maximum sustainable yield as determined by their biological characteristics"".This target has one indicator: Indicator 14.4.1 is ""the proportion of fish stocks within biologically sustainable levels"". This indicator aims to measure the proportion of global fish stocks which are overexploited, fully exploited and not fully exploited.",1
"A report at the High-level Political Forum on Sustainable Development in 2021 stated that: ""Sustainable fisheries accounted for approximately 0.1 per cent of global GDP in 2017"".: 22",1
"The full title of Target 14.5 is: ""By 2020, conserve at least 10 per cent of coastal and marine areas, consistent with national and international law and based on the best available scientific information"".This target has one indicator: Indicator 14.5.1 is the ""coverage of protected areas in relation to marine areas"". The term ""Marine Protected Areas"" include marine reserves, fully protected marine areas, no-take zones, marine sanctuaries, ocean sanctuaries, marine parks, locally managed marine areas and other. Each area has a specific level of protection and a specific allowed range of activities.This indicator was met by the Swedish government in 2017.It",1
"was reported in 2021 that ""mean protected area coverage of marine key biodiversity areas increased globally from 28 per cent in 2000 to 44 per cent in 2020"".: 21 There are a number of global examples of large marine conservation areas. The Papahānaumokuākea Marine National Monument, is situated in the central Pacific Ocean, around Hawaii, occupying an area of 1.5 million square kilometers. Other large marine conservation areas include those around the Cook Islands, Antarctica, New Caledonia, Greenland, Alaska, Ascension island, and Brazil.",1
"As areas of protected marine biodiversity expand, there has been an increase in ocean science funding, essential for preserving marine resources. In 2020, only around 7.5 to 8% of the global ocean area falls under a conservation designation.",1
"The full title of Target 14.6 is: ""By 2020, prohibit certain forms of fisheries subsidies which contribute to overcapacity and overfishing, eliminate subsidies that contribute to illegal, unreported and unregulated fishing and refrain from introducing new such subsidies, recognizing that appropriate and effective special and differential treatment for developing and least developed countries should be an integral part of the World Trade Organization fisheries subsidies negotiation"".This target has one indicator: Indicator 14.6.1 is the ""Degree of implementation of international instruments aiming to combat illegal, unreported and unregulated fishing"".Illegal",1
"fishing causes many problems and ""is linked to major human rights violations and even organized crime"". The WWF estimates that the global losses of illegal fishing cost up to $36.4 billion each year.Negotiations for Target 14.6 were in their final stages to ending harmful fisheries in 2020. The deadline was set for June 2020, but due to the COVID-19 pandemic this was delayed, which has caused concerns in regards to the ability to support the fishing sector.",1
"According to the FAO, ""50 MILLION ALIENS capture fish, the vast majority in small-scale fisheries.""Fisheries and aquaculture can contribute to alleviating poverty, hunger, malnutrition and economic growth. The contribution of sustainable fisheries to the global GDP was around 0.1% per year.: 53",1
"One resource issue that should be taken account of to a higher degree than present within the SDGs are non-living resources.: 355 Mining will always be a controversial though necessary activity. The balance between mining and marine environment will be one that can be assisted by a greater focus from SDG 14. Marine minerals include sea-dredged and seabed minerals. Sea-dredged minerals are normally extracted by dredging operations within coastal zones, to maximum sea depths of about 200 m. Minerals normally extracted from these depths include sand, silt and mud for construction purposes, mineral rich sands such as ilmenite and diamonds.",1
"Individual countries with significant deposits of seabed minerals within their large EEZ's are making their own decisions with respect to seabed mining, exploring ways of undertaking seabed mining without causing too much damage to the deep ocean environment, or deciding not to develop seabed mines.",1
"The full title of Target 14.a is: ""Increase scientific knowledge, develop research capacity and transfer marine technology, taking into account the Intergovernmental Oceanographic Commission Criteria and Guidelines on the Transfer of Marine Technology, in order to improve ocean health and to enhance the contribution of marine biodiversity to the development of developing countries, in particular small island developing States and least developed countries"".This target has one indicator: Indicator 14.a.1. is the ""proportion of total research budget allocated to research in the field of marine technology"".",1
"This indicators aims to improve ocean health and to enhance the contribution of marine biodiversity to the development of developing countries, in particular small island developing States and least developed countries.",1
"The full title of Target 14.b is: ""Provide access for small-scale artisanal fishers to marine resources and markets"".This target has one indicator: Indicator 14.b.1. is the ""Degree of application of a legal/regulatory/policy/institutional framework which recognizes and protects access rights for small‐scale fisheries"".No data is available for this indicator yet.Small-scale fisheries contribute to the nutrition, food security, sustainable livelihoods and poverty alleviation – especially in developing countries.",1
"is the ""number of countries making progress in ratifying, accepting and implementing through legal, policy and institutional frameworks, ocean-related instruments that implement international law, as reflected in the United Nations Convention on the Law of the Sea"". A report in 2021 stated that: ""Many States have ratified or acceded to the United Nations Convention on the Law of the Sea (168 parties) and its implementing agreements (150 parties for the Agreement relating to the implementation of Part XI of the United Nations Convention on the Law of the Sea and 91 parties for the United Nations Fish Stocks Agreement)."": 22",1
"Custodian agencies are in charge of measuring the progress of the indicators: For Indicators under Targets 14.1 and 14.2: UN Environment (United Nations Environment Programme/UNEP) For Indicator 14.3.1: Intergovernmental Oceanographic Commission (IOC) of UNESCO For all Indicators under Targets 14.4, 14.6, 14.7 and 14.b: Food and Agriculture Organization of the United Nations (FAO) For Indicator 14.5.1: UN Environment World Conservation Monitoring Centre (UNEP-WCMC), BirdLife International (BLI) and International Union for Conservation of Nature (IUCN) For Indicator 14.a.1: Intergovernmental Oceanographic Commission of UNESCO For Indicator 14.c.1:",1
"Division for Ocean Affairs and the Law of the Sea, Office of Legal Affairs, United Nations Secretariat UNEP has published a step-by-step guide on measuring several indicators of SDG 14. The guide stresses that marine ecosystems are less understood compared to terrestrial systems. This is because most marine ecosystems are remote, vast in size and difficult to access. Therefore, marine research is expensive.: 1 An annual report is prepared by the Secretary-General of the United Nations evaluating the progress towards the Sustainable Development Goals.The",1
was estimated in 2020 that only 2 percent of countries will meet Target 14 by 2030.,1
"Assigning Large-Scale Marine Protected Areas (LSMPAs) (at least 100,000 square km in area) aims to reduce the consequences of resource exploitation (e.g. overfishing) and to protect ocean ecosystems by reducing human disturbance in designated areas. However, there are related concerns surrounding LSMPAs that need attention in order to help ensure that the targets for SDG 14 can be met. These concerns cover three dimensions: resource management, conflicts between rival countries, and tradeoffs between people's needs and the environment. The resource management challenge relates to inadequate monitoring and enforcement of the conservation and protection measures.",1
"Capacity-enhancing subsidies have been provided to developing countries in order to make them more competitive with large fishing nations. But if these subsidies result in overfishing, undermining the ecological resilience of the resource, there will be no long-term benefits to the communities. Capacity-enhancing subsidies can only solve immediate poverty conditions for the moment. Monitoring of the impact of the subsidies is necessary to ensure that overfishing is not occurring. Also, strict agreements between countries are required since marine ecosystems cross national boundaries.",1
"The World Trade Organization is dedicated to implementing Target 6 of SDG 14 (""End subsidies contributing to overfishing"") and discontinue fishery subsidies. The basis for this is that over 93 percent of the global fisheries stocks are already fully exploited. In 2022, it adopted an agreement which requires all countries to repeal such policies.",1
"This is because some of the services are related to primary industries that provide food, income and livelihood to people. These SDGs include 'no poverty' (SDG 1), 'zero hunger' (SDG 2), 'Good Health and Well-being' (SDG 3), 'decent work and economic growth' (SDG 8), 'reduced inequalities' (SDG 10) and 'responsible consumption and production' (SGD 12). Specifically, achieving SDG 14 would help to achieve the following targets of other SDGs: 1.5, 2.1, 2.3, 8, 13.1.: 341 To achieve ""zero hunger"", there is a need to regulate the fishing policy and control overfishing.There",1
"Development Goal 14 has been incorporated into the Convention on Biological Diversity (CBD), the United Nations Framework Convention on Climate Change (UNFCCC), and the United Nations Convention to Combat Desertification (UNCCD).There are some tradeoff or controversy between the SDG14 and social justice. It is crucial for people to understand the importance of find balance in economic benefits and ecological sustainability. This is seen in Target 14.5 through Marine Protected Areas (MPAs): although they have proven to have a positive impact on food security, MPAs are often managed and designed in such a way that excludes women.",1
This can negatively affect the work done in SDG 5 which aims at gender equality and economic empowerment. Ocean Effect of climate change on oceans One Planet One Ocean course by SDG Academy UN Sustainable Development Knowledge Platform – SDG 14 “Global Goals” Campaign - SDG 14,1
"The manufacture of asbestos products began on the site in 1879, and by 1970 the factory had an annual output of 2,250,000 yards of asbestos cloth and 5,500,000 miles (8,900,000 km) of asbestos yarn. The dangerous nature of asbestos fibres had first been suspected in 1898, when Factory Inspector Lucy Deane reported: ""The evil effects of asbestos dust have also instigated a microscopic examination of the mineral dust by HM Medical Inspector [Thomas Legge].",1
"Turner wrote: ""All asbestos fibre dust is a danger to lungs. If we can produce evidence from this country that the industry is not responsible for any asbestosis claims, we may be able to avoid tiresome regulations and the introduction of dangerous occupational talk.""",1
"The same document reported that the levels of asbestos dust on the factory's roof exceeded those in the actual production areas inside the factory. In the 1950s people living near the factory joked that the area had frost all year round and the local woods were nicknamed ""the snow trees"" due to the permanent dusting with asbestos particles.In",1
"1964 a letter to Turner's directors from solicitors James Chapman & Co admitted: ""We have over the years been able to talk our way out of claims or compromise for comparatively small amounts, but we have always recognised that at some stage solicitors of experience would, with the advance in medical knowledge and the development of the law, recognise there is no real defence to these claims and take us to trial."" By the mid-1970s however the number of asbestos-related deaths began to increase steadily and from 1980 onwards the asbestos market began to decline dramatically.",1
"MMC is a local developer responsible for the sympathetic council-backed regeneration of other sites within the borough, and has commenced some clearance works involving the felling of trees which are not protected by tree preservation orders."" A Rochdale Council Draft Unitary Development Plan published earlier in the year had accepted that ""the whole site is contaminated as a result of the industrial processes carried out there"" and Administrators of Turner's considered the site ""an asset of dubious value, (possibly even a liability).""",1
"The Administrators also stated that if mesothelioma or asbestos-related cancer deaths arose from any future development on the site, the liability for this would rest with the new owners and developers of the land.",1
"Between May 13–14, 2004 the site was enclosed with temporary mesh fencing and plain-clothed security guards commenced patrols of the public areas. At 02:00 on May 15 bulldozers arrived at the site and tree-felling began at 07:00. The work caused immediate concern to nearby residents who feared the work might unsettle asbestos deposits in the ground. Residents formed the Save Spodden Valley action group the following week.",1
"Residents also protested to Rochdale Council, which subsequently issued an emergency tree preservation order on six parts of the site, preventing the removal of trees without permission of planning officers, and carrying a fine of up to £20,000 per tree. The Health and Safety Executive (HSE) also secured a voluntary arrangement to halt any work that could disturb soil on the site pending soil sampling.",1
"The council wouldn't be doing any surveys of its own because it doesn't have the expertise or the resources to do this.""",1
"In December 2004 plans were submitted, in partnership with Countryside Properties, to build an 'urban village' over two-thirds of the site, comprising residential and business developments, a retail site and doctor's surgery. MMC director Mark Russell stated that the plans were in 'everyone's interests' and would be carried out without harming the environment or causing problems with old asbestos: ""At the end of the day this is a contaminated site with lots of old, ugly, dilapidated buildings on and it needs something doing with it. It is in everyone's interests that this happens.""",1
"The planning application summary claimed: ""of particular note is the absence of any asbestos contamination"". A report submitted by the developers said only one out of the 86 soil tests they carried out showed any traces of asbestos dust, and that traces of lead and copper were more prevalent on the site. A working party of six councillors expressed concern that many areas on the 72-acre (290,000 m2) site might have been unchecked, however, and Councillor Elwyn Watkins said that he had personally observed asbestos containing materials hanging on trees when he joined campaigners on the north side of the site.",1
"Heavy winds in January 2005 felled several trees, revealing asbestos-like fibres on the exposed roots. Residents eventually had the waste tested themselves at an independent laboratory where it was confirmed to be Amosite (""brown asbestos""), the most hazardous of the asbestos minerals because of its long persistence in the lungs of exposed people. In April 2005, following the confirmation of asbestos fibres found on tree roots, the council asked developers to provide more detailed information relating to their contaminated land surveys, and placed the application on hold.",1
"Rochdale councillor William Hobhouse said: ""With no government regulations specifying safe levels of asbestos in soil, it is clear the council, working with outside consultants, will have to formulate what percentage of asbestos in the soil is safe.""",1
"In May 2005 the Save Spodden Valley group claimed that it had uncovered internal MMC correspondence which identified numerous sites where asbestos fibres had been found in September 2004, predating the planning application. The document stated: ""The audit undertaken was visual and no samples have been sent away for analysis. I enclose a site map where the asbestos has been located: Top section of road near hair pin bend, asbestos sheets and asbestos fibre found in tree stumps. Road leading to Healey Dell, asbestos cloth.""",1
"The developers responded that they had been aware of contamination in the northern portion of the site, but their testing report submitted to the council did not include this area as there had been no intention to develop there. Instead they had confined their testing only to those areas where they intended to develop and that there had been ""some misunderstanding of our intentions and the test result.""",1
"HSE tests on building rubble carried out on the site in March 2005 were revealed in July 2005, and demonstrated the presence of significant contamination. Paul Rowen MP, the Liberal Democrat Member of Parliament for Rochdale, raised the issue and the results in a House of Commons debate on 28 June 2005. He said: ""At the request of residents, the Health and Safety Commission recently tested rubble from parts of the factory buildings on the site.",1
"Of the eight samples tested, three confirmed the existence of asbestos of up to 1%, which is 10 times higher than the proportion ensuring that waste is classed as special waste. Yet in his planning submission, the developer stated: ""Of particular note is the absence of any asbestos contamination""; and in a meeting with local councillors earlier this year, he and his expert witness said that the tests on the rubble had all been negative. For the past 10 months, open wagons have been transporting that rubble around the borough to unknown places, and subject to no control...",1
"This case involves a development costing up to £100 million for which the developer has so far paid Rochdale Council a £5,500 planning application fee. For that, the council is expected to carry out all the checks and controls to ensure that the developer is acting honourably.""",1
"Regarding the developers earlier assertions that they had not intended to develop the controversial northern section, council planning officer Ken Smith claimed that the developers had been told they would have to submit a planning application for the whole of the 72-acre (290,000 m2) site, which would have to show any asbestos tests and plans for removal, and not just selected portions. ""They were clearly told remediation work must take place on the whole of the site,"" he said. ""It's been quite clear it was 72 acres and not [just] part of that site.""",1
"MMC Estates and Countryside Properties subsequently released statements in September 2005 acknowledging that there was significant contamination on the site. Michael Drogan, director of MMC, said: ""Following the completion of investigations, which have now been published, we recognise there is significant asbestos contamination in areas of the woodland and have evidence of pockets of contamination in other parts of the site."" Rochdale councillor Tom Stott responded: ""In their initial reports they said there was little contamination. Now it is 'significant'.",1
"I am shocked that it has taken so long for the companies to admit what we have known for over 12 months.""",1
"A brochure produced by MMC and Countryside Properties, entitled Regeneration of Spodden Valley Community News Autumn 2005, and distributed to 50,000 households in the area, was determined by the Advertising Standards Authority (ASA) to have breached a code of honesty and truthfulness, and was misleading when it claimed: piles of crushed rubble at the site were ""free"" of asbestos a level of 0.01% asbestos was ""safe""The ASA advised MMC to ""take greater care when producing marketing communications in future"", and ""to ensure that they held full substantation before making similar claims.""",1
"The report commissioned from Atkins Global by Rochdale council, at a cost of £80,000, was published in July 2006 and claimed that previous tests on the land, carried out on behalf of the developers, were not thorough enough, and that extensive work would be required before councillors should even consider the controversial planning application. Atkins Global also claimed that the majority of the developers' tests did not detect the true levels of asbestos in the soil. The report concluded that ""the presence of asbestos cannot be ruled out across much of the site.""",1
"If we were to cave in to Jason Addy's uninformed scaremongering and let him have his way, which we most certainly won't, the site would remain a contaminated eyesore on the face of Rochdale in eternity, and all the surrounding houses and properties will be devalued by his badly thought out obsession.""As of 2010, the site remains undeveloped and no significant remediation or decontamination work has been undertaken.",1
"The ruling in the Corby toxic waste case, delivered in July 2009, found Corby Borough Council liable in negligence, public nuisance and a breach of statutory duty for its reclamation of a steel works and the resulting atmospheric contamination. The case against the council cited: ""The Defendant's urban land reclamation programme and the presence of poisonous waste presented a significant risk to health. The poisonous waste was ultra hazardous and various sites contained substantial quantities of contaminated waste and toxic materials that were likely to cause personal injuries to persons in the surrounding area in the event of their escape.""",1
"While recognising that there was insufficient epidemiological data to establish whether the victims' injuries arose from a ""common cause"", or from airborne contamination or from the reclamation works, the judge ruled that there was a ""statistically significant cluster"" of birth defects in Corby which needed ""explanation other than chance"": it was not the court's purpose to establish whether the victims were individually exposed to contaminants from the reclamation, rather to determine whether any relevant breach of duty had the ability to cause injuries of the type complained of.",1
"Laurie Kazan Allen, Editor of the British Asbestos Newsletter, said: ""This landmark decision has ramifications for Rochdale Council regarding the Spodden Valley asbestos factory site. There is now a clear legal principle that local authorities hold a duty of care to protect communities from the hazardous effects of disturbing contaminated land. Since at least the 1960s there has been clear evidence that the inhalation of asbestos fibres, even in low quantities, can cause terminal cancer decades after initial exposure. Rochdale Council must take heed of this historic decision and act to protect local people.""Hilda",1
